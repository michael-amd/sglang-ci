==========================================
SGL Unit Test Log
==========================================
Test: test_custom_allreduce.TestCustomAllReduce
Image: rocm/sgl-dev:v0.5.6-rocm700-mi30x-20251207
Container: sgl-dev_v0.5.6-rocm700-mi30x-20251207
Hardware: mi30x
Machine: dell300x-pla-t12-38
Start time: 2025-12-07 11:03:27 CST
Test directory: /sgl-workspace/sglang/test/manual
Command: CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python3 -m unittest test_custom_allreduce.TestCustomAllReduce
==========================================

/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1204: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  process_info = ray._private.services.start_gcs_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-32_655567_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-32_655567_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-32_655567_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/utils.py:521: ResourceWarning: unclosed file <_io.TextIOWrapper name='/sys/fs/cgroup/cpu.max' mode='r' encoding='UTF-8'>
  max_file = open(cpu_max_file_name).read()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1247: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  process_info = ray._private.services.start_raylet(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-32_655567_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:03:33,727	INFO worker.py:1852 -- Started a local Ray instance.
[36m(eager_allreduce pid=480)[0m [2025-12-07 17:03:41] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(eager_allreduce pid=480)[0m [2025-12-07 17:03:56] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(eager_allreduce pid=476)[0m [2025-12-07 17:03:56] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 290 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1204: ResourceWarning: unclosed file <_io.TextIOWrapper name='/dev/null' mode='w' encoding='UTF-8'>
  process_info = ray._private.services.start_gcs_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-59_306245_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-59_306245_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-59_306245_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-03-59_306245_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:04:00,265	INFO worker.py:1852 -- Started a local Ray instance.
[36m(eager_allreduce pid=6417)[0m [2025-12-07 17:04:08] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(eager_allreduce pid=6419)[0m [2025-12-07 17:04:20] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(eager_allreduce pid=6421)[0m [2025-12-07 17:04:20] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 3x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 6237 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-22_733516_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-22_733516_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-22_733516_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-22_733516_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:04:23,595	INFO worker.py:1852 -- Started a local Ray instance.
[36m(eager_allreduce pid=12504)[0m [2025-12-07 17:04:32] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(eager_allreduce pid=12506)[0m [2025-12-07 17:04:44] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(eager_allreduce pid=12502)[0m [2025-12-07 17:04:44] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(eager_allreduce pid=12504)[0m [2025-12-07 17:04:44] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 5x across cluster][0m
[36m(eager_allreduce pid=12504)[0m [2025-12-07 17:04:44] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 12322 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-47_574266_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-47_574266_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-47_574266_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-04-47_574266_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:04:48,659	INFO worker.py:1852 -- Started a local Ray instance.
[36m(eager_allreduce pid=18719)[0m [2025-12-07 17:04:57] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(eager_allreduce pid=18721)[0m [2025-12-07 17:05:10] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(eager_allreduce pid=18722)[0m [2025-12-07 17:05:11] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 7x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 18539 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
./opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-15_395090_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-15_395090_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-15_395090_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-15_395090_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:05:16,385	INFO worker.py:1852 -- Started a local Ray instance.
[36m(graph_allreduce pid=25083)[0m [2025-12-07 17:05:24] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(graph_allreduce pid=25086)[0m [2025-12-07 17:05:35] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(graph_allreduce pid=25083)[0m [aiter] Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25083)[0m [2025-12-07 17:05:36] INFO custom_all_reduce.py:246: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25083)[0m [2025-12-07 17:05:35] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(graph_allreduce pid=25086)[0m [aiter] Registering 0 cuda graph addresses[32m [repeated 479x across cluster][0m
[36m(graph_allreduce pid=25086)[0m [2025-12-07 17:05:38] INFO custom_all_reduce.py:246: Registering 0 cuda graph addresses[32m [repeated 479x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 24900 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-40_114479_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-40_114479_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-40_114479_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-05-40_114479_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:05:41,106	INFO worker.py:1852 -- Started a local Ray instance.
[36m(graph_allreduce pid=31033)[0m [2025-12-07 17:05:49] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(graph_allreduce pid=31028)[0m [2025-12-07 17:06:00] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(graph_allreduce pid=31028)[0m [aiter] Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31028)[0m [2025-12-07 17:06:01] INFO custom_all_reduce.py:246: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31036)[0m [2025-12-07 17:06:00] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=31038)[0m [aiter] Registering 0 cuda graph addresses[32m [repeated 947x across cluster][0m
[36m(graph_allreduce pid=31038)[0m [2025-12-07 17:06:03] INFO custom_all_reduce.py:246: Registering 0 cuda graph addresses[32m [repeated 947x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 30848 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-05_142214_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-05_142214_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-05_142214_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-05_142214_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:06:06,042	INFO worker.py:1852 -- Started a local Ray instance.
[36m(graph_allreduce pid=37111)[0m [2025-12-07 17:06:14] INFO pynccl.py:83: sglang is using nccl==2.26.6
[CI Test Method] TestCustomAllReduce.test_eager_allreduce
[36m(eager_allreduce pid=480)[0m [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[36m(eager_allreduce pid=480)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(eager_allreduce pid=480)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(eager_allreduce pid=476)[0m [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(eager_allreduce pid=476)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 2x across cluster][0m
[36m(eager_allreduce pid=476)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 4x across cluster][0m
[36m(eager_allreduce pid=6419)[0m [Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[36m(eager_allreduce pid=6419)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(eager_allreduce pid=6419)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(eager_allreduce pid=6425)[0m [Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3[32m [repeated 7x across cluster][0m
[36m(eager_allreduce pid=6425)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 6x across cluster][0m
[36m(eager_allreduce pid=6425)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 8x across cluster][0m
[36m(eager_allreduce pid=12512)[0m [Gloo] Rank 4 is connected to 5 peer ranks. Expected number of connected peer ranks is : 5
[36m(eager_allreduce pid=12506)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(eager_allreduce pid=12510)[0m [Gloo] Rank 3 is connected to 5 peer ranks. Expected number of connected peer ranks is : 5[32m [repeated 11x across cluster][0m
[36m(eager_allreduce pid=12506)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(eager_allreduce pid=12502)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 10x across cluster][0m
[36m(eager_allreduce pid=12510)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 12x across cluster][0m
[36m(eager_allreduce pid=18721)[0m [Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[36m(eager_allreduce pid=18721)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(eager_allreduce pid=18721)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(eager_allreduce pid=18722)[0m [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 15x across cluster][0m
[36m(eager_allreduce pid=18722)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 14x across cluster][0m
[36m(eager_allreduce pid=18719)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 16x across cluster][0m
[CI Test Method] TestCustomAllReduce.test_graph_allreduce
[36m(graph_allreduce pid=25083)[0m [Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[36m(graph_allreduce pid=25083)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(graph_allreduce pid=25083)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(graph_allreduce pid=25086)[0m [Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=25086)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 2x across cluster][0m
[36m(graph_allreduce pid=25086)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 4x across cluster][0m
[36m(graph_allreduce pid=31033)[0m [Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3
[36m(graph_allreduce pid=31028)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(graph_allreduce pid=31028)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(graph_allreduce pid=31038)[0m [Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=31036)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 6x across cluster][0m
[36m(graph_allreduce pid=31038)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 8x across cluster][0m
[36m(graph_allreduce pid=37113)[0m [Gloo] Rank 1 is connected to 5 peer ranks. Expected number of connected peer ranks is : 5
[36m(graph_allreduce pid=37113)[0m [2025-12-07 17:06:26] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(graph_allreduce pid=37117)[0m [2025-12-07 17:06:26] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(graph_allreduce pid=37117)[0m [aiter] Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37117)[0m [2025-12-07 17:06:27] INFO custom_all_reduce.py:246: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37119)[0m [2025-12-07 17:06:26] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37119)[0m [2025-12-07 17:06:26] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37119)[0m [aiter] Registering 0 cuda graph addresses[32m [repeated 1439x across cluster][0m
[36m(graph_allreduce pid=37119)[0m [2025-12-07 17:06:31] INFO custom_all_reduce.py:246: Registering 0 cuda graph addresses[32m [repeated 1439x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 36930 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-32_967543_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1414: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-32_967543_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1425: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-32_967543_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/opt/venv/lib/python3.10/site-packages/ray/_private/node.py:1469: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-07_17-06-32_967543_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-07 17:06:33,855	INFO worker.py:1852 -- Started a local Ray instance.
[36m(graph_allreduce pid=43336)[0m [2025-12-07 17:06:42] INFO pynccl.py:83: sglang is using nccl==2.26.6
[36m(graph_allreduce pid=43346)[0m [2025-12-07 17:06:55] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.
[36m(graph_allreduce pid=43338)[0m [aiter] Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43338)[0m [2025-12-07 17:06:57] INFO custom_all_reduce.py:246: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43340)[0m [2025-12-07 17:06:55] INFO custom_all_reduce.py:421: Using AiterCustomAllreduce for ROCm.[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=43346)[0m [aiter] Registering 0 cuda graph addresses[32m [repeated 1895x across cluster][0m
[36m(graph_allreduce pid=43346)[0m [2025-12-07 17:07:00] INFO custom_all_reduce.py:246: Registering 0 cuda graph addresses[32m [repeated 1895x across cluster][0m
/usr/lib/python3.10/subprocess.py:1072: ResourceWarning: subprocess 43156 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
.
----------------------------------------------------------------------
Ran 2 tests in 209.637s

OK
[36m(graph_allreduce pid=37113)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(graph_allreduce pid=37113)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(graph_allreduce pid=37114)[0m [Gloo] Rank 4 is connected to 5 peer ranks. Expected number of connected peer ranks is : 5[32m [repeated 11x across cluster][0m
[36m(graph_allreduce pid=37119)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 10x across cluster][0m
[36m(graph_allreduce pid=37111)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 12x across cluster][0m
[36m(graph_allreduce pid=43336)[0m [Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[36m(graph_allreduce pid=43346)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
[36m(graph_allreduce pid=43346)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
[36m(graph_allreduce pid=43339)[0m [Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7[32m [repeated 15x across cluster][0m
[36m(graph_allreduce pid=43339)[0m merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv[32m [repeated 14x across cluster][0m
[36m(graph_allreduce pid=43339)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[32m [repeated 16x across cluster][0m
sys:1: DeprecationWarning: builtin type swigvarlink has no __module__ attribute

==========================================
End time: 2025-12-07 11:07:03 CST
Exit code: 0
Result: PASSED
==========================================
