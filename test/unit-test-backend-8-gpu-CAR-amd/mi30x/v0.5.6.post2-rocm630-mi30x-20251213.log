==========================================
SGL Unit Test Log
==========================================
Test: test_custom_allreduce.TestCustomAllReduce
Image: rocm/sgl-dev:v0.5.6.post2-rocm630-mi30x-20251213
Container: sgl-dev_v0.5.6.post2-rocm630-mi30x-20251213
Hardware: mi30x
Machine: dell300x-pla-t10-23
Start time: 2025-12-13 10:08:55 CST
Test directory: /sgl-workspace/sglang/test/manual
Command: CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python3 -m unittest test_custom_allreduce.TestCustomAllReduce
==========================================

[2025-12-13 16:09:03] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/utils.py:505: ResourceWarning: unclosed file <_io.TextIOWrapper name='/sys/fs/cgroup/cpu.max' mode='r' encoding='utf-8'>
  max_file = open(cpu_max_file_name).read()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-03_334730_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:09:04,387	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=476)[0m [2025-12-13 16:09:13] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=476)[0m [2025-12-13 16:09:13] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(eager_allreduce pid=476)[0m [2025-12-13 16:09:15] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=472)[0m [2025-12-13 16:09:13] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=472)[0m [2025-12-13 16:09:15] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 290 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-17_444280_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:09:18,415	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=6430)[0m [2025-12-13 16:09:26] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=6430)[0m [2025-12-13 16:09:27] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(eager_allreduce pid=6431)[0m [2025-12-13 16:09:28] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=6432)[0m [2025-12-13 16:09:26] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(eager_allreduce pid=6432)[0m [2025-12-13 16:09:28] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 3x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 6248 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-31_182475_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:09:32,147	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=12562)[0m [2025-12-13 16:09:40] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=12557)[0m [2025-12-13 16:09:42] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(eager_allreduce pid=12557)[0m [2025-12-13 16:09:43] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=12557)[0m [2025-12-13 16:09:43] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(eager_allreduce pid=12560)[0m [2025-12-13 16:09:41] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 5x across cluster][0m
[36m(eager_allreduce pid=12562)[0m [2025-12-13 16:09:43] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 5x across cluster][0m
[36m(eager_allreduce pid=12562)[0m [2025-12-13 16:09:43] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 12376 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-09-46_405670_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:09:47,367	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=18835)[0m [2025-12-13 16:09:56] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=18835)[0m [2025-12-13 16:09:57] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(eager_allreduce pid=18836)[0m [2025-12-13 16:09:59] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=18836)[0m [2025-12-13 16:09:56] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 7x across cluster][0m
[36m(eager_allreduce pid=18853)[0m [2025-12-13 16:09:59] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 7x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 18654 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
./usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-02_835353_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:10:03,919	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:12] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:13] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(graph_allreduce pid=25276)[0m [2025-12-13 16:10:14] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25276)[0m [2025-12-13 16:10:12] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:14] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25279)[0m [2025-12-13 16:10:58] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 25095 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-10-59_655417_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:11:00,627	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:09] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:09] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:11] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31236)[0m [2025-12-13 16:11:09] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31235)[0m [2025-12-13 16:11:10] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:11:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31239)[0m [2025-12-13 16:12:01] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 31056 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-12-03_424806_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:12:04,387	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=37352)[0m [2025-12-13 16:12:13] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:14] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(graph_allreduce pid=37353)[0m [2025-12-13 16:12:15] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:16] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37349)[0m [2025-12-13 16:12:13] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37352)[0m [2025-12-13 16:12:15] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37349)[0m [2025-12-13 16:12:16] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:12:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37350)[0m [2025-12-13 16:13:09] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 37166 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_16-13-11_281991_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 16:13:12,259	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=43637)[0m [2025-12-13 16:13:21] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:22] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(graph_allreduce pid=43637)[0m [2025-12-13 16:13:25] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43647)[0m [2025-12-13 16:13:21] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43647)[0m [2025-12-13 16:13:25] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:13:59] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:00] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:01] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:02] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:03] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:04] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:05] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:06] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43623)[0m [2025-12-13 16:14:18] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 43444 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
.
----------------------------------------------------------------------
Ran 2 tests in 317.077s

OK
[CI Test Method] TestCustomAllReduce.test_eager_allreduce
[CI Test Method] TestCustomAllReduce.test_graph_allreduce

==========================================
End time: 2025-12-13 10:14:26 CST
Exit code: 0
Result: PASSED
==========================================
