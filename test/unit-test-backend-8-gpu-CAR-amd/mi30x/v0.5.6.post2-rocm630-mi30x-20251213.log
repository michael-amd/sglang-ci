==========================================
SGL Unit Test Log
==========================================
Test: test_custom_allreduce.TestCustomAllReduce
Image: rocm/sgl-dev:v0.5.6.post2-rocm630-mi30x-20251213
Container: sgl-dev_v0.5.6.post2-rocm630-mi30x-20251213
Hardware: mi30x
Machine: dell300x-pla-t12-38
Start time: 2025-12-13 11:08:24 CST
Test directory: /sgl-workspace/sglang/test/manual
Command: CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python3 -m unittest test_custom_allreduce.TestCustomAllReduce
==========================================

[2025-12-13 17:08:32] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/utils.py:505: ResourceWarning: unclosed file <_io.TextIOWrapper name='/sys/fs/cgroup/cpu.max' mode='r' encoding='utf-8'>
  max_file = open(cpu_max_file_name).read()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-32_246350_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:08:33,333	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=472)[0m [2025-12-13 17:08:41] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=472)[0m [2025-12-13 17:08:42] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:08:43,318 E 354 384] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-08-32_246350_13 is over 95% full, available space: 57.2109 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(eager_allreduce pid=472)[0m [2025-12-13 17:08:44] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=470)[0m [2025-12-13 17:08:42] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=470)[0m [2025-12-13 17:08:43] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 290 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-08-46_354207_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:08:47,322	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=6416)[0m [2025-12-13 17:08:55] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=6418)[0m [2025-12-13 17:08:56] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:08:57,311 E 6301 6330] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-08-46_354207_13 is over 95% full, available space: 57.2093 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(eager_allreduce pid=6422)[0m [2025-12-13 17:08:57] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=6422)[0m [2025-12-13 17:08:55] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(eager_allreduce pid=6417)[0m [2025-12-13 17:08:57] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 3x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 6237 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-00_044098_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:09:01,022	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=12529)[0m [2025-12-13 17:09:09] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=12521)[0m [2025-12-13 17:09:10] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:09:11,011 E 12403 12433] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-00_044098_13 is over 95% full, available space: 57.2083 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(eager_allreduce pid=12521)[0m [2025-12-13 17:09:12] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=12520)[0m [2025-12-13 17:09:12] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(eager_allreduce pid=12525)[0m [2025-12-13 17:09:09] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 5x across cluster][0m
[36m(eager_allreduce pid=12525)[0m [2025-12-13 17:09:12] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 5x across cluster][0m
[36m(eager_allreduce pid=12529)[0m [2025-12-13 17:09:12] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 12339 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-14_943989_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:09:15,927	INFO worker.py:1821 -- Started a local Ray instance.
[36m(eager_allreduce pid=18780)[0m [2025-12-13 17:09:24] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(eager_allreduce pid=18782)[0m [2025-12-13 17:09:25] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:09:25,915 E 18662 18691] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-14_943989_13 is over 95% full, available space: 57.2072 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(eager_allreduce pid=18780)[0m [2025-12-13 17:09:28] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(eager_allreduce pid=18784)[0m [2025-12-13 17:09:25] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 7x across cluster][0m
[36m(eager_allreduce pid=18786)[0m [2025-12-13 17:09:28] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 7x across cluster][0m
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 18598 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
./usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-09-31_443693_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:09:32,437	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:40] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:41] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:09:42,424 E 25086 25115] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-31_443693_13 is over 95% full, available space: 57.2063 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=25206)[0m [2025-12-13 17:09:43] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25206)[0m [2025-12-13 17:09:41] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:43] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:09:52,427 E 25086 25115] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-31_443693_13 is over 95% full, available space: 57.2063 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:09:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:10:02,429 E 25086 25115] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-31_443693_13 is over 95% full, available space: 57.2062 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:07] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:08] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:09] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:10:12,431 E 25086 25115] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-31_443693_13 is over 95% full, available space: 57.2063 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:22] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:10:22,433 E 25086 25115] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-09-31_443693_13 is over 95% full, available space: 57.2062 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=25209)[0m [2025-12-13 17:10:23] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 25022 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-10-24_880466_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:10:25,833	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=31149)[0m [2025-12-13 17:10:34] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:35] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:10:35,826 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2052 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:36] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31153)[0m [2025-12-13 17:10:34] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:39] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:40] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:41] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31153)[0m [2025-12-13 17:10:36] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 3x across cluster][0m
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:45] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:10:45,829 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2052 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:10:55,833 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2052 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:10:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:05] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:11:05,836 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2052 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:10] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:11] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:12] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:13] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:14] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:15] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:11:15,840 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2051 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:15] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:16] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:17] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:18] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:19] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:20] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:25] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:11:25,843 E 31032 31062] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-10-24_880466_13 is over 95% full, available space: 57.2051 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:28] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=31148)[0m [2025-12-13 17:11:28] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 30968 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-11-30_140232_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:11:31,092	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=37291)[0m [2025-12-13 17:11:39] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:40] INFO pynccl.py:83: sglang is using nccl==2.21.5
[33m(raylet)[0m [2025-12-13 17:11:41,084 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2036 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37291)[0m [2025-12-13 17:11:42] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=37293)[0m [2025-12-13 17:11:42] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:42] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:43] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37289)[0m [2025-12-13 17:11:39] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:44] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:45] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:46] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37297)[0m [2025-12-13 17:11:42] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37295)[0m [2025-12-13 17:11:42] WARNING quick_all_reduce.py:126: Custom quick allreduce is disabled due to an unsupported world size: 6. Supported world sizes: [2, 4, 8].[32m [repeated 5x across cluster][0m
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:47] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:48] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:49] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:50] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:51] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:11:51,088 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2036 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:51] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:52] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:53] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:54] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:55] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:56] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:57] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:58] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:11:59] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:00] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:12:01,092 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2036 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:10] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:12:11,095 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2036 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:20] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:12:21,099 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2036 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:21] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:22] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:23] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:24] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:25] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:26] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:27] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:28] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:28] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:28] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:28] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:29] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:29] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:29] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:29] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:30] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:30] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:30] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:30] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:31] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:12:31,102 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2035 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:31] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:31] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:31] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:31] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:32] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:32] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:32] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:32] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:33] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:33] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:33] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:33] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:34] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:34] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:34] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:34] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:34] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:35] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:35] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:35] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:35] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:36] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:36] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:36] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:36] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:37] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:37] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:37] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:37] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:38] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:38] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:38] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:38] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:40] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:12:41,104 E 37171 37201] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-11-30_140232_13 is over 95% full, available space: 57.2031 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=37288)[0m [2025-12-13 17:12:42] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 37107 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/gcs_server.out' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1362: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/gcs_server.err' mode='a' encoding='utf-8'>
  self.start_gcs_server()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/monitor.out' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1367: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/monitor.err' mode='a' encoding='utf-8'>
  self.start_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1378: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/dashboard.err' mode='a' encoding='utf-8'>
  self.start_api_server(
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/raylet.out' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1420: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/raylet.err' mode='a' encoding='utf-8'>
  self.start_raylet(plasma_directory, object_store_memory)
ResourceWarning: Enable tracemalloc to get the object allocation traceback
/usr/local/lib/python3.12/dist-packages/ray/_private/node.py:1422: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2025-12-13_17-12-44_394351_13/logs/log_monitor.err' mode='a' encoding='utf-8'>
  self.start_log_monitor()
ResourceWarning: Enable tracemalloc to get the object allocation traceback
2025-12-13 17:12:45,358	INFO worker.py:1821 -- Started a local Ray instance.
[36m(graph_allreduce pid=43576)[0m [2025-12-13 17:12:53] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.
[33m(raylet)[0m [2025-12-13 17:12:55,354 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.2021 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:12:55] INFO pynccl.py:83: sglang is using nccl==2.21.5
[36m(graph_allreduce pid=43584)[0m [2025-12-13 17:12:58] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43584)[0m [2025-12-13 17:12:54] INFO config.py:54: PyTorch version 2.6.0a0+git8d4926e available.[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:00] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:01] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:02] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43576)[0m [2025-12-13 17:12:58] WARNING custom_all_reduce.py:424: Aiter custom all-reduce not available (optional dependency missing); falling back to sglang CustomAllreduce. Details: No module named 'aiter.dist.device_communicators'[32m [repeated 7x across cluster][0m
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:03] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:04] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:05] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:05,357 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.202 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:05] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:06] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:07] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:08] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:09] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:10] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:11] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:12] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:13] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:14] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:15] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:15,361 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.202 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:15] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:16] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:17] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:18] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:19] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:20] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:21] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:22] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:23] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:24] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:25] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:25,365 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.202 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:25] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:26] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:27] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:28] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:29] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:30] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:31] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:32] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:33] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:34] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:35,369 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.202 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:35] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:36] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:37] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:38] INFO common.py:2780: Registering 2 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:38] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:39] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:40] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:41] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:42] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:43] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:44] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:45] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:45,372 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.202 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:45] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:46] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:47] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:48] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:49] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:50] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:51] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:52] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:53] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:54] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:55] INFO common.py:2780: Registering 0 cuda graph addresses
[33m(raylet)[0m [2025-12-13 17:13:55,374 E 43452 43481] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-12-13_17-12-44_394351_13 is over 95% full, available space: 57.2016 GB; capacity: 1410.03 GB. Object creation will fail if spilling is required.
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:55] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:56] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:57] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:58] INFO common.py:2780: Registering 0 cuda graph addresses
[36m(graph_allreduce pid=43572)[0m [2025-12-13 17:13:58] INFO common.py:2780: Registering 0 cuda graph addresses
/usr/lib/python3.12/subprocess.py:1127: ResourceWarning: subprocess 43388 is still running
  _warn("subprocess %s is still running" % self.pid,
ResourceWarning: Enable tracemalloc to get the object allocation traceback
.
----------------------------------------------------------------------
Ran 2 tests in 328.372s

OK
[CI Test Method] TestCustomAllReduce.test_eager_allreduce
[CI Test Method] TestCustomAllReduce.test_graph_allreduce

==========================================
End time: 2025-12-13 11:14:05 CST
Exit code: 0
Result: PASSED
==========================================
