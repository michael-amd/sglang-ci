INFO 12-12 15:30:32 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:33] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:33] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:34] server_args=ServerArgs(model_path='/mnt/raid/models/huggingface/Qwen/Qwen3-30B-A3B-Thinking-2507', tokenizer_path='/mnt/raid/models/huggingface/Qwen/Qwen3-30B-A3B-Thinking-2507', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', rl_quant_profile=None, trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.7224999999999999, max_running_requests=128, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=130172, enable_dynamic_chunking=False, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=8, pp_size=1, pp_max_micro_batch_size=None, pp_async_batch_depth=0, stream_interval=1, stream_output=False, random_seed=162640571, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, mm_process_config={}, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='/mnt/raid/models/huggingface/Qwen/Qwen3-30B-A3B-Thinking-2507', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='aiter', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, fp8_gemm_runner_backend='auto', nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', enable_flashinfer_autotune=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_moe_a2a_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, dllm_algorithm=None, dllm_algorithm_config=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=512, cuda_graph_bs=[1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, enable_torch_compile_debug_mode=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_fused_qk_norm_rope=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, remote_instance_weight_loader_backend='nccl', remote_instance_weight_loader_support_transfer_engine=True, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, decrypted_config_file=None, decrypted_draft_config_file=None, mm_enable_dp_encoder=False, forward_hooks=None)
[2025-12-12 15:30:34] Using default HuggingFace chat template with detected content format: string
[2025-12-12 15:30:34] Detected the force reasoning pattern in chat template.
INFO 12-12 15:30:41 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:41 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
INFO 12-12 15:30:42 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:71: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:43] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:43] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:43] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:43] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:43 TP7] Process 13616 gpu_id 7 is running on CPUs: [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
[2025-12-12 15:30:43 TP7] Init torch distributed begin.
[2025-12-12 15:30:43 TP6] Process 13615 gpu_id 6 is running on CPUs: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]
[2025-12-12 15:30:43 TP6] Init torch distributed begin.
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[aiter] WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[2025-12-12 15:30:44] WARNING core.py:454: WARNING: NUMA balancing is enabled, which may cause errors. It is recommended to disable NUMA balancing by running "sudo sh -c 'echo 0 > /proc/sys/kernel/numa_balancing'" for more details: https://rocm.docs.amd.com/en/latest/how-to/system-optimization/mi300x.html#disable-numa-auto-balancing
[aiter] import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44] INFO core.py:477: import [module_aiter_enum] under /sgl-workspace/aiter/aiter/jit/module_aiter_enum.so
[2025-12-12 15:30:44 TP3] Process 13612 gpu_id 3 is running on CPUs: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]
[2025-12-12 15:30:44 TP0] Process 13609 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
[2025-12-12 15:30:44 TP4] Process 13613 gpu_id 4 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
[2025-12-12 15:30:44 TP2] Process 13611 gpu_id 2 is running on CPUs: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
[2025-12-12 15:30:44 TP1] Process 13610 gpu_id 1 is running on CPUs: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
[2025-12-12 15:30:44 TP5] Process 13614 gpu_id 5 is running on CPUs: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]
[2025-12-12 15:30:44 TP3] Init torch distributed begin.
[2025-12-12 15:30:44 TP0] Init torch distributed begin.
[2025-12-12 15:30:44 TP4] Init torch distributed begin.
[2025-12-12 15:30:44 TP2] Init torch distributed begin.
[2025-12-12 15:30:44 TP1] Init torch distributed begin.
[2025-12-12 15:30:44 TP5] Init torch distributed begin.
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-12-12 15:30:46 TP0] sglang is using nccl==2.26.6
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP1] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP2] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP4] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP3] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP0] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP6] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP1] Using AiterCustomAllreduce for ROCm.
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP7] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP2] Using AiterCustomAllreduce for ROCm.
[2025-12-12 15:30:53 TP4] Using AiterCustomAllreduce for ROCm.
[2025-12-12 15:30:53 TP3] Using AiterCustomAllreduce for ROCm.
[2025-12-12 15:30:53 TP0] Using AiterCustomAllreduce for ROCm.
[aiter] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP5] import [module_custom_all_reduce] under /sgl-workspace/aiter/aiter/jit/module_custom_all_reduce.so
[2025-12-12 15:30:53 TP6] Using AiterCustomAllreduce for ROCm.
[2025-12-12 15:30:53 TP7] Using AiterCustomAllreduce for ROCm.
[2025-12-12 15:30:53 TP5] Using AiterCustomAllreduce for ROCm.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-12-12 15:30:53 TP7] Init torch distributed ends. mem usage=3.23 GB
[2025-12-12 15:30:53 TP0] Init torch distributed ends. mem usage=2.95 GB
[2025-12-12 15:30:53 TP6] Init torch distributed ends. mem usage=3.24 GB
[2025-12-12 15:30:53 TP5] Init torch distributed ends. mem usage=3.22 GB
[2025-12-12 15:30:53 TP4] Init torch distributed ends. mem usage=3.31 GB
[2025-12-12 15:30:53 TP3] Init torch distributed ends. mem usage=3.36 GB
[2025-12-12 15:30:53 TP2] Init torch distributed ends. mem usage=3.37 GB
[2025-12-12 15:30:53 TP1] Init torch distributed ends. mem usage=3.37 GB
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.998081 13615 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.998106 13615 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:53.998128 13615 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:15982
I1212 15:30:53.998189 13615 transfer_engine.cpp:185] Auto-discovering topology...
W1212 15:30:53.998224 13615 topology.cpp:55] No RDMA devices found, check your device installation
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.998239 13616 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.998258 13616 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.998263 13615 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:53.998257 13613 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.998276 13616 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:15279
I1212 15:30:53.998281 13613 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:53.998287 13615 tcp_transport.cpp:299] TcpTransport: listen on port 15850
I1212 15:30:53.998303 13613 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:16656
I1212 15:30:53.998329 13616 transfer_engine.cpp:185] Auto-discovering topology...
I1212 15:30:53.998361 13613 transfer_engine.cpp:185] Auto-discovering topology...
W1212 15:30:53.998361 13616 topology.cpp:55] No RDMA devices found, check your device installation
W1212 15:30:53.998399 13613 topology.cpp:55] No RDMA devices found, check your device installation
I1212 15:30:53.998406 13616 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:53.998421 13616 tcp_transport.cpp:299] TcpTransport: listen on port 16254
I1212 15:30:53.998431 13613 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:53.998445 13613 tcp_transport.cpp:299] TcpTransport: listen on port 15810
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.998661 13614 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.998683 13614 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:53.998703 13614 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:15393
I1212 15:30:53.998762 13614 transfer_engine.cpp:185] Auto-discovering topology...
W1212 15:30:53.998790 13614 topology.cpp:55] No RDMA devices found, check your device installation
I1212 15:30:53.998826 13614 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:53.998840 13614 tcp_transport.cpp:299] TcpTransport: listen on port 16796
WARNING: Logging before InitGoogleLogging() is written to STDERR
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.999934 13609 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.999948 13612 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.999974 13609 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:53.999979 13612 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:53.999972 13611 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:53.999995 13611 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:53.999996 13609 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:16077
I1212 15:30:54.000006 13612 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:16819
I1212 15:30:54.000015 13611 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:16625
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1212 15:30:54.000039 13610 transfer_engine.cpp:486] Metrics reporting is disabled (set MC_TE_METRIC=1 to enable)
I1212 15:30:54.000061 13610 transfer_engine.cpp:91] Transfer Engine parseHostNameWithPort. server_name: 10.194.129.138 port: 12001
I1212 15:30:54.000061 13609 transfer_engine.cpp:185] Auto-discovering topology...
I1212 15:30:54.000065 13612 transfer_engine.cpp:185] Auto-discovering topology...
I1212 15:30:54.000067 13611 transfer_engine.cpp:185] Auto-discovering topology...
I1212 15:30:54.000082 13610 transfer_engine.cpp:146] Transfer Engine RPC using P2P handshake, listening on 10.194.129.138:15949
W1212 15:30:54.000098 13609 topology.cpp:55] No RDMA devices found, check your device installation
W1212 15:30:54.000098 13612 topology.cpp:55] No RDMA devices found, check your device installation
W1212 15:30:54.000099 13611 topology.cpp:55] No RDMA devices found, check your device installation
I1212 15:30:54.000138 13609 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:54.000138 13612 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:54.000139 13610 transfer_engine.cpp:185] Auto-discovering topology...
I1212 15:30:54.000141 13611 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:54.000156 13609 tcp_transport.cpp:299] TcpTransport: listen on port 16829
I1212 15:30:54.000159 13612 tcp_transport.cpp:299] TcpTransport: listen on port 15052
I1212 15:30:54.000170 13611 tcp_transport.cpp:299] TcpTransport: listen on port 15711
W1212 15:30:54.000173 13610 topology.cpp:55] No RDMA devices found, check your device installation
I1212 15:30:54.000208 13610 transfer_engine.cpp:200] Topology discovery complete. Found 0 HCAs.
I1212 15:30:54.000224 13610 tcp_transport.cpp:299] TcpTransport: listen on port 16388
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[2025-12-12 15:30:54 TP6] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP7] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP2] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP1] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP3] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP4] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP5] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP0] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-12 15:30:54 TP3] Load weight begin. avail mem=188.10 GB
[2025-12-12 15:30:54 TP7] Load weight begin. avail mem=188.23 GB
[2025-12-12 15:30:54 TP6] Load weight begin. avail mem=188.22 GB
[2025-12-12 15:30:54 TP2] Load weight begin. avail mem=188.09 GB
[2025-12-12 15:30:54 TP1] Load weight begin. avail mem=188.10 GB
[2025-12-12 15:30:54 TP5] Load weight begin. avail mem=188.24 GB
[2025-12-12 15:30:54 TP4] Load weight begin. avail mem=188.15 GB
[2025-12-12 15:30:54 TP0] Load weight begin. avail mem=188.51 GB
Loading safetensors checkpoint shards:   0% Completed | 0/16 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   6% Completed | 1/16 [00:02<00:40,  2.70s/it]
Loading safetensors checkpoint shards:  12% Completed | 2/16 [00:05<00:39,  2.79s/it]
Loading safetensors checkpoint shards:  19% Completed | 3/16 [00:08<00:36,  2.82s/it]
Loading safetensors checkpoint shards:  25% Completed | 4/16 [00:11<00:33,  2.82s/it]
Loading safetensors checkpoint shards:  31% Completed | 5/16 [00:13<00:29,  2.70s/it]
Loading safetensors checkpoint shards:  38% Completed | 6/16 [00:16<00:27,  2.72s/it]
Loading safetensors checkpoint shards:  44% Completed | 7/16 [00:18<00:22,  2.55s/it]
Loading safetensors checkpoint shards:  50% Completed | 8/16 [00:21<00:20,  2.58s/it]
Loading safetensors checkpoint shards:  56% Completed | 9/16 [00:24<00:19,  2.74s/it]
Loading safetensors checkpoint shards:  62% Completed | 10/16 [00:27<00:16,  2.77s/it]
Loading safetensors checkpoint shards:  69% Completed | 11/16 [00:29<00:13,  2.75s/it]
Loading safetensors checkpoint shards:  75% Completed | 12/16 [00:30<00:08,  2.06s/it]
Loading safetensors checkpoint shards:  81% Completed | 13/16 [00:32<00:06,  2.02s/it]
Loading safetensors checkpoint shards:  88% Completed | 14/16 [00:35<00:04,  2.24s/it]
Loading safetensors checkpoint shards:  94% Completed | 15/16 [00:37<00:02,  2.22s/it]
Loading safetensors checkpoint shards: 100% Completed | 16/16 [00:39<00:00,  2.25s/it]
Loading safetensors checkpoint shards: 100% Completed | 16/16 [00:39<00:00,  2.48s/it]

[2025-12-12 15:31:34 TP6] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.97 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP4] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.90 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP7] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.98 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP5] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.99 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP3] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.85 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP1] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.85 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP2] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=180.84 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP0] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=181.26 GB, mem usage=7.25 GB.
[2025-12-12 15:31:35 TP0] Using KV cache dtype: torch.bfloat16
[2025-12-12 15:31:35 TP2] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP4] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP2] Memory pool end. avail mem=51.86 GB
[2025-12-12 15:31:35 TP5] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP4] Memory pool end. avail mem=51.92 GB
[2025-12-12 15:31:35 TP5] Memory pool end. avail mem=52.00 GB
[2025-12-12 15:31:35 TP6] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP0] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP3] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP1] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP6] Memory pool end. avail mem=51.98 GB
[2025-12-12 15:31:35 TP0] Memory pool end. avail mem=52.28 GB
[2025-12-12 15:31:35 TP3] Memory pool end. avail mem=51.87 GB
[2025-12-12 15:31:35 TP1] Memory pool end. avail mem=51.86 GB
[2025-12-12 15:31:35 TP7] KV Cache is allocated. #tokens: 5620330, K size: 64.32 GB, V size: 64.32 GB
[2025-12-12 15:31:35 TP7] Memory pool end. avail mem=51.99 GB
[2025-12-12 15:31:37 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=51.28 GB
[2025-12-12 15:31:38 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=51.43 GB
[2025-12-12 15:31:38 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=51.41 GB
[2025-12-12 15:31:38 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=51.29 GB
[2025-12-12 15:31:38 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=51.34 GB
[2025-12-12 15:31:38 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=51.42 GB
[2025-12-12 15:31:38 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=51.70 GB
[2025-12-12 15:31:38 TP0] Capture cuda graph bs [1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128]
[2025-12-12 15:31:38 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=51.29 GB
  0%|          | 0/20 [00:00<?, ?it/s]Capturing batches (bs=128 avail_mem=51.47 GB):   0%|          | 0/20 [00:00<?, ?it/s][2025-12-12 15:31:47 TP5] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:47 TP5] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:48 TP4] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:48 TP4] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:49 TP6] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:49 TP6] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:50 TP2] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:50 TP2] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:52 TP3] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:52 TP3] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:53 TP7] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:53 TP7] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:55 TP0] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:55 TP0] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:56 TP1] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
[2025-12-12 15:31:56 TP1] Using MoE kernel config with down_moe=False. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=128,N=96,device_name=_down.json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
Capturing batches (bs=128 avail_mem=51.47 GB):   5%|         | 1/20 [00:17<05:41, 17.97s/it]Capturing batches (bs=120 avail_mem=50.83 GB):   5%|         | 1/20 [00:17<05:41, 17.97s/it]Capturing batches (bs=120 avail_mem=50.83 GB):  10%|         | 2/20 [00:18<02:16,  7.57s/it]Capturing batches (bs=112 avail_mem=50.82 GB):  10%|         | 2/20 [00:18<02:16,  7.57s/it]Capturing batches (bs=112 avail_mem=50.82 GB):  15%|        | 3/20 [00:18<01:11,  4.21s/it]Capturing batches (bs=104 avail_mem=50.82 GB):  15%|        | 3/20 [00:18<01:11,  4.21s/it]Capturing batches (bs=104 avail_mem=50.82 GB):  20%|        | 4/20 [00:18<00:42,  2.63s/it]Capturing batches (bs=96 avail_mem=50.82 GB):  20%|        | 4/20 [00:18<00:42,  2.63s/it] Capturing batches (bs=96 avail_mem=50.82 GB):  25%|       | 5/20 [00:18<00:26,  1.75s/it]Capturing batches (bs=88 avail_mem=50.82 GB):  25%|       | 5/20 [00:18<00:26,  1.75s/it]Capturing batches (bs=88 avail_mem=50.82 GB):  30%|       | 6/20 [00:19<00:17,  1.22s/it]Capturing batches (bs=80 avail_mem=50.82 GB):  30%|       | 6/20 [00:19<00:17,  1.22s/it]Capturing batches (bs=80 avail_mem=50.82 GB):  35%|      | 7/20 [00:19<00:11,  1.13it/s]Capturing batches (bs=72 avail_mem=50.82 GB):  35%|      | 7/20 [00:19<00:11,  1.13it/s]Capturing batches (bs=72 avail_mem=50.82 GB):  40%|      | 8/20 [00:19<00:07,  1.50it/s]Capturing batches (bs=64 avail_mem=50.82 GB):  40%|      | 8/20 [00:19<00:07,  1.50it/s]Capturing batches (bs=64 avail_mem=50.82 GB):  45%|     | 9/20 [00:19<00:05,  1.92it/s]Capturing batches (bs=56 avail_mem=50.82 GB):  45%|     | 9/20 [00:19<00:05,  1.92it/s]Capturing batches (bs=56 avail_mem=50.82 GB):  50%|     | 10/20 [00:19<00:04,  2.39it/s]Capturing batches (bs=48 avail_mem=50.82 GB):  50%|     | 10/20 [00:19<00:04,  2.39it/s]Capturing batches (bs=48 avail_mem=50.82 GB):  55%|    | 11/20 [00:20<00:03,  2.86it/s]Capturing batches (bs=40 avail_mem=50.82 GB):  55%|    | 11/20 [00:20<00:03,  2.86it/s]Capturing batches (bs=40 avail_mem=50.82 GB):  60%|    | 12/20 [00:20<00:02,  3.25it/s]Capturing batches (bs=32 avail_mem=50.82 GB):  60%|    | 12/20 [00:20<00:02,  3.25it/s]Capturing batches (bs=32 avail_mem=50.82 GB):  65%|   | 13/20 [00:20<00:02,  3.33it/s]Capturing batches (bs=24 avail_mem=50.81 GB):  65%|   | 13/20 [00:20<00:02,  3.33it/s]Capturing batches (bs=24 avail_mem=50.81 GB):  70%|   | 14/20 [00:20<00:01,  3.15it/s]Capturing batches (bs=16 avail_mem=50.81 GB):  70%|   | 14/20 [00:20<00:01,  3.15it/s]Capturing batches (bs=16 avail_mem=50.81 GB):  75%|  | 15/20 [00:21<00:01,  3.50it/s]Capturing batches (bs=12 avail_mem=50.81 GB):  75%|  | 15/20 [00:21<00:01,  3.50it/s]Capturing batches (bs=12 avail_mem=50.81 GB):  80%|  | 16/20 [00:21<00:01,  3.79it/s]Capturing batches (bs=8 avail_mem=50.81 GB):  80%|  | 16/20 [00:21<00:01,  3.79it/s] Capturing batches (bs=8 avail_mem=50.81 GB):  85%| | 17/20 [00:21<00:00,  3.99it/s]Capturing batches (bs=4 avail_mem=50.81 GB):  85%| | 17/20 [00:21<00:00,  3.99it/s]Capturing batches (bs=4 avail_mem=50.81 GB):  90%| | 18/20 [00:21<00:00,  4.16it/s]Capturing batches (bs=2 avail_mem=50.81 GB):  90%| | 18/20 [00:21<00:00,  4.16it/s]Capturing batches (bs=2 avail_mem=50.81 GB):  95%|| 19/20 [00:21<00:00,  4.19it/s]Capturing batches (bs=1 avail_mem=50.81 GB):  95%|| 19/20 [00:21<00:00,  4.19it/s]Capturing batches (bs=1 avail_mem=50.81 GB): 100%|| 20/20 [00:22<00:00,  3.53it/s]Capturing batches (bs=1 avail_mem=50.81 GB): 100%|| 20/20 [00:22<00:00,  1.12s/it]
[aiter] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP7] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP0] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP1] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP3] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP4] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP5] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP2] Registering 1940 cuda graph addresses
[aiter] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP6] Registering 1940 cuda graph addresses
[2025-12-12 15:32:01 TP5] Capture cuda graph end. Time elapsed: 23.33 s. mem usage=0.91 GB. avail mem=50.52 GB.
[2025-12-12 15:32:01 TP7] Capture cuda graph end. Time elapsed: 23.17 s. mem usage=0.91 GB. avail mem=50.51 GB.
[2025-12-12 15:32:01 TP0] Capture cuda graph end. Time elapsed: 23.11 s. mem usage=0.91 GB. avail mem=50.80 GB.
[2025-12-12 15:32:01 TP2] Capture cuda graph end. Time elapsed: 24.01 s. mem usage=0.91 GB. avail mem=50.38 GB.
[2025-12-12 15:32:01 TP6] Capture cuda graph end. Time elapsed: 23.29 s. mem usage=0.91 GB. avail mem=50.50 GB.
[2025-12-12 15:32:01 TP3] Capture cuda graph end. Time elapsed: 23.24 s. mem usage=0.91 GB. avail mem=50.39 GB.
[2025-12-12 15:32:01 TP1] Capture cuda graph end. Time elapsed: 23.06 s. mem usage=0.91 GB. avail mem=50.38 GB.
[2025-12-12 15:32:01 TP4] Capture cuda graph end. Time elapsed: 23.22 s. mem usage=0.91 GB. avail mem=50.44 GB.
[2025-12-12 15:32:01 TP0] max_total_num_tokens=5620330, chunked_prefill_size=130172, max_prefill_tokens=16384, max_running_requests=128, context_len=262144, available_gpu_mem=50.80 GB
[2025-12-12 15:32:02] INFO:     Started server process [13457]
[2025-12-12 15:32:02] INFO:     Waiting for application startup.
[2025-12-12 15:32:02] Using default chat sampling params from model generation config: {'repetition_penalty': 1.0, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[2025-12-12 15:32:02] Using default chat sampling params from model generation config: {'repetition_penalty': 1.0, 'temperature': 0.6, 'top_k': 20, 'top_p': 0.95}
[2025-12-12 15:32:02] INFO:     Application startup complete.
[2025-12-12 15:32:02] INFO:     Uvicorn running on http://127.0.0.1:30000 (Press CTRL+C to quit)
[2025-12-12 15:32:03] Endpoint '/get_model_info' is deprecated and will be removed in a future version. Please use '/model_info' instead.
[2025-12-12 15:32:03] INFO:     127.0.0.1:36214 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-12-12 15:32:03 TP0] Prefill batch, #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[aiter] start build [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/build/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP6] start build [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/build/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP4] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP7] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP2] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP3] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP1] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP5] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[2025-12-12 15:32:03 TP0] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout
[aiter] [32mfinish build [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout], cost 40.7s [0m
[2025-12-12 15:32:44 TP6] [32mfinish build [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout], cost 40.7s [0m
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP6] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP6] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP4] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP7] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP4] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP7] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP2] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP3] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP2] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP3] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP1] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP1] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP5] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP5] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[aiter] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[2025-12-12 15:32:44 TP0] import [mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout] under /sgl-workspace/aiter/aiter/jit/mha_batch_prefill_bf16_nlogits_nbias_mask_nlse_ndropout.so
[aiter] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:44 TP0] type hints mismatch, override to --> mha_batch_prefill(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, cu_seqlens_q: torch.Tensor, kv_indptr: torch.Tensor, kv_page_indices: torch.Tensor, max_seqlen_q: int, max_seqlen_k: int, dropout_p: float, softmax_scale: float, logits_soft_cap: float, zero_tensors: bool, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> List[torch.Tensor]
[2025-12-12 15:32:46] INFO:     127.0.0.1:36226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:46] The server is fired up and ready to roll!
[2025-12-12 15:32:51] Endpoint '/get_model_info' is deprecated and will be removed in a future version. Please use '/model_info' instead.
[2025-12-12 15:32:51] INFO:     127.0.0.1:52720 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-12-12 15:32:51 TP0] Prefill batch, #new-seq: 1, #new-token: 789, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-12 15:32:52] INFO:     127.0.0.1:52736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:52 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-12 15:32:52 TP0] Prefill batch, #new-seq: 49, #new-token: 3098, #cached-token: 38661, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-12-12 15:32:52 TP0] Prefill batch, #new-seq: 78, #new-token: 4980, #cached-token: 61699, token usage: 0.00, #running-req: 50, #queue-req: 69, 
[2025-12-12 15:32:53 TP0] Decode batch, #running-req: 128, #token: 13025, token usage: 0.00, cuda graph: True, gen throughput (token/s): 79.52, #queue-req: 353, 
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 379, 
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 793, token usage: 0.00, #running-req: 127, #queue-req: 378, 
[2025-12-12 15:32:53] INFO:     127.0.0.1:52944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53] INFO:     127.0.0.1:53440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53] INFO:     127.0.0.1:52754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53] INFO:     127.0.0.1:52778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 2, #new-token: 72, #cached-token: 1586, token usage: 0.00, #running-req: 126, #queue-req: 401, 
[2025-12-12 15:32:53] INFO:     127.0.0.1:53378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 475, 
[2025-12-12 15:32:53] INFO:     127.0.0.1:53366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53] INFO:     127.0.0.1:53654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 2, #new-token: 73, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 517, 
[2025-12-12 15:32:53] INFO:     127.0.0.1:53620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:53 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 567, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:52744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 2, #new-token: 100, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 632, 
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 678, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:53302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 793, token usage: 0.00, #running-req: 127, #queue-req: 735, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:53694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 822, 
[2025-12-12 15:32:54 TP0] Decode batch, #running-req: 128, #token: 17380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3934.54, #queue-req: 847, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:53158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 878, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:53024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 2, #new-token: 131, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 935, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:53048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 3, #new-token: 180, #cached-token: 2375, token usage: 0.00, #running-req: 125, #queue-req: 977, 
[2025-12-12 15:32:54] INFO:     127.0.0.1:52934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54] INFO:     127.0.0.1:53108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:54 TP0] Prefill batch, #new-seq: 2, #new-token: 149, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1044, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 3, #new-token: 216, #cached-token: 2373, token usage: 0.00, #running-req: 125, #queue-req: 1108, 
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 793, token usage: 0.00, #running-req: 127, #queue-req: 1153, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:53734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1165, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1164, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 2, #new-token: 127, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1162, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1161, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:53480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1160, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 2, #new-token: 103, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1158, 
[2025-12-12 15:32:55] INFO:     127.0.0.1:52792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55] INFO:     127.0.0.1:53610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 127, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1157, 
[2025-12-12 15:32:55 TP0] Prefill batch, #new-seq: 1, #new-token: 72, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1156, 
[2025-12-12 15:32:56 TP0] Decode batch, #running-req: 127, #token: 20532, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3338.09, #queue-req: 1156, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 85, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1155, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56] INFO:     127.0.0.1:53168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1154, 
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1153, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1152, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1151, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 87, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1150, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 117, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1149, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 135, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1148, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:53836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1147, 
[2025-12-12 15:32:56] INFO:     127.0.0.1:52826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56] INFO:     127.0.0.1:53078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:56 TP0] Prefill batch, #new-seq: 2, #new-token: 141, #cached-token: 1585, token usage: 0.00, #running-req: 126, #queue-req: 1145, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 1, #new-token: 100, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1144, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:53892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 112, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1142, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 1, #new-token: 95, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1141, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:53490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 87, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1139, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:53746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:53556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 145, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1137, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 172, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1135, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1134, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:52846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:52870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 158, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1132, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57] INFO:     127.0.0.1:53908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 2, #new-token: 112, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1130, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1129, 
[2025-12-12 15:32:57] INFO:     127.0.0.1:53216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:57 TP0] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1128, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:52926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1127, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1126, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58] INFO:     127.0.0.1:52822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 2, #new-token: 164, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1124, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:52898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58] INFO:     127.0.0.1:53358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 2, #new-token: 85, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1122, 
[2025-12-12 15:32:58 TP0] Decode batch, #running-req: 126, #token: 21905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2131.67, #queue-req: 1122, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1121, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:52810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58] INFO:     127.0.0.1:53540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 2, #new-token: 132, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1119, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1118, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1117, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1116, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:52798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58] INFO:     127.0.0.1:53204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58 TP0] Prefill batch, #new-seq: 2, #new-token: 157, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1114, 
[2025-12-12 15:32:58] INFO:     127.0.0.1:53320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:58] INFO:     127.0.0.1:53984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 147, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1112, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:52910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 142, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1110, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:54068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:54054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 141, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1108, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:54006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 105, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1106, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1105, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:52968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:53754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 123, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1103, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:54088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1102, 
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1101, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:53394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:53522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 2, #new-token: 92, #cached-token: 1585, token usage: 0.00, #running-req: 126, #queue-req: 1099, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:54018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59] INFO:     127.0.0.1:54112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 4, #new-token: 189, #cached-token: 3167, token usage: 0.00, #running-req: 124, #queue-req: 1095, 
[2025-12-12 15:32:59] INFO:     127.0.0.1:53602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:32:59 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1094, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:52806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00] INFO:     127.0.0.1:53962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1093, 
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1092, 
[2025-12-12 15:33:00 TP0] Decode batch, #running-req: 127, #token: 22642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2707.81, #queue-req: 1092, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:53906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 116, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1091, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:53226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1090, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:53876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 87, #cached-token: 793, token usage: 0.00, #running-req: 127, #queue-req: 1089, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:53160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1088, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:54040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00] INFO:     127.0.0.1:54150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 2, #new-token: 100, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1086, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:53002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 794, token usage: 0.00, #running-req: 127, #queue-req: 1085, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:54350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1084, 
[2025-12-12 15:33:00] INFO:     127.0.0.1:54158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:00 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1083, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:53530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1082, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:52868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:54080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:54304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:54482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:52766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 4, #new-token: 211, #cached-token: 3169, token usage: 0.00, #running-req: 124, #queue-req: 1078, 
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1077, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:54052 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:54098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1076, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 2, #new-token: 176, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 1074, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:54262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01] INFO:     127.0.0.1:54404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 2, #new-token: 126, #cached-token: 1585, token usage: 0.00, #running-req: 126, #queue-req: 1072, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:54280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1071, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:53978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1070, 
[2025-12-12 15:33:01] INFO:     127.0.0.1:54144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:01 TP0] Decode batch, #running-req: 128, #token: 25312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3041.00, #queue-req: 1070, 
[2025-12-12 15:33:01 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1069, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:54416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 794, token usage: 0.00, #running-req: 127, #queue-req: 1068, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:53930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02] INFO:     127.0.0.1:53724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02] INFO:     127.0.0.1:54500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 3, #new-token: 223, #cached-token: 2375, token usage: 0.00, #running-req: 125, #queue-req: 1065, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:52924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1064, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:54632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1063, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:54548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 794, token usage: 0.00, #running-req: 127, #queue-req: 1062, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:54652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1061, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:53472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1060, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:53954 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02] INFO:     127.0.0.1:54380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 2, #new-token: 128, #cached-token: 1586, token usage: 0.00, #running-req: 126, #queue-req: 1058, 
[2025-12-12 15:33:02] INFO:     127.0.0.1:54448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:02 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1057, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1056, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1055, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03] INFO:     127.0.0.1:54730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 2, #new-token: 116, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 1053, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:53022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1052, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1051, 
[2025-12-12 15:33:03 TP0] Decode batch, #running-req: 128, #token: 27837, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3143.26, #queue-req: 1051, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1050, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03] INFO:     127.0.0.1:54792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 2, #new-token: 96, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 1048, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 1047, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:53676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 1, #new-token: 101, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 1046, 
[2025-12-12 15:33:03] INFO:     127.0.0.1:54738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03] INFO:     127.0.0.1:54836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:03 TP0] Prefill batch, #new-seq: 2, #new-token: 102, #cached-token: 1586, token usage: 0.00, #running-req: 126, #queue-req: 1044, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:54782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04] INFO:     127.0.0.1:54208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1043, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:54596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 2, #new-token: 117, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 1041, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:53094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1040, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:54390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04] INFO:     127.0.0.1:54586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1039, 
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 93, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1038, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:53946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1037, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:54666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1036, 
[2025-12-12 15:33:04] INFO:     127.0.0.1:54610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:04 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1035, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:53120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 103, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1034, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:54746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1033, 
[2025-12-12 15:33:05 TP0] Decode batch, #running-req: 127, #token: 30383, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3088.53, #queue-req: 1033, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:54254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05] INFO:     127.0.0.1:54702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 2, #new-token: 78, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 1031, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:52952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1030, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:54602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1029, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:54036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05] INFO:     127.0.0.1:54934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 2, #new-token: 119, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 1027, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:53846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1026, 
[2025-12-12 15:33:05] INFO:     127.0.0.1:54288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05] INFO:     127.0.0.1:54862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1025, 
[2025-12-12 15:33:05 TP0] Prefill batch, #new-seq: 1, #new-token: 81, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 1024, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1023, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1022, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:53708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1021, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1020, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:55058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06] INFO:     127.0.0.1:55074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 2, #new-token: 144, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 1018, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:55172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1017, 
[2025-12-12 15:33:06 TP0] Decode batch, #running-req: 128, #token: 33269, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3415.34, #queue-req: 1017, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1016, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1015, 
[2025-12-12 15:33:06] INFO:     127.0.0.1:54178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:06 TP0] Prefill batch, #new-seq: 1, #new-token: 83, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1014, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1013, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1012, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:55186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1011, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07] INFO:     127.0.0.1:54598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 2, #new-token: 155, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 1009, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 1008, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:53088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07] INFO:     127.0.0.1:55124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07] INFO:     127.0.0.1:55248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 3, #new-token: 139, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 1005, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:55224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07] INFO:     127.0.0.1:55270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 1004, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 2, #new-token: 128, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 1002, 
[2025-12-12 15:33:07] INFO:     127.0.0.1:54806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07] INFO:     127.0.0.1:55044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:07 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 1001, 
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 1000, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:54030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 999, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:55136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Decode batch, #running-req: 128, #token: 35102, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3289.71, #queue-req: 999, 
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 998, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:54582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 997, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:55300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 996, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:54826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08] INFO:     127.0.0.1:54842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 2, #new-token: 144, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 994, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:54974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08] INFO:     127.0.0.1:54318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 2, #new-token: 151, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 992, 
[2025-12-12 15:33:08] INFO:     127.0.0.1:53144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:08 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 991, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:55164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 990, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 989, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 79, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 988, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09] INFO:     127.0.0.1:54698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 2, #new-token: 149, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 986, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09] INFO:     127.0.0.1:54984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 83, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 985, 
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 984, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09] INFO:     127.0.0.1:55398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 982, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:55326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09] INFO:     127.0.0.1:55440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 981, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 2, #new-token: 76, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 979, 
[2025-12-12 15:33:09] INFO:     127.0.0.1:54768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:09 TP0] Prefill batch, #new-seq: 1, #new-token: 122, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 978, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:54882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 977, 
[2025-12-12 15:33:10 TP0] Decode batch, #running-req: 128, #token: 35707, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2822.29, #queue-req: 977, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:54274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 73, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 976, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:54912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 975, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:54760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 974, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:54566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10] INFO:     127.0.0.1:55236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 2, #new-token: 120, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 972, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:55298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 971, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:55220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10] INFO:     127.0.0.1:54114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 969, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:55302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 968, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:55264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 967, 
[2025-12-12 15:33:10] INFO:     127.0.0.1:53062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:10 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 966, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:53682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 965, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:55534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11] INFO:     127.0.0.1:55556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 2, #new-token: 147, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 963, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 962, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:54928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11] INFO:     127.0.0.1:55316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 2, #new-token: 129, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 960, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:54478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 959, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:55416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 958, 
[2025-12-12 15:33:11 TP0] Decode batch, #running-req: 128, #token: 36816, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3185.44, #queue-req: 958, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:54346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 96, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 957, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:52808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:11 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 956, 
[2025-12-12 15:33:11] INFO:     127.0.0.1:55456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:55012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 2, #new-token: 128, #cached-token: 1588, token usage: 0.01, #running-req: 126, #queue-req: 954, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 953, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 952, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:55708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:53990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 3, #new-token: 204, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 949, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:54366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 948, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 86, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 947, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:54930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 946, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:55546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 2, #new-token: 110, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 944, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 943, 
[2025-12-12 15:33:12] INFO:     127.0.0.1:55308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:55640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12] INFO:     127.0.0.1:54998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:12 TP0] Prefill batch, #new-seq: 3, #new-token: 163, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 940, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:52804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:52838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Decode batch, #running-req: 128, #token: 23287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3703.25, #queue-req: 940, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:53426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 26, #new-token: 1403, #cached-token: 20583, token usage: 0.00, #running-req: 102, #queue-req: 914, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:53588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:53834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:55770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:55662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 1, #new-token: 95, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 913, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:55636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 912, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:54846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13] INFO:     127.0.0.1:55088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 2, #new-token: 178, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 910, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:55378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 1, #new-token: 108, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 909, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:55464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 908, 
[2025-12-12 15:33:13] INFO:     127.0.0.1:55516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:13 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 794, token usage: 0.00, #running-req: 127, #queue-req: 907, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14] INFO:     127.0.0.1:55526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 2, #new-token: 133, #cached-token: 1585, token usage: 0.00, #running-req: 126, #queue-req: 905, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 904, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 115, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 903, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 95, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 902, 
[2025-12-12 15:33:14 TP0] Decode batch, #running-req: 128, #token: 27868, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3849.25, #queue-req: 902, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 901, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14] INFO:     127.0.0.1:55760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 2, #new-token: 163, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 899, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14] INFO:     127.0.0.1:56304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 898, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 2, #new-token: 127, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 896, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 1, #new-token: 115, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 895, 
[2025-12-12 15:33:14] INFO:     127.0.0.1:55668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14] INFO:     127.0.0.1:55350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:14 TP0] Prefill batch, #new-seq: 2, #new-token: 132, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 893, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:53918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15] INFO:     127.0.0.1:55958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 2, #new-token: 176, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 891, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15] INFO:     127.0.0.1:55840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15] INFO:     127.0.0.1:55928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 3, #new-token: 195, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 888, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 887, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15] INFO:     127.0.0.1:56020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 2, #new-token: 137, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 885, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 884, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 883, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:55340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 882, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:56068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 881, 
[2025-12-12 15:33:15] INFO:     127.0.0.1:56276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15] INFO:     127.0.0.1:56134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:15 TP0] Prefill batch, #new-seq: 1, #new-token: 110, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 880, 
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 879, 
[2025-12-12 15:33:16 TP0] Decode batch, #running-req: 127, #token: 29504, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3004.64, #queue-req: 879, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:56114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 878, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:56228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 877, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:54016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16] INFO:     127.0.0.1:56204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 85, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 876, 
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 875, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:56212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 874, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:55660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 73, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 873, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:55788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 872, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:55906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 871, 
[2025-12-12 15:33:16] INFO:     127.0.0.1:56158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16] INFO:     127.0.0.1:56284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:16 TP0] Prefill batch, #new-seq: 2, #new-token: 132, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 869, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:56172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 868, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:56256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17] INFO:     127.0.0.1:56428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 867, 
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 866, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:54120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17] INFO:     127.0.0.1:56086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 2, #new-token: 83, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 864, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:54136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 75, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 863, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:55954 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 862, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:55784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 142, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 861, 
[2025-12-12 15:33:17 TP0] Decode batch, #running-req: 127, #token: 31496, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2996.42, #queue-req: 861, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:54200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17] INFO:     127.0.0.1:55750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 2, #new-token: 139, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 859, 
[2025-12-12 15:33:17] INFO:     127.0.0.1:56082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:17 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 858, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 857, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 856, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:54238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18] INFO:     127.0.0.1:56244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 2, #new-token: 111, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 854, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:54334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18] INFO:     127.0.0.1:55868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18] INFO:     127.0.0.1:55944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 3, #new-token: 178, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 851, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:55892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 850, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 849, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 848, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 847, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:56450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 846, 
[2025-12-12 15:33:18] INFO:     127.0.0.1:54396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:18 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 845, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:55842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 844, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:55972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 843, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:56542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 842, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:54466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:56590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:56624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 3, #new-token: 168, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 839, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:54486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:56318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 2, #new-token: 125, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 837, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:54512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:54514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:55028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:56226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Decode batch, #running-req: 128, #token: 28923, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2816.71, #queue-req: 837, 
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 4, #new-token: 232, #cached-token: 3165, token usage: 0.01, #running-req: 124, #queue-req: 833, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:54518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 832, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:55922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19] INFO:     127.0.0.1:56274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 2, #new-token: 102, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 830, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 829, 
[2025-12-12 15:33:19] INFO:     127.0.0.1:54562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:19 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 828, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:56188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20] INFO:     127.0.0.1:56618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 827, 
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 826, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:56048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 72, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 825, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:56492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20] INFO:     127.0.0.1:56506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20] INFO:     127.0.0.1:56634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 3, #new-token: 173, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 822, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:54640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 821, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:54660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 108, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 820, 
[2025-12-12 15:33:20] INFO:     127.0.0.1:55404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20] INFO:     127.0.0.1:56816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20] INFO:     127.0.0.1:56380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 2, #new-token: 127, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 818, 
[2025-12-12 15:33:20 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 817, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:54690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21] INFO:     127.0.0.1:56264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 2, #new-token: 118, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 815, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:56150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 96, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 814, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:54718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 813, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:56888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 812, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:56508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Decode batch, #running-req: 128, #token: 28378, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2841.77, #queue-req: 812, 
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 101, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 811, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:55508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21] INFO:     127.0.0.1:56906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 2, #new-token: 105, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 809, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:55424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 808, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:55776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 94, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 807, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:56706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 806, 
[2025-12-12 15:33:21] INFO:     127.0.0.1:56944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:21 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 805, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 804, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 803, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:54858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:55992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:56538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:56600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:56668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 4, #new-token: 292, #cached-token: 3168, token usage: 0.00, #running-req: 124, #queue-req: 799, 
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 798, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:57068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:57074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:57172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 3, #new-token: 134, #cached-token: 2374, token usage: 0.00, #running-req: 125, #queue-req: 795, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 2, #new-token: 123, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 793, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:57090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 2, #new-token: 168, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 791, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:57148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 790, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22 TP0] Prefill batch, #new-seq: 1, #new-token: 100, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 789, 
[2025-12-12 15:33:22] INFO:     127.0.0.1:56440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:22] INFO:     127.0.0.1:57114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Decode batch, #running-req: 128, #token: 29448, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3188.43, #queue-req: 789, 
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 2, #new-token: 101, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 787, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 786, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:54956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 785, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:55606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23] INFO:     127.0.0.1:56362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 2, #new-token: 74, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 783, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23] INFO:     127.0.0.1:57136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 2, #new-token: 103, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 781, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23] INFO:     127.0.0.1:57102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 779, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 1, #new-token: 73, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 778, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 777, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:57028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 776, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:56958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23] INFO:     127.0.0.1:57210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:23 TP0] Prefill batch, #new-seq: 2, #new-token: 79, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 774, 
[2025-12-12 15:33:23] INFO:     127.0.0.1:57160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 773, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:57014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 772, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:56652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 771, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:56486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24] INFO:     127.0.0.1:56518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 2, #new-token: 139, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 769, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:55102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 768, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:55112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24] INFO:     127.0.0.1:56802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24] INFO:     127.0.0.1:56992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 3, #new-token: 203, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 765, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:57218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 764, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:57104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24] INFO:     127.0.0.1:57350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 2, #new-token: 85, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 762, 
[2025-12-12 15:33:24 TP0] Decode batch, #running-req: 126, #token: 29906, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2727.41, #queue-req: 762, 
[2025-12-12 15:33:24] INFO:     127.0.0.1:57258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:24 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 761, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:55192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 760, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:57138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 759, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:56842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25] INFO:     127.0.0.1:57560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 2, #new-token: 89, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 757, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:56716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 81, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 756, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:55566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 755, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:57440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 754, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:57462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 753, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:57472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 752, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:57316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 94, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 751, 
[2025-12-12 15:33:25] INFO:     127.0.0.1:55250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25] INFO:     127.0.0.1:56950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:25 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 750, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:57486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 2, #new-token: 140, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 748, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:55876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 747, 
[2025-12-12 15:33:26 TP0] Decode batch, #running-req: 128, #token: 31593, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3409.00, #queue-req: 747, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:56820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26] INFO:     127.0.0.1:57120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26] INFO:     127.0.0.1:57226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 2, #new-token: 115, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 745, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:57576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 2, #new-token: 179, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 743, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:55318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 742, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:57364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 1, #new-token: 92, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 741, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:57620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 740, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:57756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:26 TP0] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 739, 
[2025-12-12 15:33:26] INFO:     127.0.0.1:55366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 3, #new-token: 170, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 736, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:55394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 2, #new-token: 113, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 734, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 1, #new-token: 72, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 733, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:56558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 2, #new-token: 156, #cached-token: 1589, token usage: 0.01, #running-req: 126, #queue-req: 731, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:57550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 2, #new-token: 136, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 729, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:57480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:57600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 2, #new-token: 206, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 727, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:55412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 726, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:56686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27] INFO:     127.0.0.1:56014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 2, #new-token: 79, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 724, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:56398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:27 TP0] Decode batch, #running-req: 128, #token: 32089, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3297.10, #queue-req: 724, 
[2025-12-12 15:33:27 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 723, 
[2025-12-12 15:33:27] INFO:     127.0.0.1:57518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 722, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:57702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 95, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 721, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:56614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28] INFO:     127.0.0.1:57100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 2, #new-token: 80, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 719, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:55472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 718, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:55490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28] INFO:     127.0.0.1:55496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 2, #new-token: 142, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 716, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:57718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28] INFO:     127.0.0.1:57764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 2, #new-token: 129, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 714, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:56940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 713, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:56930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28] INFO:     127.0.0.1:57932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 712, 
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 711, 
[2025-12-12 15:33:28] INFO:     127.0.0.1:57640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28] INFO:     127.0.0.1:57854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:28 TP0] Prefill batch, #new-seq: 2, #new-token: 138, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 709, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:57818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 708, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:56732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29] INFO:     127.0.0.1:57794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 2, #new-token: 153, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 706, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:57502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 705, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:57790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29] INFO:     127.0.0.1:55572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 2, #new-token: 132, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 703, 
[2025-12-12 15:33:29 TP0] Decode batch, #running-req: 128, #token: 33087, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3146.48, #queue-req: 703, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:56964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 702, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:55626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 701, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:55630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29] INFO:     127.0.0.1:57328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29] INFO:     127.0.0.1:57454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 3, #new-token: 174, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 698, 
[2025-12-12 15:33:29] INFO:     127.0.0.1:57742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29] INFO:     127.0.0.1:57822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:29 TP0] Prefill batch, #new-seq: 2, #new-token: 155, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 696, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:55642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 695, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:55650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 694, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:57780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 693, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:56790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 692, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:57700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30] INFO:     127.0.0.1:58026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 690, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:55712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 689, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:55728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30] INFO:     127.0.0.1:57546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 2, #new-token: 144, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 687, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:57534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 686, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:55742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 685, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:57498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 684, 
[2025-12-12 15:33:30] INFO:     127.0.0.1:57414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:30] INFO:     127.0.0.1:58124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 2, #new-token: 78, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 682, 
[2025-12-12 15:33:31 TP0] Decode batch, #running-req: 128, #token: 31906, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3121.10, #queue-req: 682, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:57360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31] INFO:     127.0.0.1:57584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31] INFO:     127.0.0.1:57890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 3, #new-token: 136, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 679, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:57866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 1, #new-token: 135, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 678, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:55816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 677, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:57942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 676, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:57396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 675, 
[2025-12-12 15:33:31] INFO:     127.0.0.1:58020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31] INFO:     127.0.0.1:58178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31] INFO:     127.0.0.1:58142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:31 TP0] Prefill batch, #new-seq: 2, #new-token: 99, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 673, 
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 672, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:57894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 671, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:58024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32] INFO:     127.0.0.1:58082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 2, #new-token: 141, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 669, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:57598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 97, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 668, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:58080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32] INFO:     127.0.0.1:58156 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 2, #new-token: 125, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 666, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:55932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32] INFO:     127.0.0.1:57308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 2, #new-token: 128, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 664, 
[2025-12-12 15:33:32 TP0] Decode batch, #running-req: 126, #token: 33164, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3558.53, #queue-req: 664, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:58076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 663, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:57878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 662, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:58244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32] INFO:     127.0.0.1:58068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 661, 
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 73, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 660, 
[2025-12-12 15:33:32] INFO:     127.0.0.1:58110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:32 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 659, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:58328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 658, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:56000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 93, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 657, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:57844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 656, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:56036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33] INFO:     127.0.0.1:57762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 2, #new-token: 115, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 654, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:58216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 653, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:58432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 652, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:57810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33] INFO:     127.0.0.1:58324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 2, #new-token: 89, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 650, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:58344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 649, 
[2025-12-12 15:33:33] INFO:     127.0.0.1:58172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33] INFO:     127.0.0.1:57274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33] INFO:     127.0.0.1:57906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:33 TP0] Prefill batch, #new-seq: 3, #new-token: 199, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 646, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:57290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 645, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:56588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:58414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 2, #new-token: 147, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 643, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:56152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:56222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:56232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:56340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:56344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 5, #new-token: 294, #cached-token: 3960, token usage: 0.01, #running-req: 123, #queue-req: 638, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 637, 
[2025-12-12 15:33:34 TP0] Decode batch, #running-req: 127, #token: 31473, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2748.54, #queue-req: 637, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:58404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 2, #new-token: 122, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 635, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 634, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 633, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34] INFO:     127.0.0.1:58180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 2, #new-token: 128, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 631, 
[2025-12-12 15:33:34] INFO:     127.0.0.1:58294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:34 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 630, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:58310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 629, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:56384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 628, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:58584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 627, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:58164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 94, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 626, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:57936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:58264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:56414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:57460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:58170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 5, #new-token: 343, #cached-token: 3961, token usage: 0.01, #running-req: 123, #queue-req: 621, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:58394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:58410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 83, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 620, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:58388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 2, #new-token: 115, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 618, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:57962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35] INFO:     127.0.0.1:58508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 2, #new-token: 191, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 616, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:56462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 615, 
[2025-12-12 15:33:35] INFO:     127.0.0.1:56466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:35 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 614, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:56482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 613, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 612, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Decode batch, #running-req: 128, #token: 31480, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2900.58, #queue-req: 612, 
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 611, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 610, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:56528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36] INFO:     127.0.0.1:58600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 609, 
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 608, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 92, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 607, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 606, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:56560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36] INFO:     127.0.0.1:56562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 2, #new-token: 101, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 604, 
[2025-12-12 15:33:36] INFO:     127.0.0.1:58522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:36 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 603, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:57952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37] INFO:     127.0.0.1:58226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 601, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 600, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:57198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 599, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:57510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 598, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:58838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 99, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 597, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:58252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 122, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 596, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:57474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 595, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:56646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 594, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:58506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 1, #new-token: 75, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 593, 
[2025-12-12 15:33:37] INFO:     127.0.0.1:57662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37] INFO:     127.0.0.1:58564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:37 TP0] Prefill batch, #new-seq: 2, #new-token: 132, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 591, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:56684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:58556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 2, #new-token: 131, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 589, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:58694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:58796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 587, 
[2025-12-12 15:33:38 TP0] Decode batch, #running-req: 126, #token: 30532, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2549.23, #queue-req: 587, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:56692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:58140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:58626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 3, #new-token: 168, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 584, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:57916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 583, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:58808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 582, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:56748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 79, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 581, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:58748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 580, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:56760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:57672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38] INFO:     127.0.0.1:58956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 3, #new-token: 165, #cached-token: 2380, token usage: 0.01, #running-req: 125, #queue-req: 577, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:58682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 576, 
[2025-12-12 15:33:38] INFO:     127.0.0.1:56834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:38 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 575, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:58568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:58870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:59004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 3, #new-token: 251, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 572, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:56814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 571, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:58718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 570, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:58354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 569, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:58802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 568, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:56872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:58714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 2, #new-token: 166, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 566, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:57976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 565, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:58418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:59182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 2, #new-token: 154, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 563, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:57922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:59090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Decode batch, #running-req: 128, #token: 29566, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2998.31, #queue-req: 563, 
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 2, #new-token: 139, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 561, 
[2025-12-12 15:33:39] INFO:     127.0.0.1:56896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39] INFO:     127.0.0.1:58850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:39 TP0] Prefill batch, #new-seq: 2, #new-token: 71, #cached-token: 1587, token usage: 0.01, #running-req: 126, #queue-req: 559, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:56918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 558, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:58664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 557, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:59190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 556, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:56908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:58380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:58528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 3, #new-token: 181, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 553, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:58732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:59040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 2, #new-token: 95, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 551, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:57590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:57580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 2, #new-token: 110, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 549, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:59060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:59148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 2, #new-token: 168, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 547, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:58760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:59074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 2, #new-token: 126, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 545, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:58396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:58784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40 TP0] Prefill batch, #new-seq: 2, #new-token: 77, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 543, 
[2025-12-12 15:33:40] INFO:     127.0.0.1:57042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:40] INFO:     127.0.0.1:57058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:59240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 3, #new-token: 239, #cached-token: 2377, token usage: 0.00, #running-req: 125, #queue-req: 540, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:59272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 539, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:58496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 1, #new-token: 113, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 538, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:58200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:58832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Decode batch, #running-req: 128, #token: 28174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3331.94, #queue-req: 538, 
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 2, #new-token: 89, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 536, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:57380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:59296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:59160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:59212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 4, #new-token: 279, #cached-token: 3166, token usage: 0.00, #running-req: 124, #queue-req: 532, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:58616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:58976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41] INFO:     127.0.0.1:59178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 2, #new-token: 111, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 530, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:57182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 2, #new-token: 160, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 528, 
[2025-12-12 15:33:41] INFO:     127.0.0.1:59022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:41 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 527, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:58776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 526, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:58638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42] INFO:     127.0.0.1:59158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42] INFO:     127.0.0.1:58820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 4, #new-token: 228, #cached-token: 3168, token usage: 0.00, #running-req: 124, #queue-req: 522, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:57244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42] INFO:     127.0.0.1:59294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 2, #new-token: 184, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 520, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:57496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 519, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:59046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 518, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:57332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 517, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:59422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 516, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:59310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 515, 
[2025-12-12 15:33:42 TP0] Decode batch, #running-req: 128, #token: 28714, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3435.94, #queue-req: 515, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:58856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 514, 
[2025-12-12 15:33:42] INFO:     127.0.0.1:58884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:42] INFO:     127.0.0.1:58908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 145, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 512, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 511, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 141, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 509, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 508, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 202, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 506, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:57410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:57418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:57432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:58690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 3, #new-token: 248, #cached-token: 2379, token usage: 0.00, #running-req: 125, #queue-req: 503, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 94, #cached-token: 1585, token usage: 0.00, #running-req: 126, #queue-req: 501, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 500, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:57484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 3, #new-token: 199, #cached-token: 2375, token usage: 0.00, #running-req: 125, #queue-req: 497, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 145, #cached-token: 1584, token usage: 0.00, #running-req: 126, #queue-req: 495, 
[2025-12-12 15:33:43] INFO:     127.0.0.1:59230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43] INFO:     127.0.0.1:59316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:43 TP0] Prefill batch, #new-seq: 2, #new-token: 124, #cached-token: 1582, token usage: 0.00, #running-req: 126, #queue-req: 493, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 492, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:58972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 87, #cached-token: 791, token usage: 0.00, #running-req: 127, #queue-req: 491, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 490, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:58538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 489, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 488, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Decode batch, #running-req: 127, #token: 28638, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2930.41, #queue-req: 488, 
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 487, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 486, 
[2025-12-12 15:33:44] INFO:     127.0.0.1:59596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44] INFO:     127.0.0.1:59736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44] INFO:     127.0.0.1:59806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:44 TP0] Prefill batch, #new-seq: 3, #new-token: 173, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 483, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:58826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45] INFO:     127.0.0.1:59858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 2, #new-token: 122, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 481, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:59704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 128, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 480, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:57636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 479, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:59652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 478, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:59636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 477, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:59566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 476, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:59790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 475, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:58890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45] INFO:     127.0.0.1:59606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 2, #new-token: 92, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 473, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:57688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 472, 
[2025-12-12 15:33:45] INFO:     127.0.0.1:57716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45] INFO:     127.0.0.1:59766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:45 TP0] Prefill batch, #new-seq: 2, #new-token: 96, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 470, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:59720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 469, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:57734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46] INFO:     127.0.0.1:60074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 2, #new-token: 97, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 467, 
[2025-12-12 15:33:46 TP0] Decode batch, #running-req: 128, #token: 29601, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3175.24, #queue-req: 467, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:58940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46] INFO:     127.0.0.1:59610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 2, #new-token: 95, #cached-token: 1588, token usage: 0.01, #running-req: 126, #queue-req: 465, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:58056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46] INFO:     127.0.0.1:59334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 2, #new-token: 151, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 463, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:59544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46] INFO:     127.0.0.1:59812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 462, 
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 461, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:59354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 460, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:59724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 459, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:59432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 458, 
[2025-12-12 15:33:46] INFO:     127.0.0.1:57838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:46] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 2, #new-token: 74, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 456, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:58918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 455, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:57862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47] INFO:     127.0.0.1:59520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 2, #new-token: 135, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 453, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:59870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 452, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:59910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 451, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:59682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 86, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 450, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:59028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 449, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:59662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 448, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:58550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 447, 
[2025-12-12 15:33:47] INFO:     127.0.0.1:60278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:47 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 446, 
[2025-12-12 15:33:48 TP0] Decode batch, #running-req: 128, #token: 30458, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2858.19, #queue-req: 446, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:60042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 445, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:57930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 2, #new-token: 78, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 443, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:59842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:60090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 2, #new-token: 178, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 441, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:59528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 440, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:59996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 439, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:57986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:58174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 4, #new-token: 283, #cached-token: 3168, token usage: 0.01, #running-req: 124, #queue-req: 435, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:58006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 3, #new-token: 165, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 432, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:60106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 431, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:59266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 2, #new-token: 87, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 429, 
[2025-12-12 15:33:48] INFO:     127.0.0.1:58040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48] INFO:     127.0.0.1:59782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:48 TP0] Prefill batch, #new-seq: 3, #new-token: 164, #cached-token: 2379, token usage: 0.00, #running-req: 125, #queue-req: 426, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:59684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49] INFO:     127.0.0.1:60262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.00, #running-req: 127, #queue-req: 425, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:60218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.00, #running-req: 126, #queue-req: 423, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:60522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 422, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:60142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 421, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:60116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 420, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:60394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 419, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:59584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 418, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:59818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49] INFO:     127.0.0.1:60266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Decode batch, #running-req: 127, #token: 28849, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2878.58, #queue-req: 418, 
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 2, #new-token: 135, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 416, 
[2025-12-12 15:33:49] INFO:     127.0.0.1:58150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:49 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 415, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 414, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:58460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50] INFO:     127.0.0.1:59580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50] INFO:     127.0.0.1:60374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 3, #new-token: 137, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 411, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:58604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 410, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:59382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 409, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 408, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50] INFO:     127.0.0.1:60306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 2, #new-token: 107, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 406, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 405, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 1, #new-token: 72, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 404, 
[2025-12-12 15:33:50] INFO:     127.0.0.1:60240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:50 TP0] Prefill batch, #new-seq: 2, #new-token: 147, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 402, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:60172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 401, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:60552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 400, 
[2025-12-12 15:33:51 TP0] Decode batch, #running-req: 128, #token: 30809, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3399.30, #queue-req: 400, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:59952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 83, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 399, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:58318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51] INFO:     127.0.0.1:60026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 2, #new-token: 119, #cached-token: 1587, token usage: 0.01, #running-req: 126, #queue-req: 397, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 396, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:60426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 75, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 395, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:59506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51] INFO:     127.0.0.1:60482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 2, #new-token: 180, #cached-token: 1590, token usage: 0.01, #running-req: 126, #queue-req: 393, 
[2025-12-12 15:33:51] INFO:     127.0.0.1:60698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:51 TP0] Prefill batch, #new-seq: 1, #new-token: 128, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 392, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:58368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 391, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:58384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52] INFO:     127.0.0.1:59402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 2, #new-token: 118, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 389, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52] INFO:     127.0.0.1:60748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 2, #new-token: 143, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 387, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52] INFO:     127.0.0.1:60670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 2, #new-token: 136, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 385, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 97, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 384, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 383, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 118, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 382, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52] INFO:     127.0.0.1:60236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 3, #new-token: 193, #cached-token: 2378, token usage: 0.01, #running-req: 125, #queue-req: 379, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:60458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 378, 
[2025-12-12 15:33:52] INFO:     127.0.0.1:58446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:52 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 377, 
[2025-12-12 15:33:53 TP0] Decode batch, #running-req: 128, #token: 30783, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2993.57, #queue-req: 377, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:58462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 121, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 375, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 374, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:59280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 97, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 372, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 371, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 1, #new-token: 86, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 370, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:59964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 86, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 368, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:58476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 367, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:59134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 172, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 365, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60338 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 98, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 363, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 2, #new-token: 108, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 361, 
[2025-12-12 15:33:53] INFO:     127.0.0.1:60506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53] INFO:     127.0.0.1:60946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:53 TP0] Prefill batch, #new-seq: 3, #new-token: 277, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 358, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 357, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 356, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 73, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 355, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:58672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54] INFO:     127.0.0.1:60190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 2, #new-token: 186, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 353, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 352, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 108, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 351, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 123, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 350, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54] INFO:     127.0.0.1:60626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 2, #new-token: 84, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 348, 
[2025-12-12 15:33:54] INFO:     127.0.0.1:60434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:54 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 347, 
[2025-12-12 15:33:55 TP0] Decode batch, #running-req: 128, #token: 31141, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2555.94, #queue-req: 347, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 346, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:58646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:60908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:60920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 3, #new-token: 139, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 343, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 1, #new-token: 88, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 342, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 341, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:60958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 2, #new-token: 85, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 339, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 338, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:60180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 337, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:58740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:59994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 2, #new-token: 107, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 335, 
[2025-12-12 15:33:55] INFO:     127.0.0.1:58756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:60990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55] INFO:     127.0.0.1:33068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:55 TP0] Prefill batch, #new-seq: 3, #new-token: 193, #cached-token: 2373, token usage: 0.01, #running-req: 125, #queue-req: 332, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:32810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 331, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:32952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 330, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:59924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 89, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 329, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:60346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 328, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:32958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 75, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 327, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:59390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 326, 
[2025-12-12 15:33:56 TP0] Decode batch, #running-req: 128, #token: 31831, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3124.26, #queue-req: 326, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:60708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 91, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 325, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:33078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 1, #new-token: 98, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 324, 
[2025-12-12 15:33:56] INFO:     127.0.0.1:58892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56] INFO:     127.0.0.1:60764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:56 TP0] Prefill batch, #new-seq: 2, #new-token: 113, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 322, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:33208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 321, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:58916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57] INFO:     127.0.0.1:58930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 2, #new-token: 135, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 319, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:60604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 107, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 318, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:58990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 83, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 317, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:59012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57] INFO:     127.0.0.1:60162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57] INFO:     127.0.0.1:60128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 3, #new-token: 178, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 314, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:60724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 313, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:32902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 312, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:33114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 311, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:60894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 110, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 310, 
[2025-12-12 15:33:57] INFO:     127.0.0.1:60254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:57 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 309, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:32892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 308, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:59106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 307, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:59116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58] INFO:     127.0.0.1:60462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 2, #new-token: 115, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 305, 
[2025-12-12 15:33:58 TP0] Decode batch, #running-req: 126, #token: 30696, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3048.56, #queue-req: 305, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:33314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 304, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:32862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58] INFO:     127.0.0.1:32780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 2, #new-token: 123, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 302, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:33256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 84, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 301, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:32768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 300, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:32928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 299, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:33158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 298, 
[2025-12-12 15:33:58] INFO:     127.0.0.1:32918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58] INFO:     127.0.0.1:32990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:58 TP0] Prefill batch, #new-seq: 2, #new-token: 141, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 296, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:59200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 295, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:33104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 294, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:32836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59] INFO:     127.0.0.1:33278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 2, #new-token: 111, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 292, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:59214 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59] INFO:     127.0.0.1:33142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 3, #new-token: 185, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 289, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:60930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 288, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:59250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 287, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:60594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 286, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:33054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 796, token usage: 0.01, #running-req: 127, #queue-req: 285, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:33276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 141, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 284, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:33248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:33:59 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 283, 
[2025-12-12 15:33:59] INFO:     127.0.0.1:59298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 282, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 104, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 281, 
[2025-12-12 15:34:00 TP0] Decode batch, #running-req: 128, #token: 31108, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2676.69, #queue-req: 281, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00] INFO:     127.0.0.1:60794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00] INFO:     127.0.0.1:33280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 2, #new-token: 164, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 279, 
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 278, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:32978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 277, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:33394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 121, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 276, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:33236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 275, 
[2025-12-12 15:34:00] INFO:     127.0.0.1:59434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00] INFO:     127.0.0.1:33300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:00 TP0] Prefill batch, #new-seq: 2, #new-token: 168, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 273, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:59444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 272, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:59450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:32886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:33420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:60294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 4, #new-token: 311, #cached-token: 3167, token usage: 0.01, #running-req: 124, #queue-req: 268, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:59478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 267, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:33144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:33456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 266, 
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 265, 
[2025-12-12 15:34:01 TP0] Decode batch, #running-req: 128, #token: 31698, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3832.54, #queue-req: 265, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:33326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:33478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 2, #new-token: 137, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 263, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:32800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 262, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:33682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 261, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:33020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01] INFO:     127.0.0.1:33184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 2, #new-token: 95, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 259, 
[2025-12-12 15:34:01] INFO:     127.0.0.1:33378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:01 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 258, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 257, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:33582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 256, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:33128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 255, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:33296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 254, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:59678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 253, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:32966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02] INFO:     127.0.0.1:33404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 2, #new-token: 104, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 251, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:59696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 2, #new-token: 136, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 249, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:60960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02] INFO:     127.0.0.1:33518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 2, #new-token: 192, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 247, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:32882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 246, 
[2025-12-12 15:34:02] INFO:     127.0.0.1:33218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:02 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 245, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:59714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 244, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:59718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 2, #new-token: 105, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 242, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:33324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 4, #new-token: 386, #cached-token: 3169, token usage: 0.01, #running-req: 124, #queue-req: 238, 
[2025-12-12 15:34:03 TP0] Decode batch, #running-req: 128, #token: 31261, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2758.76, #queue-req: 238, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:33032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 237, 
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 236, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:60974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 235, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:33322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 234, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:32942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 1, #new-token: 121, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 233, 
[2025-12-12 15:34:03] INFO:     127.0.0.1:59832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03] INFO:     127.0.0.1:33194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:03 TP0] Prefill batch, #new-seq: 2, #new-token: 104, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 231, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:60760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 230, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04] INFO:     127.0.0.1:33548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 2, #new-token: 130, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 228, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:33568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 78, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 227, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:33722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 226, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:33552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 225, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:33706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04] INFO:     127.0.0.1:33740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 224, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:33618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 2, #new-token: 175, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 222, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:59876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 221, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:59878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 220, 
[2025-12-12 15:34:04] INFO:     127.0.0.1:59888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:04 TP0] Prefill batch, #new-seq: 1, #new-token: 75, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 219, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 218, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 217, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:59940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 104, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 216, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Decode batch, #running-req: 127, #token: 29999, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2691.54, #queue-req: 216, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:59978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05] INFO:     127.0.0.1:33874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 3, #new-token: 164, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 213, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 212, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 211, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:60010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05] INFO:     127.0.0.1:60036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05] INFO:     127.0.0.1:33262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 3, #new-token: 143, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 208, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05] INFO:     127.0.0.1:33524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 2, #new-token: 96, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 206, 
[2025-12-12 15:34:05] INFO:     127.0.0.1:33434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 205, 
[2025-12-12 15:34:05 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 204, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06] INFO:     127.0.0.1:33858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06] INFO:     127.0.0.1:33872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 3, #new-token: 145, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 201, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:60438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 79, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 200, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 109, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 199, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 198, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 197, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 98, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 196, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:60200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06] INFO:     127.0.0.1:33958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06] INFO:     127.0.0.1:33916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 2, #new-token: 109, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 194, 
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 86, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 193, 
[2025-12-12 15:34:06] INFO:     127.0.0.1:33632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:06 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 192, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:60216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 191, 
[2025-12-12 15:34:07 TP0] Decode batch, #running-req: 127, #token: 29774, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2855.16, #queue-req: 191, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:34208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 190, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:33984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 189, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:33520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 188, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:34076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 187, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:33824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07] INFO:     127.0.0.1:33988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 2, #new-token: 131, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 185, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 184, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:60322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 183, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:60358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07] INFO:     127.0.0.1:33576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07] INFO:     127.0.0.1:33766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 3, #new-token: 203, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 180, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:34030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:07 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 179, 
[2025-12-12 15:34:07] INFO:     127.0.0.1:34232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:60386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 2, #new-token: 94, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 177, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:33970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 176, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:34048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 175, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:33714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 174, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:34444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 77, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 173, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:34034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:34244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:60442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 3, #new-token: 193, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 170, 
[2025-12-12 15:34:08 TP0] Decode batch, #running-req: 125, #token: 29719, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3145.02, #queue-req: 170, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:60502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:33840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:34396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 3, #new-token: 108, #cached-token: 2374, token usage: 0.01, #running-req: 125, #queue-req: 167, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:34362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 166, 
[2025-12-12 15:34:08] INFO:     127.0.0.1:34342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08] INFO:     127.0.0.1:34196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:08 TP0] Prefill batch, #new-seq: 1, #new-token: 71, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 165, 
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 164, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 163, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09] INFO:     127.0.0.1:34088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 2, #new-token: 125, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 161, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09] INFO:     127.0.0.1:34238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09] INFO:     127.0.0.1:34488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09] INFO:     127.0.0.1:34010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 3, #new-token: 215, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 158, 
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 157, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 156, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09] INFO:     127.0.0.1:34268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 155, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 2, #new-token: 134, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 153, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 121, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 152, 
[2025-12-12 15:34:09] INFO:     127.0.0.1:34330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:09 TP0] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 151, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:34406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 150, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:34460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10] INFO:     127.0.0.1:34404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 149, 
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 69, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 148, 
[2025-12-12 15:34:10 TP0] Decode batch, #running-req: 127, #token: 32384, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2960.45, #queue-req: 148, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:60602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 147, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:34304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 82, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 146, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:34060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10] INFO:     127.0.0.1:33628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 145, 
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 144, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:60632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 2, #new-token: 104, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 142, 
[2025-12-12 15:34:10] INFO:     127.0.0.1:34558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:10 TP0] Prefill batch, #new-seq: 1, #new-token: 150, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 141, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 140, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:60712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11] INFO:     127.0.0.1:34438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11] INFO:     127.0.0.1:34718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 3, #new-token: 158, #cached-token: 2379, token usage: 0.01, #running-req: 125, #queue-req: 137, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 136, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 116, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 135, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 134, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 133, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 132, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:33508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 2, #new-token: 91, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 130, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11] INFO:     127.0.0.1:34678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 2, #new-token: 147, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 128, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:34772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11 TP0] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 127, 
[2025-12-12 15:34:11] INFO:     127.0.0.1:60806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:11] INFO:     127.0.0.1:60814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12] INFO:     127.0.0.1:34732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 3, #new-token: 217, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 124, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:34494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 122, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 123, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:33994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12] INFO:     127.0.0.1:34520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12] INFO:     127.0.0.1:34744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 3, #new-token: 174, #cached-token: 2378, token usage: 0.01, #running-req: 125, #queue-req: 120, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:34552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 159, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 119, 
[2025-12-12 15:34:12 TP0] Decode batch, #running-req: 128, #token: 32404, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2551.50, #queue-req: 119, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:34996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 795, token usage: 0.01, #running-req: 127, #queue-req: 118, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:34852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 117, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:34648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 116, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:60848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 80, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 115, 
[2025-12-12 15:34:12] INFO:     127.0.0.1:33886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:12 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 114, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 1, #new-token: 68, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 113, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:33980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 112, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:33640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:34784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:34894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 3, #new-token: 269, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 109, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:34598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 2, #new-token: 103, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 107, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:60940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 106, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:34782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 2, #new-token: 112, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 104, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:34760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 2, #new-token: 209, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 102, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 101, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:34170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Decode batch, #running-req: 128, #token: 34281, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3501.08, #queue-req: 101, 
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 1, #new-token: 105, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 100, 
[2025-12-12 15:34:13] INFO:     127.0.0.1:60998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13] INFO:     127.0.0.1:33250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:13 TP0] Prefill batch, #new-seq: 2, #new-token: 115, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 98, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:34692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 97, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:34284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:34476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:34570 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 3, #new-token: 135, #cached-token: 2379, token usage: 0.01, #running-req: 125, #queue-req: 94, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 93, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 92, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:32826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:34258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 3, #new-token: 141, #cached-token: 2375, token usage: 0.01, #running-req: 125, #queue-req: 89, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 99, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 88, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 87, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:34998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 2, #new-token: 103, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 85, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:35006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14] INFO:     127.0.0.1:35072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 2, #new-token: 102, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 83, 
[2025-12-12 15:34:14] INFO:     127.0.0.1:32866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:14 TP0] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 82, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:34654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 81, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:32932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:35048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 2, #new-token: 125, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 79, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:35092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 78, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:35162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:35400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 2, #new-token: 139, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 76, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:34360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 75, 
[2025-12-12 15:34:15 TP0] Decode batch, #running-req: 127, #token: 31178, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2902.49, #queue-req: 75, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:33672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 74, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:33004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:35236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 2, #new-token: 178, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 72, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:34958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:35036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 2, #new-token: 162, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 70, 
[2025-12-12 15:34:15] INFO:     127.0.0.1:33034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:33040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15] INFO:     127.0.0.1:35076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:15 TP0] Prefill batch, #new-seq: 3, #new-token: 231, #cached-token: 2376, token usage: 0.01, #running-req: 125, #queue-req: 67, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:33092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16] INFO:     127.0.0.1:33100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 2, #new-token: 91, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 65, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 93, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 64, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 106, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 63, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34156 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 62, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16] INFO:     127.0.0.1:35222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 61, 
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 60, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 59, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16] INFO:     127.0.0.1:35302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 2, #new-token: 162, #cached-token: 1582, token usage: 0.01, #running-req: 126, #queue-req: 57, 
[2025-12-12 15:34:16] INFO:     127.0.0.1:34368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16] INFO:     127.0.0.1:35264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:16 TP0] Prefill batch, #new-seq: 3, #new-token: 312, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 54, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:34808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 100, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 53, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:34180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17] INFO:     127.0.0.1:34982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 2, #new-token: 94, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 51, 
[2025-12-12 15:34:17 TP0] Decode batch, #running-req: 128, #token: 30758, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3149.23, #queue-req: 51, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:33252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17] INFO:     127.0.0.1:35198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 2, #new-token: 102, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 49, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:35280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 48, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:34780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 47, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:35022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 46, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:35376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 45, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 44, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:34934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 74, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 43, 
[2025-12-12 15:34:17] INFO:     127.0.0.1:35466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:17 TP0] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 42, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:34100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 41, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:34148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 40, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:34872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18] INFO:     127.0.0.1:35108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 2, #new-token: 127, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 38, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:34350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 37, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:33358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 36, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:35146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18] INFO:     127.0.0.1:35594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18] INFO:     127.0.0.1:35618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 3, #new-token: 216, #cached-token: 2377, token usage: 0.01, #running-req: 125, #queue-req: 33, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:35500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 794, token usage: 0.01, #running-req: 127, #queue-req: 32, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:35340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18] INFO:     127.0.0.1:35390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 2, #new-token: 97, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 30, 
[2025-12-12 15:34:18 TP0] Decode batch, #running-req: 128, #token: 31169, token usage: 0.01, cuda graph: True, gen throughput (token/s): 2988.24, #queue-req: 30, 
[2025-12-12 15:34:18] INFO:     127.0.0.1:34272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18] INFO:     127.0.0.1:34962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:18 TP0] Prefill batch, #new-seq: 2, #new-token: 130, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 28, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:35484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 27, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:34628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 26, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:33410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19] INFO:     127.0.0.1:35298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 2, #new-token: 137, #cached-token: 1586, token usage: 0.01, #running-req: 126, #queue-req: 24, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:35350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 23, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:33446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19] INFO:     127.0.0.1:35196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 2, #new-token: 170, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 21, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19] INFO:     127.0.0.1:35128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 2, #new-token: 111, #cached-token: 1583, token usage: 0.01, #running-req: 126, #queue-req: 19, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:35078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 18, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:35694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 79, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 17, 
[2025-12-12 15:34:19] INFO:     127.0.0.1:35292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:19 TP0] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 16, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:33494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 15, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:34828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20] INFO:     127.0.0.1:34930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 2, #new-token: 121, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 13, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20] INFO:     127.0.0.1:35920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 2, #new-token: 181, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 11, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 10, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:33558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 9, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 72, #cached-token: 791, token usage: 0.01, #running-req: 127, #queue-req: 8, 
[2025-12-12 15:34:20 TP0] Decode batch, #running-req: 128, #token: 31001, token usage: 0.01, cuda graph: True, gen throughput (token/s): 3056.67, #queue-req: 8, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20] INFO:     127.0.0.1:35554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 2, #new-token: 125, #cached-token: 1584, token usage: 0.01, #running-req: 126, #queue-req: 6, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 793, token usage: 0.01, #running-req: 127, #queue-req: 5, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20] INFO:     127.0.0.1:35328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 2, #new-token: 95, #cached-token: 1585, token usage: 0.01, #running-req: 126, #queue-req: 3, 
[2025-12-12 15:34:20] INFO:     127.0.0.1:35720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:20 TP0] Prefill batch, #new-seq: 1, #new-token: 76, #cached-token: 792, token usage: 0.01, #running-req: 127, #queue-req: 2, 
[2025-12-12 15:34:21] INFO:     127.0.0.1:34624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21 TP0] Prefill batch, #new-seq: 2, #new-token: 81, #cached-token: 1587, token usage: 0.01, #running-req: 126, #queue-req: 0, 
[2025-12-12 15:34:21] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:34916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35214 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33710 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21 TP0] Decode batch, #running-req: 108, #token: 28409, token usage: 0.01, cuda graph: True, gen throughput (token/s): 5700.34, #queue-req: 0, 
[2025-12-12 15:34:21] INFO:     127.0.0.1:35766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:34970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:33914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:34844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21 TP0] Decode batch, #running-req: 80, #token: 23662, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8153.64, #queue-req: 0, 
[2025-12-12 15:34:21] INFO:     127.0.0.1:35054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:36086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:21] INFO:     127.0.0.1:35640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22 TP0] Decode batch, #running-req: 61, #token: 21041, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6787.55, #queue-req: 0, 
[2025-12-12 15:34:22] INFO:     127.0.0.1:36164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:35316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22 TP0] Decode batch, #running-req: 48, #token: 18742, token usage: 0.00, cuda graph: True, gen throughput (token/s): 5708.55, #queue-req: 0, 
[2025-12-12 15:34:22] INFO:     127.0.0.1:34468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:34510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:22] INFO:     127.0.0.1:36104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:35990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23 TP0] Decode batch, #running-req: 42, #token: 18226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4622.09, #queue-req: 0, 
[2025-12-12 15:34:23] INFO:     127.0.0.1:35744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:35682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23 TP0] Decode batch, #running-req: 36, #token: 16940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4470.40, #queue-req: 0, 
[2025-12-12 15:34:23] INFO:     127.0.0.1:36074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:36224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:34908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:35186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23 TP0] Decode batch, #running-req: 27, #token: 13387, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3462.92, #queue-req: 0, 
[2025-12-12 15:34:23] INFO:     127.0.0.1:34990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:35026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:23] INFO:     127.0.0.1:35066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24 TP0] Decode batch, #running-req: 21, #token: 10574, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2916.24, #queue-req: 0, 
[2025-12-12 15:34:24] INFO:     127.0.0.1:36180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24 TP0] Decode batch, #running-req: 20, #token: 10907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2332.04, #queue-req: 0, 
[2025-12-12 15:34:24] INFO:     127.0.0.1:36120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:36096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:36208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24 TP0] Decode batch, #running-req: 10, #token: 5372, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1944.35, #queue-req: 0, 
[2025-12-12 15:34:24] INFO:     127.0.0.1:35638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:24] INFO:     127.0.0.1:35756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25] INFO:     127.0.0.1:35830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25 TP0] Decode batch, #running-req: 8, #token: 4501, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1138.79, #queue-req: 0, 
[2025-12-12 15:34:25] INFO:     127.0.0.1:35904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25] INFO:     127.0.0.1:35970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25] INFO:     127.0.0.1:36014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25 TP0] Decode batch, #running-req: 4, #token: 2961, token usage: 0.00, cuda graph: True, gen throughput (token/s): 836.38, #queue-req: 0, 
[2025-12-12 15:34:25] INFO:     127.0.0.1:36136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25] INFO:     127.0.0.1:36162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25] INFO:     127.0.0.1:36228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:25 TP0] Decode batch, #running-req: 1, #token: 1342, token usage: 0.00, cuda graph: True, gen throughput (token/s): 462.27, #queue-req: 0, 
[2025-12-12 15:34:25] INFO:     127.0.0.1:36268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-12 15:34:26] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 8 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
