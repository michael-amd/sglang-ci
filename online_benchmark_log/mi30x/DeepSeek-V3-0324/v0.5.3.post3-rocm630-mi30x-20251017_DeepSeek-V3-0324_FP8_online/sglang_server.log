/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:30:45 __init__.py:179] Automatically detected platform rocm.
WARNING 10-18 01:30:45 rocm.py:34] `fork` method is not supported by ROCm. VLLM_WORKER_MULTIPROC_METHOD is overridden to `spawn` instead.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:30:47] server_args=ServerArgs(model_path='/mnt/raid/models/huggingface/deepseek-ai/DeepSeek-V3-0324', tokenizer_path='/mnt/raid/models/huggingface/deepseek-ai/DeepSeek-V3-0324', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, mem_fraction_static=0.9, max_running_requests=1024, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=16384, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', elastic_ep_backend=None, mooncake_ib_device=None, tp_size=8, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=404744280, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, crash_on_nan=False, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, enable_trace=False, oltp_traces_endpoint='localhost:4317', api_key=None, served_model_name='/mnt/raid/models/huggingface/deepseek-ai/DeepSeek-V3-0324', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='triton', max_lora_chunk_size=16, attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill='flashmla_prefill', nsa_decode='fa3', enable_beta_spec=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=512, cuda_graph_bs=[1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:30:48] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:02 __init__.py:179] Automatically detected platform rocm.
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:02 __init__.py:179] Automatically detected platform rocm.
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
INFO 10-18 01:31:03 __init__.py:179] Automatically detected platform rocm.
/usr/local/lib/python3.12/dist-packages/vllm/platforms/__init__.py:34: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml
INFO 10-18 01:31:04 __init__.py:179] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:31:04 TP0] Process 292 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
`torch_dtype` is deprecated! Use `dtype` instead!
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:31:04 TP0] Init torch distributed begin.
[2025-10-18 01:31:05 TP2] Process 294 gpu_id 2 is running on CPUs: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:31:05 TP5] Process 297 gpu_id 5 is running on CPUs: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]
`torch_dtype` is deprecated! Use `dtype` instead!
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:31:05 TP2] Init torch distributed begin.
[2025-10-18 01:31:05 TP5] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:31:05 TP4] Process 296 gpu_id 4 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
`torch_dtype` is deprecated! Use `dtype` instead!
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:60: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-18 01:31:06 TP1] Process 293 gpu_id 1 is running on CPUs: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:31:06 TP4] Init torch distributed begin.
[2025-10-18 01:31:06 TP7] Process 299 gpu_id 7 is running on CPUs: [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:31:06 TP3] Process 295 gpu_id 3 is running on CPUs: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:31:06 TP6] Process 298 gpu_id 6 is running on CPUs: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-10-18 01:31:06 TP1] Init torch distributed begin.
[2025-10-18 01:31:06 TP7] Init torch distributed begin.
[2025-10-18 01:31:06 TP3] Init torch distributed begin.
[2025-10-18 01:31:06 TP6] Init torch distributed begin.
[2025-10-18 01:31:06 TP0] sglang is using nccl==2.21.5
[2025-10-18 01:31:08 TP0] Init torch distributed ends. mem usage=3.63 GB
[2025-10-18 01:31:08 TP7] Init torch distributed ends. mem usage=3.92 GB
[2025-10-18 01:31:08 TP5] Init torch distributed ends. mem usage=3.91 GB
[2025-10-18 01:31:08 TP6] Init torch distributed ends. mem usage=3.93 GB
[2025-10-18 01:31:08 TP4] Init torch distributed ends. mem usage=3.99 GB
[2025-10-18 01:31:08 TP3] Init torch distributed ends. mem usage=4.04 GB
[2025-10-18 01:31:08 TP2] Init torch distributed ends. mem usage=4.05 GB
[2025-10-18 01:31:08 TP1] Init torch distributed ends. mem usage=4.05 GB
[2025-10-18 01:31:10 TP4] Load weight begin. avail mem=187.27 GB
[2025-10-18 01:31:10 TP2] Load weight begin. avail mem=187.21 GB
[2025-10-18 01:31:10 TP3] Load weight begin. avail mem=187.22 GB
[2025-10-18 01:31:10 TP7] Load weight begin. avail mem=187.34 GB
[2025-10-18 01:31:10 TP5] Load weight begin. avail mem=187.35 GB
[2025-10-18 01:31:10 TP6] Load weight begin. avail mem=187.33 GB
[2025-10-18 01:31:10 TP1] Load weight begin. avail mem=187.21 GB
[2025-10-18 01:31:10 TP0] Load weight begin. avail mem=187.63 GB
[2025-10-18 01:31:10 TP0] Detected fp8 checkpoint.
[2025-10-18 01:31:10 TP0] Only Deepseek V3/R1 on NV-platform with capability >= 80 can use shared experts fusion optimization. Shared experts fusion optimization is disabled.
Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   1% Completed | 1/163 [00:00<00:31,  5.08it/s]
Loading safetensors checkpoint shards:   1% Completed | 2/163 [00:00<00:25,  6.23it/s]
Loading safetensors checkpoint shards:   2% Completed | 3/163 [00:00<00:21,  7.31it/s]
Loading safetensors checkpoint shards:   2% Completed | 4/163 [00:00<00:20,  7.64it/s]
Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:00<00:24,  6.49it/s]
Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:00<00:16,  9.60it/s]
Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:01<00:36,  4.18it/s]
Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:01<00:22,  6.60it/s]
Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:02<00:19,  7.81it/s]
Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:02<00:14, 10.12it/s]
Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:02<00:12, 11.14it/s]
Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:02<00:13, 10.85it/s]
Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:02<00:11, 11.82it/s]
Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:02<00:13, 10.07it/s]
Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:03<00:13,  9.65it/s]
Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:04<00:23,  5.68it/s]
Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:04<00:16,  7.96it/s]
Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:04<00:23,  5.41it/s]
Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:04<00:18,  6.73it/s]
Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:05<00:15,  8.15it/s]
Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:05<00:12,  9.71it/s]
Loading safetensors checkpoint shards:  26% Completed | 43/163 [00:05<00:10, 10.92it/s]
Loading safetensors checkpoint shards:  28% Completed | 45/163 [00:05<00:09, 11.97it/s]
Loading safetensors checkpoint shards:  29% Completed | 48/163 [00:05<00:07, 14.82it/s]
Loading safetensors checkpoint shards:  31% Completed | 50/163 [00:05<00:07, 15.81it/s]
Loading safetensors checkpoint shards:  33% Completed | 53/163 [00:06<00:10, 10.63it/s]
Loading safetensors checkpoint shards:  34% Completed | 56/163 [00:06<00:08, 12.92it/s]
Loading safetensors checkpoint shards:  36% Completed | 58/163 [00:06<00:07, 13.77it/s]
Loading safetensors checkpoint shards:  37% Completed | 60/163 [00:06<00:06, 14.81it/s]
Loading safetensors checkpoint shards:  38% Completed | 62/163 [00:06<00:06, 15.89it/s]
Loading safetensors checkpoint shards:  40% Completed | 65/163 [00:06<00:07, 13.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 67/163 [00:07<00:14,  6.48it/s]
Loading safetensors checkpoint shards:  43% Completed | 70/163 [00:07<00:10,  8.62it/s]
Loading safetensors checkpoint shards:  44% Completed | 72/163 [00:07<00:09,  9.66it/s]
Loading safetensors checkpoint shards:  45% Completed | 74/163 [00:08<00:08, 10.00it/s]
Loading safetensors checkpoint shards:  47% Completed | 77/163 [00:08<00:06, 12.42it/s]
Loading safetensors checkpoint shards:  48% Completed | 79/163 [00:08<00:06, 12.31it/s]
Loading safetensors checkpoint shards:  50% Completed | 82/163 [00:08<00:05, 14.49it/s]
Loading safetensors checkpoint shards:  52% Completed | 84/163 [00:08<00:05, 13.33it/s]
Loading safetensors checkpoint shards:  53% Completed | 86/163 [00:08<00:05, 14.54it/s]
Loading safetensors checkpoint shards:  55% Completed | 89/163 [00:08<00:05, 14.50it/s]
Loading safetensors checkpoint shards:  56% Completed | 92/163 [00:09<00:04, 16.55it/s]
Loading safetensors checkpoint shards:  58% Completed | 94/163 [00:09<00:04, 17.12it/s]
Loading safetensors checkpoint shards:  59% Completed | 96/163 [00:09<00:04, 14.55it/s]
Loading safetensors checkpoint shards:  60% Completed | 98/163 [00:09<00:04, 14.92it/s]
Loading safetensors checkpoint shards:  61% Completed | 100/163 [00:09<00:04, 13.38it/s]
Loading safetensors checkpoint shards:  63% Completed | 103/163 [00:09<00:03, 15.56it/s]
Loading safetensors checkpoint shards:  64% Completed | 105/163 [00:10<00:09,  5.96it/s]
Loading safetensors checkpoint shards:  66% Completed | 108/163 [00:10<00:06,  7.93it/s]
Loading safetensors checkpoint shards:  67% Completed | 110/163 [00:11<00:05,  9.37it/s]
Loading safetensors checkpoint shards:  69% Completed | 112/163 [00:11<00:04, 10.39it/s]
Loading safetensors checkpoint shards:  70% Completed | 114/163 [00:11<00:04, 11.73it/s]
Loading safetensors checkpoint shards:  72% Completed | 117/163 [00:11<00:03, 14.03it/s]
Loading safetensors checkpoint shards:  74% Completed | 120/163 [00:11<00:03, 12.66it/s]
Loading safetensors checkpoint shards:  75% Completed | 122/163 [00:11<00:02, 13.89it/s]
Loading safetensors checkpoint shards:  77% Completed | 125/163 [00:11<00:02, 15.98it/s]
Loading safetensors checkpoint shards:  78% Completed | 127/163 [00:12<00:02, 16.12it/s]
Loading safetensors checkpoint shards:  80% Completed | 130/163 [00:12<00:01, 17.83it/s]
Loading safetensors checkpoint shards:  81% Completed | 132/163 [00:12<00:02, 12.22it/s]
Loading safetensors checkpoint shards:  83% Completed | 135/163 [00:12<00:02, 13.91it/s]
Loading safetensors checkpoint shards:  85% Completed | 138/163 [00:12<00:01, 15.78it/s]
Loading safetensors checkpoint shards:  86% Completed | 140/163 [00:12<00:01, 16.24it/s]
Loading safetensors checkpoint shards:  87% Completed | 142/163 [00:13<00:01, 14.53it/s]
Loading safetensors checkpoint shards:  89% Completed | 145/163 [00:13<00:01, 16.44it/s]
Loading safetensors checkpoint shards:  90% Completed | 147/163 [00:13<00:00, 16.90it/s]
Loading safetensors checkpoint shards:  91% Completed | 149/163 [00:13<00:00, 17.49it/s]
Loading safetensors checkpoint shards:  93% Completed | 151/163 [00:13<00:00, 13.01it/s]
Loading safetensors checkpoint shards:  94% Completed | 153/163 [00:14<00:01,  5.32it/s]
Loading safetensors checkpoint shards:  95% Completed | 155/163 [00:14<00:01,  6.63it/s]
Loading safetensors checkpoint shards:  96% Completed | 157/163 [00:14<00:00,  7.53it/s]
Loading safetensors checkpoint shards:  98% Completed | 160/163 [00:15<00:00,  9.96it/s]
Loading safetensors checkpoint shards:  99% Completed | 162/163 [00:15<00:00, 11.31it/s]
Loading safetensors checkpoint shards: 100% Completed | 163/163 [00:15<00:00, 10.68it/s]

[2025-10-18 01:31:53 TP4] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.70 GB, mem usage=79.56 GB.
[2025-10-18 01:31:53 TP5] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.79 GB, mem usage=79.56 GB.
[2025-10-18 01:31:54 TP6] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.77 GB, mem usage=79.56 GB.
[2025-10-18 01:31:55 TP3] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.65 GB, mem usage=79.56 GB.
[2025-10-18 01:31:55 TP7] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.78 GB, mem usage=79.56 GB.
[2025-10-18 01:31:57 TP2] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.64 GB, mem usage=79.56 GB.
[2025-10-18 01:31:58 TP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=107.65 GB, mem usage=79.56 GB.
[2025-10-18 01:31:59 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=108.06 GB, mem usage=79.56 GB.
[2025-10-18 01:31:59 TP0] Using KV cache dtype: torch.bfloat16
[2025-10-18 01:31:59 TP6] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP6] Memory pool end. avail mem=43.52 GB
[2025-10-18 01:31:59 TP1] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP7] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP1] Memory pool end. avail mem=43.40 GB
[2025-10-18 01:31:59 TP0] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP7] Memory pool end. avail mem=43.53 GB
[2025-10-18 01:31:59 TP0] Memory pool end. avail mem=43.81 GB
[2025-10-18 01:31:59 TP2] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP4] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP2] Memory pool end. avail mem=43.39 GB
[2025-10-18 01:31:59 TP4] Memory pool end. avail mem=43.45 GB
[2025-10-18 01:31:59 TP3] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP3] Memory pool end. avail mem=43.40 GB
[2025-10-18 01:31:59 TP5] KV Cache is allocated. #tokens: 971748, KV size: 63.60 GB
[2025-10-18 01:31:59 TP5] Memory pool end. avail mem=43.54 GB
[2025-10-18 01:32:00 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=43.19 GB
[2025-10-18 01:32:00 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=43.33 GB
[2025-10-18 01:32:01 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=43.61 GB
[2025-10-18 01:32:01 TP0] Capture cuda graph bs [1, 2, 4, 8, 12, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512]
[2025-10-18 01:32:02 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=43.33 GB
  0%|          | 0/52 [00:00<?, ?it/s]Capturing batches (bs=512 avail_mem=42.97 GB):   0%|          | 0/52 [00:00<?, ?it/s][2025-10-18 01:32:02 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=43.25 GB
[2025-10-18 01:32:02 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=43.19 GB
[2025-10-18 01:32:02 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=43.20 GB
[2025-10-18 01:32:02 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=43.32 GB
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:04 TP7] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:05 TP5] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:05 TP6] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:05 TP5] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:05 TP7] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:05 TP4] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:05 TP6] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:05 TP4] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:06 TP7] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:06 TP5] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:06 TP4] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:06 TP7] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:06 TP7] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:06 TP7] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:06 TP7] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:06 TP7] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:06 TP7] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:07 TP6] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP5] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP5] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP5] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP5] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP5] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:07 TP5] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP4] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP4] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP4] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP4] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP4] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:07 TP4] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP6] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP6] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP6] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP6] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:07 TP6] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:07 TP6] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:22 TP2] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:22 TP3] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:22 TP1] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[2025-10-18 01:32:22 TP0] type hints mismatch, override to --> dynamic_per_token_scaled_quant(out: torch.Tensor, input: torch.Tensor, scales: torch.Tensor, scale_ub: Optional[torch.Tensor] = None, shuffle_scale: bool = True) -> None
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:22 TP2] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:22 TP3] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:23 TP0] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:23 TP1] shape M:512, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:24 TP3] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:24 TP2] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:24 TP1] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[2025-10-18 01:32:24 TP0] type hints mismatch, override to --> rope_cached_positions_2c_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: torch.Tensor, arg4: torch.Tensor, arg5: torch.Tensor, arg6: torch.Tensor, arg7: int, arg8: bool, arg9: bool) -> None
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//mla/mla_dec_stage1_bf16_a16w16_subQ16_mqa16.co GetFunction: _ZN5aiter39mla_dec_stage1_bf16_a16w16_subQ16_mqa16E Success
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP3] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP3] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP3] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP3] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP3] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP1] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:24 TP3] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP1] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP1] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP1] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP1] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP2] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP2] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP2] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP2] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP2] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP0] shape M:512, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP0] shape M:512, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:24 TP1] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP0] shape M:512, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP0] shape M:512, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:24 TP0] shape M:512, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:24 TP2] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
[aiter] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:24 TP0] [fused_moe] using default for (512, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] hipModuleLoad: /sgl-workspace/aiter/hsa/gfx942//fmoe/fmoe_fp8_blockscale_g1u1_novs_subGU_256.co GetFunction: _ZN5aiter39fmoe_fp8_blockscale_g1u1_novs_subGU_256E Success
Capturing batches (bs=512 avail_mem=42.97 GB):   2%|         | 1/52 [00:23<19:38, 23.11s/it]Capturing batches (bs=496 avail_mem=42.31 GB):   2%|         | 1/52 [00:23<19:38, 23.11s/it][aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP4] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP5] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP3] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP1] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP7] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP2] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP0] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:25 TP6] [fused_moe] using default for (496, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=496 avail_mem=42.31 GB):   4%|         | 2/52 [00:24<08:23, 10.07s/it]Capturing batches (bs=480 avail_mem=42.30 GB):   4%|         | 2/52 [00:24<08:23, 10.07s/it][aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP6] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP3] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP2] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP4] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP5] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP0] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP7] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP1] [fused_moe] using default for (480, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=480 avail_mem=42.30 GB):   6%|         | 3/52 [00:24<04:37,  5.66s/it]Capturing batches (bs=464 avail_mem=42.29 GB):   6%|         | 3/52 [00:24<04:37,  5.66s/it][aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP2] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP5] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP3] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP0] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP4] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP7] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP1] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:26 TP6] [fused_moe] using default for (464, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=464 avail_mem=42.29 GB):   8%|         | 4/52 [00:24<02:52,  3.59s/it]Capturing batches (bs=448 avail_mem=42.29 GB):   8%|         | 4/52 [00:24<02:52,  3.59s/it][aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP6] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP5] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP7] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP0] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP2] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP1] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP3] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP4] [fused_moe] using default for (448, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=448 avail_mem=42.29 GB):  10%|         | 5/52 [00:25<01:54,  2.44s/it]Capturing batches (bs=432 avail_mem=42.28 GB):  10%|         | 5/52 [00:25<01:54,  2.44s/it][aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP1] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP2] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP3] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP6] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP5] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP0] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP7] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP4] [fused_moe] using default for (432, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=432 avail_mem=42.28 GB):  12%|        | 6/52 [00:25<01:20,  1.76s/it]Capturing batches (bs=416 avail_mem=42.28 GB):  12%|        | 6/52 [00:25<01:20,  1.76s/it][aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP1] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP2] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP6] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP4] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP0] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP7] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP3] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:27 TP5] [fused_moe] using default for (416, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=416 avail_mem=42.28 GB):  13%|        | 7/52 [00:26<00:59,  1.32s/it]Capturing batches (bs=400 avail_mem=42.27 GB):  13%|        | 7/52 [00:26<00:59,  1.32s/it][aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP3] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP7] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP5] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP6] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP1] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP2] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP0] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP4] [fused_moe] using default for (400, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=400 avail_mem=42.27 GB):  15%|        | 8/52 [00:26<00:45,  1.03s/it]Capturing batches (bs=384 avail_mem=42.27 GB):  15%|        | 8/52 [00:26<00:45,  1.03s/it][aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP4] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP1] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP3] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP6] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP2] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP0] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP5] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:28 TP7] [fused_moe] using default for (384, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=384 avail_mem=42.27 GB):  17%|        | 9/52 [00:26<00:34,  1.26it/s]Capturing batches (bs=368 avail_mem=42.27 GB):  17%|        | 9/52 [00:26<00:34,  1.26it/s][aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP1] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP3] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP2] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP0] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP6] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP5] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP7] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP4] [fused_moe] using default for (368, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=368 avail_mem=42.27 GB):  19%|        | 10/52 [00:27<00:28,  1.47it/s]Capturing batches (bs=352 avail_mem=42.26 GB):  19%|        | 10/52 [00:27<00:28,  1.47it/s][aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP2] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP1] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP3] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP4] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP6] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP5] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP7] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP0] [fused_moe] using default for (352, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=352 avail_mem=42.26 GB):  21%|        | 11/52 [00:27<00:24,  1.67it/s]Capturing batches (bs=336 avail_mem=42.26 GB):  21%|        | 11/52 [00:27<00:24,  1.67it/s][aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP2] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP1] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP0] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP3] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP4] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP6] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP7] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:29 TP5] [fused_moe] using default for (336, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=336 avail_mem=42.26 GB):  23%|       | 12/52 [00:28<00:21,  1.84it/s]Capturing batches (bs=320 avail_mem=42.25 GB):  23%|       | 12/52 [00:28<00:21,  1.84it/s][aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP4] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP5] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP1] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP3] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP6] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP2] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP7] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP0] [fused_moe] using default for (320, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=320 avail_mem=42.25 GB):  25%|       | 13/52 [00:28<00:17,  2.17it/s]Capturing batches (bs=304 avail_mem=42.25 GB):  25%|       | 13/52 [00:28<00:17,  2.17it/s][aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP6] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP5] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP4] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP2] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP3] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP0] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP1] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP7] [fused_moe] using default for (304, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=304 avail_mem=42.25 GB):  27%|       | 14/52 [00:28<00:17,  2.23it/s]Capturing batches (bs=288 avail_mem=42.24 GB):  27%|       | 14/52 [00:28<00:17,  2.23it/s][aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP1] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP3] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP4] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP5] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP6] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP2] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP0] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:30 TP7] [fused_moe] using default for (288, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=288 avail_mem=42.24 GB):  29%|       | 15/52 [00:29<00:14,  2.53it/s]Capturing batches (bs=272 avail_mem=42.24 GB):  29%|       | 15/52 [00:29<00:14,  2.53it/s][aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP1] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP3] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP2] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP0] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP5] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP6] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP4] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP7] [fused_moe] using default for (272, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=272 avail_mem=42.24 GB):  31%|       | 16/52 [00:29<00:14,  2.46it/s]Capturing batches (bs=256 avail_mem=42.24 GB):  31%|       | 16/52 [00:29<00:14,  2.46it/s][aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP6] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP6] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP4] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP4] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP5] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP5] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP3] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP3] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP2] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP2] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP1] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP1] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP7] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP7] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:31 TP0] shape M:256, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x128_16x16_16x16_8x32x1_8x32x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:31 TP0] [fused_moe] using default for (256, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=256 avail_mem=42.24 GB):  33%|      | 17/52 [00:29<00:14,  2.44it/s]Capturing batches (bs=248 avail_mem=42.23 GB):  33%|      | 17/52 [00:29<00:14,  2.44it/s][aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP7] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP6] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP1] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP5] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP4] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP0] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP2] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP3] [fused_moe] using default for (248, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=248 avail_mem=42.23 GB):  35%|      | 18/52 [00:30<00:14,  2.42it/s]Capturing batches (bs=240 avail_mem=42.22 GB):  35%|      | 18/52 [00:30<00:14,  2.42it/s][aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP3] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP2] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP1] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP4] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP5] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP6] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP7] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP0] [fused_moe] using default for (240, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=240 avail_mem=42.22 GB):  37%|      | 19/52 [00:30<00:13,  2.41it/s]Capturing batches (bs=232 avail_mem=42.22 GB):  37%|      | 19/52 [00:30<00:13,  2.41it/s][aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP5] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP6] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP4] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP7] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP1] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP2] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP3] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:32 TP0] [fused_moe] using default for (232, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=232 avail_mem=42.22 GB):  38%|      | 20/52 [00:31<00:13,  2.39it/s]Capturing batches (bs=224 avail_mem=42.21 GB):  38%|      | 20/52 [00:31<00:13,  2.39it/s][aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP7] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP4] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP6] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP5] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP1] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP2] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP0] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP3] [fused_moe] using default for (224, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=224 avail_mem=42.21 GB):  40%|      | 21/52 [00:31<00:12,  2.39it/s]Capturing batches (bs=216 avail_mem=42.21 GB):  40%|      | 21/52 [00:31<00:12,  2.39it/s][aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP6] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP5] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP4] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP2] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP1] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP0] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP3] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:33 TP7] [fused_moe] using default for (216, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=216 avail_mem=42.21 GB):  42%|     | 22/52 [00:32<00:12,  2.39it/s]Capturing batches (bs=208 avail_mem=42.20 GB):  42%|     | 22/52 [00:32<00:12,  2.39it/s][aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP4] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP1] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP3] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP5] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP6] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP7] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP2] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP0] [fused_moe] using default for (208, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=208 avail_mem=42.20 GB):  44%|     | 23/52 [00:32<00:10,  2.67it/s]Capturing batches (bs=200 avail_mem=42.20 GB):  44%|     | 23/52 [00:32<00:10,  2.67it/s][aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP6] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP0] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP4] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP3] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP5] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP7] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP1] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP2] [fused_moe] using default for (200, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=200 avail_mem=42.20 GB):  46%|     | 24/52 [00:32<00:10,  2.58it/s]Capturing batches (bs=192 avail_mem=42.20 GB):  46%|     | 24/52 [00:32<00:10,  2.58it/s][aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP4] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP1] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP3] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP6] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP5] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP2] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP0] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:34 TP7] [fused_moe] using default for (192, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=192 avail_mem=42.20 GB):  48%|     | 25/52 [00:32<00:09,  2.81it/s]Capturing batches (bs=184 avail_mem=42.19 GB):  48%|     | 25/52 [00:32<00:09,  2.81it/s][aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP4] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP1] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP3] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP5] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP2] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP6] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP7] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP0] [fused_moe] using default for (184, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=184 avail_mem=42.19 GB):  50%|     | 26/52 [00:33<00:08,  3.00it/s]Capturing batches (bs=176 avail_mem=42.19 GB):  50%|     | 26/52 [00:33<00:08,  3.00it/s][aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP1] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP2] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP4] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP6] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP3] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP5] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP7] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP0] [fused_moe] using default for (176, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=176 avail_mem=42.19 GB):  52%|    | 27/52 [00:33<00:07,  3.18it/s]Capturing batches (bs=168 avail_mem=42.19 GB):  52%|    | 27/52 [00:33<00:07,  3.18it/s][aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP4] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP5] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP0] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP6] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP3] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP1] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP2] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:35 TP7] [fused_moe] using default for (168, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=168 avail_mem=42.19 GB):  54%|    | 28/52 [00:33<00:08,  2.89it/s]Capturing batches (bs=160 avail_mem=42.18 GB):  54%|    | 28/52 [00:33<00:08,  2.89it/s][aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP4] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP1] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP3] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP2] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP6] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP5] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP0] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP7] [fused_moe] using default for (160, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=160 avail_mem=42.18 GB):  56%|    | 29/52 [00:34<00:07,  3.10it/s]Capturing batches (bs=152 avail_mem=42.18 GB):  56%|    | 29/52 [00:34<00:07,  3.10it/s][aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP7] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP4] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP5] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP6] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP0] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP3] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP2] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP1] [fused_moe] using default for (152, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=152 avail_mem=42.18 GB):  58%|    | 30/52 [00:34<00:07,  2.86it/s]Capturing batches (bs=144 avail_mem=42.17 GB):  58%|    | 30/52 [00:34<00:07,  2.86it/s][aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP4] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP1] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP2] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP3] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP6] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP5] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP0] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP7] [fused_moe] using default for (144, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=144 avail_mem=42.17 GB):  60%|    | 31/52 [00:34<00:06,  3.04it/s]Capturing batches (bs=136 avail_mem=42.17 GB):  60%|    | 31/52 [00:34<00:06,  3.04it/s][aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP4] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP1] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP5] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP2] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP3] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP6] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP0] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:36 TP7] [fused_moe] using default for (136, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=136 avail_mem=42.17 GB):  62%|   | 32/52 [00:35<00:06,  3.22it/s]Capturing batches (bs=128 avail_mem=42.17 GB):  62%|   | 32/52 [00:35<00:06,  3.22it/s][aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP4] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP1] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP3] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP5] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP6] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP2] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP0] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:37 TP7] shape M:128, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP4] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP1] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP3] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP5] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP6] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP2] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP0] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP7] [fused_moe] using default for (128, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=128 avail_mem=42.17 GB):  63%|   | 33/52 [00:35<00:05,  3.32it/s]Capturing batches (bs=120 avail_mem=42.16 GB):  63%|   | 33/52 [00:35<00:05,  3.32it/s][aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP1] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP2] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP6] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP3] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP7] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP5] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP4] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP0] [fused_moe] using default for (120, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=120 avail_mem=42.16 GB):  65%|   | 34/52 [00:35<00:06,  2.97it/s]Capturing batches (bs=112 avail_mem=42.16 GB):  65%|   | 34/52 [00:35<00:06,  2.97it/s][aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP4] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP3] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP1] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP2] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP5] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP6] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP0] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:37 TP7] [fused_moe] using default for (112, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=112 avail_mem=42.16 GB):  67%|   | 35/52 [00:36<00:05,  3.16it/s]Capturing batches (bs=104 avail_mem=42.16 GB):  67%|   | 35/52 [00:36<00:05,  3.16it/s][aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP1] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP3] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP0] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP4] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP5] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP2] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP7] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP6] [fused_moe] using default for (104, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=104 avail_mem=42.16 GB):  69%|   | 36/52 [00:36<00:05,  2.88it/s]Capturing batches (bs=96 avail_mem=42.15 GB):  69%|   | 36/52 [00:36<00:05,  2.88it/s] [aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP4] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP1] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP5] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP3] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP2] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP0] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP6] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:38 TP7] [fused_moe] using default for (96, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=96 avail_mem=42.15 GB):  71%|   | 37/52 [00:36<00:04,  3.08it/s]Capturing batches (bs=88 avail_mem=42.15 GB):  71%|   | 37/52 [00:36<00:04,  3.08it/s][aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP2] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP0] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP5] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP4] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP3] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP1] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP6] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP7] [fused_moe] using default for (88, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=88 avail_mem=42.15 GB):  73%|  | 38/52 [00:37<00:04,  2.82it/s]Capturing batches (bs=80 avail_mem=42.14 GB):  73%|  | 38/52 [00:37<00:04,  2.82it/s][aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP4] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP6] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP1] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP3] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP5] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP2] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP0] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP7] [fused_moe] using default for (80, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=80 avail_mem=42.14 GB):  75%|  | 39/52 [00:37<00:04,  3.01it/s]Capturing batches (bs=72 avail_mem=42.14 GB):  75%|  | 39/52 [00:37<00:04,  3.01it/s][aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP7] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP6] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP3] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP4] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP1] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP0] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP2] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:39 TP5] [fused_moe] using default for (72, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=72 avail_mem=42.14 GB):  77%|  | 40/52 [00:37<00:04,  2.78it/s]Capturing batches (bs=64 avail_mem=42.13 GB):  77%|  | 40/52 [00:37<00:04,  2.78it/s][aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP4] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP2] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP3] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP1] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:40 TP6] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP5] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP0] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:32:40 TP7] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP4] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP5] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP3] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP2] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP1] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP0] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP6] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP7] [fused_moe] using default for (64, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=64 avail_mem=42.13 GB):  79%|  | 41/52 [00:38<00:03,  3.00it/s]Capturing batches (bs=56 avail_mem=42.13 GB):  79%|  | 41/52 [00:38<00:03,  3.00it/s][aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP5] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP7] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP3] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP0] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP4] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP6] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP1] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP2] [fused_moe] using default for (56, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=56 avail_mem=42.13 GB):  81%|  | 42/52 [00:38<00:03,  2.78it/s]Capturing batches (bs=48 avail_mem=42.12 GB):  81%|  | 42/52 [00:38<00:03,  2.78it/s][aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP4] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP1] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP3] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP5] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP2] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP6] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP0] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:40 TP7] [fused_moe] using default for (48, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=48 avail_mem=42.12 GB):  83%| | 43/52 [00:38<00:02,  3.01it/s]Capturing batches (bs=40 avail_mem=42.12 GB):  83%| | 43/52 [00:38<00:02,  3.01it/s][aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP5] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP1] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP4] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP2] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP3] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP7] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP6] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP0] [fused_moe] using default for (40, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=40 avail_mem=42.12 GB):  85%| | 44/52 [00:39<00:02,  2.78it/s]Capturing batches (bs=32 avail_mem=42.12 GB):  85%| | 44/52 [00:39<00:02,  2.78it/s][aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP4] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP1] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP3] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP6] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP2] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP5] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP7] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:41 TP0] shape M:32, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP4] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP1] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP3] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP6] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP2] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP5] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP7] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP0] [fused_moe] using default for (32, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=32 avail_mem=42.12 GB):  87%| | 45/52 [00:39<00:02,  3.00it/s]Capturing batches (bs=24 avail_mem=42.11 GB):  87%| | 45/52 [00:39<00:02,  3.00it/s][aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP1] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP3] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP5] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP6] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP0] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP7] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP4] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:41 TP2] [fused_moe] using default for (24, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=24 avail_mem=42.11 GB):  88%| | 46/52 [00:40<00:02,  2.77it/s]Capturing batches (bs=16 avail_mem=42.11 GB):  88%| | 46/52 [00:40<00:02,  2.77it/s][aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP4] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP5] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP2] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP6] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP1] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP3] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP0] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:32:42 TP7] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP4] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP5] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP2] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP6] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP1] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP3] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP0] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP7] [fused_moe] using default for (16, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=16 avail_mem=42.11 GB):  90%| | 47/52 [00:40<00:01,  3.01it/s]Capturing batches (bs=12 avail_mem=42.10 GB):  90%| | 47/52 [00:40<00:01,  3.01it/s][aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP1] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP3] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP4] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP5] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP2] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP6] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP7] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP0] [fused_moe] using default for (12, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=12 avail_mem=42.10 GB):  92%|| 48/52 [00:40<00:01,  3.22it/s]Capturing batches (bs=8 avail_mem=42.10 GB):  92%|| 48/52 [00:40<00:01,  3.22it/s] [aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP4] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP1] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP3] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP2] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP6] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP5] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP7] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP0] [fused_moe] using default for (8, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=8 avail_mem=42.10 GB):  94%|| 49/52 [00:40<00:00,  3.37it/s]Capturing batches (bs=4 avail_mem=42.10 GB):  94%|| 49/52 [00:40<00:00,  3.37it/s][aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP1] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP4] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP3] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP6] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP2] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP5] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP7] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:42 TP0] [fused_moe] using default for (4, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=4 avail_mem=42.10 GB):  96%|| 50/52 [00:41<00:00,  3.49it/s]Capturing batches (bs=2 avail_mem=42.09 GB):  96%|| 50/52 [00:41<00:00,  3.49it/s][aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP4] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP3] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP5] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP2] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP6] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP1] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP0] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:43 TP7] [fused_moe] using default for (2, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=2 avail_mem=42.09 GB):  98%|| 51/52 [00:41<00:00,  3.58it/s]Capturing batches (bs=1 avail_mem=42.09 GB):  98%|| 51/52 [00:41<00:00,  3.58it/s][aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP5] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP0] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP7] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP2] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP3] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP4] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP6] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:32:44 TP1] [fused_moe] using default for (1, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
Capturing batches (bs=1 avail_mem=42.09 GB): 100%|| 52/52 [00:42<00:00,  1.93it/s]Capturing batches (bs=1 avail_mem=42.09 GB): 100%|| 52/52 [00:42<00:00,  1.23it/s]
[2025-10-18 01:32:45 TP0] Registering 6396 cuda graph addresses
[2025-10-18 01:32:45 TP3] Capture cuda graph end. Time elapsed: 42.59 s. mem usage=1.53 GB. avail mem=41.67 GB.
[2025-10-18 01:32:45 TP4] Capture cuda graph end. Time elapsed: 43.22 s. mem usage=1.53 GB. avail mem=41.72 GB.
[2025-10-18 01:32:45 TP5] Capture cuda graph end. Time elapsed: 43.27 s. mem usage=1.53 GB. avail mem=41.81 GB.
[2025-10-18 01:32:45 TP1] Capture cuda graph end. Time elapsed: 44.50 s. mem usage=1.53 GB. avail mem=41.67 GB.
[2025-10-18 01:32:45 TP2] Capture cuda graph end. Time elapsed: 42.74 s. mem usage=1.53 GB. avail mem=41.66 GB.
[2025-10-18 01:32:45 TP0] Capture cuda graph end. Time elapsed: 43.73 s. mem usage=1.53 GB. avail mem=42.08 GB.
[2025-10-18 01:32:45 TP6] Capture cuda graph end. Time elapsed: 42.63 s. mem usage=1.53 GB. avail mem=41.79 GB.
[2025-10-18 01:32:45 TP7] Capture cuda graph end. Time elapsed: 44.47 s. mem usage=1.53 GB. avail mem=41.80 GB.
[2025-10-18 01:32:45 TP0] max_total_num_tokens=971748, chunked_prefill_size=16384, max_prefill_tokens=16384, max_running_requests=1024, context_len=163840, available_gpu_mem=42.08 GB
[2025-10-18 01:32:46] INFO:     Started server process [47]
[2025-10-18 01:32:46] INFO:     Waiting for application startup.
[2025-10-18 01:32:46] INFO:     Application startup complete.
[2025-10-18 01:32:46] INFO:     Uvicorn running on http://127.0.0.1:30000 (Press CTRL+C to quit)
[2025-10-18 01:32:47] INFO:     127.0.0.1:36970 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-10-18 01:32:47 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:32:47] INFO:     127.0.0.1:36978 - "GET /get_model_info HTTP/1.1" 200 OK
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP4] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP5] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP7] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP3] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP0] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP1] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:48 TP2] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[aiter] start build [mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip] under /sgl-workspace/aiter/aiter/jit/build/mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
[2025-10-18 01:32:49 TP6] start build [mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip] under /sgl-workspace/aiter/aiter/jit/build/mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip
warning: unknown warning option '-Wno-missing-template-arg-list-after-template-kw'; did you mean '-Wno-gnu-string-literal-operator-template'? [-Wunknown-warning-option]
1 warning generated when compiling for gfx942.
warning: unknown warning option '-Wno-missing-template-arg-list-after-template-kw'; did you mean '-Wno-gnu-string-literal-operator-template'? [-Wunknown-warning-option]
1 warning generated when compiling for host.
[2025-10-18 01:32:55] INFO:     127.0.0.1:57240 - "GET /get_model_info HTTP/1.1" 200 OK
[92mSuccessfully preprocessed all matching files.[0m
[aiter] finish build [mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip], cost 55.33819013s
[2025-10-18 01:33:43 TP6] finish build [mha_varlen_fwd_bf16_nlogits_nbias_mask_nlse_ndropout_nskip], cost 55.33819013s
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP6] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP4] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP5] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP7] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP3] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP0] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP1] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:43 TP2] [fused_moe] using default for (7, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:44 TP0] Prefill batch. #new-seq: 1, #new-token: 667, #cached-token: 0, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:44 TP2] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:44 TP1] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:44 TP0] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:44 TP3] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:46 TP5] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:46 TP7] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:46 TP4] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:46 TP6] [fused_moe] using default for (667, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47] INFO:     127.0.0.1:57254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:47 TP0] Prefill batch. #new-seq: 10, #new-token: 632, #cached-token: 6670, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP4] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP5] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP3] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP7] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP0] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP2] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP6] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP1] [fused_moe] using default for (632, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP0] Prefill batch. #new-seq: 64, #new-token: 3567, #cached-token: 42688, token usage: 0.00, #running-req: 11, #queue-req: 0, 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP4] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP5] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP6] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP7] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP0] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP3] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP2] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP1] [fused_moe] using default for (1024, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:47 TP0] Prefill batch. #new-seq: 63, #new-token: 4178, #cached-token: 42158, token usage: 0.00, #running-req: 75, #queue-req: 0, 
[2025-10-18 01:33:48 TP0] Prefill batch. #new-seq: 156, #new-token: 9198, #cached-token: 104429, token usage: 0.01, #running-req: 138, #queue-req: 0, 
[2025-10-18 01:33:48 TP0] Prefill batch. #new-seq: 155, #new-token: 9527, #cached-token: 103768, token usage: 0.02, #running-req: 294, #queue-req: 0, 
[2025-10-18 01:33:49 TP0] Prefill batch. #new-seq: 282, #new-token: 16334, #cached-token: 188841, token usage: 0.03, #running-req: 449, #queue-req: 105, 
[2025-10-18 01:33:51 TP0] Prefill batch. #new-seq: 271, #new-token: 16346, #cached-token: 181508, token usage: 0.05, #running-req: 731, #queue-req: 51, 
[2025-10-18 01:33:52 TP0] Prefill batch. #new-seq: 22, #new-token: 1664, #cached-token: 14735, token usage: 0.06, #running-req: 1002, #queue-req: 296, 
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP5] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP5] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP5] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP5] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP5] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP5] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP6] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP6] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP6] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP6] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP3] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP0] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP3] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP0] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP3] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP3] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP6] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP0] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP6] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP0] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP3] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP3] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP0] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP0] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP4] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP4] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP4] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP4] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP4] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP4] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP2] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP2] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP2] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP2] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP2] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP2] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP7] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP7] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP7] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP7] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP7] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP7] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP1] shape M:1024, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP1] shape M:1024, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP1] shape M:1024, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[2025-10-18 01:33:53 TP1] shape M:1024, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x128x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v3!
[aiter] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP1] shape M:1024, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53 TP1] shape M:1024, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x128_16x16_32x32_8x32x1_8x32x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:33:53] INFO:     127.0.0.1:36974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:53] The server is fired up and ready to roll!
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP4] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP6] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP5] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP2] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP0] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP7] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP1] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP3] [fused_moe] using default for (1023, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:53 TP0] Prefill batch. #new-seq: 1, #new-token: 40, #cached-token: 670, token usage: 0.07, #running-req: 1023, #queue-req: 295, 
[2025-10-18 01:33:56] INFO:     127.0.0.1:59532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:56 TP0] Prefill batch. #new-seq: 1, #new-token: 43, #cached-token: 669, token usage: 0.09, #running-req: 1023, #queue-req: 294, 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP4] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP2] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP6] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP5] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP0] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP1] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP3] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:56 TP7] [fused_moe] using default for (43, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57] INFO:     127.0.0.1:56740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:57] INFO:     127.0.0.1:57134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 69, #cached-token: 669, token usage: 0.10, #running-req: 1023, #queue-req: 293, 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP4] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP6] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP2] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP0] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP5] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP1] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP3] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP7] [fused_moe] using default for (69, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 41, #cached-token: 670, token usage: 0.10, #running-req: 1023, #queue-req: 292, 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP3] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP0] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP2] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP4] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP6] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP1] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP7] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP5] [fused_moe] using default for (41, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57] INFO:     127.0.0.1:59592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 66, #cached-token: 670, token usage: 0.10, #running-req: 1023, #queue-req: 291, 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP3] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP6] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP0] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP2] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP5] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP4] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP1] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:57 TP7] [fused_moe] using default for (66, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] Decode batch. #running-req: 1024, #token: 101557, token usage: 0.10, cuda graph: False, gen throughput (token/s): 536.43, #queue-req: 291, 
[2025-10-18 01:33:58] INFO:     127.0.0.1:57184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:60302 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (1022, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58] INFO:     127.0.0.1:56652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:58094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:32806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:33132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58 TP0] Prefill batch. #new-seq: 2, #new-token: 182, #cached-token: 1339, token usage: 0.11, #running-req: 1022, #queue-req: 289, 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (182, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58] INFO:     127.0.0.1:57730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:59080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:59404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:34254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:37204 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (1015, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] Prefill batch. #new-seq: 9, #new-token: 624, #cached-token: 6031, token usage: 0.11, #running-req: 1015, #queue-req: 280, 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (624, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58] INFO:     127.0.0.1:58150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:58224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:59560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:34282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:58] INFO:     127.0.0.1:37096 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (1019, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] Prefill batch. #new-seq: 5, #new-token: 303, #cached-token: 3353, token usage: 0.11, #running-req: 1019, #queue-req: 275, 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP6] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP0] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP2] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP4] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP1] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP5] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP3] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:58 TP7] [fused_moe] using default for (303, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59] INFO:     127.0.0.1:57080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:57166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:57220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:57256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:57364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:58848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:32954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33422 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (1014, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] Prefill batch. #new-seq: 10, #new-token: 537, #cached-token: 6701, token usage: 0.11, #running-req: 1014, #queue-req: 265, 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (537, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59] INFO:     127.0.0.1:58144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:59986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:35094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:35976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:37192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:37332 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (1017, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] Prefill batch. #new-seq: 7, #new-token: 341, #cached-token: 4689, token usage: 0.11, #running-req: 1017, #queue-req: 258, 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (341, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59] INFO:     127.0.0.1:59868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:60462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:35322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:36518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59 TP0] Prefill batch. #new-seq: 5, #new-token: 253, #cached-token: 3351, token usage: 0.11, #running-req: 1019, #queue-req: 253, 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (253, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59] INFO:     127.0.0.1:60970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:32770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:33074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:34534 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (1020, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] Prefill batch. #new-seq: 4, #new-token: 266, #cached-token: 2680, token usage: 0.11, #running-req: 1020, #queue-req: 249, 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (266, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59] INFO:     127.0.0.1:57126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:57958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:58996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:60086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:36072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:36286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:36678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:33:59] INFO:     127.0.0.1:37264 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (1016, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] Prefill batch. #new-seq: 8, #new-token: 583, #cached-token: 5359, token usage: 0.11, #running-req: 1016, #queue-req: 241, 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP6] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP0] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP4] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP2] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP1] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP5] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP3] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:33:59 TP7] [fused_moe] using default for (583, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00] INFO:     127.0.0.1:56634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:58832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:58856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:59516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:59682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:35836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:37750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00 TP0] Prefill batch. #new-seq: 10, #new-token: 607, #cached-token: 6702, token usage: 0.11, #running-req: 1014, #queue-req: 231, 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP0] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP4] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP6] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP2] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP1] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP5] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP3] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP7] [fused_moe] using default for (607, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00] INFO:     127.0.0.1:57762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:58932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:33614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:35636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:37386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00 TP0] Prefill batch. #new-seq: 7, #new-token: 480, #cached-token: 4690, token usage: 0.11, #running-req: 1017, #queue-req: 224, 
[2025-10-18 01:34:00] INFO:     127.0.0.1:57632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:60602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:32992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:33164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:33438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00 TP0] Prefill batch. #new-seq: 8, #new-token: 461, #cached-token: 5358, token usage: 0.11, #running-req: 1016, #queue-req: 216, 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP4] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP5] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP3] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP1] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP7] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP2] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP6] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP0] [fused_moe] using default for (461, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00] INFO:     127.0.0.1:59230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00 TP0] Prefill batch. #new-seq: 4, #new-token: 181, #cached-token: 2679, token usage: 0.12, #running-req: 1020, #queue-req: 212, 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP0] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP6] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP2] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP4] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP1] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP5] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP3] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00 TP7] [fused_moe] using default for (181, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:00] INFO:     127.0.0.1:57646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:57894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:59388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:59760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:33724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:34938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:00] INFO:     127.0.0.1:36608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01 TP0] Prefill batch. #new-seq: 9, #new-token: 440, #cached-token: 6027, token usage: 0.12, #running-req: 1015, #queue-req: 203, 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (440, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01] INFO:     127.0.0.1:57356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:57924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:59978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:60266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:60788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:33306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:35470 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (1011, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] Prefill batch. #new-seq: 13, #new-token: 771, #cached-token: 8710, token usage: 0.12, #running-req: 1011, #queue-req: 190, 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (771, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01] INFO:     127.0.0.1:57852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:60162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:32902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:33050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:35290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01 TP0] Prefill batch. #new-seq: 8, #new-token: 465, #cached-token: 5358, token usage: 0.12, #running-req: 1016, #queue-req: 182, 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (465, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01] INFO:     127.0.0.1:56626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:59176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:35394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01 TP0] Prefill batch. #new-seq: 7, #new-token: 402, #cached-token: 4688, token usage: 0.12, #running-req: 1017, #queue-req: 175, 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (402, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01] INFO:     127.0.0.1:57210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:57430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:57636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:60038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01 TP0] Prefill batch. #new-seq: 7, #new-token: 371, #cached-token: 4690, token usage: 0.12, #running-req: 1017, #queue-req: 168, 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP4] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP0] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP6] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP2] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP1] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP5] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP3] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01 TP7] [fused_moe] using default for (371, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:01] INFO:     127.0.0.1:57694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:58704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:59638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:59982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:33278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:33294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:34492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:35758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:01] INFO:     127.0.0.1:36298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02 TP0] Prefill batch. #new-seq: 9, #new-token: 478, #cached-token: 6031, token usage: 0.12, #running-req: 1015, #queue-req: 159, 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (478, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02] INFO:     127.0.0.1:60942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:37186 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (1018, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] Prefill batch. #new-seq: 6, #new-token: 366, #cached-token: 4017, token usage: 0.12, #running-req: 1018, #queue-req: 153, 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (366, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02] INFO:     127.0.0.1:33186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:33288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:33506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:36864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:37124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:37490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02 TP0] Prefill batch. #new-seq: 7, #new-token: 405, #cached-token: 4690, token usage: 0.12, #running-req: 1017, #queue-req: 146, 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (405, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02] INFO:     127.0.0.1:57680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:58374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:58868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:59670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:33006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:36474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:36810 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (1013, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] Prefill batch. #new-seq: 11, #new-token: 733, #cached-token: 7374, token usage: 0.12, #running-req: 1013, #queue-req: 135, 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (733, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02] INFO:     127.0.0.1:56884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:57466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:58212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:59036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:33504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:34794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:35862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:36850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:02 TP0] Prefill batch. #new-seq: 11, #new-token: 619, #cached-token: 7367, token usage: 0.12, #running-req: 1013, #queue-req: 124, 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP0] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP6] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP2] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP4] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP1] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP5] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP3] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:02 TP7] [fused_moe] using default for (619, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03] INFO:     127.0.0.1:57208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:33844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:34280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:35440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03 TP0] Prefill batch. #new-seq: 8, #new-token: 579, #cached-token: 5362, token usage: 0.12, #running-req: 1016, #queue-req: 116, 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP4] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP6] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP2] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP1] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP5] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP3] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP7] [fused_moe] using default for (579, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03] INFO:     127.0.0.1:57890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:33958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:34564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36754 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP4] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP6] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP5] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP2] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP3] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP1] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP7] [fused_moe] using default for (1012, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] Prefill batch. #new-seq: 12, #new-token: 785, #cached-token: 8043, token usage: 0.12, #running-req: 1012, #queue-req: 104, 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP6] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP4] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP2] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP1] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP5] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP3] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP7] [fused_moe] using default for (785, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03] INFO:     127.0.0.1:57130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:57330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:57932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:34416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03 TP0] Prefill batch. #new-seq: 11, #new-token: 711, #cached-token: 7373, token usage: 0.12, #running-req: 1013, #queue-req: 93, 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP4] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP6] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP2] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP1] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP5] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP3] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP7] [fused_moe] using default for (711, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03] INFO:     127.0.0.1:56930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:32888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:32970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:36920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:37456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03 TP0] Prefill batch. #new-seq: 11, #new-token: 603, #cached-token: 7369, token usage: 0.12, #running-req: 1013, #queue-req: 82, 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP0] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP6] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP4] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP2] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP1] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP5] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP3] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03 TP7] [fused_moe] using default for (603, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:03] INFO:     127.0.0.1:57508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:57606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:58810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:59362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:60408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:33648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:03] INFO:     127.0.0.1:35514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04 TP0] Prefill batch. #new-seq: 11, #new-token: 659, #cached-token: 7365, token usage: 0.12, #running-req: 1013, #queue-req: 71, 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (659, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04] INFO:     127.0.0.1:56800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:56982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:57422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:57438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:59056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:59338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:59884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:36288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:36584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:37014 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (1008, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] Prefill batch. #new-seq: 16, #new-token: 1156, #cached-token: 10717, token usage: 0.12, #running-req: 1008, #queue-req: 55, 
[2025-10-18 01:34:04] INFO:     127.0.0.1:57344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:58302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:60046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:32968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:36338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:36368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:36934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:37504 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (1009, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] Prefill batch. #new-seq: 15, #new-token: 920, #cached-token: 10048, token usage: 0.12, #running-req: 1009, #queue-req: 40, 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (920, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04] INFO:     127.0.0.1:57620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:58060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:58190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:60590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:37032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04 TP0] Prefill batch. #new-seq: 10, #new-token: 587, #cached-token: 6702, token usage: 0.12, #running-req: 1014, #queue-req: 30, 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (587, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04] INFO:     127.0.0.1:58898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:59390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:60004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:60418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:33866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:34884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:35548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04] INFO:     127.0.0.1:37462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:04 TP0] Prefill batch. #new-seq: 12, #new-token: 717, #cached-token: 8040, token usage: 0.12, #running-req: 1012, #queue-req: 18, 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP4] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP6] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP0] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP2] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP1] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP5] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP3] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:04 TP7] [fused_moe] using default for (717, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05] INFO:     127.0.0.1:56920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:58614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05 TP0] Prefill batch. #new-seq: 9, #new-token: 579, #cached-token: 6027, token usage: 0.13, #running-req: 1015, #queue-req: 9, 
[2025-10-18 01:34:05] INFO:     127.0.0.1:56858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:57524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:58030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:58432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:58620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:32782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:36420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37510 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP4] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP6] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP2] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP1] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP5] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP3] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP7] [fused_moe] using default for (1010, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] Prefill batch. #new-seq: 9, #new-token: 482, #cached-token: 6034, token usage: 0.13, #running-req: 1010, #queue-req: 0, 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP4] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP6] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP1] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP2] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP5] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP3] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP7] [fused_moe] using default for (482, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05] INFO:     127.0.0.1:57908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:36848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:56812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:57830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37534 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP4] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP6] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP2] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP1] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP5] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP3] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP7] [fused_moe] using default for (1000, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05] INFO:     127.0.0.1:58544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:60566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:36706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:36770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:37366 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP4] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP6] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP5] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP2] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP7] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP3] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP1] [fused_moe] using default for (990, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05] INFO:     127.0.0.1:58254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:59654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:32944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:33400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:34582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:05] INFO:     127.0.0.1:35900 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP6] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP2] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP4] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP0] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP1] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP5] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP3] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:05 TP7] [fused_moe] using default for (977, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06] INFO:     127.0.0.1:56988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37080 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP4] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP2] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP6] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP1] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP5] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP3] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP7] [fused_moe] using default for (966, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] Decode batch. #running-req: 977, #token: 120274, token usage: 0.12, cuda graph: False, gen throughput (token/s): 5091.07, #queue-req: 0, 
[2025-10-18 01:34:06] INFO:     127.0.0.1:59810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:35084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36748 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP4] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP6] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP2] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP1] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP5] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP3] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP7] [fused_moe] using default for (959, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06] INFO:     127.0.0.1:56874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:59192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:32844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37420 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP4] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP6] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP2] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP5] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP1] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP7] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP3] [fused_moe] using default for (946, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37576 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP6] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP4] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP2] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP5] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP3] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP1] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP7] [fused_moe] using default for (936, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06] INFO:     127.0.0.1:56766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:59582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:33762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:34630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:34958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:35172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:35832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:59014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:34150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:35914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:36812 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP1] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP0] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP4] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP2] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP5] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP6] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP7] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06 TP3] [fused_moe] using default for (911, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:06] INFO:     127.0.0.1:56870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:57876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:58602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:59270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:60596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:32814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:34728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:35480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:06] INFO:     127.0.0.1:37316 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (901, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:56952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:58452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37028 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (891, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:56666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:58220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37868 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (873, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:57494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37520 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (862, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:56712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:32798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37354 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (853, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:56852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:33918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36996 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (840, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:57666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37732 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (831, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:57814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:36278 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (824, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07] INFO:     127.0.0.1:57014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:57018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:58084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:59934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:34030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:35420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:07] INFO:     127.0.0.1:37678 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP4] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP6] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP2] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP0] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP1] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP5] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP3] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:07 TP7] [fused_moe] using default for (812, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:56654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:57552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:58240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:35444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:38260 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (803, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:57044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:38484 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (792, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:57318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33730 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (788, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:60502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:32932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37908 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (782, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:57842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:58498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:35762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:35952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37590 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (769, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:59166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:59482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:32874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:35556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37358 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (761, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:56808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:56892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:59422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:60574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:34970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:38428 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (751, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP6] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP4] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP2] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP0] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP5] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP1] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP3] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08 TP7] [fused_moe] using default for (736, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:08] INFO:     127.0.0.1:57026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:57408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:57562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:57696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:32840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:33852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:36430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:37738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:08] INFO:     127.0.0.1:38974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:57280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:58160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37530 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (725, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:57956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37682 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (720, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:56714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:57758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:58634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38504 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (709, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:57748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38960 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (693, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:57244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:58688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36840 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (680, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:59286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:40074 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (668, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:56750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:57170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:39088 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (655, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:56794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:57484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:58912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:59666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:35808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:38356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:39252 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (641, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09] INFO:     127.0.0.1:57740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:58218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:60846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:33702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:34440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:36904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:09] INFO:     127.0.0.1:37646 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP4] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP6] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP2] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP0] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP5] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP3] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP1] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:09 TP7] [fused_moe] using default for (633, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:32858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:32916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:32984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38652 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (618, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:32866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:56998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:60860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:33148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:33778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38930 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (598, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39454 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (594, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:60250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38522 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (590, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:56910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:60116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:60316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:60898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:33896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:40022 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (577, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:56966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38472 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (567, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:60346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:33424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:36998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:40110 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (551, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:58858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:32828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39786 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP3] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP7] [fused_moe] using default for (539, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] Decode batch. #running-req: 551, #token: 84555, token usage: 0.09, cuda graph: False, gen throughput (token/s): 6356.96, #queue-req: 0, 
[2025-10-18 01:34:10] INFO:     127.0.0.1:56778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:57864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:59740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:34588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:35246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:37226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:38714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:10] INFO:     127.0.0.1:39604 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP2] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP6] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP4] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP0] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP5] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:10 TP1] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP3] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP7] [fused_moe] using default for (527, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11] INFO:     127.0.0.1:59608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39322 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP6] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP4] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP2] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP0] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP5] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP1] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP3] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11 TP7] [fused_moe] using default for (515, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:34:11] INFO:     127.0.0.1:58482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:57148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:57186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:56700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:57324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:56682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:40086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:56650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:56946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:40362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:60956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:34296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:38582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:58106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:59828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:33020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:36336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:37484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:39022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:11] INFO:     127.0.0.1:40356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:58294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:34596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:33356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:34084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:33604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:58196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:36330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:33968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:58528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:33790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:58280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:34190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:34722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:35346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:34932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:36972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:36122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:57540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:59010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:60936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:37772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:38972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:39194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:12] INFO:     127.0.0.1:40476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:57996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:35262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:57060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:56906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:57854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:57986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:35776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:35068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:36990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13 TP0] Decode batch. #running-req: 248, #token: 48028, token usage: 0.05, cuda graph: True, gen throughput (token/s): 6058.73, #queue-req: 0, 
[2025-10-18 01:34:13] INFO:     127.0.0.1:57384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:56784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:35738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:58944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:34186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:59046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:33944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:37672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:38902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:39136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:13] INFO:     127.0.0.1:40210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:57034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:58986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:35406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:35698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:37852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:34268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:56722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:57378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:35054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:37330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:59022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:60988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:35986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:59712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:33378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:34038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:58808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:57578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:60518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:33098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:59626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:59854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:34372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:36374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:59150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:37760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:58580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:58974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:60916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:57090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:40234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:33640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:35228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:60734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:38236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:14] INFO:     127.0.0.1:39024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:57946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:40390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:36434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:33666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:57442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:36866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:33034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:37546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:37884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:40424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:40214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15 TP0] Decode batch. #running-req: 91, #token: 22789, token usage: 0.02, cuda graph: True, gen throughput (token/s): 3536.32, #queue-req: 0, 
[2025-10-18 01:34:15] INFO:     127.0.0.1:57770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:33452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:59236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:57532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:34468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:37962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:32784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:40276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:56692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:59660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:60708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:34720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:37826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:37922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:35672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:58036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:33748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:39894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:40340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:58260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:57168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:38004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:57056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:15] INFO:     127.0.0.1:33796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:38638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:37394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:40272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:34918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:40462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:33904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:35938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:34256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:36940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:38020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:39010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:58096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16 TP0] Decode batch. #running-req: 28, #token: 9078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1629.41, #queue-req: 0, 
[2025-10-18 01:34:16] INFO:     127.0.0.1:39798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:40300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:38466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:36890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:37712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:40306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:35006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:16] INFO:     127.0.0.1:57662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:57480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:59434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:38684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:39362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:60392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:38360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:39966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:37426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:40196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:38516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:39098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:35472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:38298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:38792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17 TP0] Decode batch. #running-req: 6, #token: 2807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 650.03, #queue-req: 0, 
[2025-10-18 01:34:17] INFO:     127.0.0.1:39060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:37600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:17] INFO:     127.0.0.1:37694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:18 TP0] Decode batch. #running-req: 3, #token: 1510, token usage: 0.00, cuda graph: True, gen throughput (token/s): 181.46, #queue-req: 0, 
[2025-10-18 01:34:18] INFO:     127.0.0.1:39216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:19] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:19 TP0] Decode batch. #running-req: 1, #token: 1110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 71.60, #queue-req: 0, 
[2025-10-18 01:34:20] INFO:     127.0.0.1:58466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:34:33] INFO:     127.0.0.1:42516 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-10-18 01:34:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 666, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP5] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP2] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP1] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP7] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP0] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP3] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP6] waiting for baton release at /sgl-workspace/aiter/aiter/jit/build/lock_mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[aiter] start build [mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip] under /sgl-workspace/aiter/aiter/jit/build/mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
[2025-10-18 01:34:33 TP4] start build [mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip] under /sgl-workspace/aiter/aiter/jit/build/mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip
warning: unknown warning option '-Wno-missing-template-arg-list-after-template-kw'; did you mean '-Wno-gnu-string-literal-operator-template'? [-Wunknown-warning-option]
1 warning generated when compiling for gfx942.
warning: unknown warning option '-Wno-missing-template-arg-list-after-template-kw'; did you mean '-Wno-gnu-string-literal-operator-template'? [-Wunknown-warning-option]
1 warning generated when compiling for host.
[92mSuccessfully preprocessed all matching files.[0m
[aiter] finish build [mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip], cost 54.49730690s
[2025-10-18 01:35:28 TP4] finish build [mha_varlen_fwd_bf16_nlogits_nbias_nmask_nlse_ndropout_nskip], cost 54.49730690s
[2025-10-18 01:35:28] INFO:     127.0.0.1:42524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 733, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 23, #new-token: 23, #cached-token: 16706, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP4] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP5] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP3] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP7] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP1] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP6] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP2] [fused_moe] using default for (23, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6619, token usage: 0.00, #running-req: 24, #queue-req: 0, 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP4] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP5] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP7] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP6] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP3] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP1] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP2] [fused_moe] using default for (9, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 53, #new-token: 53, #cached-token: 38669, token usage: 0.01, #running-req: 33, #queue-req: 0, 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP4] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP6] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP7] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP5] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP2] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP3] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP1] [fused_moe] using default for (53, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 47, #new-token: 47, #cached-token: 34055, token usage: 0.01, #running-req: 86, #queue-req: 0, 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP4] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP7] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP5] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP3] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP1] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP6] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP2] [fused_moe] using default for (47, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 61, #new-token: 61, #cached-token: 44558, token usage: 0.01, #running-req: 133, #queue-req: 0, 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP4] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP5] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP7] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP3] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP1] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP6] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP2] [fused_moe] using default for (61, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:28 TP0] Prefill batch. #new-seq: 52, #new-token: 52, #cached-token: 37808, token usage: 0.02, #running-req: 194, #queue-req: 0, 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (52, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 65, #new-token: 65, #cached-token: 47277, token usage: 0.02, #running-req: 246, #queue-req: 0, 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (65, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 55, #new-token: 55, #cached-token: 40064, token usage: 0.02, #running-req: 311, #queue-req: 0, 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (55, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 69, #new-token: 69, #cached-token: 50400, token usage: 0.03, #running-req: 366, #queue-req: 0, 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 58, #new-token: 58, #cached-token: 42063, token usage: 0.03, #running-req: 435, #queue-req: 0, 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (58, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 74, #new-token: 74, #cached-token: 53558, token usage: 0.04, #running-req: 493, #queue-req: 0, 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (74, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 63, #new-token: 63, #cached-token: 45947, token usage: 0.04, #running-req: 567, #queue-req: 0, 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (63, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 71, #new-token: 71, #cached-token: 51680, token usage: 0.04, #running-req: 630, #queue-req: 0, 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP4] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP7] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP3] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP1] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP6] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP2] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP5] [fused_moe] using default for (71, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:29 TP0] Prefill batch. #new-seq: 67, #new-token: 67, #cached-token: 48691, token usage: 0.05, #running-req: 701, #queue-req: 0, 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (67, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] Prefill batch. #new-seq: 74, #new-token: 74, #cached-token: 54245, token usage: 0.05, #running-req: 768, #queue-req: 0, 
[2025-10-18 01:35:30 TP0] Prefill batch. #new-seq: 42, #new-token: 42, #cached-token: 30376, token usage: 0.05, #running-req: 842, #queue-req: 0, 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (42, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (884, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] Prefill batch. #new-seq: 39, #new-token: 39, #cached-token: 28175, token usage: 0.06, #running-req: 884, #queue-req: 0, 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (39, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] Prefill batch. #new-seq: 50, #new-token: 50, #cached-token: 36892, token usage: 0.06, #running-req: 923, #queue-req: 0, 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (50, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] Prefill batch. #new-seq: 51, #new-token: 51, #cached-token: 37359, token usage: 0.07, #running-req: 973, #queue-req: 2, 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP4] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP7] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP5] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP3] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP2] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP1] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP6] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:30 TP0] [fused_moe] using default for (51, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:32 TP0] Decode batch. #running-req: 1024, #token: 72752, token usage: 0.07, cuda graph: False, gen throughput (token/s): 138.31, #queue-req: 295, 
[2025-10-18 01:35:33] INFO:     127.0.0.1:53840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 737, token usage: 0.09, #running-req: 1023, #queue-req: 294, 
[2025-10-18 01:35:34] INFO:     127.0.0.1:51678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 746, token usage: 0.10, #running-req: 1023, #queue-req: 293, 
[2025-10-18 01:35:34] INFO:     127.0.0.1:53872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 735, token usage: 0.10, #running-req: 1023, #queue-req: 292, 
[2025-10-18 01:35:35] INFO:     127.0.0.1:51042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 729, token usage: 0.10, #running-req: 1023, #queue-req: 291, 
[2025-10-18 01:35:35] INFO:     127.0.0.1:51750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35] INFO:     127.0.0.1:54552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35] INFO:     127.0.0.1:55498 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP4] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP6] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP2] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP3] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP0] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP7] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP1] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP5] [fused_moe] using default for (1021, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2298, token usage: 0.11, #running-req: 1021, #queue-req: 288, 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP4] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP2] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP0] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP7] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP1] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP6] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP3] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35 TP5] [fused_moe] using default for (3, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:35] INFO:     127.0.0.1:51786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35] INFO:     127.0.0.1:55716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:35] INFO:     127.0.0.1:55732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2202, token usage: 0.11, #running-req: 1021, #queue-req: 285, 
[2025-10-18 01:35:36] INFO:     127.0.0.1:52178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:53320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:53700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:56688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2925, token usage: 0.11, #running-req: 1020, #queue-req: 281, 
[2025-10-18 01:35:36] INFO:     127.0.0.1:51432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:51666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:53852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:55232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:56716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3673, token usage: 0.11, #running-req: 1019, #queue-req: 276, 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP4] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP0] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP2] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP6] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP7] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP3] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP1] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP5] [fused_moe] using default for (5, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36] INFO:     127.0.0.1:51494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:51564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:51606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:51748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:53236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:55628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:55656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:55850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:56168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:59820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7186, token usage: 0.11, #running-req: 1014, #queue-req: 266, 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP4] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP2] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP0] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP7] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP6] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP3] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP1] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36 TP5] [fused_moe] using default for (10, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:36] INFO:     127.0.0.1:52620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:54210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:55976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:57880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:59680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3622, token usage: 0.11, #running-req: 1019, #queue-req: 261, 
[2025-10-18 01:35:36] INFO:     127.0.0.1:54108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:54718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:36] INFO:     127.0.0.1:60282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2161, token usage: 0.11, #running-req: 1021, #queue-req: 258, 
[2025-10-18 01:35:37] INFO:     127.0.0.1:51018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:53200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:57028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5039, token usage: 0.11, #running-req: 1017, #queue-req: 251, 
[2025-10-18 01:35:37] INFO:     127.0.0.1:51744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:51902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:52622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:54536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:56746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7436, token usage: 0.11, #running-req: 1014, #queue-req: 241, 
[2025-10-18 01:35:37] INFO:     127.0.0.1:53190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:53240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:53826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:53996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:57336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5772, token usage: 0.11, #running-req: 1016, #queue-req: 233, 
[2025-10-18 01:35:37] INFO:     127.0.0.1:51570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:53112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:54342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:58672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:59880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5923, token usage: 0.11, #running-req: 1016, #queue-req: 225, 
[2025-10-18 01:35:37 TP0] Decode batch. #running-req: 1016, #token: 110293, token usage: 0.11, cuda graph: False, gen throughput (token/s): 6915.62, #queue-req: 225, 
[2025-10-18 01:35:37] INFO:     127.0.0.1:52192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:55890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:56598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:37] INFO:     127.0.0.1:60268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4397, token usage: 0.11, #running-req: 1018, #queue-req: 219, 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP4] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP6] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP0] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP2] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP3] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP7] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP1] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38 TP5] [fused_moe] using default for (6, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:38] INFO:     127.0.0.1:53498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:55110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:56084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:56468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:59986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4344, token usage: 0.12, #running-req: 1018, #queue-req: 213, 
[2025-10-18 01:35:38] INFO:     127.0.0.1:51352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:51908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:54040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:54868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:56180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:56912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:59054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6416, token usage: 0.12, #running-req: 1015, #queue-req: 204, 
[2025-10-18 01:35:38] INFO:     127.0.0.1:51006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:51338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:54198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:55038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:56804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:58042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:59136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6586, token usage: 0.12, #running-req: 1015, #queue-req: 195, 
[2025-10-18 01:35:38] INFO:     127.0.0.1:51754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:54412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:55364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:55738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5091, token usage: 0.12, #running-req: 1017, #queue-req: 188, 
[2025-10-18 01:35:38] INFO:     127.0.0.1:52718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:52776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:53432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:38] INFO:     127.0.0.1:57518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5094, token usage: 0.12, #running-req: 1017, #queue-req: 181, 
[2025-10-18 01:35:39] INFO:     127.0.0.1:51424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:51722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:52418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:52890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:54278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:56526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7981, token usage: 0.12, #running-req: 1013, #queue-req: 170, 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP4] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP0] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP6] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP7] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP3] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP2] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP1] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39 TP5] [fused_moe] using default for (11, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:39] INFO:     127.0.0.1:52492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:53930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:54220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:54450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:56924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:56996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:58896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7163, token usage: 0.12, #running-req: 1014, #queue-req: 160, 
[2025-10-18 01:35:39] INFO:     127.0.0.1:55764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:56886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:58344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:58630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:58826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5849, token usage: 0.12, #running-req: 1016, #queue-req: 152, 
[2025-10-18 01:35:39] INFO:     127.0.0.1:51158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:54260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:57692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5826, token usage: 0.12, #running-req: 1016, #queue-req: 144, 
[2025-10-18 01:35:39] INFO:     127.0.0.1:51484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:52758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:39] INFO:     127.0.0.1:55950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5213, token usage: 0.12, #running-req: 1017, #queue-req: 137, 
[2025-10-18 01:35:40] INFO:     127.0.0.1:52518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:52604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:55454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:55944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:60328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7908, token usage: 0.12, #running-req: 1013, #queue-req: 126, 
[2025-10-18 01:35:40] INFO:     127.0.0.1:52002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:57318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:57966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4443, token usage: 0.12, #running-req: 1018, #queue-req: 120, 
[2025-10-18 01:35:40] INFO:     127.0.0.1:51880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:52214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:52958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:54348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:57056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8169, token usage: 0.12, #running-req: 1013, #queue-req: 109, 
[2025-10-18 01:35:40] INFO:     127.0.0.1:51486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:51770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:52320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:52596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:53982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:54986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:56090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:58994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40] INFO:     127.0.0.1:59160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:40 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7374, token usage: 0.12, #running-req: 1014, #queue-req: 99, 
[2025-10-18 01:35:41] INFO:     127.0.0.1:51194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:51404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:51642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9384, token usage: 0.12, #running-req: 1011, #queue-req: 86, 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP4] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP3] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP6] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP2] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP7] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP0] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP1] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41 TP5] [fused_moe] using default for (13, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:41] INFO:     127.0.0.1:52380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5060, token usage: 0.12, #running-req: 1017, #queue-req: 79, 
[2025-10-18 01:35:41] INFO:     127.0.0.1:51974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:55848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:55928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:60132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9577, token usage: 0.12, #running-req: 1011, #queue-req: 66, 
[2025-10-18 01:35:41] INFO:     127.0.0.1:51660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:52686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:55524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41 TP0] Prefill batch. #new-seq: 16, #new-token: 16, #cached-token: 11836, token usage: 0.13, #running-req: 1008, #queue-req: 50, 
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP4] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP6] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP2] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP3] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP7] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP0] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP1] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41 TP5] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:35:41] INFO:     127.0.0.1:51608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:53344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:54836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:55220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:56830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:57540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:58426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41] INFO:     127.0.0.1:59188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:41 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7243, token usage: 0.13, #running-req: 1014, #queue-req: 40, 
[2025-10-18 01:35:42] INFO:     127.0.0.1:53408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:55642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:56014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:56156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:56296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:58106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:60092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:60336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8038, token usage: 0.13, #running-req: 1013, #queue-req: 29, 
[2025-10-18 01:35:42] INFO:     127.0.0.1:51224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:55670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6544, token usage: 0.13, #running-req: 1015, #queue-req: 20, 
[2025-10-18 01:35:42] INFO:     127.0.0.1:51638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:53394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:59030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:59528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:59604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10210, token usage: 0.13, #running-req: 1010, #queue-req: 6, 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP4] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP0] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP6] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP7] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP2] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP3] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP1] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42 TP5] [fused_moe] using default for (14, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:42] INFO:     127.0.0.1:51978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:54424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:55132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:56444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:58192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4336, token usage: 0.13, #running-req: 1016, #queue-req: 0, 
[2025-10-18 01:35:42] INFO:     127.0.0.1:51806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:52510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:55682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:56812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:57654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:58276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:59456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:60318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:42] INFO:     127.0.0.1:60394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:54812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:60022 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (998, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:53082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59922 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (988, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:51252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59964 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (974, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:51172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57992 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (968, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:51302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59654 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (956, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:51548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57384 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (947, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:51050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:51534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59348 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (933, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43] INFO:     127.0.0.1:52878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:52950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:53448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:54188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:55316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:56546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:57250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:58910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:43] INFO:     127.0.0.1:59322 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP4] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP2] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP6] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP0] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP3] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP7] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP5] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:43 TP1] [fused_moe] using default for (919, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57412 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (909, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:60502 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (892, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59938 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (878, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:53864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:60246 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (868, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59114 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (856, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:53980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:60166 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (843, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59954 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (839, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] Decode batch. #running-req: 843, #token: 111818, token usage: 0.12, cuda graph: False, gen throughput (token/s): 5637.37, #queue-req: 0, 
[2025-10-18 01:35:44] INFO:     127.0.0.1:51066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:51736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:52532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:54880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:55994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:56100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:57946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:58854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:44] INFO:     127.0.0.1:59574 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP2] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP4] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP6] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP3] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP0] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP7] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP1] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:44 TP5] [fused_moe] using default for (826, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:51266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:51658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60446 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (814, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:52186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60912 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (804, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:51896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:32884 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (791, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:51366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60622 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (784, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:52130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (776, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:51210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:51330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:52116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58464 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (768, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:51934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:52948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:53686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59910 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (753, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45] INFO:     127.0.0.1:52484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:54822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:55198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:56660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:57494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:58984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:59742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:60354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:32826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:45] INFO:     127.0.0.1:33358 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (740, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP4] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP0] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP2] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP6] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP3] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP7] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP1] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:45 TP5] [fused_moe] using default for (730, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:52834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:51128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:51142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:52252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60390 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (722, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:54738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60352 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (713, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:51460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:52108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58828 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (702, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:51480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:51604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:51616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:51710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:32920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:32956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:34510 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (688, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:54482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33288 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (678, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:51178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:52630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:32984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33088 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (663, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:51810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:56334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:33464 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (649, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46] INFO:     127.0.0.1:53718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:53966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:54652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:55338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:57400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:58714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:59834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:46] INFO:     127.0.0.1:60284 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP4] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP0] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP3] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP7] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP6] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP2] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP1] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:46 TP5] [fused_moe] using default for (640, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59564 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (635, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:33050 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (627, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:32780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:33450 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (616, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:52052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:33848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:34262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:34644 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (601, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:52972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:32932 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (592, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:51648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:33622 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (580, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:33854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:34478 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (566, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:54178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:57932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:58936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:59992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60968 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP4] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP0] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP3] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP7] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP6] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP2] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP1] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47 TP5] [fused_moe] using default for (549, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:47] INFO:     127.0.0.1:51316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:52762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:53460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:55296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:56516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:32870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:34048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:47] INFO:     127.0.0.1:34548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:52712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33386 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP4] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP6] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP2] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP3] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP0] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP7] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP1] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP5] [fused_moe] using default for (531, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48] INFO:     127.0.0.1:51222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33988 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP4] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP6] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP2] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP0] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP3] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP7] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP1] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48 TP5] [fused_moe] using default for (519, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:35:48] INFO:     127.0.0.1:52070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:52828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:32896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:52684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:52726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:32772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:32808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:59500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:52814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:55924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:60030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48 TP0] Decode batch. #running-req: 440, #token: 73674, token usage: 0.08, cuda graph: True, gen throughput (token/s): 6373.66, #queue-req: 0, 
[2025-10-18 01:35:48] INFO:     127.0.0.1:51988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:51540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:53158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:54980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:56796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:57592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:33670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:48] INFO:     127.0.0.1:34442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:51574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:56520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:56696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:51924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:56620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:53758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:53766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:51504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:53424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:56212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:58450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:57226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:32898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:32992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:53594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:32788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:32842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:32914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:34496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:51386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:52980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:54486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:55414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:59782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:60886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:49] INFO:     127.0.0.1:33970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:59542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:55090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:32812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:55028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:55748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:55832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:56558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:58076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:56140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:57808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:51084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:51188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:32972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:56962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:58342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:59982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:51216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:57978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:53884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:51280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:57564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:58292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:57816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:33600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:55632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:56610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:60848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:54644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:52656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:50] INFO:     127.0.0.1:34330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:55172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:58264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51 TP0] Decode batch. #running-req: 196, #token: 41200, token usage: 0.04, cuda graph: True, gen throughput (token/s): 5454.74, #queue-req: 0, 
[2025-10-18 01:35:51] INFO:     127.0.0.1:58520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:53166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:54856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:57568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:53192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:58648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:57266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:55806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:56490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:57556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:58256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:58974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:59952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:52326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:53304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:53898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:32810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:53300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:54564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:60684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:33800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:51] INFO:     127.0.0.1:34416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:54996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:55158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:57844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:54150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:59040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:59446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:56124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:54126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:56348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:56758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:52348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:32828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:56954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:52258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:55916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:58138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:59172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:58200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:60572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:58350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:54752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:55582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:51960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:52372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:54972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:32792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:32946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52 TP0] Decode batch. #running-req: 67, #token: 17542, token usage: 0.02, cuda graph: True, gen throughput (token/s): 2997.42, #queue-req: 0, 
[2025-10-18 01:35:52] INFO:     127.0.0.1:33254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:53804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:33918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:52582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:56226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:58212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:52200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:52] INFO:     127.0.0.1:34798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:58088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:57436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:60140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:60004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:32858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:55766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:59488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:59530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:58476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:59544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:60082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:33796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:57524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:32864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:54630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:53742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:53] INFO:     127.0.0.1:34004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:54950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:34748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54 TP0] Decode batch. #running-req: 22, #token: 6425, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1305.39, #queue-req: 0, 
[2025-10-18 01:35:54] INFO:     127.0.0.1:51464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:34386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:32782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:57890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:60642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:58368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:60116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:60926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:33170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:32900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:58060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54] INFO:     127.0.0.1:60300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:54 TP0] Decode batch. #running-req: 4, #token: 1316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 420.72, #queue-req: 0, 
[2025-10-18 01:35:54] INFO:     127.0.0.1:33454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:55] INFO:     127.0.0.1:60288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:35:55] INFO:     127.0.0.1:33608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:08] INFO:     127.0.0.1:35218 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-10-18 01:36:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 666, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:36:08] INFO:     127.0.0.1:35230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 733, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:36:08 TP0] Prefill batch. #new-seq: 40, #new-token: 40, #cached-token: 28999, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 47, #new-token: 47, #cached-token: 34206, token usage: 0.01, #running-req: 41, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 50, #new-token: 50, #cached-token: 36423, token usage: 0.01, #running-req: 88, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 51, #new-token: 51, #cached-token: 37411, token usage: 0.01, #running-req: 138, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 56, #new-token: 56, #cached-token: 40729, token usage: 0.02, #running-req: 189, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 55, #new-token: 55, #cached-token: 39913, token usage: 0.02, #running-req: 245, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 60, #new-token: 60, #cached-token: 43703, token usage: 0.02, #running-req: 300, #queue-req: 0, 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP4] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP7] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP6] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP1] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP2] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP3] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP5] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP0] [fused_moe] using default for (60, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 58, #new-token: 58, #cached-token: 42228, token usage: 0.03, #running-req: 360, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 66, #new-token: 66, #cached-token: 48212, token usage: 0.03, #running-req: 418, #queue-req: 0, 
[2025-10-18 01:36:09 TP0] Prefill batch. #new-seq: 62, #new-token: 62, #cached-token: 44794, token usage: 0.03, #running-req: 484, #queue-req: 0, 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP4] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP7] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP6] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP5] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP1] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP3] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP2] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP0] [fused_moe] using default for (62, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 71, #new-token: 71, #cached-token: 51700, token usage: 0.04, #running-req: 546, #queue-req: 0, 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 66, #new-token: 66, #cached-token: 47925, token usage: 0.04, #running-req: 617, #queue-req: 0, 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3622, token usage: 0.04, #running-req: 683, #queue-req: 0, 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 15, #new-token: 15, #cached-token: 11027, token usage: 0.04, #running-req: 688, #queue-req: 0, 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP4] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP6] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP7] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP5] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP0] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP1] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP3] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP2] [fused_moe] using default for (15, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 48, #new-token: 48, #cached-token: 34867, token usage: 0.05, #running-req: 703, #queue-req: 0, 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 52, #new-token: 52, #cached-token: 37944, token usage: 0.05, #running-req: 751, #queue-req: 0, 
[2025-10-18 01:36:10 TP0] Prefill batch. #new-seq: 56, #new-token: 56, #cached-token: 40889, token usage: 0.05, #running-req: 803, #queue-req: 0, 
[2025-10-18 01:36:11 TP0] Prefill batch. #new-seq: 58, #new-token: 58, #cached-token: 41967, token usage: 0.06, #running-req: 859, #queue-req: 0, 
[2025-10-18 01:36:11 TP0] Prefill batch. #new-seq: 61, #new-token: 61, #cached-token: 44838, token usage: 0.06, #running-req: 917, #queue-req: 0, 
[2025-10-18 01:36:11 TP0] Prefill batch. #new-seq: 46, #new-token: 46, #cached-token: 33873, token usage: 0.06, #running-req: 978, #queue-req: 16, 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP4] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP2] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP1] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP6] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP3] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP7] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP0] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:11 TP5] [fused_moe] using default for (46, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:12 TP0] Decode batch. #running-req: 1024, #token: 72776, token usage: 0.07, cuda graph: False, gen throughput (token/s): 563.75, #queue-req: 295, 
[2025-10-18 01:36:14] INFO:     127.0.0.1:38126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 716, token usage: 0.09, #running-req: 1023, #queue-req: 294, 
[2025-10-18 01:36:15] INFO:     127.0.0.1:35994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 766, token usage: 0.10, #running-req: 1023, #queue-req: 293, 
[2025-10-18 01:36:15] INFO:     127.0.0.1:38170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 731, token usage: 0.10, #running-req: 1023, #queue-req: 292, 
[2025-10-18 01:36:16] INFO:     127.0.0.1:35500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:38928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:35282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:36126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:39608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1434, token usage: 0.11, #running-req: 1022, #queue-req: 290, 
[2025-10-18 01:36:16] INFO:     127.0.0.1:36476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:36882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:37476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:37976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:41052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5864, token usage: 0.11, #running-req: 1016, #queue-req: 282, 
[2025-10-18 01:36:16] INFO:     127.0.0.1:36236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:38130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:39796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:41068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2934, token usage: 0.11, #running-req: 1020, #queue-req: 278, 
[2025-10-18 01:36:16] INFO:     127.0.0.1:35506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:35614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:35700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:35866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:37406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:39992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:40122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:40220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:40506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:16] INFO:     127.0.0.1:44084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7216, token usage: 0.11, #running-req: 1014, #queue-req: 268, 
[2025-10-18 01:36:17] INFO:     127.0.0.1:36838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:40316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:44248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:44652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2923, token usage: 0.11, #running-req: 1020, #queue-req: 264, 
[2025-10-18 01:36:17] INFO:     127.0.0.1:35952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:38476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:39054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:40120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:42068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:42304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:42922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:44218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:44364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6466, token usage: 0.11, #running-req: 1015, #queue-req: 255, 
[2025-10-18 01:36:17] INFO:     127.0.0.1:41396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:43452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1435, token usage: 0.11, #running-req: 1022, #queue-req: 253, 
[2025-10-18 01:36:17] INFO:     127.0.0.1:35656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:36850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:37654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:38750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:39696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17] INFO:     127.0.0.1:43726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:17 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4434, token usage: 0.11, #running-req: 1018, #queue-req: 247, 
[2025-10-18 01:36:18] INFO:     127.0.0.1:35256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:36514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:37434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:37664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:38106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:38294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:44292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7355, token usage: 0.11, #running-req: 1014, #queue-req: 237, 
[2025-10-18 01:36:18] INFO:     127.0.0.1:36042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:36066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:37460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:38606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:39814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:42776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:44434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6569, token usage: 0.11, #running-req: 1015, #queue-req: 228, 
[2025-10-18 01:36:18 TP0] Decode batch. #running-req: 1015, #token: 109970, token usage: 0.11, cuda graph: False, gen throughput (token/s): 6988.10, #queue-req: 228, 
[2025-10-18 01:36:18] INFO:     127.0.0.1:36260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:36496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:39196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:39720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:39882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:40260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:40924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:42590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6582, token usage: 0.11, #running-req: 1015, #queue-req: 219, 
[2025-10-18 01:36:18] INFO:     127.0.0.1:37784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:39438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:40436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:40808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3648, token usage: 0.12, #running-req: 1019, #queue-req: 214, 
[2025-10-18 01:36:18] INFO:     127.0.0.1:36108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:36584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:36936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:37702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:38358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:40528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:41668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:43328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18] INFO:     127.0.0.1:44676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:18 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6434, token usage: 0.12, #running-req: 1015, #queue-req: 205, 
[2025-10-18 01:36:19] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:38590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:38908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:39374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:42496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:43428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7292, token usage: 0.12, #running-req: 1014, #queue-req: 195, 
[2025-10-18 01:36:19] INFO:     127.0.0.1:36098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:39928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:39938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:43236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:44068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4364, token usage: 0.12, #running-req: 1018, #queue-req: 189, 
[2025-10-18 01:36:19] INFO:     127.0.0.1:36970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:36978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:38682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5839, token usage: 0.12, #running-req: 1016, #queue-req: 181, 
[2025-10-18 01:36:19] INFO:     127.0.0.1:35240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:36682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:40872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:42456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:43820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:44412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10069, token usage: 0.12, #running-req: 1010, #queue-req: 167, 
[2025-10-18 01:36:19] INFO:     127.0.0.1:36094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:36738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:37648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:38238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:38614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:19] INFO:     127.0.0.1:41920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5797, token usage: 0.12, #running-req: 1016, #queue-req: 159, 
[2025-10-18 01:36:20] INFO:     127.0.0.1:39956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:41230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:43304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2151, token usage: 0.12, #running-req: 1021, #queue-req: 156, 
[2025-10-18 01:36:20] INFO:     127.0.0.1:35670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:37326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:38824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:39706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:39736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:43430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:44210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7314, token usage: 0.12, #running-req: 1014, #queue-req: 146, 
[2025-10-18 01:36:20] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:38274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:41024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:43840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:44702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8019, token usage: 0.12, #running-req: 1013, #queue-req: 135, 
[2025-10-18 01:36:20] INFO:     127.0.0.1:35392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:36742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:37662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:43756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7329, token usage: 0.12, #running-req: 1014, #queue-req: 125, 
[2025-10-18 01:36:20] INFO:     127.0.0.1:35630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:36154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:36716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:39742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:40612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:41082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:20] INFO:     127.0.0.1:42806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5216, token usage: 0.12, #running-req: 1017, #queue-req: 118, 
[2025-10-18 01:36:21] INFO:     127.0.0.1:36068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:39618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:40766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:41428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:42376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:42426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21 TP0] Prefill batch. #new-seq: 15, #new-token: 15, #cached-token: 11032, token usage: 0.12, #running-req: 1009, #queue-req: 103, 
[2025-10-18 01:36:21] INFO:     127.0.0.1:35822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:39282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:44102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7297, token usage: 0.12, #running-req: 1014, #queue-req: 93, 
[2025-10-18 01:36:21] INFO:     127.0.0.1:35600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:39024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:39768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:42288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7961, token usage: 0.12, #running-req: 1013, #queue-req: 82, 
[2025-10-18 01:36:21] INFO:     127.0.0.1:35558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:39004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:40444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:40846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6544, token usage: 0.12, #running-req: 1015, #queue-req: 73, 
[2025-10-18 01:36:21] INFO:     127.0.0.1:35454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:36592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:37868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:38844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:40210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:40294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:41000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:41152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:21] INFO:     127.0.0.1:43978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9608, token usage: 0.12, #running-req: 1011, #queue-req: 60, 
[2025-10-18 01:36:22] INFO:     127.0.0.1:36918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:37390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:38696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:41048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:41358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:42370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7428, token usage: 0.12, #running-req: 1014, #queue-req: 50, 
[2025-10-18 01:36:22] INFO:     127.0.0.1:36058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:41196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:42316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:42612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:43886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:44496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:44618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9411, token usage: 0.13, #running-req: 1011, #queue-req: 37, 
[2025-10-18 01:36:22] INFO:     127.0.0.1:37548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:38060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:38640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:40800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:42156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:42838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:44008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7995, token usage: 0.13, #running-req: 1013, #queue-req: 26, 
[2025-10-18 01:36:22] INFO:     127.0.0.1:35810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:35982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:36454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:36518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:36976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:37228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:38830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:39570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:41582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:41770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22] INFO:     127.0.0.1:44426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:22 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9520, token usage: 0.13, #running-req: 1011, #queue-req: 13, 
[2025-10-18 01:36:23] INFO:     127.0.0.1:36722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:38396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:38794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:44512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6555, token usage: 0.13, #running-req: 1015, #queue-req: 4, 
[2025-10-18 01:36:23] INFO:     127.0.0.1:39482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:43388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2890, token usage: 0.13, #running-req: 1019, #queue-req: 0, 
[2025-10-18 01:36:23] INFO:     127.0.0.1:35458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:36758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:44184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:36750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:36830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:40600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42070 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP4] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP3] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP0] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP2] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP7] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP6] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP1] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP5] [fused_moe] using default for (1002, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23] INFO:     127.0.0.1:37592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:41448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:43720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:43736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:43804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:44346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:44394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:44636 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP4] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP2] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP3] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP6] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP0] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP7] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP1] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP5] [fused_moe] using default for (993, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23] INFO:     127.0.0.1:35584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:35918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:36546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:36910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:37114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:38254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:39674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:23] INFO:     127.0.0.1:42844 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP4] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP2] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP6] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP0] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP3] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP7] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP1] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:23 TP5] [fused_moe] using default for (980, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:44052 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (971, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43696 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (962, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:44448 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (950, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:36200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (943, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:37142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:41192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:41892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43966 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (932, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:41618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43768 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (922, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:38930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:44344 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (910, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24] INFO:     127.0.0.1:35312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:35992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:36762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:37488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:39974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:40884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:41272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:42564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:43994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:24] INFO:     127.0.0.1:44830 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP4] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP0] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP6] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP2] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP3] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP7] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP1] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:24 TP5] [fused_moe] using default for (893, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:35474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43460 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (879, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:35338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:35612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:37172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44548 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (870, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:35650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:37502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44574 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (846, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] Decode batch. #running-req: 856, #token: 113954, token usage: 0.12, cuda graph: False, gen throughput (token/s): 5601.52, #queue-req: 0, 
[2025-10-18 01:36:25] INFO:     127.0.0.1:38722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:35640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:37558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:38552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40814 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (832, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:35976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:43962 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (823, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:38730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:40636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:42416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:44690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:45168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:45352 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP2] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP4] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP6] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP0] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP5] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP1] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP3] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25 TP7] [fused_moe] using default for (811, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:25] INFO:     127.0.0.1:35926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:36482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:25] INFO:     127.0.0.1:39680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43848 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (801, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26] INFO:     127.0.0.1:36416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44858 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (790, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26] INFO:     127.0.0.1:36338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:37064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:37692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:45892 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (772, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26] INFO:     127.0.0.1:35748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:35788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:45296 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (760, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (750, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26] INFO:     127.0.0.1:36072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:45910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:44612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:35300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:35518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:36388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:37640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:37806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:38486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:39962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:40000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:41740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:42272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:26] INFO:     127.0.0.1:43688 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP2] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP4] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP6] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP0] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP3] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP7] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP1] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:26 TP5] [fused_moe] using default for (724, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:37176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:37772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45522 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (707, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:35652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45804 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (691, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:38128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45448 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (685, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:35382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:37790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:46074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:46654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:47058 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (666, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:35426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44772 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (658, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:36400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:43792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:35284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:37572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:37964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:35738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:35772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:42170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44850 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP1] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP2] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP3] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP0] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP4] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP6] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP7] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27 TP5] [fused_moe] using default for (629, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:27] INFO:     127.0.0.1:36376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:36506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:37310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:38744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:39638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:40558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:41302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:44650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:45864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:46026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:27] INFO:     127.0.0.1:47196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46452 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP4] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP0] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP2] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP6] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP3] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP7] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP1] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP5] [fused_moe] using default for (605, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28] INFO:     127.0.0.1:37324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:36898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:36004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:36298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45348 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP4] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP6] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP2] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP0] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP7] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP3] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP1] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP5] [fused_moe] using default for (571, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28] INFO:     127.0.0.1:35346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:47094 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP2] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP4] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP6] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP0] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP3] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP7] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP1] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP5] [fused_moe] using default for (557, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28] INFO:     127.0.0.1:36796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:36956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46664 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP2] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP4] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP6] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP0] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP3] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP7] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP1] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP5] [fused_moe] using default for (540, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28] INFO:     127.0.0.1:35412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:35792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:38200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46010 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP4] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP2] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP6] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP0] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP7] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP3] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP1] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28 TP5] [fused_moe] using default for (523, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:28] INFO:     127.0.0.1:35548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:42556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:46308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:39382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:43182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:45458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:37608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:40878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:41846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:28] INFO:     127.0.0.1:44268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:39452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:39652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:39388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:39344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:42862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29 TP0] Decode batch. #running-req: 447, #token: 73587, token usage: 0.08, cuda graph: True, gen throughput (token/s): 6382.63, #queue-req: 0, 
[2025-10-18 01:36:29] INFO:     127.0.0.1:35270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:39294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:36666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:43082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:35858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:40856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:36186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:36580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:38918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:47034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:36372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:37376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:41600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:44482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:45714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:29] INFO:     127.0.0.1:46700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:36310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:36990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:38044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:38062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:40744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:41032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:41590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:43308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:36960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:35682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:40560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:40970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:43652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:43314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:35440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:38514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:35916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:36930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:40092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:43920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:40180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:46906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:36622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:42404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:41536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:47314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:37198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:39310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:44786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:30] INFO:     127.0.0.1:45914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:37396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:40480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:41654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:37960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:40958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:37444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:41326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:35940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:39420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:39952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:41592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:39754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:40742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:41206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:36704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:47288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:38184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:39520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:41098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31 TP0] Decode batch. #running-req: 192, #token: 40585, token usage: 0.04, cuda graph: True, gen throughput (token/s): 5071.77, #queue-req: 0, 
[2025-10-18 01:36:31] INFO:     127.0.0.1:43522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:37550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:42912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:44900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:45776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:31] INFO:     127.0.0.1:46998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:37410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:42010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:44362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:39188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:36022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:44536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:38328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:41628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:43346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:36858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:38206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:37148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:36606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:44670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:37718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:38936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:42198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:44940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:44984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:41298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:42258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:37878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:43402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:35490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:40410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:45282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:46824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:32] INFO:     127.0.0.1:47204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:47390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:39260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:38462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:40712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:41116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:47262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:43934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:44460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:40262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:36630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:41616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:47082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:39592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:40574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:37174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:42600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:42560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:37578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:39278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:37780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:36420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:38030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:44876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:39108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33 TP0] Decode batch. #running-req: 64, #token: 17213, token usage: 0.02, cuda graph: True, gen throughput (token/s): 2916.19, #queue-req: 0, 
[2025-10-18 01:36:33] INFO:     127.0.0.1:46884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:45732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:36560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:38258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:40538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:46740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:36502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:44518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:47336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:42670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:43854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:33] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:45546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:44590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:47272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:39900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:45658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:47410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:42626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:43902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:42870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:36644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:41940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:35712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:36820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:42510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:47278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:45344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:45412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:35326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:36142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:45972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:47298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:43828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34 TP0] Decode batch. #running-req: 20, #token: 6629, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1287.79, #queue-req: 0, 
[2025-10-18 01:36:34] INFO:     127.0.0.1:46280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:38992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:47170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:34] INFO:     127.0.0.1:46166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:37918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:44606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:45568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:45268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:45198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:46104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:46334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:46960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:42458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:42766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:44746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35 TP0] Decode batch. #running-req: 4, #token: 2072, token usage: 0.00, cuda graph: True, gen throughput (token/s): 449.58, #queue-req: 0, 
[2025-10-18 01:36:35] INFO:     127.0.0.1:46058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:35] INFO:     127.0.0.1:44726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:36] INFO:     127.0.0.1:46212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:36 TP0] Decode batch. #running-req: 1, #token: 1119, token usage: 0.00, cuda graph: True, gen throughput (token/s): 92.46, #queue-req: 0, 
[2025-10-18 01:36:37 TP0] Decode batch. #running-req: 1, #token: 1159, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.56, #queue-req: 0, 
[2025-10-18 01:36:38 TP0] Decode batch. #running-req: 1, #token: 1199, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.51, #queue-req: 0, 
[2025-10-18 01:36:38] INFO:     127.0.0.1:42764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:51] INFO:     127.0.0.1:57548 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 666, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:36:52] INFO:     127.0.0.1:57550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 733, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 39, #new-token: 39, #cached-token: 28160, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 48, #new-token: 48, #cached-token: 35058, token usage: 0.01, #running-req: 40, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 48, #new-token: 48, #cached-token: 34957, token usage: 0.01, #running-req: 88, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 55, #new-token: 55, #cached-token: 40305, token usage: 0.01, #running-req: 136, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 51, #new-token: 51, #cached-token: 37072, token usage: 0.02, #running-req: 191, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 55, #new-token: 55, #cached-token: 39886, token usage: 0.02, #running-req: 242, #queue-req: 0, 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 54, #new-token: 54, #cached-token: 39329, token usage: 0.02, #running-req: 297, #queue-req: 0, 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP5] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP6] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP4] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP2] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP7] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP3] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP1] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP0] [fused_moe] using default for (54, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP0] Prefill batch. #new-seq: 59, #new-token: 59, #cached-token: 42902, token usage: 0.03, #running-req: 351, #queue-req: 0, 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP6] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP4] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP5] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP7] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP3] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP2] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP1] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:52 TP0] [fused_moe] using default for (59, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 40, #new-token: 40, #cached-token: 29448, token usage: 0.03, #running-req: 410, #queue-req: 0, 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10121, token usage: 0.03, #running-req: 450, #queue-req: 0, 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 77, #new-token: 77, #cached-token: 55809, token usage: 0.04, #running-req: 464, #queue-req: 0, 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP0] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP6] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP4] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP5] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP7] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP2] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP1] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP3] [fused_moe] using default for (77, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 50, #new-token: 50, #cached-token: 36324, token usage: 0.04, #running-req: 541, #queue-req: 0, 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 86, #new-token: 86, #cached-token: 62511, token usage: 0.04, #running-req: 591, #queue-req: 0, 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP0] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP4] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP5] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP3] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP6] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP2] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP1] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP7] [fused_moe] using default for (86, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:53 TP0] Prefill batch. #new-seq: 60, #new-token: 60, #cached-token: 43691, token usage: 0.05, #running-req: 677, #queue-req: 0, 
[2025-10-18 01:36:54 TP0] Prefill batch. #new-seq: 90, #new-token: 90, #cached-token: 65784, token usage: 0.05, #running-req: 737, #queue-req: 0, 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP4] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP5] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP3] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP1] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP6] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP2] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP7] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP0] [fused_moe] using default for (90, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP0] Prefill batch. #new-seq: 63, #new-token: 63, #cached-token: 45686, token usage: 0.06, #running-req: 827, #queue-req: 0, 
[2025-10-18 01:36:54 TP0] Prefill batch. #new-seq: 93, #new-token: 93, #cached-token: 67963, token usage: 0.06, #running-req: 890, #queue-req: 0, 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP0] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP5] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP3] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP2] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP4] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP7] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP6] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP1] [fused_moe] using default for (93, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:36:54 TP0] Prefill batch. #new-seq: 41, #new-token: 41, #cached-token: 30133, token usage: 0.07, #running-req: 983, #queue-req: 22, 
[2025-10-18 01:36:55 TP0] Decode batch. #running-req: 1024, #token: 66589, token usage: 0.07, cuda graph: False, gen throughput (token/s): 229.51, #queue-req: 247, 
[2025-10-18 01:36:56] INFO:     127.0.0.1:58086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 756, token usage: 0.08, #running-req: 1023, #queue-req: 294, 
[2025-10-18 01:36:57] INFO:     127.0.0.1:60388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 745, token usage: 0.09, #running-req: 1023, #queue-req: 293, 
[2025-10-18 01:36:58] INFO:     127.0.0.1:60432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:58] INFO:     127.0.0.1:38082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 733, token usage: 0.10, #running-req: 1023, #queue-req: 292, 
[2025-10-18 01:36:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 779, token usage: 0.10, #running-req: 1023, #queue-req: 291, 
[2025-10-18 01:36:59] INFO:     127.0.0.1:57584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:58158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:32916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:58468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2255, token usage: 0.10, #running-req: 1021, #queue-req: 288, 
[2025-10-18 01:36:59] INFO:     127.0.0.1:58804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:59998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:60300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2957, token usage: 0.11, #running-req: 1020, #queue-req: 284, 
[2025-10-18 01:36:59] INFO:     127.0.0.1:58688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59] INFO:     127.0.0.1:60414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:36:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1447, token usage: 0.11, #running-req: 1022, #queue-req: 282, 
[2025-10-18 01:37:00] INFO:     127.0.0.1:57980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:57982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:58190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:58716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2904, token usage: 0.11, #running-req: 1020, #queue-req: 278, 
[2025-10-18 01:37:00] INFO:     127.0.0.1:57716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:59226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:60838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:33988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:34154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3631, token usage: 0.11, #running-req: 1019, #queue-req: 273, 
[2025-10-18 01:37:00] INFO:     127.0.0.1:58134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:60022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:60702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:33132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:35232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:35770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:38148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5027, token usage: 0.11, #running-req: 1017, #queue-req: 266, 
[2025-10-18 01:37:00 TP0] Decode batch. #running-req: 1017, #token: 105766, token usage: 0.11, cuda graph: False, gen throughput (token/s): 7412.85, #queue-req: 266, 
[2025-10-18 01:37:00] INFO:     127.0.0.1:35254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:38052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1481, token usage: 0.11, #running-req: 1022, #queue-req: 264, 
[2025-10-18 01:37:00] INFO:     127.0.0.1:58122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:58592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:60982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:34212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:34298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:34374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:34690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:37344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00] INFO:     127.0.0.1:38380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:00 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6466, token usage: 0.11, #running-req: 1015, #queue-req: 255, 
[2025-10-18 01:37:01] INFO:     127.0.0.1:57570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:59686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:59866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:60378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:34482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:36104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:38138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:38252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6574, token usage: 0.11, #running-req: 1015, #queue-req: 246, 
[2025-10-18 01:37:01] INFO:     127.0.0.1:58204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:58612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:59712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2882, token usage: 0.11, #running-req: 1020, #queue-req: 242, 
[2025-10-18 01:37:01] INFO:     127.0.0.1:58840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:59870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:34216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:35512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 3049, token usage: 0.11, #running-req: 1020, #queue-req: 238, 
[2025-10-18 01:37:01] INFO:     127.0.0.1:60138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:33834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:34060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:34274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:36782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:38216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5851, token usage: 0.11, #running-req: 1016, #queue-req: 230, 
[2025-10-18 01:37:01] INFO:     127.0.0.1:58460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:58576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:58944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:59498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:60624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:33320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:35810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:36852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:37778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:38036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01] INFO:     127.0.0.1:38422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:01 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9466, token usage: 0.11, #running-req: 1011, #queue-req: 217, 
[2025-10-18 01:37:02] INFO:     127.0.0.1:57986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:58768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:60826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:32888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:34604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:36672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:37178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:38318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7219, token usage: 0.12, #running-req: 1014, #queue-req: 207, 
[2025-10-18 01:37:02] INFO:     127.0.0.1:58438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:32806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:33910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:33964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:34394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:35124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:35874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:38356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6502, token usage: 0.12, #running-req: 1015, #queue-req: 198, 
[2025-10-18 01:37:02] INFO:     127.0.0.1:57560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:60850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:33562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:35008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:35300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:37404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:37556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8006, token usage: 0.12, #running-req: 1013, #queue-req: 187, 
[2025-10-18 01:37:02] INFO:     127.0.0.1:58498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:59898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:60160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:60280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:60936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:33872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:34706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:37502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02] INFO:     127.0.0.1:37628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:02 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7304, token usage: 0.12, #running-req: 1014, #queue-req: 177, 
[2025-10-18 01:37:03] INFO:     127.0.0.1:59084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:60490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:33498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:34276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:38558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5764, token usage: 0.12, #running-req: 1016, #queue-req: 169, 
[2025-10-18 01:37:03] INFO:     127.0.0.1:34092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:36298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2117, token usage: 0.12, #running-req: 1021, #queue-req: 166, 
[2025-10-18 01:37:03] INFO:     127.0.0.1:35518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:36004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:36466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:37832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3611, token usage: 0.12, #running-req: 1019, #queue-req: 161, 
[2025-10-18 01:37:03] INFO:     127.0.0.1:58674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3624, token usage: 0.12, #running-req: 1019, #queue-req: 156, 
[2025-10-18 01:37:03] INFO:     127.0.0.1:59112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:59852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:32780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:33666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:37368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03] INFO:     127.0.0.1:37690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:03 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6563, token usage: 0.12, #running-req: 1015, #queue-req: 147, 
[2025-10-18 01:37:04] INFO:     127.0.0.1:58082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:33924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:38136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7357, token usage: 0.12, #running-req: 1014, #queue-req: 137, 
[2025-10-18 01:37:04] INFO:     127.0.0.1:58858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:32776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:33844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:33906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:38602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6484, token usage: 0.12, #running-req: 1015, #queue-req: 128, 
[2025-10-18 01:37:04] INFO:     127.0.0.1:57856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:58228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:33428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10381, token usage: 0.12, #running-req: 1010, #queue-req: 114, 
[2025-10-18 01:37:04] INFO:     127.0.0.1:58176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:58540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:33098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:35628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10397, token usage: 0.12, #running-req: 1010, #queue-req: 100, 
[2025-10-18 01:37:04] INFO:     127.0.0.1:57872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:57960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:59710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:60260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:34802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:36442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04] INFO:     127.0.0.1:37578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:04 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10085, token usage: 0.12, #running-req: 1010, #queue-req: 86, 
[2025-10-18 01:37:05] INFO:     127.0.0.1:57748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:57994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:58946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:59526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:32816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:34934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7963, token usage: 0.12, #running-req: 1013, #queue-req: 75, 
[2025-10-18 01:37:05] INFO:     127.0.0.1:36312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:59300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:33060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4511, token usage: 0.12, #running-req: 1018, #queue-req: 69, 
[2025-10-18 01:37:05] INFO:     127.0.0.1:58450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:58786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:58862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:59584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:33172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:33308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:34014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:34358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8034, token usage: 0.12, #running-req: 1013, #queue-req: 58, 
[2025-10-18 01:37:05] INFO:     127.0.0.1:59628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:33076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:36778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5973, token usage: 0.13, #running-req: 1016, #queue-req: 50, 
[2025-10-18 01:37:05] INFO:     127.0.0.1:57808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:58162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:59338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:60644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:35316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:36388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:05] INFO:     127.0.0.1:37608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5816, token usage: 0.13, #running-req: 1016, #queue-req: 42, 
[2025-10-18 01:37:06] INFO:     127.0.0.1:57904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38500 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP1] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP2] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP3] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP5] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP6] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP4] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP0] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP7] [fused_moe] using default for (1005, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP0] Prefill batch. #new-seq: 19, #new-token: 19, #cached-token: 13793, token usage: 0.13, #running-req: 1005, #queue-req: 23, 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP2] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP6] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP3] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP1] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP5] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP4] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP7] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP0] [fused_moe] using default for (19, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06] INFO:     127.0.0.1:58926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:32808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:32834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 9532, token usage: 0.13, #running-req: 1011, #queue-req: 10, 
[2025-10-18 01:37:06] INFO:     127.0.0.1:57756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:58296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:34996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7230, token usage: 0.13, #running-req: 1009, #queue-req: 0, 
[2025-10-18 01:37:06] INFO:     127.0.0.1:59122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:59568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:33970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:35682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:36236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:37844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:06] INFO:     127.0.0.1:38472 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP2] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP1] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP3] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP5] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP6] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP4] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP7] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:06 TP0] [fused_moe] using default for (1004, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07] INFO:     127.0.0.1:58628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:38114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:38244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:57830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:38288 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP1] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP3] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP2] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP6] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP5] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP4] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP7] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP0] [fused_moe] using default for (973, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07] INFO:     127.0.0.1:57774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:36906 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP2] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP1] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP3] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP6] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP5] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP4] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP7] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP0] [fused_moe] using default for (961, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07] INFO:     127.0.0.1:57728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:57940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:32820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:35348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:38034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:33734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:38492 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP1] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP2] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP3] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP6] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP5] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP4] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP0] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07 TP7] [fused_moe] using default for (930, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:07] INFO:     127.0.0.1:57900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:58482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:59790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:60962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:32928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:34300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:07] INFO:     127.0.0.1:37674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:57608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:38242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:38420 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (905, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] Decode batch. #running-req: 920, #token: 116660, token usage: 0.12, cuda graph: False, gen throughput (token/s): 5307.99, #queue-req: 0, 
[2025-10-18 01:37:08] INFO:     127.0.0.1:60418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37796 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (894, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08] INFO:     127.0.0.1:57652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:57920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:38246 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (885, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08] INFO:     127.0.0.1:58334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:32792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:32904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37048 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (874, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08] INFO:     127.0.0.1:58742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37994 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (863, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08] INFO:     127.0.0.1:58910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:33334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:57902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:60954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:32866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:38260 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (849, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08] INFO:     127.0.0.1:57590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:58818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:59232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:34888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:35640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:36818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:08] INFO:     127.0.0.1:37946 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP2] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP1] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP3] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP6] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP4] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP5] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP7] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:08 TP0] [fused_moe] using default for (829, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09] INFO:     127.0.0.1:58188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:57926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:59884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:32850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39294 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP1] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP3] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP2] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP6] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP5] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP4] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP7] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP0] [fused_moe] using default for (794, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09] INFO:     127.0.0.1:58552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:32770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:59440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37846 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP1] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP2] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP6] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP3] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP0] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP4] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP5] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP7] [fused_moe] using default for (777, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09] INFO:     127.0.0.1:57760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34466 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP1] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP2] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP3] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP5] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP4] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP6] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP7] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP0] [fused_moe] using default for (763, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09] INFO:     127.0.0.1:58198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:36968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:57974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:60948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:37716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:58516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:33772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:34242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:35268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:38298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:09] INFO:     127.0.0.1:39210 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP2] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP1] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP3] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP6] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP5] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP0] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP4] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:09 TP7] [fused_moe] using default for (741, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:57664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:58704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38302 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (731, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:58210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:58636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:32836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39674 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (706, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:57698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:58068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39366 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (690, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:57744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38792 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (676, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:60312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:60756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:36548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:37818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:39858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:40004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:40784 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (660, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10] INFO:     127.0.0.1:58748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:59984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:33714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:34544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:35836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:10] INFO:     127.0.0.1:38140 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP1] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP2] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP3] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP6] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP5] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP4] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP0] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:10 TP7] [fused_moe] using default for (651, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:57784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39458 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (643, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:57602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37932 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (630, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:58282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39714 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (622, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:60190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:32862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40902 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (608, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:58112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:59352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:59818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40230 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (596, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:57816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:57686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:57702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:32886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38854 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (576, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:58262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:59896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:34020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40764 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (564, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11] INFO:     127.0.0.1:57722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:59170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:32958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:33554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:36450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:58542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:35792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:37294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:38728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:39118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:11] INFO:     127.0.0.1:40808 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP1] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP2] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP5] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP6] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP4] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP0] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP3] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:11 TP7] [fused_moe] using default for (538, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12] INFO:     127.0.0.1:59428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40382 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP1] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP2] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP5] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP3] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP0] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP6] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP4] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP7] [fused_moe] using default for (522, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12] INFO:     127.0.0.1:59286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:59728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39840 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP1] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP2] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP0] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP6] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP5] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP4] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP3] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12 TP7] [fused_moe] using default for (514, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:12] INFO:     127.0.0.1:57636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:59964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:58026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:32944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:57848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12 TP0] Decode batch. #running-req: 494, #token: 79985, token usage: 0.08, cuda graph: True, gen throughput (token/s): 6515.79, #queue-req: 0, 
[2025-10-18 01:37:12] INFO:     127.0.0.1:33596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:32790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:59404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:60528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:35636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:57578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:36062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:33472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:38864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:59158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:59832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:34414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:37252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:39300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:40716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:12] INFO:     127.0.0.1:41056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:32908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:32986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:33114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:41048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:58446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:33952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:58602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:41018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:58146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:33028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:37838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:37682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:37802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:37376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:57730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:58096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:35170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:34964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:37312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:58588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:33608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:41094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:38620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:59820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:60610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:36736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:39888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:40650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:41022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:13] INFO:     127.0.0.1:41122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:37910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:41066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:41126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:37174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:37960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:34338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:41104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:57612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:35906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:41080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:35458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:58402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:32998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:36792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:36412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:41074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:32880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:35260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:35360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:36766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:36042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:36998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:57792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:60460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14 TP0] Decode batch. #running-req: 221, #token: 44696, token usage: 0.05, cuda graph: True, gen throughput (token/s): 5736.33, #queue-req: 0, 
[2025-10-18 01:37:14] INFO:     127.0.0.1:59592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:34666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:59244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:33296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:34444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:38936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:39662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:14] INFO:     127.0.0.1:40706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:57888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:35542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:33418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:35174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:57678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:36046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:60786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:33622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:34918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:36754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:37598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:41072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:57846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:34052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:35742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:60720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:34332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:35030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:36026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:59538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:37430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:32938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:38968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:34616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:57624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:58830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:39178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:15] INFO:     127.0.0.1:40534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:58362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:60074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:38772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:35134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:60230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:35716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:37480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:36746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:35446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:41098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:60132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:35272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:58988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:58898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:60262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:37922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:33416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:33720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:38696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16 TP0] Decode batch. #running-req: 78, #token: 19789, token usage: 0.02, cuda graph: True, gen throughput (token/s): 3188.52, #queue-req: 0, 
[2025-10-18 01:37:16] INFO:     127.0.0.1:59014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:60512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:36688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:38808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:58560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:33196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:34256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:37648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:36534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:39350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:40546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:16] INFO:     127.0.0.1:41032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:34742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:41112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:36692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:38322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:39478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:36286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:33406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:35890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:34196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:38490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:39936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:38780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:57954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:58010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:58996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:37896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:36012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:36952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:39266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:33012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17] INFO:     127.0.0.1:40538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:17 TP0] Decode batch. #running-req: 29, #token: 8414, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1464.19, #queue-req: 0, 
[2025-10-18 01:37:17] INFO:     127.0.0.1:37862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:41006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:59182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:32974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:40572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:60328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:36828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:38586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:38762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:58490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:40876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:40728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:36810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:40684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:36474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18] INFO:     127.0.0.1:39856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:18 TP0] Decode batch. #running-req: 5, #token: 2350, token usage: 0.00, cuda graph: True, gen throughput (token/s): 595.46, #queue-req: 0, 
[2025-10-18 01:37:18] INFO:     127.0.0.1:40156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:19] INFO:     127.0.0.1:39968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:19] INFO:     127.0.0.1:38612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:19 TP0] Decode batch. #running-req: 2, #token: 1504, token usage: 0.00, cuda graph: True, gen throughput (token/s): 144.82, #queue-req: 0, 
[2025-10-18 01:37:19] INFO:     127.0.0.1:38626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:20] INFO:     127.0.0.1:59408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:33] INFO:     127.0.0.1:55126 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 666, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:37:33] INFO:     127.0.0.1:55130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 733, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 39, #new-token: 39, #cached-token: 28365, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 47, #new-token: 47, #cached-token: 34082, token usage: 0.01, #running-req: 40, #queue-req: 0, 
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 49, #new-token: 49, #cached-token: 35728, token usage: 0.01, #running-req: 87, #queue-req: 0, 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP4] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP6] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP7] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP3] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP5] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP2] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP1] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP0] [fused_moe] using default for (49, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 54, #new-token: 54, #cached-token: 39598, token usage: 0.01, #running-req: 136, #queue-req: 0, 
[2025-10-18 01:37:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 696, token usage: 0.01, #running-req: 190, #queue-req: 0, 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 16, #new-token: 16, #cached-token: 11714, token usage: 0.01, #running-req: 191, #queue-req: 0, 
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP4] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP7] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP6] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP5] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP3] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP1] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP2] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] shape M:16, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 66, #new-token: 66, #cached-token: 47787, token usage: 0.02, #running-req: 207, #queue-req: 0, 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 49, #new-token: 49, #cached-token: 35624, token usage: 0.02, #running-req: 273, #queue-req: 0, 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 73, #new-token: 73, #cached-token: 53153, token usage: 0.03, #running-req: 322, #queue-req: 0, 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP0] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP4] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP6] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP7] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP5] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP2] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP3] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP1] [fused_moe] using default for (73, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 54, #new-token: 54, #cached-token: 39626, token usage: 0.03, #running-req: 395, #queue-req: 0, 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 78, #new-token: 78, #cached-token: 56529, token usage: 0.03, #running-req: 449, #queue-req: 0, 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP4] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP7] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP6] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP3] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP1] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP2] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP5] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP0] [fused_moe] using default for (78, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP0] Prefill batch. #new-seq: 57, #new-token: 57, #cached-token: 41304, token usage: 0.04, #running-req: 527, #queue-req: 0, 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP4] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP3] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP1] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP2] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP5] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP6] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP7] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:34 TP0] [fused_moe] using default for (57, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 84, #new-token: 84, #cached-token: 61118, token usage: 0.04, #running-req: 584, #queue-req: 0, 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP3] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP4] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP2] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP7] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP6] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP1] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP0] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP5] [fused_moe] using default for (84, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 60, #new-token: 60, #cached-token: 43747, token usage: 0.05, #running-req: 668, #queue-req: 0, 
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 89, #new-token: 89, #cached-token: 64977, token usage: 0.05, #running-req: 728, #queue-req: 0, 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP4] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP3] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP6] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP2] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP1] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP7] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP5] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP0] [fused_moe] using default for (89, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 64, #new-token: 64, #cached-token: 46480, token usage: 0.06, #running-req: 817, #queue-req: 0, 
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:3072, K:1536 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:4096, K:512 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:7168, K:2048 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x128x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_8_1x2_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:4608, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:7168, K:2304 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x64x64x256_16x16_32x32_16x16x1_16x16x1_1x32x1x8_8_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP1] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP2] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP3] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP0] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP4] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:512, K:7168 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x16x64x256_16x16_16x16_16x16x1_16x16x1_1x16x1x16_4_1x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP7] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[aiter] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP5] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP6] shape M:64, N:7168, K:256 is tuned on cu_num = 304 in CKGEMM, kernel name is a8w8_blockscale_1x128x128_256x32x64x256_16x16_16x16_16x16x1_16x16x1_1x32x1x8_8_2x1_intrawave_v1!
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 93, #new-token: 93, #cached-token: 67952, token usage: 0.06, #running-req: 881, #queue-req: 0, 
[2025-10-18 01:37:35 TP0] Prefill batch. #new-seq: 50, #new-token: 50, #cached-token: 36704, token usage: 0.06, #running-req: 974, #queue-req: 67, 
[2025-10-18 01:37:37 TP0] Decode batch. #running-req: 1024, #token: 70717, token usage: 0.07, cuda graph: False, gen throughput (token/s): 459.92, #queue-req: 295, 
[2025-10-18 01:37:39] INFO:     127.0.0.1:58110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 723, token usage: 0.09, #running-req: 1023, #queue-req: 294, 
[2025-10-18 01:37:39] INFO:     127.0.0.1:55786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 710, token usage: 0.09, #running-req: 1023, #queue-req: 293, 
[2025-10-18 01:37:40] INFO:     127.0.0.1:58164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:40] INFO:     127.0.0.1:55922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 737, token usage: 0.10, #running-req: 1023, #queue-req: 292, 
[2025-10-18 01:37:40] INFO:     127.0.0.1:55166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:40] INFO:     127.0.0.1:56224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:40 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2254, token usage: 0.10, #running-req: 1021, #queue-req: 289, 
[2025-10-18 01:37:40] INFO:     127.0.0.1:56384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 779, token usage: 0.10, #running-req: 1023, #queue-req: 288, 
[2025-10-18 01:37:41] INFO:     127.0.0.1:56342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 730, token usage: 0.11, #running-req: 1023, #queue-req: 287, 
[2025-10-18 01:37:41] INFO:     127.0.0.1:55492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:55502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:55802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:58808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:59902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41 TP0] Prefill batch. #new-seq: 5, #new-token: 5, #cached-token: 3664, token usage: 0.11, #running-req: 1019, #queue-req: 282, 
[2025-10-18 01:37:41] INFO:     127.0.0.1:56822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:59550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1482, token usage: 0.11, #running-req: 1022, #queue-req: 280, 
[2025-10-18 01:37:41] INFO:     127.0.0.1:57648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:58028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:60916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2178, token usage: 0.11, #running-req: 1021, #queue-req: 277, 
[2025-10-18 01:37:41] INFO:     127.0.0.1:60946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:41] INFO:     127.0.0.1:35512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 1464, token usage: 0.11, #running-req: 1022, #queue-req: 275, 
[2025-10-18 01:37:42] INFO:     127.0.0.1:55876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:56824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:57412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:59514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:60058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:60176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:60436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5026, token usage: 0.11, #running-req: 1017, #queue-req: 268, 
[2025-10-18 01:37:42] INFO:     127.0.0.1:55138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:56442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:60292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:33570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:35618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:35748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4364, token usage: 0.11, #running-req: 1018, #queue-req: 262, 
[2025-10-18 01:37:42] INFO:     127.0.0.1:55452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:56126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:58408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:58960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:60074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:33774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:34962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:35640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5758, token usage: 0.11, #running-req: 1016, #queue-req: 254, 
[2025-10-18 01:37:42] INFO:     127.0.0.1:56348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:56406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:32996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 2142, token usage: 0.11, #running-req: 1021, #queue-req: 251, 
[2025-10-18 01:37:42 TP0] Decode batch. #running-req: 1021, #token: 108848, token usage: 0.11, cuda graph: False, gen throughput (token/s): 6941.68, #queue-req: 251, 
[2025-10-18 01:37:42] INFO:     127.0.0.1:58638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:59704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:59870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:34770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:35086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:42] INFO:     127.0.0.1:35684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4437, token usage: 0.11, #running-req: 1018, #queue-req: 245, 
[2025-10-18 01:37:43] INFO:     127.0.0.1:55980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:58096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:58258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:35186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:36158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43 TP0] Prefill batch. #new-seq: 15, #new-token: 15, #cached-token: 11044, token usage: 0.11, #running-req: 1009, #queue-req: 230, 
[2025-10-18 01:37:43] INFO:     127.0.0.1:55588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:58522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:58572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:60362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:35848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43 TP0] Prefill batch. #new-seq: 10, #new-token: 10, #cached-token: 7311, token usage: 0.11, #running-req: 1014, #queue-req: 220, 
[2025-10-18 01:37:43] INFO:     127.0.0.1:56010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:59124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:59824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:59842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:60210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:60808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6482, token usage: 0.12, #running-req: 1015, #queue-req: 211, 
[2025-10-18 01:37:43] INFO:     127.0.0.1:55136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:59390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:60686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:32822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:33242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5014, token usage: 0.12, #running-req: 1017, #queue-req: 204, 
[2025-10-18 01:37:43] INFO:     127.0.0.1:55732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:56676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:57984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:58322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:60444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:32908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:33264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:43] INFO:     127.0.0.1:34912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5858, token usage: 0.12, #running-req: 1016, #queue-req: 196, 
[2025-10-18 01:37:44] INFO:     127.0.0.1:56712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:58506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:58784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:59300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:34964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5072, token usage: 0.12, #running-req: 1017, #queue-req: 189, 
[2025-10-18 01:37:44] INFO:     127.0.0.1:57212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:58692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:59636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:59794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5129, token usage: 0.12, #running-req: 1017, #queue-req: 182, 
[2025-10-18 01:37:44] INFO:     127.0.0.1:56972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:58594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:32910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:35794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5763, token usage: 0.12, #running-req: 1016, #queue-req: 174, 
[2025-10-18 01:37:44] INFO:     127.0.0.1:56116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:57842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:60730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:33460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44] INFO:     127.0.0.1:34910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:44 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 7898, token usage: 0.12, #running-req: 1013, #queue-req: 163, 
[2025-10-18 01:37:45] INFO:     127.0.0.1:55314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:55524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:58220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:58526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:32970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6523, token usage: 0.12, #running-req: 1015, #queue-req: 154, 
[2025-10-18 01:37:45] INFO:     127.0.0.1:56704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:32878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:33108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45 TP0] Prefill batch. #new-seq: 8, #new-token: 8, #cached-token: 5877, token usage: 0.12, #running-req: 1016, #queue-req: 146, 
[2025-10-18 01:37:45] INFO:     127.0.0.1:55534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:57934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5145, token usage: 0.12, #running-req: 1017, #queue-req: 139, 
[2025-10-18 01:37:45] INFO:     127.0.0.1:56050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:59656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6510, token usage: 0.12, #running-req: 1015, #queue-req: 130, 
[2025-10-18 01:37:45] INFO:     127.0.0.1:55780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:56778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:57350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:57446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:34364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45] INFO:     127.0.0.1:35486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:45 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 8909, token usage: 0.12, #running-req: 1012, #queue-req: 118, 
[2025-10-18 01:37:46] INFO:     127.0.0.1:55716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:56604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:56648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:56742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:59948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:60378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:34486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:34608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:34990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8075, token usage: 0.12, #running-req: 1013, #queue-req: 107, 
[2025-10-18 01:37:46] INFO:     127.0.0.1:55374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:55900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:56546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:57968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:60620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46 TP0] Prefill batch. #new-seq: 11, #new-token: 11, #cached-token: 8109, token usage: 0.12, #running-req: 1013, #queue-req: 96, 
[2025-10-18 01:37:46] INFO:     127.0.0.1:56924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:59244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:34874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 5022, token usage: 0.12, #running-req: 1017, #queue-req: 89, 
[2025-10-18 01:37:46] INFO:     127.0.0.1:56028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:56984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:57568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:59598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:59846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:60340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:60968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:33984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 10146, token usage: 0.12, #running-req: 1010, #queue-req: 75, 
[2025-10-18 01:37:46] INFO:     127.0.0.1:56944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:57528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:57936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:46] INFO:     127.0.0.1:35058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47 TP0] Prefill batch. #new-seq: 4, #new-token: 4, #cached-token: 2951, token usage: 0.13, #running-req: 1020, #queue-req: 71, 
[2025-10-18 01:37:47] INFO:     127.0.0.1:55438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:32794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:35008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 8849, token usage: 0.13, #running-req: 1012, #queue-req: 59, 
[2025-10-18 01:37:47] INFO:     127.0.0.1:55372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:55950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:59694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:35332 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP4] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP2] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP6] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP3] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP7] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP1] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP5] [fused_moe] using default for (1007, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] Prefill batch. #new-seq: 17, #new-token: 17, #cached-token: 12534, token usage: 0.13, #running-req: 1007, #queue-req: 42, 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP4] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP6] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP7] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP2] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP3] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP5] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP1] [fused_moe] using default for (17, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6545, token usage: 0.13, #running-req: 1015, #queue-req: 33, 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP6] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP4] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP7] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP5] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP3] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP1] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP2] [fused_moe] using default for (1006, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47] INFO:     127.0.0.1:55608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:59106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:32848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:32984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:55656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:56746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:35880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47 TP0] Prefill batch. #new-seq: 18, #new-token: 18, #cached-token: 13114, token usage: 0.13, #running-req: 1006, #queue-req: 15, 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP4] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP6] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP7] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP2] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP3] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP0] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP5] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47 TP1] [fused_moe] using default for (18, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:47] INFO:     127.0.0.1:56812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:57602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:58326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:59146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:59800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:33836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:34208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:47] INFO:     127.0.0.1:35834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48 TP0] Prefill batch. #new-seq: 9, #new-token: 9, #cached-token: 6576, token usage: 0.13, #running-req: 1015, #queue-req: 6, 
[2025-10-18 01:37:48] INFO:     127.0.0.1:55602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48 TP0] Prefill batch. #new-seq: 6, #new-token: 6, #cached-token: 4320, token usage: 0.13, #running-req: 1009, #queue-req: 0, 
[2025-10-18 01:37:48] INFO:     127.0.0.1:55616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:55576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:32810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35720 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP0] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP6] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP2] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP4] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP3] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP7] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP1] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP5] [fused_moe] using default for (996, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48] INFO:     127.0.0.1:55910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:55960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35770 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP4] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP2] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP6] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP0] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP3] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP7] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP1] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP5] [fused_moe] using default for (985, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48] INFO:     127.0.0.1:55340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:55558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:60346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:32832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35132 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP2] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP6] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP4] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP0] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP3] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP7] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP1] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP5] [fused_moe] using default for (970, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48] INFO:     127.0.0.1:55752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:56078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:57092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:58942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:59590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:60512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:33662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:34720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:48] INFO:     127.0.0.1:35472 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP2] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP6] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP4] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP0] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP3] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP7] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP1] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:48 TP5] [fused_moe] using default for (960, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:58342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35146 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (952, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:55186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:56626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:36072 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (942, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:55458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:56240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33430 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (925, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:55726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:56130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:58074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:58502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35234 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (908, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:55244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:55832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:56172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:56696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:58614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:33864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:36262 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (895, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:56190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:57538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:58814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35454 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (887, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49] INFO:     127.0.0.1:56096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:59660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:60766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:32894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:34498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:49] INFO:     127.0.0.1:35754 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP2] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP6] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP4] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP0] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP3] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP1] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP7] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:49 TP5] [fused_moe] using default for (876, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50] INFO:     127.0.0.1:56750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35924 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (867, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] Decode batch. #running-req: 876, #token: 115580, token usage: 0.12, cuda graph: False, gen throughput (token/s): 5445.78, #queue-req: 0, 
[2025-10-18 01:37:50] INFO:     127.0.0.1:55510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:55998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:57640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:55174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:56390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:56460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:57700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36208 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (842, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50] INFO:     127.0.0.1:55678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:55942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35918 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (837, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50] INFO:     127.0.0.1:57304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:55816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:56290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:57190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:57460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33884 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (818, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50] INFO:     127.0.0.1:56160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:58148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:32874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36860 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (808, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50] INFO:     127.0.0.1:56374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:59168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:60544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:32808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:33086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:34980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:50] INFO:     127.0.0.1:36628 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP2] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP6] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP4] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP0] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP3] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP7] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP1] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:50 TP5] [fused_moe] using default for (795, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:55370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:55388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34522 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (787, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:55728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:56206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58382 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:58394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59004 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:59076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60550 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:35704 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:36344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (774, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:57068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:57366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35882 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (765, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:56274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:56470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:32962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (747, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:55256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:56030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:56346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:37364 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (737, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:56254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:36082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:55742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:56070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:57788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:36200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:57468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:36806 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (714, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51] INFO:     127.0.0.1:57820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:57826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:58994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:59742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:60868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:33632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:34744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:35984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:36876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:51] INFO:     127.0.0.1:37038 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP2] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP6] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP4] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP0] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP3] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP7] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP1] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:51 TP5] [fused_moe] using default for (700, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52] INFO:     127.0.0.1:55358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:56794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37276 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP2] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP6] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP4] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP0] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP3] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP7] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP1] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP5] [fused_moe] using default for (692, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52] INFO:     127.0.0.1:56754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:32946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:56014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:56836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:57206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:38022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:38420 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP6] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP2] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP4] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP3] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP0] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP7] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP1] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP5] [fused_moe] using default for (662, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52] INFO:     127.0.0.1:58908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37658 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP2] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP4] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP6] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP0] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP3] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP7] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP1] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP5] [fused_moe] using default for (653, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52] INFO:     127.0.0.1:56520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:57874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35570 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP4] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP6] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP2] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP0] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP3] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP1] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP7] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP5] [fused_moe] using default for (644, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52] INFO:     127.0.0.1:55770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:55972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:56150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:57334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:57462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:58048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:33704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:34542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:35916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:37486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:55264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:55300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:55404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:56774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:59090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:32994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:52] INFO:     127.0.0.1:36758 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP4] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP2] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP6] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP0] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP3] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP7] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP1] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:52 TP5] [fused_moe] using default for (611, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:55660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:32920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:38524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:32930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36914 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP6] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP4] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP2] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP7] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP5] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP0] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP3] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP1] [fused_moe] using default for (597, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:55632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37854 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP2] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP6] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP4] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP0] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP1] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP3] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP5] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP7] [fused_moe] using default for (586, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:55328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35980 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP2] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP6] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP0] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP4] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP3] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP7] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP1] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP5] [fused_moe] using default for (575, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:55242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:55674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:38450 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP2] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP4] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP6] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP0] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP3] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP7] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP1] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP5] [fused_moe] using default for (545, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:56638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:32864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:38062 - "POST /generate HTTP/1.1" 200 OK
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP2] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP6] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP4] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP0] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP3] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP7] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP1] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[aiter] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53 TP5] [fused_moe] using default for (532, 7168, 256, 256, 8, 'ActivationType.Silu', 'torch.bfloat16', 'torch.float8_e4m3fnuz', 'torch.float8_e4m3fnuz', 'QuantType.per_128x128', True, False) 
[2025-10-18 01:37:53] INFO:     127.0.0.1:56908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:55478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:56878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:35662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:58634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:60464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:55702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:57900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:59732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:33388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:34348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:36132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:37402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:53] INFO:     127.0.0.1:38108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:56964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:35318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:55154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:32846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54 TP0] Decode batch. #running-req: 460, #token: 75296, token usage: 0.08, cuda graph: True, gen throughput (token/s): 6349.15, #queue-req: 0, 
[2025-10-18 01:37:54] INFO:     127.0.0.1:57066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:34624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:35696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:56268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:32782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:56322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:59990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:36496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:58856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:55762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:57080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:33200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:35236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:37224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:54] INFO:     127.0.0.1:38246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:58898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:34800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:55350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:58068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:58956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:34476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:58462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:59434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:59438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:55884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:55572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:34218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:55664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:58568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:59358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:59280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:55866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:37884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:56766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:57380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:59188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:60420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:33494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:35496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:36644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:55] INFO:     127.0.0.1:38492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:60796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:34258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:60702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:34484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:33722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:59648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:59964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:33492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:35650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:60836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:58172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56 TP0] Decode batch. #running-req: 208, #token: 42483, token usage: 0.04, cuda graph: True, gen throughput (token/s): 5535.54, #queue-req: 0, 
[2025-10-18 01:37:56] INFO:     127.0.0.1:55914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:59228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:32934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:60954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:32862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:33522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:57634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:60472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:55464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:59122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:36392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:37750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:56] INFO:     127.0.0.1:38568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:33214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:34190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:35462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:35732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:34840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:35952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:56542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:59016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:57422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:58184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:58416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:57726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:55284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:57132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:56060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:34996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:59454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:34160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:55420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:55986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:58822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:33062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:34900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:57918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:60396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:33192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:36160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:56894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:37268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:57] INFO:     127.0.0.1:38010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:56162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:56484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:56594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:59202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:32768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:60588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:35378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:60220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:57808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:32932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:36300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:57952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:33754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:34134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:59810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:60498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:34076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:36228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:36428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:36942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58 TP0] Decode batch. #running-req: 71, #token: 17444, token usage: 0.02, cuda graph: True, gen throughput (token/s): 3077.29, #queue-req: 0, 
[2025-10-18 01:37:58] INFO:     127.0.0.1:55810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:59212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:58080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:56420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:34150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:36704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:59720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:58054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:35994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:35340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:58230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:37878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:38590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:33352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:58] INFO:     127.0.0.1:34174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:35304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:36828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:56584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:56798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:34456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:33472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:34014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:36852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:58894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:34306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59 TP0] Decode batch. #running-req: 22, #token: 7036, token usage: 0.01, cuda graph: True, gen throughput (token/s): 1339.72, #queue-req: 0, 
[2025-10-18 01:37:59] INFO:     127.0.0.1:38656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:38000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:37704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:37:59] INFO:     127.0.0.1:36136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:38320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:36376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:36760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:36886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:56044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:35808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:33948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:37498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:36660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00 TP0] Decode batch. #running-req: 5, #token: 2091, token usage: 0.00, cuda graph: True, gen throughput (token/s): 499.77, #queue-req: 0, 
[2025-10-18 01:38:00] INFO:     127.0.0.1:35796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:00] INFO:     127.0.0.1:35998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:01] INFO:     127.0.0.1:37626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:01] INFO:     127.0.0.1:34288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:01 TP0] Decode batch. #running-req: 1, #token: 1079, token usage: 0.00, cuda graph: True, gen throughput (token/s): 137.25, #queue-req: 0, 
[2025-10-18 01:38:02 TP0] Decode batch. #running-req: 1, #token: 1119, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.58, #queue-req: 0, 
[2025-10-18 01:38:03 TP0] Decode batch. #running-req: 1, #token: 1159, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.55, #queue-req: 0, 
[2025-10-18 01:38:03 TP0] Decode batch. #running-req: 1, #token: 1199, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.53, #queue-req: 0, 
[2025-10-18 01:38:04 TP0] Decode batch. #running-req: 1, #token: 1239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.51, #queue-req: 0, 
[2025-10-18 01:38:05] INFO:     127.0.0.1:57054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:17] INFO:     127.0.0.1:46322 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 01:38:35] INFO:     127.0.0.1:58440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:35 TP0] Prefill batch. #new-seq: 1, #new-token: 3200, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:38:36 TP0] Decode batch. #running-req: 1, #token: 3217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1.27, #queue-req: 0, 
[2025-10-18 01:38:37] INFO:     127.0.0.1:58442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:38:37] INFO:     127.0.0.1:58464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 6, 
[2025-10-18 01:38:37] INFO:     127.0.0.1:58588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.02, #running-req: 6, #queue-req: 19, 
[2025-10-18 01:38:37] INFO:     127.0.0.1:58722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:58992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:37] INFO:     127.0.0.1:59090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38] INFO:     127.0.0.1:59614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:38:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:38:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:38:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:38:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:38:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:38:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:38:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:38:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:38:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:38:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.18, #running-req: 56, #queue-req: 67, 
[2025-10-18 01:38:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.20, #running-req: 61, #queue-req: 62, 
[2025-10-18 01:38:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.22, #running-req: 66, #queue-req: 57, 
[2025-10-18 01:38:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.23, #running-req: 71, #queue-req: 52, 
[2025-10-18 01:38:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.25, #running-req: 76, #queue-req: 47, 
[2025-10-18 01:38:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.27, #running-req: 81, #queue-req: 42, 
[2025-10-18 01:38:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.28, #running-req: 86, #queue-req: 37, 
[2025-10-18 01:38:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.30, #running-req: 91, #queue-req: 32, 
[2025-10-18 01:38:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.32, #running-req: 96, #queue-req: 27, 
[2025-10-18 01:38:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.33, #running-req: 101, #queue-req: 22, 
[2025-10-18 01:38:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.35, #running-req: 106, #queue-req: 17, 
[2025-10-18 01:38:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.37, #running-req: 111, #queue-req: 12, 
[2025-10-18 01:38:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.38, #running-req: 116, #queue-req: 7, 
[2025-10-18 01:38:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.40, #running-req: 121, #queue-req: 2, 
[2025-10-18 01:38:56 TP0] Prefill batch. #new-seq: 2, #new-token: 6394, #cached-token: 8, token usage: 0.41, #running-req: 126, #queue-req: 0, 
[2025-10-18 01:38:59 TP0] Decode batch. #running-req: 128, #token: 412447, token usage: 0.42, cuda graph: True, gen throughput (token/s): 129.33, #queue-req: 0, 
[2025-10-18 01:39:01 TP0] Decode batch. #running-req: 128, #token: 417567, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2580.09, #queue-req: 0, 
[2025-10-18 01:39:03 TP0] Decode batch. #running-req: 128, #token: 422687, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2557.85, #queue-req: 0, 
[2025-10-18 01:39:05 TP0] Decode batch. #running-req: 128, #token: 427807, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2542.96, #queue-req: 0, 
[2025-10-18 01:39:07 TP0] Decode batch. #running-req: 128, #token: 432927, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2531.45, #queue-req: 0, 
[2025-10-18 01:39:09 TP0] Decode batch. #running-req: 128, #token: 438047, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2522.23, #queue-req: 0, 
[2025-10-18 01:39:11 TP0] Decode batch. #running-req: 128, #token: 443167, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2515.14, #queue-req: 0, 
[2025-10-18 01:39:13 TP0] Decode batch. #running-req: 128, #token: 448287, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2507.26, #queue-req: 0, 
[2025-10-18 01:39:15 TP0] Decode batch. #running-req: 128, #token: 453407, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2464.21, #queue-req: 0, 
[2025-10-18 01:39:17 TP0] Decode batch. #running-req: 128, #token: 458527, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2492.70, #queue-req: 0, 
[2025-10-18 01:39:19 TP0] Decode batch. #running-req: 128, #token: 463647, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2489.13, #queue-req: 0, 
[2025-10-18 01:39:21 TP0] Decode batch. #running-req: 128, #token: 468767, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2483.13, #queue-req: 0, 
[2025-10-18 01:39:23 TP0] Decode batch. #running-req: 128, #token: 473887, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2477.22, #queue-req: 0, 
[2025-10-18 01:39:25 TP0] Decode batch. #running-req: 128, #token: 479007, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2469.30, #queue-req: 0, 
[2025-10-18 01:39:27 TP0] Decode batch. #running-req: 128, #token: 484127, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2463.40, #queue-req: 0, 
[2025-10-18 01:39:29 TP0] Decode batch. #running-req: 128, #token: 489247, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2459.49, #queue-req: 0, 
[2025-10-18 01:39:31 TP0] Decode batch. #running-req: 128, #token: 494367, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2455.93, #queue-req: 0, 
[2025-10-18 01:39:33 TP0] Decode batch. #running-req: 128, #token: 499487, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2449.91, #queue-req: 0, 
[2025-10-18 01:39:35 TP0] Decode batch. #running-req: 128, #token: 504607, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2446.67, #queue-req: 0, 
[2025-10-18 01:39:38 TP0] Decode batch. #running-req: 128, #token: 509727, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2439.47, #queue-req: 0, 
[2025-10-18 01:39:38] INFO:     127.0.0.1:59020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:39:39] INFO:     127.0.0.1:59030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:39:39] INFO:     127.0.0.1:59162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.02, #running-req: 6, #queue-req: 37, 
[2025-10-18 01:39:39] INFO:     127.0.0.1:59452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:59992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:39] INFO:     127.0.0.1:60172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:39:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:39:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:39:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:39:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:39:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:39:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:39:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:39:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:39:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:39:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.18, #running-req: 56, #queue-req: 67, 
[2025-10-18 01:39:48 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.20, #running-req: 61, #queue-req: 61, 
[2025-10-18 01:39:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.22, #running-req: 67, #queue-req: 56, 
[2025-10-18 01:39:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15977, #cached-token: 28, token usage: 0.23, #running-req: 72, #queue-req: 51, 
[2025-10-18 01:39:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.25, #running-req: 77, #queue-req: 46, 
[2025-10-18 01:39:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.27, #running-req: 82, #queue-req: 41, 
[2025-10-18 01:39:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.28, #running-req: 87, #queue-req: 36, 
[2025-10-18 01:39:53 TP0] Prefill batch. #new-seq: 6, #new-token: 15994, #cached-token: 3212, token usage: 0.30, #running-req: 92, #queue-req: 30, 
[2025-10-18 01:39:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.32, #running-req: 98, #queue-req: 25, 
[2025-10-18 01:39:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.34, #running-req: 103, #queue-req: 20, 
[2025-10-18 01:39:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.35, #running-req: 108, #queue-req: 15, 
[2025-10-18 01:39:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.37, #running-req: 113, #queue-req: 10, 
[2025-10-18 01:39:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.39, #running-req: 118, #queue-req: 5, 
[2025-10-18 01:39:57 TP0] Prefill batch. #new-seq: 5, #new-token: 12792, #cached-token: 3213, token usage: 0.40, #running-req: 123, #queue-req: 0, 
[2025-10-18 01:40:00 TP0] Decode batch. #running-req: 128, #token: 406045, token usage: 0.42, cuda graph: True, gen throughput (token/s): 229.33, #queue-req: 0, 
[2025-10-18 01:40:02 TP0] Decode batch. #running-req: 128, #token: 411165, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2561.65, #queue-req: 0, 
[2025-10-18 01:40:04 TP0] Decode batch. #running-req: 128, #token: 416285, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2537.75, #queue-req: 0, 
[2025-10-18 01:40:06 TP0] Decode batch. #running-req: 128, #token: 421405, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2527.05, #queue-req: 0, 
[2025-10-18 01:40:08 TP0] Decode batch. #running-req: 128, #token: 426525, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2519.74, #queue-req: 0, 
[2025-10-18 01:40:10 TP0] Decode batch. #running-req: 128, #token: 431645, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2510.34, #queue-req: 0, 
[2025-10-18 01:40:12 TP0] Decode batch. #running-req: 128, #token: 436765, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2505.36, #queue-req: 0, 
[2025-10-18 01:40:14 TP0] Decode batch. #running-req: 128, #token: 441885, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2497.00, #queue-req: 0, 
[2025-10-18 01:40:16 TP0] Decode batch. #running-req: 128, #token: 447005, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2490.98, #queue-req: 0, 
[2025-10-18 01:40:18 TP0] Decode batch. #running-req: 128, #token: 452125, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2487.97, #queue-req: 0, 
[2025-10-18 01:40:20 TP0] Decode batch. #running-req: 128, #token: 457245, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2439.20, #queue-req: 0, 
[2025-10-18 01:40:22 TP0] Decode batch. #running-req: 128, #token: 462365, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2477.19, #queue-req: 0, 
[2025-10-18 01:40:24 TP0] Decode batch. #running-req: 128, #token: 467485, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2471.46, #queue-req: 0, 
[2025-10-18 01:40:27 TP0] Decode batch. #running-req: 128, #token: 472605, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2464.00, #queue-req: 0, 
[2025-10-18 01:40:29 TP0] Decode batch. #running-req: 128, #token: 477725, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2460.24, #queue-req: 0, 
[2025-10-18 01:40:31 TP0] Decode batch. #running-req: 128, #token: 482845, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2457.14, #queue-req: 0, 
[2025-10-18 01:40:33 TP0] Decode batch. #running-req: 128, #token: 487965, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2454.53, #queue-req: 0, 
[2025-10-18 01:40:35 TP0] Decode batch. #running-req: 128, #token: 493085, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2450.65, #queue-req: 0, 
[2025-10-18 01:40:37 TP0] Decode batch. #running-req: 128, #token: 498205, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2444.31, #queue-req: 0, 
[2025-10-18 01:40:39 TP0] Decode batch. #running-req: 128, #token: 503325, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2443.22, #queue-req: 0, 
[2025-10-18 01:40:40] INFO:     127.0.0.1:60284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:40:40] INFO:     127.0.0.1:60292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:40:40] INFO:     127.0.0.1:60420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 34, 
[2025-10-18 01:40:40] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:40] INFO:     127.0.0.1:60950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:60996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:32992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41] INFO:     127.0.0.1:33212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:40:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:40:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:40:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:40:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:40:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:40:45 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 86, 
[2025-10-18 01:40:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 81, 
[2025-10-18 01:40:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 76, 
[2025-10-18 01:40:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 71, 
[2025-10-18 01:40:48 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 65, 
[2025-10-18 01:40:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.21, #running-req: 63, #queue-req: 60, 
[2025-10-18 01:40:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.22, #running-req: 68, #queue-req: 55, 
[2025-10-18 01:40:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.24, #running-req: 73, #queue-req: 50, 
[2025-10-18 01:40:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.26, #running-req: 78, #queue-req: 45, 
[2025-10-18 01:40:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.27, #running-req: 83, #queue-req: 40, 
[2025-10-18 01:40:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.29, #running-req: 88, #queue-req: 35, 
[2025-10-18 01:40:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.31, #running-req: 93, #queue-req: 30, 
[2025-10-18 01:40:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 98, #queue-req: 25, 
[2025-10-18 01:40:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.34, #running-req: 103, #queue-req: 20, 
[2025-10-18 01:40:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.36, #running-req: 108, #queue-req: 15, 
[2025-10-18 01:40:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.37, #running-req: 113, #queue-req: 10, 
[2025-10-18 01:40:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.39, #running-req: 118, #queue-req: 5, 
[2025-10-18 01:40:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.40, #running-req: 123, #queue-req: 0, 
[2025-10-18 01:41:01 TP0] Decode batch. #running-req: 128, #token: 412444, token usage: 0.42, cuda graph: True, gen throughput (token/s): 229.05, #queue-req: 0, 
[2025-10-18 01:41:03 TP0] Decode batch. #running-req: 128, #token: 417564, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2558.96, #queue-req: 0, 
[2025-10-18 01:41:05 TP0] Decode batch. #running-req: 128, #token: 422684, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2538.01, #queue-req: 0, 
[2025-10-18 01:41:07 TP0] Decode batch. #running-req: 128, #token: 427804, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2524.75, #queue-req: 0, 
[2025-10-18 01:41:09 TP0] Decode batch. #running-req: 128, #token: 432924, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2517.54, #queue-req: 0, 
[2025-10-18 01:41:12 TP0] Decode batch. #running-req: 128, #token: 438044, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2510.34, #queue-req: 0, 
[2025-10-18 01:41:14 TP0] Decode batch. #running-req: 128, #token: 443164, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2505.65, #queue-req: 0, 
[2025-10-18 01:41:16 TP0] Decode batch. #running-req: 128, #token: 448284, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2498.17, #queue-req: 0, 
[2025-10-18 01:41:18 TP0] Decode batch. #running-req: 128, #token: 453404, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2494.71, #queue-req: 0, 
[2025-10-18 01:41:20 TP0] Decode batch. #running-req: 128, #token: 458524, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2487.29, #queue-req: 0, 
[2025-10-18 01:41:22 TP0] Decode batch. #running-req: 128, #token: 463644, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2482.04, #queue-req: 0, 
[2025-10-18 01:41:24 TP0] Decode batch. #running-req: 128, #token: 468764, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2483.85, #queue-req: 0, 
[2025-10-18 01:41:26 TP0] Decode batch. #running-req: 128, #token: 473884, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2444.53, #queue-req: 0, 
[2025-10-18 01:41:28 TP0] Decode batch. #running-req: 128, #token: 479004, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2472.47, #queue-req: 0, 
[2025-10-18 01:41:30 TP0] Decode batch. #running-req: 128, #token: 484124, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2467.91, #queue-req: 0, 
[2025-10-18 01:41:32 TP0] Decode batch. #running-req: 128, #token: 489244, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2464.17, #queue-req: 0, 
[2025-10-18 01:41:34 TP0] Decode batch. #running-req: 128, #token: 494364, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2457.86, #queue-req: 0, 
[2025-10-18 01:41:36 TP0] Decode batch. #running-req: 128, #token: 499484, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2455.57, #queue-req: 0, 
[2025-10-18 01:41:38 TP0] Decode batch. #running-req: 128, #token: 504604, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2448.63, #queue-req: 0, 
[2025-10-18 01:41:41 TP0] Decode batch. #running-req: 128, #token: 509724, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2443.40, #queue-req: 0, 
[2025-10-18 01:41:41] INFO:     127.0.0.1:40858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:41 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:41:41] INFO:     127.0.0.1:40874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:41] INFO:     127.0.0.1:40886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:40996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:41:42] INFO:     127.0.0.1:41016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 37, 
[2025-10-18 01:41:42] INFO:     127.0.0.1:41332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:42] INFO:     127.0.0.1:41928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:41:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 100, 
[2025-10-18 01:41:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 95, 
[2025-10-18 01:41:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 90, 
[2025-10-18 01:41:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 85, 
[2025-10-18 01:41:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 80, 
[2025-10-18 01:41:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 75, 
[2025-10-18 01:41:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 70, 
[2025-10-18 01:41:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 65, 
[2025-10-18 01:41:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 60, 
[2025-10-18 01:41:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 55, 
[2025-10-18 01:41:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.20, #running-req: 61, #queue-req: 50, 
[2025-10-18 01:41:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.22, #running-req: 66, #queue-req: 45, 
[2025-10-18 01:41:52 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.24, #running-req: 71, #queue-req: 39, 
[2025-10-18 01:41:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.25, #running-req: 77, #queue-req: 34, 
[2025-10-18 01:41:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.27, #running-req: 82, #queue-req: 29, 
[2025-10-18 01:41:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.29, #running-req: 87, #queue-req: 24, 
[2025-10-18 01:41:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.30, #running-req: 92, #queue-req: 19, 
[2025-10-18 01:41:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 97, #queue-req: 14, 
[2025-10-18 01:41:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.34, #running-req: 102, #queue-req: 9, 
[2025-10-18 01:41:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.35, #running-req: 107, #queue-req: 4, 
[2025-10-18 01:41:59 TP0] Prefill batch. #new-seq: 4, #new-token: 12787, #cached-token: 17, token usage: 0.37, #running-req: 112, #queue-req: 0, 
[2025-10-18 01:42:01 TP0] Decode batch. #running-req: 116, #token: 373782, token usage: 0.38, cuda graph: True, gen throughput (token/s): 235.47, #queue-req: 0, 
[2025-10-18 01:42:03 TP0] Decode batch. #running-req: 116, #token: 378422, token usage: 0.39, cuda graph: True, gen throughput (token/s): 2385.20, #queue-req: 0, 
[2025-10-18 01:42:05 TP0] Decode batch. #running-req: 116, #token: 383062, token usage: 0.39, cuda graph: True, gen throughput (token/s): 2366.56, #queue-req: 0, 
[2025-10-18 01:42:07 TP0] Decode batch. #running-req: 116, #token: 387702, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2351.02, #queue-req: 0, 
[2025-10-18 01:42:09 TP0] Decode batch. #running-req: 116, #token: 392342, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2344.72, #queue-req: 0, 
[2025-10-18 01:42:11 TP0] Decode batch. #running-req: 116, #token: 396982, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2339.14, #queue-req: 0, 
[2025-10-18 01:42:13 TP0] Decode batch. #running-req: 116, #token: 401622, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2332.63, #queue-req: 0, 
[2025-10-18 01:42:15 TP0] Decode batch. #running-req: 116, #token: 406262, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2328.28, #queue-req: 0, 
[2025-10-18 01:42:17 TP0] Decode batch. #running-req: 116, #token: 410902, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2323.93, #queue-req: 0, 
[2025-10-18 01:42:19 TP0] Decode batch. #running-req: 116, #token: 415542, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2322.32, #queue-req: 0, 
[2025-10-18 01:42:21 TP0] Decode batch. #running-req: 116, #token: 420182, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2317.52, #queue-req: 0, 
[2025-10-18 01:42:23 TP0] Decode batch. #running-req: 116, #token: 424822, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2313.44, #queue-req: 0, 
[2025-10-18 01:42:25 TP0] Decode batch. #running-req: 116, #token: 429462, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2310.19, #queue-req: 0, 
[2025-10-18 01:42:27 TP0] Decode batch. #running-req: 116, #token: 434102, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2305.68, #queue-req: 0, 
[2025-10-18 01:42:29 TP0] Decode batch. #running-req: 116, #token: 438742, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2300.06, #queue-req: 0, 
[2025-10-18 01:42:31 TP0] Decode batch. #running-req: 116, #token: 443382, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2271.08, #queue-req: 0, 
[2025-10-18 01:42:33 TP0] Decode batch. #running-req: 116, #token: 448022, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2291.27, #queue-req: 0, 
[2025-10-18 01:42:35 TP0] Decode batch. #running-req: 116, #token: 452662, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2287.95, #queue-req: 0, 
[2025-10-18 01:42:37 TP0] Decode batch. #running-req: 116, #token: 457302, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2284.97, #queue-req: 0, 
[2025-10-18 01:42:39 TP0] Decode batch. #running-req: 116, #token: 461942, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2279.58, #queue-req: 0, 
[2025-10-18 01:42:40] INFO:     127.0.0.1:48988 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 01:43:04] INFO:     127.0.0.1:40678 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 01:43:10] INFO:     127.0.0.1:38924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:43:11 TP0] Decode batch. #running-req: 1, #token: 3225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 63.14, #queue-req: 0, 
[2025-10-18 01:43:12] INFO:     127.0.0.1:38936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:38940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:43:12] INFO:     127.0.0.1:38956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:38962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:38970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:38980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:38990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:43:12] INFO:     127.0.0.1:39058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 20, 
[2025-10-18 01:43:12] INFO:     127.0.0.1:39236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:12] INFO:     127.0.0.1:39616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:39988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13] INFO:     127.0.0.1:40078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:43:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:43:14 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:43:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:43:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:43:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:43:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:43:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:43:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:43:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:43:20 TP0] Prefill batch. #new-seq: 6, #new-token: 15989, #cached-token: 3217, token usage: 0.19, #running-req: 56, #queue-req: 66, 
[2025-10-18 01:43:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.20, #running-req: 62, #queue-req: 61, 
[2025-10-18 01:43:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.22, #running-req: 67, #queue-req: 56, 
[2025-10-18 01:43:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.24, #running-req: 72, #queue-req: 51, 
[2025-10-18 01:43:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.25, #running-req: 77, #queue-req: 46, 
[2025-10-18 01:43:24 TP0] Prefill batch. #new-seq: 6, #new-token: 15982, #cached-token: 3224, token usage: 0.27, #running-req: 82, #queue-req: 40, 
[2025-10-18 01:43:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.29, #running-req: 88, #queue-req: 35, 
[2025-10-18 01:43:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.31, #running-req: 93, #queue-req: 30, 
[2025-10-18 01:43:27 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.32, #running-req: 98, #queue-req: 25, 
[2025-10-18 01:43:27 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.34, #running-req: 103, #queue-req: 20, 
[2025-10-18 01:43:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.36, #running-req: 108, #queue-req: 15, 
[2025-10-18 01:43:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.37, #running-req: 113, #queue-req: 10, 
[2025-10-18 01:43:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.39, #running-req: 118, #queue-req: 5, 
[2025-10-18 01:43:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.40, #running-req: 123, #queue-req: 0, 
[2025-10-18 01:43:33 TP0] Decode batch. #running-req: 128, #token: 413471, token usage: 0.43, cuda graph: True, gen throughput (token/s): 174.67, #queue-req: 0, 
[2025-10-18 01:43:35 TP0] Decode batch. #running-req: 128, #token: 418591, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2560.47, #queue-req: 0, 
[2025-10-18 01:43:38 TP0] Decode batch. #running-req: 128, #token: 423711, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2537.51, #queue-req: 0, 
[2025-10-18 01:43:40 TP0] Decode batch. #running-req: 128, #token: 428831, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2528.15, #queue-req: 0, 
[2025-10-18 01:43:42 TP0] Decode batch. #running-req: 128, #token: 433951, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2519.02, #queue-req: 0, 
[2025-10-18 01:43:44 TP0] Decode batch. #running-req: 128, #token: 439071, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2510.25, #queue-req: 0, 
[2025-10-18 01:43:46 TP0] Decode batch. #running-req: 128, #token: 444191, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2503.77, #queue-req: 0, 
[2025-10-18 01:43:48 TP0] Decode batch. #running-req: 128, #token: 449311, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2496.05, #queue-req: 0, 
[2025-10-18 01:43:50 TP0] Decode batch. #running-req: 128, #token: 454431, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2487.83, #queue-req: 0, 
[2025-10-18 01:43:52 TP0] Decode batch. #running-req: 128, #token: 459551, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2482.14, #queue-req: 0, 
[2025-10-18 01:43:54 TP0] Decode batch. #running-req: 128, #token: 464671, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2480.16, #queue-req: 0, 
[2025-10-18 01:43:56 TP0] Decode batch. #running-req: 128, #token: 469791, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2473.74, #queue-req: 0, 
[2025-10-18 01:43:58 TP0] Decode batch. #running-req: 128, #token: 474911, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2465.98, #queue-req: 0, 
[2025-10-18 01:44:00 TP0] Decode batch. #running-req: 128, #token: 480031, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2459.46, #queue-req: 0, 
[2025-10-18 01:44:02 TP0] Decode batch. #running-req: 128, #token: 485151, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2451.91, #queue-req: 0, 
[2025-10-18 01:44:04 TP0] Decode batch. #running-req: 128, #token: 490271, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2449.48, #queue-req: 0, 
[2025-10-18 01:44:06 TP0] Decode batch. #running-req: 128, #token: 495391, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2443.90, #queue-req: 0, 
[2025-10-18 01:44:08 TP0] Decode batch. #running-req: 128, #token: 500511, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2443.23, #queue-req: 0, 
[2025-10-18 01:44:11 TP0] Decode batch. #running-req: 128, #token: 505631, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2436.91, #queue-req: 0, 
[2025-10-18 01:44:13 TP0] Decode batch. #running-req: 128, #token: 510751, token usage: 0.53, cuda graph: True, gen throughput (token/s): 2432.87, #queue-req: 0, 
[2025-10-18 01:44:13] INFO:     127.0.0.1:37998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:44:13] INFO:     127.0.0.1:38006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:44:13] INFO:     127.0.0.1:38106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:13] INFO:     127.0.0.1:38316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 35, 
[2025-10-18 01:44:14] INFO:     127.0.0.1:38406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:38996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14] INFO:     127.0.0.1:39222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:44:14 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:44:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:44:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:44:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:44:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:44:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:44:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:44:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:44:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:44:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.18, #running-req: 56, #queue-req: 67, 
[2025-10-18 01:44:22 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.20, #running-req: 61, #queue-req: 61, 
[2025-10-18 01:44:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.22, #running-req: 67, #queue-req: 56, 
[2025-10-18 01:44:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15975, #cached-token: 30, token usage: 0.23, #running-req: 72, #queue-req: 51, 
[2025-10-18 01:44:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.25, #running-req: 77, #queue-req: 46, 
[2025-10-18 01:44:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.27, #running-req: 82, #queue-req: 41, 
[2025-10-18 01:44:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.28, #running-req: 87, #queue-req: 36, 
[2025-10-18 01:44:27 TP0] Prefill batch. #new-seq: 7, #new-token: 15995, #cached-token: 6412, token usage: 0.31, #running-req: 92, #queue-req: 29, 
[2025-10-18 01:44:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.32, #running-req: 99, #queue-req: 24, 
[2025-10-18 01:44:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.34, #running-req: 104, #queue-req: 19, 
[2025-10-18 01:44:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.36, #running-req: 109, #queue-req: 14, 
[2025-10-18 01:44:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.37, #running-req: 114, #queue-req: 9, 
[2025-10-18 01:44:31 TP0] Prefill batch. #new-seq: 6, #new-token: 15982, #cached-token: 3224, token usage: 0.39, #running-req: 119, #queue-req: 3, 
[2025-10-18 01:44:32 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.40, #running-req: 125, #queue-req: 0, 
[2025-10-18 01:44:35 TP0] Decode batch. #running-req: 128, #token: 407069, token usage: 0.42, cuda graph: True, gen throughput (token/s): 232.39, #queue-req: 0, 
[2025-10-18 01:44:37 TP0] Decode batch. #running-req: 128, #token: 412189, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2541.91, #queue-req: 0, 
[2025-10-18 01:44:39 TP0] Decode batch. #running-req: 128, #token: 417309, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2526.41, #queue-req: 0, 
[2025-10-18 01:44:41 TP0] Decode batch. #running-req: 128, #token: 422429, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2518.53, #queue-req: 0, 
[2025-10-18 01:44:43 TP0] Decode batch. #running-req: 128, #token: 427549, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2511.17, #queue-req: 0, 
[2025-10-18 01:44:45 TP0] Decode batch. #running-req: 128, #token: 432669, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2501.98, #queue-req: 0, 
[2025-10-18 01:44:47 TP0] Decode batch. #running-req: 128, #token: 437789, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2497.26, #queue-req: 0, 
[2025-10-18 01:44:49 TP0] Decode batch. #running-req: 128, #token: 442909, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2492.45, #queue-req: 0, 
[2025-10-18 01:44:51 TP0] Decode batch. #running-req: 128, #token: 448029, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2483.91, #queue-req: 0, 
[2025-10-18 01:44:53 TP0] Decode batch. #running-req: 128, #token: 453149, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2480.28, #queue-req: 0, 
[2025-10-18 01:44:55 TP0] Decode batch. #running-req: 128, #token: 458269, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2473.27, #queue-req: 0, 
[2025-10-18 01:44:57 TP0] Decode batch. #running-req: 128, #token: 463389, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2469.17, #queue-req: 0, 
[2025-10-18 01:44:59 TP0] Decode batch. #running-req: 128, #token: 468509, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2465.65, #queue-req: 0, 
[2025-10-18 01:45:01 TP0] Decode batch. #running-req: 128, #token: 473629, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2459.74, #queue-req: 0, 
[2025-10-18 01:45:04 TP0] Decode batch. #running-req: 128, #token: 478749, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2455.43, #queue-req: 0, 
[2025-10-18 01:45:06 TP0] Decode batch. #running-req: 128, #token: 483869, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2450.23, #queue-req: 0, 
[2025-10-18 01:45:08 TP0] Decode batch. #running-req: 128, #token: 488989, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2447.78, #queue-req: 0, 
[2025-10-18 01:45:10 TP0] Decode batch. #running-req: 128, #token: 494109, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2444.32, #queue-req: 0, 
[2025-10-18 01:45:12 TP0] Decode batch. #running-req: 128, #token: 499229, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2436.41, #queue-req: 0, 
[2025-10-18 01:45:14 TP0] Decode batch. #running-req: 128, #token: 504349, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2433.90, #queue-req: 0, 
[2025-10-18 01:45:14] INFO:     127.0.0.1:52298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:45:15] INFO:     127.0.0.1:52312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:45:15] INFO:     127.0.0.1:52460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 34, 
[2025-10-18 01:45:15] INFO:     127.0.0.1:52768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:52994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:15] INFO:     127.0.0.1:53494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:45:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:45:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:45:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:45:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:45:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:45:20 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 86, 
[2025-10-18 01:45:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 81, 
[2025-10-18 01:45:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 76, 
[2025-10-18 01:45:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 71, 
[2025-10-18 01:45:23 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 65, 
[2025-10-18 01:45:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.21, #running-req: 63, #queue-req: 60, 
[2025-10-18 01:45:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.22, #running-req: 68, #queue-req: 55, 
[2025-10-18 01:45:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.24, #running-req: 73, #queue-req: 50, 
[2025-10-18 01:45:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.26, #running-req: 78, #queue-req: 45, 
[2025-10-18 01:45:27 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.27, #running-req: 83, #queue-req: 40, 
[2025-10-18 01:45:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.29, #running-req: 88, #queue-req: 35, 
[2025-10-18 01:45:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.31, #running-req: 93, #queue-req: 30, 
[2025-10-18 01:45:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 98, #queue-req: 25, 
[2025-10-18 01:45:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.34, #running-req: 103, #queue-req: 20, 
[2025-10-18 01:45:31 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.36, #running-req: 108, #queue-req: 15, 
[2025-10-18 01:45:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.37, #running-req: 113, #queue-req: 10, 
[2025-10-18 01:45:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.39, #running-req: 118, #queue-req: 5, 
[2025-10-18 01:45:33 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.40, #running-req: 123, #queue-req: 0, 
[2025-10-18 01:45:36 TP0] Decode batch. #running-req: 128, #token: 413468, token usage: 0.43, cuda graph: True, gen throughput (token/s): 229.53, #queue-req: 0, 
[2025-10-18 01:45:38 TP0] Decode batch. #running-req: 128, #token: 418588, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2549.69, #queue-req: 0, 
[2025-10-18 01:45:40 TP0] Decode batch. #running-req: 128, #token: 423708, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2528.93, #queue-req: 0, 
[2025-10-18 01:45:42 TP0] Decode batch. #running-req: 128, #token: 428828, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2520.32, #queue-req: 0, 
[2025-10-18 01:45:44 TP0] Decode batch. #running-req: 128, #token: 433948, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2512.73, #queue-req: 0, 
[2025-10-18 01:45:46 TP0] Decode batch. #running-req: 128, #token: 439068, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2506.19, #queue-req: 0, 
[2025-10-18 01:45:48 TP0] Decode batch. #running-req: 128, #token: 444188, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2499.32, #queue-req: 0, 
[2025-10-18 01:45:51 TP0] Decode batch. #running-req: 128, #token: 449308, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2492.68, #queue-req: 0, 
[2025-10-18 01:45:53 TP0] Decode batch. #running-req: 128, #token: 454428, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2487.30, #queue-req: 0, 
[2025-10-18 01:45:55 TP0] Decode batch. #running-req: 128, #token: 459548, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2485.50, #queue-req: 0, 
[2025-10-18 01:45:57 TP0] Decode batch. #running-req: 128, #token: 464668, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2478.18, #queue-req: 0, 
[2025-10-18 01:45:59 TP0] Decode batch. #running-req: 128, #token: 469788, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2476.42, #queue-req: 0, 
[2025-10-18 01:46:01 TP0] Decode batch. #running-req: 128, #token: 474908, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2474.07, #queue-req: 0, 
[2025-10-18 01:46:03 TP0] Decode batch. #running-req: 128, #token: 480028, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2466.61, #queue-req: 0, 
[2025-10-18 01:46:05 TP0] Decode batch. #running-req: 128, #token: 485148, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2460.64, #queue-req: 0, 
[2025-10-18 01:46:07 TP0] Decode batch. #running-req: 128, #token: 490268, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2458.36, #queue-req: 0, 
[2025-10-18 01:46:09 TP0] Decode batch. #running-req: 128, #token: 495388, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2454.69, #queue-req: 0, 
[2025-10-18 01:46:11 TP0] Decode batch. #running-req: 128, #token: 500508, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2448.07, #queue-req: 0, 
[2025-10-18 01:46:13 TP0] Decode batch. #running-req: 128, #token: 505628, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2440.82, #queue-req: 0, 
[2025-10-18 01:46:15 TP0] Decode batch. #running-req: 128, #token: 510748, token usage: 0.53, cuda graph: True, gen throughput (token/s): 2436.66, #queue-req: 0, 
[2025-10-18 01:46:16] INFO:     127.0.0.1:45156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:46:16] INFO:     127.0.0.1:45162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:46:16] INFO:     127.0.0.1:45320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 36, 
[2025-10-18 01:46:16] INFO:     127.0.0.1:45596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:16] INFO:     127.0.0.1:45830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:45986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17] INFO:     127.0.0.1:46170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:46:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 100, 
[2025-10-18 01:46:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 95, 
[2025-10-18 01:46:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 90, 
[2025-10-18 01:46:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 85, 
[2025-10-18 01:46:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 80, 
[2025-10-18 01:46:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 75, 
[2025-10-18 01:46:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 70, 
[2025-10-18 01:46:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 65, 
[2025-10-18 01:46:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 60, 
[2025-10-18 01:46:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 55, 
[2025-10-18 01:46:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.20, #running-req: 61, #queue-req: 50, 
[2025-10-18 01:46:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.22, #running-req: 66, #queue-req: 45, 
[2025-10-18 01:46:27 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.24, #running-req: 71, #queue-req: 39, 
[2025-10-18 01:46:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.25, #running-req: 77, #queue-req: 34, 
[2025-10-18 01:46:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.27, #running-req: 82, #queue-req: 29, 
[2025-10-18 01:46:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.29, #running-req: 87, #queue-req: 24, 
[2025-10-18 01:46:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.30, #running-req: 92, #queue-req: 19, 
[2025-10-18 01:46:31 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 97, #queue-req: 14, 
[2025-10-18 01:46:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.34, #running-req: 102, #queue-req: 9, 
[2025-10-18 01:46:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.35, #running-req: 107, #queue-req: 4, 
[2025-10-18 01:46:33 TP0] Prefill batch. #new-seq: 4, #new-token: 12787, #cached-token: 17, token usage: 0.37, #running-req: 112, #queue-req: 0, 
[2025-10-18 01:46:36 TP0] Decode batch. #running-req: 116, #token: 374710, token usage: 0.39, cuda graph: True, gen throughput (token/s): 231.13, #queue-req: 0, 
[2025-10-18 01:46:38 TP0] Decode batch. #running-req: 116, #token: 379350, token usage: 0.39, cuda graph: True, gen throughput (token/s): 2371.61, #queue-req: 0, 
[2025-10-18 01:46:40 TP0] Decode batch. #running-req: 116, #token: 383990, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2354.16, #queue-req: 0, 
[2025-10-18 01:46:42 TP0] Decode batch. #running-req: 116, #token: 388630, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2342.76, #queue-req: 0, 
[2025-10-18 01:46:44 TP0] Decode batch. #running-req: 116, #token: 393270, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2336.01, #queue-req: 0, 
[2025-10-18 01:46:46 TP0] Decode batch. #running-req: 116, #token: 397910, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2328.89, #queue-req: 0, 
[2025-10-18 01:46:48 TP0] Decode batch. #running-req: 116, #token: 402550, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2323.93, #queue-req: 0, 
[2025-10-18 01:46:50 TP0] Decode batch. #running-req: 116, #token: 407190, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2318.28, #queue-req: 0, 
[2025-10-18 01:46:52 TP0] Decode batch. #running-req: 116, #token: 411830, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2311.12, #queue-req: 0, 
[2025-10-18 01:46:54 TP0] Decode batch. #running-req: 116, #token: 416470, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2311.91, #queue-req: 0, 
[2025-10-18 01:46:56 TP0] Decode batch. #running-req: 116, #token: 421110, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2306.77, #queue-req: 0, 
[2025-10-18 01:46:58 TP0] Decode batch. #running-req: 116, #token: 425750, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2304.05, #queue-req: 0, 
[2025-10-18 01:47:00 TP0] Decode batch. #running-req: 116, #token: 430390, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2298.64, #queue-req: 0, 
[2025-10-18 01:47:02 TP0] Decode batch. #running-req: 116, #token: 435030, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2292.37, #queue-req: 0, 
[2025-10-18 01:47:04 TP0] Decode batch. #running-req: 116, #token: 439670, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2288.32, #queue-req: 0, 
[2025-10-18 01:47:06 TP0] Decode batch. #running-req: 116, #token: 444310, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2285.89, #queue-req: 0, 
[2025-10-18 01:47:08 TP0] Decode batch. #running-req: 116, #token: 448950, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2277.92, #queue-req: 0, 
[2025-10-18 01:47:10 TP0] Decode batch. #running-req: 116, #token: 453590, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2275.97, #queue-req: 0, 
[2025-10-18 01:47:12 TP0] Decode batch. #running-req: 116, #token: 458230, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2272.56, #queue-req: 0, 
[2025-10-18 01:47:14 TP0] Decode batch. #running-req: 116, #token: 462870, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2265.45, #queue-req: 0, 
[2025-10-18 01:47:15] INFO:     127.0.0.1:34210 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 01:47:38] INFO:     127.0.0.1:37634 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 01:47:45] INFO:     127.0.0.1:42958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:45 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:47:46 TP0] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 34.27, #queue-req: 0, 
[2025-10-18 01:47:47] INFO:     127.0.0.1:42966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:42970 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:47:47] INFO:     127.0.0.1:42974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:42986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:42996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:47:47] INFO:     127.0.0.1:43106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43170 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 20, 
[2025-10-18 01:47:47] INFO:     127.0.0.1:43254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:43984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:47] INFO:     127.0.0.1:44098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:47:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:47:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:47:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:47:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:47:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:47:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:47:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:47:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:47:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:47:55 TP0] Prefill batch. #new-seq: 6, #new-token: 15989, #cached-token: 3217, token usage: 0.19, #running-req: 56, #queue-req: 66, 
[2025-10-18 01:47:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.20, #running-req: 62, #queue-req: 61, 
[2025-10-18 01:47:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.22, #running-req: 67, #queue-req: 56, 
[2025-10-18 01:47:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.24, #running-req: 72, #queue-req: 51, 
[2025-10-18 01:47:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.25, #running-req: 77, #queue-req: 46, 
[2025-10-18 01:47:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15976, #cached-token: 29, token usage: 0.27, #running-req: 82, #queue-req: 41, 
[2025-10-18 01:48:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.29, #running-req: 87, #queue-req: 36, 
[2025-10-18 01:48:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.30, #running-req: 92, #queue-req: 31, 
[2025-10-18 01:48:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 97, #queue-req: 26, 
[2025-10-18 01:48:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.34, #running-req: 102, #queue-req: 21, 
[2025-10-18 01:48:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.35, #running-req: 107, #queue-req: 16, 
[2025-10-18 01:48:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.37, #running-req: 112, #queue-req: 11, 
[2025-10-18 01:48:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.39, #running-req: 117, #queue-req: 6, 
[2025-10-18 01:48:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.40, #running-req: 122, #queue-req: 1, 
[2025-10-18 01:48:06 TP0] Prefill batch. #new-seq: 1, #new-token: 3196, #cached-token: 5, token usage: 0.42, #running-req: 127, #queue-req: 0, 
[2025-10-18 01:48:09 TP0] Decode batch. #running-req: 128, #token: 414495, token usage: 0.43, cuda graph: True, gen throughput (token/s): 214.98, #queue-req: 0, 
[2025-10-18 01:48:11 TP0] Decode batch. #running-req: 128, #token: 419615, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2553.57, #queue-req: 0, 
[2025-10-18 01:48:13 TP0] Decode batch. #running-req: 128, #token: 424735, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2537.11, #queue-req: 0, 
[2025-10-18 01:48:15 TP0] Decode batch. #running-req: 128, #token: 429855, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2525.01, #queue-req: 0, 
[2025-10-18 01:48:17 TP0] Decode batch. #running-req: 128, #token: 434975, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2518.26, #queue-req: 0, 
[2025-10-18 01:48:19 TP0] Decode batch. #running-req: 128, #token: 440095, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2510.89, #queue-req: 0, 
[2025-10-18 01:48:21 TP0] Decode batch. #running-req: 128, #token: 445215, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2500.35, #queue-req: 0, 
[2025-10-18 01:48:23 TP0] Decode batch. #running-req: 128, #token: 450335, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2492.50, #queue-req: 0, 
[2025-10-18 01:48:25 TP0] Decode batch. #running-req: 128, #token: 455455, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2485.81, #queue-req: 0, 
[2025-10-18 01:48:27 TP0] Decode batch. #running-req: 128, #token: 460575, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2479.91, #queue-req: 0, 
[2025-10-18 01:48:29 TP0] Decode batch. #running-req: 128, #token: 465695, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2476.09, #queue-req: 0, 
[2025-10-18 01:48:31 TP0] Decode batch. #running-req: 128, #token: 470815, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2469.16, #queue-req: 0, 
[2025-10-18 01:48:33 TP0] Decode batch. #running-req: 128, #token: 475935, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2463.65, #queue-req: 0, 
[2025-10-18 01:48:35 TP0] Decode batch. #running-req: 128, #token: 481055, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2459.71, #queue-req: 0, 
[2025-10-18 01:48:38 TP0] Decode batch. #running-req: 128, #token: 486175, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2454.72, #queue-req: 0, 
[2025-10-18 01:48:40 TP0] Decode batch. #running-req: 128, #token: 491295, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2447.31, #queue-req: 0, 
[2025-10-18 01:48:42 TP0] Decode batch. #running-req: 128, #token: 496415, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2445.08, #queue-req: 0, 
[2025-10-18 01:48:44 TP0] Decode batch. #running-req: 128, #token: 501535, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2442.01, #queue-req: 0, 
[2025-10-18 01:48:46 TP0] Decode batch. #running-req: 128, #token: 506655, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2435.54, #queue-req: 0, 
[2025-10-18 01:48:48 TP0] Decode batch. #running-req: 128, #token: 128, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2385.34, #queue-req: 0, 
[2025-10-18 01:48:48] INFO:     127.0.0.1:59686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:48:48] INFO:     127.0.0.1:59688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 7, 
[2025-10-18 01:48:48] INFO:     127.0.0.1:59800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:59992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 39, 
[2025-10-18 01:48:48] INFO:     127.0.0.1:60076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:48] INFO:     127.0.0.1:60110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49] INFO:     127.0.0.1:60694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:48:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:48:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:48:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:48:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:48:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:48:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 87, 
[2025-10-18 01:48:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 82, 
[2025-10-18 01:48:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 77, 
[2025-10-18 01:48:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 72, 
[2025-10-18 01:48:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.18, #running-req: 56, #queue-req: 67, 
[2025-10-18 01:48:57 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.20, #running-req: 61, #queue-req: 61, 
[2025-10-18 01:48:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.22, #running-req: 67, #queue-req: 56, 
[2025-10-18 01:48:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15975, #cached-token: 30, token usage: 0.23, #running-req: 72, #queue-req: 51, 
[2025-10-18 01:49:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.25, #running-req: 77, #queue-req: 46, 
[2025-10-18 01:49:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.27, #running-req: 82, #queue-req: 41, 
[2025-10-18 01:49:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.28, #running-req: 87, #queue-req: 36, 
[2025-10-18 01:49:02 TP0] Prefill batch. #new-seq: 7, #new-token: 15995, #cached-token: 6412, token usage: 0.31, #running-req: 92, #queue-req: 29, 
[2025-10-18 01:49:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.32, #running-req: 99, #queue-req: 24, 
[2025-10-18 01:49:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.34, #running-req: 104, #queue-req: 19, 
[2025-10-18 01:49:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.36, #running-req: 109, #queue-req: 14, 
[2025-10-18 01:49:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.37, #running-req: 114, #queue-req: 9, 
[2025-10-18 01:49:06 TP0] Prefill batch. #new-seq: 6, #new-token: 15982, #cached-token: 3224, token usage: 0.39, #running-req: 119, #queue-req: 3, 
[2025-10-18 01:49:07 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.40, #running-req: 125, #queue-req: 0, 
[2025-10-18 01:49:10 TP0] Decode batch. #running-req: 128, #token: 408093, token usage: 0.42, cuda graph: True, gen throughput (token/s): 233.36, #queue-req: 0, 
[2025-10-18 01:49:12 TP0] Decode batch. #running-req: 128, #token: 413213, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2544.16, #queue-req: 0, 
[2025-10-18 01:49:14 TP0] Decode batch. #running-req: 128, #token: 418333, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2527.21, #queue-req: 0, 
[2025-10-18 01:49:16 TP0] Decode batch. #running-req: 128, #token: 423453, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2519.69, #queue-req: 0, 
[2025-10-18 01:49:18 TP0] Decode batch. #running-req: 128, #token: 428573, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2512.41, #queue-req: 0, 
[2025-10-18 01:49:20 TP0] Decode batch. #running-req: 128, #token: 433693, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2506.33, #queue-req: 0, 
[2025-10-18 01:49:22 TP0] Decode batch. #running-req: 128, #token: 438813, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2500.38, #queue-req: 0, 
[2025-10-18 01:49:24 TP0] Decode batch. #running-req: 128, #token: 443933, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2494.50, #queue-req: 0, 
[2025-10-18 01:49:26 TP0] Decode batch. #running-req: 128, #token: 449053, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2489.87, #queue-req: 0, 
[2025-10-18 01:49:28 TP0] Decode batch. #running-req: 128, #token: 454173, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2481.05, #queue-req: 0, 
[2025-10-18 01:49:30 TP0] Decode batch. #running-req: 128, #token: 459293, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2481.01, #queue-req: 0, 
[2025-10-18 01:49:33 TP0] Decode batch. #running-req: 128, #token: 464413, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2471.91, #queue-req: 0, 
[2025-10-18 01:49:35 TP0] Decode batch. #running-req: 128, #token: 469533, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2468.05, #queue-req: 0, 
[2025-10-18 01:49:37 TP0] Decode batch. #running-req: 128, #token: 474653, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2462.49, #queue-req: 0, 
[2025-10-18 01:49:39 TP0] Decode batch. #running-req: 128, #token: 479773, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2459.85, #queue-req: 0, 
[2025-10-18 01:49:41 TP0] Decode batch. #running-req: 128, #token: 484893, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2452.60, #queue-req: 0, 
[2025-10-18 01:49:43 TP0] Decode batch. #running-req: 128, #token: 490013, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2446.37, #queue-req: 0, 
[2025-10-18 01:49:45 TP0] Decode batch. #running-req: 128, #token: 495133, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2440.68, #queue-req: 0, 
[2025-10-18 01:49:47 TP0] Decode batch. #running-req: 128, #token: 500253, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2439.48, #queue-req: 0, 
[2025-10-18 01:49:49 TP0] Decode batch. #running-req: 128, #token: 128, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2387.19, #queue-req: 0, 
[2025-10-18 01:49:49] INFO:     127.0.0.1:45176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:49:49] INFO:     127.0.0.1:45184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:49:49] INFO:     127.0.0.1:45294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:49] INFO:     127.0.0.1:45390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 37, 
[2025-10-18 01:49:50] INFO:     127.0.0.1:45608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:45996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50] INFO:     127.0.0.1:46258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:49:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 112, 
[2025-10-18 01:49:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.05, #running-req: 16, #queue-req: 107, 
[2025-10-18 01:49:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 102, 
[2025-10-18 01:49:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 97, 
[2025-10-18 01:49:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 92, 
[2025-10-18 01:49:54 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 86, 
[2025-10-18 01:49:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 81, 
[2025-10-18 01:49:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 76, 
[2025-10-18 01:49:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 71, 
[2025-10-18 01:49:58 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 65, 
[2025-10-18 01:49:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.21, #running-req: 63, #queue-req: 60, 
[2025-10-18 01:49:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.22, #running-req: 68, #queue-req: 55, 
[2025-10-18 01:50:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.24, #running-req: 73, #queue-req: 50, 
[2025-10-18 01:50:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.26, #running-req: 78, #queue-req: 45, 
[2025-10-18 01:50:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.27, #running-req: 83, #queue-req: 40, 
[2025-10-18 01:50:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.29, #running-req: 88, #queue-req: 35, 
[2025-10-18 01:50:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.31, #running-req: 93, #queue-req: 30, 
[2025-10-18 01:50:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 98, #queue-req: 25, 
[2025-10-18 01:50:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.34, #running-req: 103, #queue-req: 20, 
[2025-10-18 01:50:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.36, #running-req: 108, #queue-req: 15, 
[2025-10-18 01:50:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.37, #running-req: 113, #queue-req: 10, 
[2025-10-18 01:50:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.39, #running-req: 118, #queue-req: 5, 
[2025-10-18 01:50:08 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.40, #running-req: 123, #queue-req: 0, 
[2025-10-18 01:50:12 TP0] Decode batch. #running-req: 128, #token: 414492, token usage: 0.43, cuda graph: True, gen throughput (token/s): 229.87, #queue-req: 0, 
[2025-10-18 01:50:14 TP0] Decode batch. #running-req: 128, #token: 419612, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2541.01, #queue-req: 0, 
[2025-10-18 01:50:16 TP0] Decode batch. #running-req: 128, #token: 424732, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2524.73, #queue-req: 0, 
[2025-10-18 01:50:18 TP0] Decode batch. #running-req: 128, #token: 429852, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2516.64, #queue-req: 0, 
[2025-10-18 01:50:20 TP0] Decode batch. #running-req: 128, #token: 434972, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2505.35, #queue-req: 0, 
[2025-10-18 01:50:22 TP0] Decode batch. #running-req: 128, #token: 440092, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2500.82, #queue-req: 0, 
[2025-10-18 01:50:24 TP0] Decode batch. #running-req: 128, #token: 445212, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2495.17, #queue-req: 0, 
[2025-10-18 01:50:26 TP0] Decode batch. #running-req: 128, #token: 450332, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2490.77, #queue-req: 0, 
[2025-10-18 01:50:28 TP0] Decode batch. #running-req: 128, #token: 455452, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2482.93, #queue-req: 0, 
[2025-10-18 01:50:30 TP0] Decode batch. #running-req: 128, #token: 460572, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2476.80, #queue-req: 0, 
[2025-10-18 01:50:32 TP0] Decode batch. #running-req: 128, #token: 465692, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2479.45, #queue-req: 0, 
[2025-10-18 01:50:34 TP0] Decode batch. #running-req: 128, #token: 470812, token usage: 0.48, cuda graph: True, gen throughput (token/s): 2470.81, #queue-req: 0, 
[2025-10-18 01:50:36 TP0] Decode batch. #running-req: 128, #token: 475932, token usage: 0.49, cuda graph: True, gen throughput (token/s): 2467.21, #queue-req: 0, 
[2025-10-18 01:50:38 TP0] Decode batch. #running-req: 128, #token: 481052, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2460.59, #queue-req: 0, 
[2025-10-18 01:50:40 TP0] Decode batch. #running-req: 128, #token: 486172, token usage: 0.50, cuda graph: True, gen throughput (token/s): 2454.43, #queue-req: 0, 
[2025-10-18 01:50:42 TP0] Decode batch. #running-req: 128, #token: 491292, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2449.65, #queue-req: 0, 
[2025-10-18 01:50:45 TP0] Decode batch. #running-req: 128, #token: 496412, token usage: 0.51, cuda graph: True, gen throughput (token/s): 2444.52, #queue-req: 0, 
[2025-10-18 01:50:47 TP0] Decode batch. #running-req: 128, #token: 501532, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2442.15, #queue-req: 0, 
[2025-10-18 01:50:49 TP0] Decode batch. #running-req: 128, #token: 506652, token usage: 0.52, cuda graph: True, gen throughput (token/s): 2439.08, #queue-req: 0, 
[2025-10-18 01:50:51 TP0] Decode batch. #running-req: 128, #token: 128, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2379.85, #queue-req: 0, 
[2025-10-18 01:50:51] INFO:     127.0.0.1:34994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:50:51] INFO:     127.0.0.1:35010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:50:51] INFO:     127.0.0.1:35130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 37, 
[2025-10-18 01:50:51] INFO:     127.0.0.1:35484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:51] INFO:     127.0.0.1:35830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:35990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52] INFO:     127.0.0.1:36086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:50:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 100, 
[2025-10-18 01:50:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 95, 
[2025-10-18 01:50:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 90, 
[2025-10-18 01:50:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 85, 
[2025-10-18 01:50:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 80, 
[2025-10-18 01:50:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 75, 
[2025-10-18 01:50:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 70, 
[2025-10-18 01:50:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 65, 
[2025-10-18 01:50:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 60, 
[2025-10-18 01:50:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 55, 
[2025-10-18 01:51:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.20, #running-req: 61, #queue-req: 50, 
[2025-10-18 01:51:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.22, #running-req: 66, #queue-req: 45, 
[2025-10-18 01:51:02 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.24, #running-req: 71, #queue-req: 39, 
[2025-10-18 01:51:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.25, #running-req: 77, #queue-req: 34, 
[2025-10-18 01:51:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.27, #running-req: 82, #queue-req: 29, 
[2025-10-18 01:51:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.29, #running-req: 87, #queue-req: 24, 
[2025-10-18 01:51:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.30, #running-req: 92, #queue-req: 19, 
[2025-10-18 01:51:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.32, #running-req: 97, #queue-req: 14, 
[2025-10-18 01:51:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.34, #running-req: 102, #queue-req: 9, 
[2025-10-18 01:51:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.35, #running-req: 107, #queue-req: 4, 
[2025-10-18 01:51:08 TP0] Prefill batch. #new-seq: 4, #new-token: 12787, #cached-token: 17, token usage: 0.37, #running-req: 112, #queue-req: 0, 
[2025-10-18 01:51:11 TP0] Decode batch. #running-req: 116, #token: 375638, token usage: 0.39, cuda graph: True, gen throughput (token/s): 227.44, #queue-req: 0, 
[2025-10-18 01:51:13 TP0] Decode batch. #running-req: 116, #token: 380278, token usage: 0.39, cuda graph: True, gen throughput (token/s): 2370.69, #queue-req: 0, 
[2025-10-18 01:51:15 TP0] Decode batch. #running-req: 116, #token: 384918, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2360.37, #queue-req: 0, 
[2025-10-18 01:51:17 TP0] Decode batch. #running-req: 116, #token: 389558, token usage: 0.40, cuda graph: True, gen throughput (token/s): 2351.57, #queue-req: 0, 
[2025-10-18 01:51:19 TP0] Decode batch. #running-req: 116, #token: 394198, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2341.63, #queue-req: 0, 
[2025-10-18 01:51:21 TP0] Decode batch. #running-req: 116, #token: 398838, token usage: 0.41, cuda graph: True, gen throughput (token/s): 2331.93, #queue-req: 0, 
[2025-10-18 01:51:23 TP0] Decode batch. #running-req: 116, #token: 403478, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2326.50, #queue-req: 0, 
[2025-10-18 01:51:25 TP0] Decode batch. #running-req: 116, #token: 408118, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2322.35, #queue-req: 0, 
[2025-10-18 01:51:27 TP0] Decode batch. #running-req: 116, #token: 412758, token usage: 0.42, cuda graph: True, gen throughput (token/s): 2316.48, #queue-req: 0, 
[2025-10-18 01:51:29 TP0] Decode batch. #running-req: 116, #token: 417398, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2317.11, #queue-req: 0, 
[2025-10-18 01:51:31 TP0] Decode batch. #running-req: 116, #token: 422038, token usage: 0.43, cuda graph: True, gen throughput (token/s): 2310.91, #queue-req: 0, 
[2025-10-18 01:51:33 TP0] Decode batch. #running-req: 116, #token: 426678, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2310.97, #queue-req: 0, 
[2025-10-18 01:51:35 TP0] Decode batch. #running-req: 116, #token: 431318, token usage: 0.44, cuda graph: True, gen throughput (token/s): 2305.68, #queue-req: 0, 
[2025-10-18 01:51:37 TP0] Decode batch. #running-req: 116, #token: 435958, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2300.84, #queue-req: 0, 
[2025-10-18 01:51:39 TP0] Decode batch. #running-req: 116, #token: 440598, token usage: 0.45, cuda graph: True, gen throughput (token/s): 2293.57, #queue-req: 0, 
[2025-10-18 01:51:41 TP0] Decode batch. #running-req: 116, #token: 445238, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2289.77, #queue-req: 0, 
[2025-10-18 01:51:43 TP0] Decode batch. #running-req: 116, #token: 449878, token usage: 0.46, cuda graph: True, gen throughput (token/s): 2288.90, #queue-req: 0, 
[2025-10-18 01:51:45 TP0] Decode batch. #running-req: 116, #token: 454518, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2284.17, #queue-req: 0, 
[2025-10-18 01:51:47 TP0] Decode batch. #running-req: 116, #token: 459158, token usage: 0.47, cuda graph: True, gen throughput (token/s): 2281.70, #queue-req: 0, 
[2025-10-18 01:51:49 TP0] Decode batch. #running-req: 116, #token: 116, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2234.43, #queue-req: 0, 
[2025-10-18 01:51:49] INFO:     127.0.0.1:48836 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 01:52:08] INFO:     127.0.0.1:38806 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 01:52:14] INFO:     127.0.0.1:38816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:14 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:52:16] INFO:     127.0.0.1:45586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:52:16] INFO:     127.0.0.1:45592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:52:16] INFO:     127.0.0.1:45698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 21, 
[2025-10-18 01:52:16] INFO:     127.0.0.1:45862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:45994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:16] INFO:     127.0.0.1:46162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:52:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:52:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:52:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:52:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:52:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:52:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:52:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:52:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:52:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:52:24 TP0] Prefill batch. #new-seq: 6, #new-token: 15989, #cached-token: 3217, token usage: 0.19, #running-req: 56, #queue-req: 2, 
[2025-10-18 01:52:25 TP0] Prefill batch. #new-seq: 2, #new-token: 6398, #cached-token: 4, token usage: 0.20, #running-req: 62, #queue-req: 0, 
[2025-10-18 01:52:26 TP0] Decode batch. #running-req: 64, #token: 205224, token usage: 0.21, cuda graph: True, gen throughput (token/s): 16.16, #queue-req: 0, 
[2025-10-18 01:52:28 TP0] Decode batch. #running-req: 64, #token: 207784, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1583.29, #queue-req: 0, 
[2025-10-18 01:52:30 TP0] Decode batch. #running-req: 64, #token: 210344, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1562.09, #queue-req: 0, 
[2025-10-18 01:52:31 TP0] Decode batch. #running-req: 64, #token: 212904, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1550.44, #queue-req: 0, 
[2025-10-18 01:52:33 TP0] Decode batch. #running-req: 64, #token: 215464, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1543.80, #queue-req: 0, 
[2025-10-18 01:52:35 TP0] Decode batch. #running-req: 64, #token: 218024, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.00, #queue-req: 0, 
[2025-10-18 01:52:36 TP0] Decode batch. #running-req: 64, #token: 220584, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1534.51, #queue-req: 0, 
[2025-10-18 01:52:38 TP0] Decode batch. #running-req: 64, #token: 223144, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1529.18, #queue-req: 0, 
[2025-10-18 01:52:40 TP0] Decode batch. #running-req: 64, #token: 225704, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1527.21, #queue-req: 0, 
[2025-10-18 01:52:41 TP0] Decode batch. #running-req: 64, #token: 228264, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1520.31, #queue-req: 0, 
[2025-10-18 01:52:43 TP0] Decode batch. #running-req: 64, #token: 230824, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.41, #queue-req: 0, 
[2025-10-18 01:52:45 TP0] Decode batch. #running-req: 64, #token: 233384, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1516.99, #queue-req: 0, 
[2025-10-18 01:52:46 TP0] Decode batch. #running-req: 64, #token: 235944, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.56, #queue-req: 0, 
[2025-10-18 01:52:48 TP0] Decode batch. #running-req: 64, #token: 238504, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.73, #queue-req: 0, 
[2025-10-18 01:52:50 TP0] Decode batch. #running-req: 64, #token: 241064, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.88, #queue-req: 0, 
[2025-10-18 01:52:51 TP0] Decode batch. #running-req: 64, #token: 243624, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.72, #queue-req: 0, 
[2025-10-18 01:52:53 TP0] Decode batch. #running-req: 64, #token: 246184, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1511.04, #queue-req: 0, 
[2025-10-18 01:52:55 TP0] Decode batch. #running-req: 64, #token: 248744, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1509.33, #queue-req: 0, 
[2025-10-18 01:52:56 TP0] Decode batch. #running-req: 64, #token: 251304, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1509.42, #queue-req: 0, 
[2025-10-18 01:52:58 TP0] Decode batch. #running-req: 64, #token: 253864, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.98, #queue-req: 0, 
[2025-10-18 01:53:00] INFO:     127.0.0.1:44290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00 TP0] Prefill batch. #new-seq: 1, #new-token: 3195, #cached-token: 6, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:53:00] INFO:     127.0.0.1:44302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 01:53:00] INFO:     127.0.0.1:44440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44460 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 41, 
[2025-10-18 01:53:00] INFO:     127.0.0.1:44720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:00] INFO:     127.0.0.1:44822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:53:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15978, #cached-token: 27, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:53:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:53:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:53:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:53:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:53:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:53:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:53:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:53:08 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 01:53:09 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 01:53:10 TP0] Decode batch. #running-req: 64, #token: 205207, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.69, #queue-req: 0, 
[2025-10-18 01:53:12 TP0] Decode batch. #running-req: 64, #token: 207767, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1575.92, #queue-req: 0, 
[2025-10-18 01:53:13 TP0] Decode batch. #running-req: 64, #token: 210327, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1553.31, #queue-req: 0, 
[2025-10-18 01:53:15 TP0] Decode batch. #running-req: 64, #token: 212887, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1547.85, #queue-req: 0, 
[2025-10-18 01:53:17 TP0] Decode batch. #running-req: 64, #token: 215447, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1535.47, #queue-req: 0, 
[2025-10-18 01:53:18 TP0] Decode batch. #running-req: 64, #token: 218007, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1532.71, #queue-req: 0, 
[2025-10-18 01:53:20 TP0] Decode batch. #running-req: 64, #token: 220567, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1526.75, #queue-req: 0, 
[2025-10-18 01:53:22 TP0] Decode batch. #running-req: 64, #token: 223127, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.92, #queue-req: 0, 
[2025-10-18 01:53:24 TP0] Decode batch. #running-req: 64, #token: 225687, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.99, #queue-req: 0, 
[2025-10-18 01:53:25 TP0] Decode batch. #running-req: 64, #token: 228247, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1519.73, #queue-req: 0, 
[2025-10-18 01:53:27 TP0] Decode batch. #running-req: 64, #token: 230807, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.65, #queue-req: 0, 
[2025-10-18 01:53:29 TP0] Decode batch. #running-req: 64, #token: 233367, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.08, #queue-req: 0, 
[2025-10-18 01:53:30 TP0] Decode batch. #running-req: 64, #token: 235927, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.23, #queue-req: 0, 
[2025-10-18 01:53:32 TP0] Decode batch. #running-req: 64, #token: 238487, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1521.03, #queue-req: 0, 
[2025-10-18 01:53:34 TP0] Decode batch. #running-req: 64, #token: 241047, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1516.83, #queue-req: 0, 
[2025-10-18 01:53:35 TP0] Decode batch. #running-req: 64, #token: 243607, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1514.03, #queue-req: 0, 
[2025-10-18 01:53:37 TP0] Decode batch. #running-req: 64, #token: 246167, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.90, #queue-req: 0, 
[2025-10-18 01:53:39 TP0] Decode batch. #running-req: 64, #token: 248727, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1509.96, #queue-req: 0, 
[2025-10-18 01:53:40 TP0] Decode batch. #running-req: 64, #token: 251287, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1511.30, #queue-req: 0, 
[2025-10-18 01:53:42 TP0] Decode batch. #running-req: 64, #token: 253847, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1510.29, #queue-req: 0, 
[2025-10-18 01:53:43] INFO:     127.0.0.1:58894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:43 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:53:44] INFO:     127.0.0.1:58902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:58994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 01:53:44] INFO:     127.0.0.1:59048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 39, 
[2025-10-18 01:53:44] INFO:     127.0.0.1:59264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:44] INFO:     127.0.0.1:59382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:53:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:53:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:53:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:53:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:53:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:53:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:53:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:53:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:53:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:53:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 01:53:53 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 01:53:54 TP0] Decode batch. #running-req: 64, #token: 205221, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.30, #queue-req: 0, 
[2025-10-18 01:53:56 TP0] Decode batch. #running-req: 64, #token: 207781, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1568.27, #queue-req: 0, 
[2025-10-18 01:53:57 TP0] Decode batch. #running-req: 64, #token: 210341, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1548.17, #queue-req: 0, 
[2025-10-18 01:53:59 TP0] Decode batch. #running-req: 64, #token: 212901, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1537.63, #queue-req: 0, 
[2025-10-18 01:54:01 TP0] Decode batch. #running-req: 64, #token: 215461, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1531.10, #queue-req: 0, 
[2025-10-18 01:54:02 TP0] Decode batch. #running-req: 64, #token: 218021, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1526.12, #queue-req: 0, 
[2025-10-18 01:54:04 TP0] Decode batch. #running-req: 64, #token: 220581, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1520.26, #queue-req: 0, 
[2025-10-18 01:54:06 TP0] Decode batch. #running-req: 64, #token: 223141, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1515.57, #queue-req: 0, 
[2025-10-18 01:54:07 TP0] Decode batch. #running-req: 64, #token: 225701, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1515.28, #queue-req: 0, 
[2025-10-18 01:54:09 TP0] Decode batch. #running-req: 64, #token: 228261, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1513.97, #queue-req: 0, 
[2025-10-18 01:54:11 TP0] Decode batch. #running-req: 64, #token: 230821, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1513.68, #queue-req: 0, 
[2025-10-18 01:54:13 TP0] Decode batch. #running-req: 64, #token: 233381, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1512.57, #queue-req: 0, 
[2025-10-18 01:54:14 TP0] Decode batch. #running-req: 64, #token: 235941, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1513.86, #queue-req: 0, 
[2025-10-18 01:54:16 TP0] Decode batch. #running-req: 64, #token: 238501, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.85, #queue-req: 0, 
[2025-10-18 01:54:18 TP0] Decode batch. #running-req: 64, #token: 241061, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.79, #queue-req: 0, 
[2025-10-18 01:54:19 TP0] Decode batch. #running-req: 64, #token: 243621, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1508.20, #queue-req: 0, 
[2025-10-18 01:54:21 TP0] Decode batch. #running-req: 64, #token: 246181, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1507.82, #queue-req: 0, 
[2025-10-18 01:54:23 TP0] Decode batch. #running-req: 64, #token: 248741, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.26, #queue-req: 0, 
[2025-10-18 01:54:24 TP0] Decode batch. #running-req: 64, #token: 251301, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1500.22, #queue-req: 0, 
[2025-10-18 01:54:26 TP0] Decode batch. #running-req: 64, #token: 253861, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1499.67, #queue-req: 0, 
[2025-10-18 01:54:28] INFO:     127.0.0.1:39006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:54:28] INFO:     127.0.0.1:39018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28 TP0] Prefill batch. #new-seq: 6, #new-token: 15987, #cached-token: 3219, token usage: 0.01, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:54:28] INFO:     127.0.0.1:39174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39364 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.02, #running-req: 7, #queue-req: 37, 
[2025-10-18 01:54:28] INFO:     127.0.0.1:39496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:28] INFO:     127.0.0.1:39612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:54:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.04, #running-req: 12, #queue-req: 47, 
[2025-10-18 01:54:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.06, #running-req: 17, #queue-req: 42, 
[2025-10-18 01:54:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 22, #queue-req: 37, 
[2025-10-18 01:54:31 TP0] Prefill batch. #new-seq: 7, #new-token: 15993, #cached-token: 6414, token usage: 0.10, #running-req: 27, #queue-req: 30, 
[2025-10-18 01:54:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.11, #running-req: 34, #queue-req: 25, 
[2025-10-18 01:54:33 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.13, #running-req: 39, #queue-req: 20, 
[2025-10-18 01:54:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.14, #running-req: 44, #queue-req: 15, 
[2025-10-18 01:54:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.16, #running-req: 49, #queue-req: 10, 
[2025-10-18 01:54:35 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.18, #running-req: 54, #queue-req: 5, 
[2025-10-18 01:54:36 TP0] Prefill batch. #new-seq: 5, #new-token: 12792, #cached-token: 3213, token usage: 0.19, #running-req: 59, #queue-req: 0, 
[2025-10-18 01:54:38 TP0] Decode batch. #running-req: 64, #token: 202010, token usage: 0.21, cuda graph: True, gen throughput (token/s): 223.74, #queue-req: 0, 
[2025-10-18 01:54:39 TP0] Decode batch. #running-req: 64, #token: 204570, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1570.30, #queue-req: 0, 
[2025-10-18 01:54:41 TP0] Decode batch. #running-req: 64, #token: 207130, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1546.27, #queue-req: 0, 
[2025-10-18 01:54:42 TP0] Decode batch. #running-req: 64, #token: 209690, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1539.16, #queue-req: 0, 
[2025-10-18 01:54:44 TP0] Decode batch. #running-req: 64, #token: 212250, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1539.52, #queue-req: 0, 
[2025-10-18 01:54:46 TP0] Decode batch. #running-req: 64, #token: 214810, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1535.01, #queue-req: 0, 
[2025-10-18 01:54:47 TP0] Decode batch. #running-req: 64, #token: 217370, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1534.62, #queue-req: 0, 
[2025-10-18 01:54:49 TP0] Decode batch. #running-req: 64, #token: 219930, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1531.96, #queue-req: 0, 
[2025-10-18 01:54:51 TP0] Decode batch. #running-req: 64, #token: 222490, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1530.84, #queue-req: 0, 
[2025-10-18 01:54:53 TP0] Decode batch. #running-req: 64, #token: 225050, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.75, #queue-req: 0, 
[2025-10-18 01:54:54 TP0] Decode batch. #running-req: 64, #token: 227610, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.34, #queue-req: 0, 
[2025-10-18 01:54:56 TP0] Decode batch. #running-req: 64, #token: 230170, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1522.48, #queue-req: 0, 
[2025-10-18 01:54:58 TP0] Decode batch. #running-req: 64, #token: 232730, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.49, #queue-req: 0, 
[2025-10-18 01:54:59 TP0] Decode batch. #running-req: 64, #token: 235290, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1525.03, #queue-req: 0, 
[2025-10-18 01:55:01 TP0] Decode batch. #running-req: 64, #token: 237850, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1523.62, #queue-req: 0, 
[2025-10-18 01:55:03 TP0] Decode batch. #running-req: 64, #token: 240410, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1524.33, #queue-req: 0, 
[2025-10-18 01:55:04 TP0] Decode batch. #running-req: 64, #token: 242970, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1522.19, #queue-req: 0, 
[2025-10-18 01:55:06 TP0] Decode batch. #running-req: 64, #token: 245530, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1519.79, #queue-req: 0, 
[2025-10-18 01:55:08 TP0] Decode batch. #running-req: 64, #token: 248090, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.15, #queue-req: 0, 
[2025-10-18 01:55:09 TP0] Decode batch. #running-req: 64, #token: 250650, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1519.83, #queue-req: 0, 
[2025-10-18 01:55:11] INFO:     127.0.0.1:50486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:55:11] INFO:     127.0.0.1:50496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 01:55:11] INFO:     127.0.0.1:50640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50746 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 37, 
[2025-10-18 01:55:11] INFO:     127.0.0.1:50974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:50996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:11] INFO:     127.0.0.1:51106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:12 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:55:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:55:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:55:14 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:55:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:55:16 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 22, 
[2025-10-18 01:55:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 17, 
[2025-10-18 01:55:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 12, 
[2025-10-18 01:55:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 7, 
[2025-10-18 01:55:19 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 1, 
[2025-10-18 01:55:20 TP0] Prefill batch. #new-seq: 1, #new-token: 3193, #cached-token: 8, token usage: 0.21, #running-req: 63, #queue-req: 0, 
[2025-10-18 01:55:21 TP0] Decode batch. #running-req: 64, #token: 205210, token usage: 0.21, cuda graph: True, gen throughput (token/s): 217.96, #queue-req: 0, 
[2025-10-18 01:55:23 TP0] Decode batch. #running-req: 64, #token: 207770, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1563.37, #queue-req: 0, 
[2025-10-18 01:55:24 TP0] Decode batch. #running-req: 64, #token: 210330, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1545.87, #queue-req: 0, 
[2025-10-18 01:55:26 TP0] Decode batch. #running-req: 64, #token: 212890, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.54, #queue-req: 0, 
[2025-10-18 01:55:28 TP0] Decode batch. #running-req: 64, #token: 215450, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1535.48, #queue-req: 0, 
[2025-10-18 01:55:29 TP0] Decode batch. #running-req: 64, #token: 218010, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1530.29, #queue-req: 0, 
[2025-10-18 01:55:31 TP0] Decode batch. #running-req: 64, #token: 220570, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1525.63, #queue-req: 0, 
[2025-10-18 01:55:33 TP0] Decode batch. #running-req: 64, #token: 223130, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1519.30, #queue-req: 0, 
[2025-10-18 01:55:34 TP0] Decode batch. #running-req: 64, #token: 225690, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1517.83, #queue-req: 0, 
[2025-10-18 01:55:36 TP0] Decode batch. #running-req: 64, #token: 228250, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1519.54, #queue-req: 0, 
[2025-10-18 01:55:38 TP0] Decode batch. #running-req: 64, #token: 230810, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.80, #queue-req: 0, 
[2025-10-18 01:55:39 TP0] Decode batch. #running-req: 64, #token: 233370, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1524.94, #queue-req: 0, 
[2025-10-18 01:55:41 TP0] Decode batch. #running-req: 64, #token: 235930, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1527.46, #queue-req: 0, 
[2025-10-18 01:55:43 TP0] Decode batch. #running-req: 64, #token: 238490, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1527.85, #queue-req: 0, 
[2025-10-18 01:55:45 TP0] Decode batch. #running-req: 64, #token: 241050, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1531.71, #queue-req: 0, 
[2025-10-18 01:55:46 TP0] Decode batch. #running-req: 64, #token: 243610, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1520.41, #queue-req: 0, 
[2025-10-18 01:55:48 TP0] Decode batch. #running-req: 64, #token: 246170, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1522.31, #queue-req: 0, 
[2025-10-18 01:55:50 TP0] Decode batch. #running-req: 64, #token: 248730, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.86, #queue-req: 0, 
[2025-10-18 01:55:51 TP0] Decode batch. #running-req: 64, #token: 251290, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1520.74, #queue-req: 0, 
[2025-10-18 01:55:53 TP0] Decode batch. #running-req: 64, #token: 253850, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.53, #queue-req: 0, 
[2025-10-18 01:55:54] INFO:     127.0.0.1:42066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:55:54] INFO:     127.0.0.1:42068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 01:55:54] INFO:     127.0.0.1:42194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:54] INFO:     127.0.0.1:42250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 01:55:55] INFO:     127.0.0.1:42552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55] INFO:     127.0.0.1:42690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:55:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:55:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:55:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:55:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:55:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:55:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:56:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:56:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:56:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:56:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 01:56:03 TP0] Prefill batch. #new-seq: 3, #new-token: 9597, #cached-token: 6, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 01:56:05 TP0] Decode batch. #running-req: 64, #token: 205224, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.94, #queue-req: 0, 
[2025-10-18 01:56:07 TP0] Decode batch. #running-req: 64, #token: 207784, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1575.42, #queue-req: 0, 
[2025-10-18 01:56:08 TP0] Decode batch. #running-req: 64, #token: 210344, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1545.76, #queue-req: 0, 
[2025-10-18 01:56:10 TP0] Decode batch. #running-req: 64, #token: 212904, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1540.53, #queue-req: 0, 
[2025-10-18 01:56:12 TP0] Decode batch. #running-req: 64, #token: 215464, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.06, #queue-req: 0, 
[2025-10-18 01:56:13 TP0] Decode batch. #running-req: 64, #token: 218024, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1533.77, #queue-req: 0, 
[2025-10-18 01:56:15 TP0] Decode batch. #running-req: 64, #token: 220584, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1534.94, #queue-req: 0, 
[2025-10-18 01:56:17 TP0] Decode batch. #running-req: 64, #token: 223144, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1531.25, #queue-req: 0, 
[2025-10-18 01:56:18 TP0] Decode batch. #running-req: 64, #token: 225704, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1530.82, #queue-req: 0, 
[2025-10-18 01:56:20 TP0] Decode batch. #running-req: 64, #token: 228264, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1527.70, #queue-req: 0, 
[2025-10-18 01:56:22 TP0] Decode batch. #running-req: 64, #token: 230824, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1529.85, #queue-req: 0, 
[2025-10-18 01:56:23 TP0] Decode batch. #running-req: 64, #token: 233384, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1530.73, #queue-req: 0, 
[2025-10-18 01:56:25 TP0] Decode batch. #running-req: 64, #token: 235944, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1532.85, #queue-req: 0, 
[2025-10-18 01:56:27 TP0] Decode batch. #running-req: 64, #token: 238504, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1531.14, #queue-req: 0, 
[2025-10-18 01:56:28 TP0] Decode batch. #running-req: 64, #token: 241064, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1529.81, #queue-req: 0, 
[2025-10-18 01:56:30 TP0] Decode batch. #running-req: 64, #token: 243624, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1526.84, #queue-req: 0, 
[2025-10-18 01:56:32 TP0] Decode batch. #running-req: 64, #token: 246184, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1523.92, #queue-req: 0, 
[2025-10-18 01:56:33 TP0] Decode batch. #running-req: 64, #token: 248744, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.31, #queue-req: 0, 
[2025-10-18 01:56:35 TP0] Decode batch. #running-req: 64, #token: 251304, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1517.91, #queue-req: 0, 
[2025-10-18 01:56:37 TP0] Decode batch. #running-req: 64, #token: 253864, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1516.08, #queue-req: 0, 
[2025-10-18 01:56:38] INFO:     127.0.0.1:46810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:56:38] INFO:     127.0.0.1:46814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 01:56:38] INFO:     127.0.0.1:46934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:46988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 01:56:38] INFO:     127.0.0.1:47240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47284 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:38] INFO:     127.0.0.1:47332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:39] INFO:     127.0.0.1:47344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:39] INFO:     127.0.0.1:47358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:39] INFO:     127.0.0.1:47370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:56:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:56:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:56:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:56:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:56:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:56:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:56:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:56:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:56:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:56:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 01:56:47 TP0] Prefill batch. #new-seq: 3, #new-token: 9593, #cached-token: 10, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 01:56:49 TP0] Decode batch. #running-req: 64, #token: 205214, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.49, #queue-req: 0, 
[2025-10-18 01:56:50 TP0] Decode batch. #running-req: 64, #token: 207774, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1571.32, #queue-req: 0, 
[2025-10-18 01:56:52 TP0] Decode batch. #running-req: 64, #token: 210334, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1551.30, #queue-req: 0, 
[2025-10-18 01:56:54 TP0] Decode batch. #running-req: 64, #token: 212894, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1541.14, #queue-req: 0, 
[2025-10-18 01:56:55 TP0] Decode batch. #running-req: 64, #token: 215454, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1534.08, #queue-req: 0, 
[2025-10-18 01:56:57 TP0] Decode batch. #running-req: 64, #token: 218014, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1528.49, #queue-req: 0, 
[2025-10-18 01:56:59 TP0] Decode batch. #running-req: 64, #token: 220574, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.42, #queue-req: 0, 
[2025-10-18 01:57:00 TP0] Decode batch. #running-req: 64, #token: 223134, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.29, #queue-req: 0, 
[2025-10-18 01:57:02 TP0] Decode batch. #running-req: 64, #token: 225694, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.17, #queue-req: 0, 
[2025-10-18 01:57:04 TP0] Decode batch. #running-req: 64, #token: 228254, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.68, #queue-req: 0, 
[2025-10-18 01:57:05 TP0] Decode batch. #running-req: 64, #token: 230814, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1522.03, #queue-req: 0, 
[2025-10-18 01:57:07 TP0] Decode batch. #running-req: 64, #token: 233374, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.04, #queue-req: 0, 
[2025-10-18 01:57:09 TP0] Decode batch. #running-req: 64, #token: 235934, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.11, #queue-req: 0, 
[2025-10-18 01:57:11 TP0] Decode batch. #running-req: 64, #token: 238494, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1514.04, #queue-req: 0, 
[2025-10-18 01:57:12 TP0] Decode batch. #running-req: 64, #token: 241054, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.36, #queue-req: 0, 
[2025-10-18 01:57:14 TP0] Decode batch. #running-req: 64, #token: 243614, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1505.42, #queue-req: 0, 
[2025-10-18 01:57:16 TP0] Decode batch. #running-req: 64, #token: 246174, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1508.51, #queue-req: 0, 
[2025-10-18 01:57:17 TP0] Decode batch. #running-req: 64, #token: 248734, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.96, #queue-req: 0, 
[2025-10-18 01:57:19 TP0] Decode batch. #running-req: 64, #token: 251294, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1506.42, #queue-req: 0, 
[2025-10-18 01:57:21 TP0] Decode batch. #running-req: 64, #token: 253854, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1503.69, #queue-req: 0, 
[2025-10-18 01:57:22] INFO:     127.0.0.1:51906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:57:22] INFO:     127.0.0.1:51918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:51988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 01:57:22] INFO:     127.0.0.1:52040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22] INFO:     127.0.0.1:52376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 01:57:22] INFO:     127.0.0.1:52378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:57:23 TP0] Prefill batch. #new-seq: 6, #new-token: 15988, #cached-token: 3218, token usage: 0.04, #running-req: 11, #queue-req: 35, 
[2025-10-18 01:57:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.06, #running-req: 17, #queue-req: 30, 
[2025-10-18 01:57:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 22, #queue-req: 25, 
[2025-10-18 01:57:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.09, #running-req: 27, #queue-req: 20, 
[2025-10-18 01:57:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.11, #running-req: 32, #queue-req: 15, 
[2025-10-18 01:57:27 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.12, #running-req: 37, #queue-req: 10, 
[2025-10-18 01:57:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.14, #running-req: 42, #queue-req: 5, 
[2025-10-18 01:57:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.15, #running-req: 47, #queue-req: 0, 
[2025-10-18 01:57:31 TP0] Decode batch. #running-req: 52, #token: 166738, token usage: 0.17, cuda graph: True, gen throughput (token/s): 249.13, #queue-req: 0, 
[2025-10-18 01:57:32 TP0] Decode batch. #running-req: 52, #token: 168818, token usage: 0.17, cuda graph: True, gen throughput (token/s): 1322.28, #queue-req: 0, 
[2025-10-18 01:57:34 TP0] Decode batch. #running-req: 52, #token: 170898, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1307.86, #queue-req: 0, 
[2025-10-18 01:57:35 TP0] Decode batch. #running-req: 52, #token: 172978, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1301.17, #queue-req: 0, 
[2025-10-18 01:57:37 TP0] Decode batch. #running-req: 52, #token: 175058, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1295.88, #queue-req: 0, 
[2025-10-18 01:57:39 TP0] Decode batch. #running-req: 52, #token: 177138, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1291.25, #queue-req: 0, 
[2025-10-18 01:57:40 TP0] Decode batch. #running-req: 52, #token: 179218, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1291.60, #queue-req: 0, 
[2025-10-18 01:57:42 TP0] Decode batch. #running-req: 52, #token: 181298, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1291.63, #queue-req: 0, 
[2025-10-18 01:57:43 TP0] Decode batch. #running-req: 52, #token: 183378, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1288.35, #queue-req: 0, 
[2025-10-18 01:57:45 TP0] Decode batch. #running-req: 52, #token: 185458, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1288.32, #queue-req: 0, 
[2025-10-18 01:57:47 TP0] Decode batch. #running-req: 52, #token: 187538, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1288.24, #queue-req: 0, 
[2025-10-18 01:57:48 TP0] Decode batch. #running-req: 52, #token: 189618, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1286.35, #queue-req: 0, 
[2025-10-18 01:57:50 TP0] Decode batch. #running-req: 52, #token: 191698, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1289.69, #queue-req: 0, 
[2025-10-18 01:57:52 TP0] Decode batch. #running-req: 52, #token: 193778, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1287.37, #queue-req: 0, 
[2025-10-18 01:57:53 TP0] Decode batch. #running-req: 52, #token: 195858, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1285.16, #queue-req: 0, 
[2025-10-18 01:57:55 TP0] Decode batch. #running-req: 52, #token: 197938, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1285.36, #queue-req: 0, 
[2025-10-18 01:57:56 TP0] Decode batch. #running-req: 52, #token: 200018, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1283.31, #queue-req: 0, 
[2025-10-18 01:57:58 TP0] Decode batch. #running-req: 52, #token: 202098, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1280.32, #queue-req: 0, 
[2025-10-18 01:58:00 TP0] Decode batch. #running-req: 52, #token: 204178, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1277.71, #queue-req: 0, 
[2025-10-18 01:58:01 TP0] Decode batch. #running-req: 52, #token: 206258, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1278.89, #queue-req: 0, 
[2025-10-18 01:58:03] INFO:     127.0.0.1:53382 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 01:58:26] INFO:     127.0.0.1:38340 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 01:58:32] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:32 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:58:33 TP0] Decode batch. #running-req: 1, #token: 3209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.74, #queue-req: 0, 
[2025-10-18 01:58:34] INFO:     127.0.0.1:42924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:42936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:58:34] INFO:     127.0.0.1:42944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:42960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:42976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:42992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:42994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 01:58:34] INFO:     127.0.0.1:43068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 22, 
[2025-10-18 01:58:34] INFO:     127.0.0.1:43230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:34] INFO:     127.0.0.1:43248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:58:35 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:58:36 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:58:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:58:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:58:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:58:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:58:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:58:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:58:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:58:42 TP0] Prefill batch. #new-seq: 6, #new-token: 15989, #cached-token: 3217, token usage: 0.19, #running-req: 56, #queue-req: 2, 
[2025-10-18 01:58:43 TP0] Prefill batch. #new-seq: 2, #new-token: 6398, #cached-token: 4, token usage: 0.20, #running-req: 62, #queue-req: 0, 
[2025-10-18 01:58:45 TP0] Decode batch. #running-req: 64, #token: 205736, token usage: 0.21, cuda graph: True, gen throughput (token/s): 81.13, #queue-req: 0, 
[2025-10-18 01:58:47 TP0] Decode batch. #running-req: 64, #token: 208296, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1573.76, #queue-req: 0, 
[2025-10-18 01:58:48 TP0] Decode batch. #running-req: 64, #token: 210856, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1554.81, #queue-req: 0, 
[2025-10-18 01:58:50 TP0] Decode batch. #running-req: 64, #token: 213416, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1543.84, #queue-req: 0, 
[2025-10-18 01:58:51 TP0] Decode batch. #running-req: 64, #token: 215976, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1536.18, #queue-req: 0, 
[2025-10-18 01:58:53 TP0] Decode batch. #running-req: 64, #token: 218536, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1522.62, #queue-req: 0, 
[2025-10-18 01:58:55 TP0] Decode batch. #running-req: 64, #token: 221096, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.08, #queue-req: 0, 
[2025-10-18 01:58:57 TP0] Decode batch. #running-req: 64, #token: 223656, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.86, #queue-req: 0, 
[2025-10-18 01:58:58 TP0] Decode batch. #running-req: 64, #token: 226216, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.73, #queue-req: 0, 
[2025-10-18 01:59:00 TP0] Decode batch. #running-req: 64, #token: 228776, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1517.13, #queue-req: 0, 
[2025-10-18 01:59:02 TP0] Decode batch. #running-req: 64, #token: 231336, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1516.92, #queue-req: 0, 
[2025-10-18 01:59:03 TP0] Decode batch. #running-req: 64, #token: 233896, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1516.53, #queue-req: 0, 
[2025-10-18 01:59:05 TP0] Decode batch. #running-req: 64, #token: 236456, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.43, #queue-req: 0, 
[2025-10-18 01:59:07 TP0] Decode batch. #running-req: 64, #token: 239016, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.02, #queue-req: 0, 
[2025-10-18 01:59:08 TP0] Decode batch. #running-req: 64, #token: 241576, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1518.42, #queue-req: 0, 
[2025-10-18 01:59:10 TP0] Decode batch. #running-req: 64, #token: 244136, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.34, #queue-req: 0, 
[2025-10-18 01:59:12 TP0] Decode batch. #running-req: 64, #token: 246696, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1511.01, #queue-req: 0, 
[2025-10-18 01:59:13 TP0] Decode batch. #running-req: 64, #token: 249256, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1506.77, #queue-req: 0, 
[2025-10-18 01:59:15 TP0] Decode batch. #running-req: 64, #token: 251816, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1503.03, #queue-req: 0, 
[2025-10-18 01:59:17 TP0] Decode batch. #running-req: 64, #token: 254376, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1501.69, #queue-req: 0, 
[2025-10-18 01:59:18] INFO:     127.0.0.1:41588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18 TP0] Prefill batch. #new-seq: 1, #new-token: 3195, #cached-token: 6, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 01:59:18] INFO:     127.0.0.1:41598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 01:59:18] INFO:     127.0.0.1:41770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41988 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:41996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 42, 
[2025-10-18 01:59:18] INFO:     127.0.0.1:42068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:18] INFO:     127.0.0.1:42148 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 01:59:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 01:59:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15978, #cached-token: 27, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 01:59:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 01:59:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 01:59:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 01:59:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 01:59:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 01:59:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 01:59:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 01:59:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 01:59:27 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 01:59:29 TP0] Decode batch. #running-req: 64, #token: 205719, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.84, #queue-req: 0, 
[2025-10-18 01:59:30 TP0] Decode batch. #running-req: 64, #token: 208279, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1564.03, #queue-req: 0, 
[2025-10-18 01:59:32 TP0] Decode batch. #running-req: 64, #token: 210839, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1549.80, #queue-req: 0, 
[2025-10-18 01:59:34 TP0] Decode batch. #running-req: 64, #token: 213399, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1543.03, #queue-req: 0, 
[2025-10-18 01:59:35 TP0] Decode batch. #running-req: 64, #token: 215959, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1537.10, #queue-req: 0, 
[2025-10-18 01:59:37 TP0] Decode batch. #running-req: 64, #token: 218519, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1532.60, #queue-req: 0, 
[2025-10-18 01:59:39 TP0] Decode batch. #running-req: 64, #token: 221079, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1527.19, #queue-req: 0, 
[2025-10-18 01:59:40 TP0] Decode batch. #running-req: 64, #token: 223639, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.19, #queue-req: 0, 
[2025-10-18 01:59:42 TP0] Decode batch. #running-req: 64, #token: 226199, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.80, #queue-req: 0, 
[2025-10-18 01:59:44 TP0] Decode batch. #running-req: 64, #token: 228759, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.71, #queue-req: 0, 
[2025-10-18 01:59:46 TP0] Decode batch. #running-req: 64, #token: 231319, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.91, #queue-req: 0, 
[2025-10-18 01:59:47 TP0] Decode batch. #running-req: 64, #token: 233879, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.70, #queue-req: 0, 
[2025-10-18 01:59:49 TP0] Decode batch. #running-req: 64, #token: 236439, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.52, #queue-req: 0, 
[2025-10-18 01:59:51 TP0] Decode batch. #running-req: 64, #token: 238999, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1520.77, #queue-req: 0, 
[2025-10-18 01:59:52 TP0] Decode batch. #running-req: 64, #token: 241559, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1517.89, #queue-req: 0, 
[2025-10-18 01:59:54 TP0] Decode batch. #running-req: 64, #token: 244119, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.39, #queue-req: 0, 
[2025-10-18 01:59:56 TP0] Decode batch. #running-req: 64, #token: 246679, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1511.96, #queue-req: 0, 
[2025-10-18 01:59:57 TP0] Decode batch. #running-req: 64, #token: 249239, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1506.33, #queue-req: 0, 
[2025-10-18 01:59:59 TP0] Decode batch. #running-req: 64, #token: 251799, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1505.79, #queue-req: 0, 
[2025-10-18 02:00:01 TP0] Decode batch. #running-req: 64, #token: 254359, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1501.99, #queue-req: 0, 
[2025-10-18 02:00:02] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:00:02] INFO:     127.0.0.1:48464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48578 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:00:02] INFO:     127.0.0.1:48606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 39, 
[2025-10-18 02:00:02] INFO:     127.0.0.1:48904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:48994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:02] INFO:     127.0.0.1:49010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:00:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:00:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:00:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:00:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:00:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:00:08 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:00:09 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:00:09 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:00:10 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:00:11 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:00:13 TP0] Decode batch. #running-req: 64, #token: 205733, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.43, #queue-req: 0, 
[2025-10-18 02:00:14 TP0] Decode batch. #running-req: 64, #token: 208293, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1563.31, #queue-req: 0, 
[2025-10-18 02:00:16 TP0] Decode batch. #running-req: 64, #token: 210853, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1546.14, #queue-req: 0, 
[2025-10-18 02:00:18 TP0] Decode batch. #running-req: 64, #token: 213413, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1533.83, #queue-req: 0, 
[2025-10-18 02:00:19 TP0] Decode batch. #running-req: 64, #token: 215973, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1528.68, #queue-req: 0, 
[2025-10-18 02:00:21 TP0] Decode batch. #running-req: 64, #token: 218533, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1520.59, #queue-req: 0, 
[2025-10-18 02:00:23 TP0] Decode batch. #running-req: 64, #token: 221093, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1517.96, #queue-req: 0, 
[2025-10-18 02:00:24 TP0] Decode batch. #running-req: 64, #token: 223653, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1513.28, #queue-req: 0, 
[2025-10-18 02:00:26 TP0] Decode batch. #running-req: 64, #token: 226213, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1510.94, #queue-req: 0, 
[2025-10-18 02:00:28 TP0] Decode batch. #running-req: 64, #token: 228773, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1510.87, #queue-req: 0, 
[2025-10-18 02:00:30 TP0] Decode batch. #running-req: 64, #token: 231333, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1508.96, #queue-req: 0, 
[2025-10-18 02:00:31 TP0] Decode batch. #running-req: 64, #token: 233893, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1507.46, #queue-req: 0, 
[2025-10-18 02:00:33 TP0] Decode batch. #running-req: 64, #token: 236453, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1509.07, #queue-req: 0, 
[2025-10-18 02:00:35 TP0] Decode batch. #running-req: 64, #token: 239013, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1508.33, #queue-req: 0, 
[2025-10-18 02:00:36 TP0] Decode batch. #running-req: 64, #token: 241573, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1508.01, #queue-req: 0, 
[2025-10-18 02:00:38 TP0] Decode batch. #running-req: 64, #token: 244133, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1504.66, #queue-req: 0, 
[2025-10-18 02:00:40 TP0] Decode batch. #running-req: 64, #token: 246693, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1502.94, #queue-req: 0, 
[2025-10-18 02:00:41 TP0] Decode batch. #running-req: 64, #token: 249253, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1500.66, #queue-req: 0, 
[2025-10-18 02:00:43 TP0] Decode batch. #running-req: 64, #token: 251813, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1499.28, #queue-req: 0, 
[2025-10-18 02:00:45 TP0] Decode batch. #running-req: 64, #token: 254373, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1497.44, #queue-req: 0, 
[2025-10-18 02:00:46] INFO:     127.0.0.1:54154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:00:46] INFO:     127.0.0.1:54158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46 TP0] Prefill batch. #new-seq: 6, #new-token: 15987, #cached-token: 3219, token usage: 0.01, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:00:46] INFO:     127.0.0.1:54252 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.02, #running-req: 7, #queue-req: 38, 
[2025-10-18 02:00:46] INFO:     127.0.0.1:54580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54634 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:46] INFO:     127.0.0.1:54682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:00:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.04, #running-req: 12, #queue-req: 47, 
[2025-10-18 02:00:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.06, #running-req: 17, #queue-req: 42, 
[2025-10-18 02:00:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 22, #queue-req: 37, 
[2025-10-18 02:00:49 TP0] Prefill batch. #new-seq: 7, #new-token: 15993, #cached-token: 6414, token usage: 0.10, #running-req: 27, #queue-req: 30, 
[2025-10-18 02:00:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.11, #running-req: 34, #queue-req: 25, 
[2025-10-18 02:00:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.13, #running-req: 39, #queue-req: 20, 
[2025-10-18 02:00:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.14, #running-req: 44, #queue-req: 15, 
[2025-10-18 02:00:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.16, #running-req: 49, #queue-req: 10, 
[2025-10-18 02:00:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.18, #running-req: 54, #queue-req: 5, 
[2025-10-18 02:00:54 TP0] Prefill batch. #new-seq: 5, #new-token: 12792, #cached-token: 3213, token usage: 0.19, #running-req: 59, #queue-req: 0, 
[2025-10-18 02:00:56 TP0] Decode batch. #running-req: 64, #token: 202522, token usage: 0.21, cuda graph: True, gen throughput (token/s): 224.08, #queue-req: 0, 
[2025-10-18 02:00:58 TP0] Decode batch. #running-req: 64, #token: 205082, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1554.75, #queue-req: 0, 
[2025-10-18 02:01:00 TP0] Decode batch. #running-req: 64, #token: 207642, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1533.95, #queue-req: 0, 
[2025-10-18 02:01:01 TP0] Decode batch. #running-req: 64, #token: 210202, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1532.69, #queue-req: 0, 
[2025-10-18 02:01:03 TP0] Decode batch. #running-req: 64, #token: 212762, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1532.67, #queue-req: 0, 
[2025-10-18 02:01:05 TP0] Decode batch. #running-req: 64, #token: 215322, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1528.43, #queue-req: 0, 
[2025-10-18 02:01:06 TP0] Decode batch. #running-req: 64, #token: 217882, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1526.53, #queue-req: 0, 
[2025-10-18 02:01:08 TP0] Decode batch. #running-req: 64, #token: 220442, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.59, #queue-req: 0, 
[2025-10-18 02:01:10 TP0] Decode batch. #running-req: 64, #token: 223002, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.33, #queue-req: 0, 
[2025-10-18 02:01:11 TP0] Decode batch. #running-req: 64, #token: 225562, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.06, #queue-req: 0, 
[2025-10-18 02:01:13 TP0] Decode batch. #running-req: 64, #token: 228122, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1519.13, #queue-req: 0, 
[2025-10-18 02:01:15 TP0] Decode batch. #running-req: 64, #token: 230682, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.73, #queue-req: 0, 
[2025-10-18 02:01:16 TP0] Decode batch. #running-req: 64, #token: 233242, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.33, #queue-req: 0, 
[2025-10-18 02:01:18 TP0] Decode batch. #running-req: 64, #token: 235802, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.60, #queue-req: 0, 
[2025-10-18 02:01:20 TP0] Decode batch. #running-req: 64, #token: 238362, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1521.41, #queue-req: 0, 
[2025-10-18 02:01:21 TP0] Decode batch. #running-req: 64, #token: 240922, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1520.73, #queue-req: 0, 
[2025-10-18 02:01:23 TP0] Decode batch. #running-req: 64, #token: 243482, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1521.19, #queue-req: 0, 
[2025-10-18 02:01:25 TP0] Decode batch. #running-req: 64, #token: 246042, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1517.31, #queue-req: 0, 
[2025-10-18 02:01:26 TP0] Decode batch. #running-req: 64, #token: 248602, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1514.34, #queue-req: 0, 
[2025-10-18 02:01:28 TP0] Decode batch. #running-req: 64, #token: 251162, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.00, #queue-req: 0, 
[2025-10-18 02:01:29] INFO:     127.0.0.1:45482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:01:29] INFO:     127.0.0.1:45488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45622 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:01:29] INFO:     127.0.0.1:45638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:29] INFO:     127.0.0.1:45820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:01:30] INFO:     127.0.0.1:45916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:45984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30] INFO:     127.0.0.1:46064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:01:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:01:31 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:01:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:01:33 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:01:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:01:34 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 22, 
[2025-10-18 02:01:35 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 17, 
[2025-10-18 02:01:36 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 12, 
[2025-10-18 02:01:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 7, 
[2025-10-18 02:01:38 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 1, 
[2025-10-18 02:01:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3193, #cached-token: 8, token usage: 0.21, #running-req: 63, #queue-req: 0, 
[2025-10-18 02:01:40 TP0] Decode batch. #running-req: 64, #token: 205722, token usage: 0.21, cuda graph: True, gen throughput (token/s): 217.75, #queue-req: 0, 
[2025-10-18 02:01:42 TP0] Decode batch. #running-req: 64, #token: 208282, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1557.36, #queue-req: 0, 
[2025-10-18 02:01:43 TP0] Decode batch. #running-req: 64, #token: 210842, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1544.84, #queue-req: 0, 
[2025-10-18 02:01:45 TP0] Decode batch. #running-req: 64, #token: 213402, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1540.95, #queue-req: 0, 
[2025-10-18 02:01:47 TP0] Decode batch. #running-req: 64, #token: 215962, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1534.40, #queue-req: 0, 
[2025-10-18 02:01:48 TP0] Decode batch. #running-req: 64, #token: 218522, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1528.39, #queue-req: 0, 
[2025-10-18 02:01:50 TP0] Decode batch. #running-req: 64, #token: 221082, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1525.00, #queue-req: 0, 
[2025-10-18 02:01:52 TP0] Decode batch. #running-req: 64, #token: 223642, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.26, #queue-req: 0, 
[2025-10-18 02:01:53 TP0] Decode batch. #running-req: 64, #token: 226202, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.58, #queue-req: 0, 
[2025-10-18 02:01:55 TP0] Decode batch. #running-req: 64, #token: 228762, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.61, #queue-req: 0, 
[2025-10-18 02:01:57 TP0] Decode batch. #running-req: 64, #token: 231322, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.48, #queue-req: 0, 
[2025-10-18 02:01:58 TP0] Decode batch. #running-req: 64, #token: 233882, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.90, #queue-req: 0, 
[2025-10-18 02:02:00 TP0] Decode batch. #running-req: 64, #token: 236442, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1523.04, #queue-req: 0, 
[2025-10-18 02:02:02 TP0] Decode batch. #running-req: 64, #token: 239002, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1522.85, #queue-req: 0, 
[2025-10-18 02:02:03 TP0] Decode batch. #running-req: 64, #token: 241562, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1521.33, #queue-req: 0, 
[2025-10-18 02:02:05 TP0] Decode batch. #running-req: 64, #token: 244122, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1519.43, #queue-req: 0, 
[2025-10-18 02:02:07 TP0] Decode batch. #running-req: 64, #token: 246682, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1516.68, #queue-req: 0, 
[2025-10-18 02:02:08 TP0] Decode batch. #running-req: 64, #token: 249242, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.33, #queue-req: 0, 
[2025-10-18 02:02:10 TP0] Decode batch. #running-req: 64, #token: 251802, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1516.43, #queue-req: 0, 
[2025-10-18 02:02:12 TP0] Decode batch. #running-req: 64, #token: 254362, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1510.32, #queue-req: 0, 
[2025-10-18 02:02:13] INFO:     127.0.0.1:46618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:02:13] INFO:     127.0.0.1:46626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:02:13] INFO:     127.0.0.1:46758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:46998 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:02:13] INFO:     127.0.0.1:47072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:13] INFO:     127.0.0.1:47200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:14 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:02:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:02:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:02:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:02:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:02:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:02:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:02:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:02:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:02:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:02:22 TP0] Prefill batch. #new-seq: 3, #new-token: 9597, #cached-token: 6, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:02:24 TP0] Decode batch. #running-req: 64, #token: 205736, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.37, #queue-req: 0, 
[2025-10-18 02:02:25 TP0] Decode batch. #running-req: 64, #token: 208296, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1570.34, #queue-req: 0, 
[2025-10-18 02:02:27 TP0] Decode batch. #running-req: 64, #token: 210856, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1550.83, #queue-req: 0, 
[2025-10-18 02:02:29 TP0] Decode batch. #running-req: 64, #token: 213416, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1542.98, #queue-req: 0, 
[2025-10-18 02:02:30 TP0] Decode batch. #running-req: 64, #token: 215976, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1536.15, #queue-req: 0, 
[2025-10-18 02:02:32 TP0] Decode batch. #running-req: 64, #token: 218536, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1533.80, #queue-req: 0, 
[2025-10-18 02:02:34 TP0] Decode batch. #running-req: 64, #token: 221096, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1533.71, #queue-req: 0, 
[2025-10-18 02:02:35 TP0] Decode batch. #running-req: 64, #token: 223656, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1532.36, #queue-req: 0, 
[2025-10-18 02:02:37 TP0] Decode batch. #running-req: 64, #token: 226216, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1534.90, #queue-req: 0, 
[2025-10-18 02:02:39 TP0] Decode batch. #running-req: 64, #token: 228776, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1533.81, #queue-req: 0, 
[2025-10-18 02:02:40 TP0] Decode batch. #running-req: 64, #token: 231336, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1530.08, #queue-req: 0, 
[2025-10-18 02:02:42 TP0] Decode batch. #running-req: 64, #token: 233896, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1532.00, #queue-req: 0, 
[2025-10-18 02:02:44 TP0] Decode batch. #running-req: 64, #token: 236456, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1532.62, #queue-req: 0, 
[2025-10-18 02:02:45 TP0] Decode batch. #running-req: 64, #token: 239016, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1529.98, #queue-req: 0, 
[2025-10-18 02:02:47 TP0] Decode batch. #running-req: 64, #token: 241576, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1526.98, #queue-req: 0, 
[2025-10-18 02:02:49 TP0] Decode batch. #running-req: 64, #token: 244136, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1523.00, #queue-req: 0, 
[2025-10-18 02:02:51 TP0] Decode batch. #running-req: 64, #token: 246696, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1522.22, #queue-req: 0, 
[2025-10-18 02:02:52 TP0] Decode batch. #running-req: 64, #token: 249256, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1518.42, #queue-req: 0, 
[2025-10-18 02:02:54 TP0] Decode batch. #running-req: 64, #token: 251816, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.53, #queue-req: 0, 
[2025-10-18 02:02:56 TP0] Decode batch. #running-req: 64, #token: 254376, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.47, #queue-req: 0, 
[2025-10-18 02:02:57] INFO:     127.0.0.1:49832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:02:57] INFO:     127.0.0.1:49844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:02:57] INFO:     127.0.0.1:49982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:49990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:02:57] INFO:     127.0.0.1:50322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:57] INFO:     127.0.0.1:50412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:02:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:02:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:02:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:03:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:03:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:03:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:03:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:03:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:03:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:03:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:03:06 TP0] Prefill batch. #new-seq: 3, #new-token: 9593, #cached-token: 10, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:03:08 TP0] Decode batch. #running-req: 64, #token: 205726, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.11, #queue-req: 0, 
[2025-10-18 02:03:09 TP0] Decode batch. #running-req: 64, #token: 208286, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1569.65, #queue-req: 0, 
[2025-10-18 02:03:11 TP0] Decode batch. #running-req: 64, #token: 210846, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1558.59, #queue-req: 0, 
[2025-10-18 02:03:13 TP0] Decode batch. #running-req: 64, #token: 213406, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1551.78, #queue-req: 0, 
[2025-10-18 02:03:14 TP0] Decode batch. #running-req: 64, #token: 215966, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1544.72, #queue-req: 0, 
[2025-10-18 02:03:16 TP0] Decode batch. #running-req: 64, #token: 218526, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1536.63, #queue-req: 0, 
[2025-10-18 02:03:17 TP0] Decode batch. #running-req: 64, #token: 221086, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1535.94, #queue-req: 0, 
[2025-10-18 02:03:19 TP0] Decode batch. #running-req: 64, #token: 223646, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1531.56, #queue-req: 0, 
[2025-10-18 02:03:21 TP0] Decode batch. #running-req: 64, #token: 226206, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1531.08, #queue-req: 0, 
[2025-10-18 02:03:23 TP0] Decode batch. #running-req: 64, #token: 228766, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1529.30, #queue-req: 0, 
[2025-10-18 02:03:24 TP0] Decode batch. #running-req: 64, #token: 231326, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1525.64, #queue-req: 0, 
[2025-10-18 02:03:26 TP0] Decode batch. #running-req: 64, #token: 233886, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1527.75, #queue-req: 0, 
[2025-10-18 02:03:28 TP0] Decode batch. #running-req: 64, #token: 236446, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1526.89, #queue-req: 0, 
[2025-10-18 02:03:29 TP0] Decode batch. #running-req: 64, #token: 239006, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1525.31, #queue-req: 0, 
[2025-10-18 02:03:31 TP0] Decode batch. #running-req: 64, #token: 241566, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1525.02, #queue-req: 0, 
[2025-10-18 02:03:33 TP0] Decode batch. #running-req: 64, #token: 244126, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1517.04, #queue-req: 0, 
[2025-10-18 02:03:34 TP0] Decode batch. #running-req: 64, #token: 246686, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.34, #queue-req: 0, 
[2025-10-18 02:03:36 TP0] Decode batch. #running-req: 64, #token: 249246, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.35, #queue-req: 0, 
[2025-10-18 02:03:38 TP0] Decode batch. #running-req: 64, #token: 251806, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.21, #queue-req: 0, 
[2025-10-18 02:03:39 TP0] Decode batch. #running-req: 64, #token: 254366, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1510.20, #queue-req: 0, 
[2025-10-18 02:03:40] INFO:     127.0.0.1:51026 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:03:40] INFO:     127.0.0.1:51042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:40] INFO:     127.0.0.1:51120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:03:41] INFO:     127.0.0.1:51204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51366 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41] INFO:     127.0.0.1:51530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:03:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.02, #running-req: 6, #queue-req: 40, 
[2025-10-18 02:03:42 TP0] Prefill batch. #new-seq: 6, #new-token: 15988, #cached-token: 3218, token usage: 0.04, #running-req: 11, #queue-req: 35, 
[2025-10-18 02:03:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.06, #running-req: 17, #queue-req: 30, 
[2025-10-18 02:03:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 22, #queue-req: 25, 
[2025-10-18 02:03:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.09, #running-req: 27, #queue-req: 20, 
[2025-10-18 02:03:45 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.11, #running-req: 32, #queue-req: 15, 
[2025-10-18 02:03:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.12, #running-req: 37, #queue-req: 10, 
[2025-10-18 02:03:46 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.14, #running-req: 42, #queue-req: 5, 
[2025-10-18 02:03:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.15, #running-req: 47, #queue-req: 0, 
[2025-10-18 02:03:49 TP0] Decode batch. #running-req: 52, #token: 167154, token usage: 0.17, cuda graph: True, gen throughput (token/s): 240.76, #queue-req: 0, 
[2025-10-18 02:03:51 TP0] Decode batch. #running-req: 52, #token: 169234, token usage: 0.17, cuda graph: True, gen throughput (token/s): 1321.85, #queue-req: 0, 
[2025-10-18 02:03:52 TP0] Decode batch. #running-req: 52, #token: 171314, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1305.94, #queue-req: 0, 
[2025-10-18 02:03:54 TP0] Decode batch. #running-req: 52, #token: 173394, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1298.86, #queue-req: 0, 
[2025-10-18 02:03:56 TP0] Decode batch. #running-req: 52, #token: 175474, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1291.32, #queue-req: 0, 
[2025-10-18 02:03:57 TP0] Decode batch. #running-req: 52, #token: 177554, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1293.16, #queue-req: 0, 
[2025-10-18 02:03:59 TP0] Decode batch. #running-req: 52, #token: 179634, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1295.34, #queue-req: 0, 
[2025-10-18 02:04:00 TP0] Decode batch. #running-req: 52, #token: 181714, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1298.11, #queue-req: 0, 
[2025-10-18 02:04:02 TP0] Decode batch. #running-req: 52, #token: 183794, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1293.45, #queue-req: 0, 
[2025-10-18 02:04:04 TP0] Decode batch. #running-req: 52, #token: 185874, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1290.90, #queue-req: 0, 
[2025-10-18 02:04:05 TP0] Decode batch. #running-req: 52, #token: 187954, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1291.12, #queue-req: 0, 
[2025-10-18 02:04:07 TP0] Decode batch. #running-req: 52, #token: 190034, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1291.95, #queue-req: 0, 
[2025-10-18 02:04:08 TP0] Decode batch. #running-req: 52, #token: 192114, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1290.35, #queue-req: 0, 
[2025-10-18 02:04:10 TP0] Decode batch. #running-req: 52, #token: 194194, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1287.39, #queue-req: 0, 
[2025-10-18 02:04:12 TP0] Decode batch. #running-req: 52, #token: 196274, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1287.11, #queue-req: 0, 
[2025-10-18 02:04:13 TP0] Decode batch. #running-req: 52, #token: 198354, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1287.23, #queue-req: 0, 
[2025-10-18 02:04:15 TP0] Decode batch. #running-req: 52, #token: 200434, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1282.89, #queue-req: 0, 
[2025-10-18 02:04:17 TP0] Decode batch. #running-req: 52, #token: 202514, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1280.67, #queue-req: 0, 
[2025-10-18 02:04:18 TP0] Decode batch. #running-req: 52, #token: 204594, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1278.74, #queue-req: 0, 
[2025-10-18 02:04:20 TP0] Decode batch. #running-req: 52, #token: 206674, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1278.92, #queue-req: 0, 
[2025-10-18 02:04:21] INFO:     127.0.0.1:41326 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:04:44] INFO:     127.0.0.1:53590 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:04:50] INFO:     127.0.0.1:36306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:50 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:04:51 TP0] Decode batch. #running-req: 1, #token: 3217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 42.31, #queue-req: 0, 
[2025-10-18 02:04:52] INFO:     127.0.0.1:36322 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:04:52] INFO:     127.0.0.1:36350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36386 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 8, 
[2025-10-18 02:04:52] INFO:     127.0.0.1:36446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36630 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 21, 
[2025-10-18 02:04:52] INFO:     127.0.0.1:36640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:52] INFO:     127.0.0.1:36644 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53] INFO:     127.0.0.1:36912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:04:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:04:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:04:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:04:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:04:56 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:04:57 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:04:58 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:04:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:05:00 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:05:00 TP0] Prefill batch. #new-seq: 6, #new-token: 15989, #cached-token: 3217, token usage: 0.19, #running-req: 56, #queue-req: 2, 
[2025-10-18 02:05:01 TP0] Prefill batch. #new-seq: 2, #new-token: 6398, #cached-token: 4, token usage: 0.20, #running-req: 62, #queue-req: 0, 
[2025-10-18 02:05:03 TP0] Decode batch. #running-req: 64, #token: 206248, token usage: 0.21, cuda graph: True, gen throughput (token/s): 121.18, #queue-req: 0, 
[2025-10-18 02:05:05 TP0] Decode batch. #running-req: 64, #token: 208808, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1568.85, #queue-req: 0, 
[2025-10-18 02:05:06 TP0] Decode batch. #running-req: 64, #token: 211368, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1554.84, #queue-req: 0, 
[2025-10-18 02:05:08 TP0] Decode batch. #running-req: 64, #token: 213928, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1544.77, #queue-req: 0, 
[2025-10-18 02:05:10 TP0] Decode batch. #running-req: 64, #token: 216488, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1540.53, #queue-req: 0, 
[2025-10-18 02:05:11 TP0] Decode batch. #running-req: 64, #token: 219048, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1534.06, #queue-req: 0, 
[2025-10-18 02:05:13 TP0] Decode batch. #running-req: 64, #token: 221608, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1529.82, #queue-req: 0, 
[2025-10-18 02:05:15 TP0] Decode batch. #running-req: 64, #token: 224168, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1528.93, #queue-req: 0, 
[2025-10-18 02:05:16 TP0] Decode batch. #running-req: 64, #token: 226728, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.59, #queue-req: 0, 
[2025-10-18 02:05:18 TP0] Decode batch. #running-req: 64, #token: 229288, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.34, #queue-req: 0, 
[2025-10-18 02:05:20 TP0] Decode batch. #running-req: 64, #token: 231848, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.58, #queue-req: 0, 
[2025-10-18 02:05:22 TP0] Decode batch. #running-req: 64, #token: 234408, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.40, #queue-req: 0, 
[2025-10-18 02:05:23 TP0] Decode batch. #running-req: 64, #token: 236968, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.12, #queue-req: 0, 
[2025-10-18 02:05:25 TP0] Decode batch. #running-req: 64, #token: 239528, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1518.07, #queue-req: 0, 
[2025-10-18 02:05:27 TP0] Decode batch. #running-req: 64, #token: 242088, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1514.57, #queue-req: 0, 
[2025-10-18 02:05:28 TP0] Decode batch. #running-req: 64, #token: 244648, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1511.92, #queue-req: 0, 
[2025-10-18 02:05:30 TP0] Decode batch. #running-req: 64, #token: 247208, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1509.08, #queue-req: 0, 
[2025-10-18 02:05:32 TP0] Decode batch. #running-req: 64, #token: 249768, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1505.57, #queue-req: 0, 
[2025-10-18 02:05:33 TP0] Decode batch. #running-req: 64, #token: 252328, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1501.27, #queue-req: 0, 
[2025-10-18 02:05:35 TP0] Decode batch. #running-req: 64, #token: 254888, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1500.31, #queue-req: 0, 
[2025-10-18 02:05:36] INFO:     127.0.0.1:35800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36 TP0] Prefill batch. #new-seq: 1, #new-token: 3195, #cached-token: 6, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:05:36] INFO:     127.0.0.1:35810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 11, 
[2025-10-18 02:05:36] INFO:     127.0.0.1:35978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:35990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36138 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36150 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36190 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 41, 
[2025-10-18 02:05:36] INFO:     127.0.0.1:36274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:36] INFO:     127.0.0.1:36370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:05:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:05:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15978, #cached-token: 27, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:05:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:05:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:05:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:05:41 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:05:42 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:05:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:05:43 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:05:44 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:05:45 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:05:47 TP0] Decode batch. #running-req: 64, #token: 206231, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.20, #queue-req: 0, 
[2025-10-18 02:05:49 TP0] Decode batch. #running-req: 64, #token: 208791, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1564.73, #queue-req: 0, 
[2025-10-18 02:05:50 TP0] Decode batch. #running-req: 64, #token: 211351, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1551.30, #queue-req: 0, 
[2025-10-18 02:05:52 TP0] Decode batch. #running-req: 64, #token: 213911, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1545.14, #queue-req: 0, 
[2025-10-18 02:05:54 TP0] Decode batch. #running-req: 64, #token: 216471, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.52, #queue-req: 0, 
[2025-10-18 02:05:55 TP0] Decode batch. #running-req: 64, #token: 219031, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1530.62, #queue-req: 0, 
[2025-10-18 02:05:57 TP0] Decode batch. #running-req: 64, #token: 221591, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1530.07, #queue-req: 0, 
[2025-10-18 02:05:59 TP0] Decode batch. #running-req: 64, #token: 224151, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1528.11, #queue-req: 0, 
[2025-10-18 02:06:00 TP0] Decode batch. #running-req: 64, #token: 226711, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.37, #queue-req: 0, 
[2025-10-18 02:06:02 TP0] Decode batch. #running-req: 64, #token: 229271, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.94, #queue-req: 0, 
[2025-10-18 02:06:04 TP0] Decode batch. #running-req: 64, #token: 231831, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.09, #queue-req: 0, 
[2025-10-18 02:06:05 TP0] Decode batch. #running-req: 64, #token: 234391, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1513.83, #queue-req: 0, 
[2025-10-18 02:06:07 TP0] Decode batch. #running-req: 64, #token: 236951, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1517.20, #queue-req: 0, 
[2025-10-18 02:06:09 TP0] Decode batch. #running-req: 64, #token: 239511, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.65, #queue-req: 0, 
[2025-10-18 02:06:11 TP0] Decode batch. #running-req: 64, #token: 242071, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1515.64, #queue-req: 0, 
[2025-10-18 02:06:12 TP0] Decode batch. #running-req: 64, #token: 244631, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.00, #queue-req: 0, 
[2025-10-18 02:06:14 TP0] Decode batch. #running-req: 64, #token: 247191, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1510.42, #queue-req: 0, 
[2025-10-18 02:06:16 TP0] Decode batch. #running-req: 64, #token: 249751, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1509.05, #queue-req: 0, 
[2025-10-18 02:06:17 TP0] Decode batch. #running-req: 64, #token: 252311, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1508.00, #queue-req: 0, 
[2025-10-18 02:06:19 TP0] Decode batch. #running-req: 64, #token: 254871, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1510.69, #queue-req: 0, 
[2025-10-18 02:06:20] INFO:     127.0.0.1:41382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20 TP0] Prefill batch. #new-seq: 1, #new-token: 3191, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:06:20] INFO:     127.0.0.1:41390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:06:20] INFO:     127.0.0.1:41508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:06:20] INFO:     127.0.0.1:41814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41872 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41880 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:20] INFO:     127.0.0.1:41910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:06:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:06:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:06:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:06:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:06:24 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:06:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:06:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:06:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:06:27 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:06:28 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:06:29 TP0] Prefill batch. #new-seq: 3, #new-token: 9592, #cached-token: 11, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:06:31 TP0] Decode batch. #running-req: 64, #token: 206245, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.86, #queue-req: 0, 
[2025-10-18 02:06:33 TP0] Decode batch. #running-req: 64, #token: 208805, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1558.36, #queue-req: 0, 
[2025-10-18 02:06:34 TP0] Decode batch. #running-req: 64, #token: 211365, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1546.21, #queue-req: 0, 
[2025-10-18 02:06:36 TP0] Decode batch. #running-req: 64, #token: 213925, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1537.33, #queue-req: 0, 
[2025-10-18 02:06:38 TP0] Decode batch. #running-req: 64, #token: 216485, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1528.96, #queue-req: 0, 
[2025-10-18 02:06:39 TP0] Decode batch. #running-req: 64, #token: 219045, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1521.56, #queue-req: 0, 
[2025-10-18 02:06:41 TP0] Decode batch. #running-req: 64, #token: 221605, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1516.54, #queue-req: 0, 
[2025-10-18 02:06:43 TP0] Decode batch. #running-req: 64, #token: 224165, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1512.75, #queue-req: 0, 
[2025-10-18 02:06:44 TP0] Decode batch. #running-req: 64, #token: 226725, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1511.18, #queue-req: 0, 
[2025-10-18 02:06:46 TP0] Decode batch. #running-req: 64, #token: 229285, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1513.60, #queue-req: 0, 
[2025-10-18 02:06:48 TP0] Decode batch. #running-req: 64, #token: 231845, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1510.86, #queue-req: 0, 
[2025-10-18 02:06:49 TP0] Decode batch. #running-req: 64, #token: 234405, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1514.48, #queue-req: 0, 
[2025-10-18 02:06:51 TP0] Decode batch. #running-req: 64, #token: 236965, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1512.01, #queue-req: 0, 
[2025-10-18 02:06:53 TP0] Decode batch. #running-req: 64, #token: 239525, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.98, #queue-req: 0, 
[2025-10-18 02:06:55 TP0] Decode batch. #running-req: 64, #token: 242085, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1514.16, #queue-req: 0, 
[2025-10-18 02:06:56 TP0] Decode batch. #running-req: 64, #token: 244645, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1509.51, #queue-req: 0, 
[2025-10-18 02:06:58 TP0] Decode batch. #running-req: 64, #token: 247205, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1508.12, #queue-req: 0, 
[2025-10-18 02:07:00 TP0] Decode batch. #running-req: 64, #token: 249765, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1506.00, #queue-req: 0, 
[2025-10-18 02:07:01 TP0] Decode batch. #running-req: 64, #token: 252325, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.27, #queue-req: 0, 
[2025-10-18 02:07:03 TP0] Decode batch. #running-req: 64, #token: 254885, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.28, #queue-req: 0, 
[2025-10-18 02:07:04] INFO:     127.0.0.1:42272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:07:04] INFO:     127.0.0.1:42282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04 TP0] Prefill batch. #new-seq: 4, #new-token: 9592, #cached-token: 3212, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:07:04] INFO:     127.0.0.1:42330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42432 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42468 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.02, #running-req: 5, #queue-req: 14, 
[2025-10-18 02:07:04] INFO:     127.0.0.1:42490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42618 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42682 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42728 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42764 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:04] INFO:     127.0.0.1:42828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15977, #cached-token: 28, token usage: 0.03, #running-req: 10, #queue-req: 49, 
[2025-10-18 02:07:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.05, #running-req: 15, #queue-req: 44, 
[2025-10-18 02:07:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 20, #queue-req: 39, 
[2025-10-18 02:07:07 TP0] Prefill batch. #new-seq: 6, #new-token: 15992, #cached-token: 3214, token usage: 0.09, #running-req: 25, #queue-req: 33, 
[2025-10-18 02:07:08 TP0] Prefill batch. #new-seq: 6, #new-token: 15994, #cached-token: 3212, token usage: 0.11, #running-req: 31, #queue-req: 27, 
[2025-10-18 02:07:09 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.12, #running-req: 37, #queue-req: 22, 
[2025-10-18 02:07:09 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.14, #running-req: 42, #queue-req: 17, 
[2025-10-18 02:07:10 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.15, #running-req: 47, #queue-req: 12, 
[2025-10-18 02:07:11 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.17, #running-req: 52, #queue-req: 7, 
[2025-10-18 02:07:12 TP0] Prefill batch. #new-seq: 6, #new-token: 15984, #cached-token: 3222, token usage: 0.19, #running-req: 57, #queue-req: 1, 
[2025-10-18 02:07:13 TP0] Prefill batch. #new-seq: 1, #new-token: 3198, #cached-token: 3, token usage: 0.20, #running-req: 63, #queue-req: 0, 
[2025-10-18 02:07:14 TP0] Decode batch. #running-req: 64, #token: 202908, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.84, #queue-req: 0, 
[2025-10-18 02:07:16 TP0] Decode batch. #running-req: 64, #token: 205468, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1549.15, #queue-req: 0, 
[2025-10-18 02:07:18 TP0] Decode batch. #running-req: 64, #token: 208028, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1534.51, #queue-req: 0, 
[2025-10-18 02:07:19 TP0] Decode batch. #running-req: 64, #token: 210588, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1532.45, #queue-req: 0, 
[2025-10-18 02:07:21 TP0] Decode batch. #running-req: 64, #token: 213148, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1529.78, #queue-req: 0, 
[2025-10-18 02:07:23 TP0] Decode batch. #running-req: 64, #token: 215708, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1526.71, #queue-req: 0, 
[2025-10-18 02:07:24 TP0] Decode batch. #running-req: 64, #token: 218268, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1526.23, #queue-req: 0, 
[2025-10-18 02:07:26 TP0] Decode batch. #running-req: 64, #token: 220828, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.16, #queue-req: 0, 
[2025-10-18 02:07:28 TP0] Decode batch. #running-req: 64, #token: 223388, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.95, #queue-req: 0, 
[2025-10-18 02:07:30 TP0] Decode batch. #running-req: 64, #token: 225948, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1520.07, #queue-req: 0, 
[2025-10-18 02:07:31 TP0] Decode batch. #running-req: 64, #token: 228508, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.52, #queue-req: 0, 
[2025-10-18 02:07:33 TP0] Decode batch. #running-req: 64, #token: 231068, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.49, #queue-req: 0, 
[2025-10-18 02:07:35 TP0] Decode batch. #running-req: 64, #token: 233628, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1522.84, #queue-req: 0, 
[2025-10-18 02:07:36 TP0] Decode batch. #running-req: 64, #token: 236188, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.60, #queue-req: 0, 
[2025-10-18 02:07:38 TP0] Decode batch. #running-req: 64, #token: 238748, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1521.97, #queue-req: 0, 
[2025-10-18 02:07:40 TP0] Decode batch. #running-req: 64, #token: 241308, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1518.60, #queue-req: 0, 
[2025-10-18 02:07:41 TP0] Decode batch. #running-req: 64, #token: 243868, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.18, #queue-req: 0, 
[2025-10-18 02:07:43 TP0] Decode batch. #running-req: 64, #token: 246428, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.24, #queue-req: 0, 
[2025-10-18 02:07:45 TP0] Decode batch. #running-req: 64, #token: 248988, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1508.42, #queue-req: 0, 
[2025-10-18 02:07:46 TP0] Decode batch. #running-req: 64, #token: 251548, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1507.57, #queue-req: 0, 
[2025-10-18 02:07:47] INFO:     127.0.0.1:59206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.26, #running-req: 63, #queue-req: 0, 
[2025-10-18 02:07:47] INFO:     127.0.0.1:59218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59256 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.00, #running-req: 1, #queue-req: 3, 
[2025-10-18 02:07:47] INFO:     127.0.0.1:59298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59370 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:47] INFO:     127.0.0.1:59442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.02, #running-req: 6, #queue-req: 17, 
[2025-10-18 02:07:48] INFO:     127.0.0.1:59478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59740 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59770 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48] INFO:     127.0.0.1:59776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:07:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:07:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:07:50 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:07:51 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:07:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:07:52 TP0] Prefill batch. #new-seq: 6, #new-token: 15991, #cached-token: 3215, token usage: 0.12, #running-req: 36, #queue-req: 22, 
[2025-10-18 02:07:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.14, #running-req: 42, #queue-req: 17, 
[2025-10-18 02:07:54 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.15, #running-req: 47, #queue-req: 12, 
[2025-10-18 02:07:55 TP0] Prefill batch. #new-seq: 5, #new-token: 15980, #cached-token: 25, token usage: 0.17, #running-req: 52, #queue-req: 7, 
[2025-10-18 02:07:56 TP0] Prefill batch. #new-seq: 6, #new-token: 15985, #cached-token: 3221, token usage: 0.19, #running-req: 57, #queue-req: 1, 
[2025-10-18 02:07:56 TP0] Prefill batch. #new-seq: 1, #new-token: 3193, #cached-token: 8, token usage: 0.21, #running-req: 63, #queue-req: 0, 
[2025-10-18 02:07:58 TP0] Decode batch. #running-req: 64, #token: 206107, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.48, #queue-req: 0, 
[2025-10-18 02:08:00 TP0] Decode batch. #running-req: 64, #token: 208667, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1550.68, #queue-req: 0, 
[2025-10-18 02:08:01 TP0] Decode batch. #running-req: 64, #token: 211227, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.22, #queue-req: 0, 
[2025-10-18 02:08:03 TP0] Decode batch. #running-req: 64, #token: 213787, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1534.94, #queue-req: 0, 
[2025-10-18 02:08:05 TP0] Decode batch. #running-req: 64, #token: 216347, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1529.40, #queue-req: 0, 
[2025-10-18 02:08:07 TP0] Decode batch. #running-req: 64, #token: 218907, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.95, #queue-req: 0, 
[2025-10-18 02:08:08 TP0] Decode batch. #running-req: 64, #token: 221467, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1522.77, #queue-req: 0, 
[2025-10-18 02:08:10 TP0] Decode batch. #running-req: 64, #token: 224027, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1516.13, #queue-req: 0, 
[2025-10-18 02:08:12 TP0] Decode batch. #running-req: 64, #token: 226587, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1516.79, #queue-req: 0, 
[2025-10-18 02:08:13 TP0] Decode batch. #running-req: 64, #token: 229147, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1513.44, #queue-req: 0, 
[2025-10-18 02:08:15 TP0] Decode batch. #running-req: 64, #token: 231707, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1514.29, #queue-req: 0, 
[2025-10-18 02:08:17 TP0] Decode batch. #running-req: 64, #token: 234267, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1518.77, #queue-req: 0, 
[2025-10-18 02:08:18 TP0] Decode batch. #running-req: 64, #token: 236827, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1521.63, #queue-req: 0, 
[2025-10-18 02:08:20 TP0] Decode batch. #running-req: 64, #token: 239387, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1517.89, #queue-req: 0, 
[2025-10-18 02:08:22 TP0] Decode batch. #running-req: 64, #token: 241947, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1514.70, #queue-req: 0, 
[2025-10-18 02:08:23 TP0] Decode batch. #running-req: 64, #token: 244507, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.92, #queue-req: 0, 
[2025-10-18 02:08:25 TP0] Decode batch. #running-req: 64, #token: 247067, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1516.17, #queue-req: 0, 
[2025-10-18 02:08:27 TP0] Decode batch. #running-req: 64, #token: 249627, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1514.59, #queue-req: 0, 
[2025-10-18 02:08:28 TP0] Decode batch. #running-req: 64, #token: 252187, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1515.70, #queue-req: 0, 
[2025-10-18 02:08:30 TP0] Decode batch. #running-req: 64, #token: 254747, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1508.63, #queue-req: 0, 
[2025-10-18 02:08:31] INFO:     127.0.0.1:37784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 63, #queue-req: 0, 
[2025-10-18 02:08:31] INFO:     127.0.0.1:37790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.00, #running-req: 64, #queue-req: 9, 
[2025-10-18 02:08:31] INFO:     127.0.0.1:37908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:37994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38046 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38132 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 69, #queue-req: 38, 
[2025-10-18 02:08:31] INFO:     127.0.0.1:38200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38220 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38234 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:31] INFO:     127.0.0.1:38312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:08:32 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 74, #queue-req: 48, 
[2025-10-18 02:08:33 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.05, #running-req: 79, #queue-req: 43, 
[2025-10-18 02:08:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.07, #running-req: 84, #queue-req: 38, 
[2025-10-18 02:08:34 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.09, #running-req: 89, #queue-req: 33, 
[2025-10-18 02:08:35 TP0] Prefill batch. #new-seq: 5, #new-token: 15994, #cached-token: 11, token usage: 0.10, #running-req: 94, #queue-req: 28, 
[2025-10-18 02:08:36 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.12, #running-req: 99, #queue-req: 23, 
[2025-10-18 02:08:37 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.13, #running-req: 104, #queue-req: 18, 
[2025-10-18 02:08:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.15, #running-req: 109, #queue-req: 13, 
[2025-10-18 02:08:38 TP0] Prefill batch. #new-seq: 5, #new-token: 15984, #cached-token: 21, token usage: 0.17, #running-req: 114, #queue-req: 8, 
[2025-10-18 02:08:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.18, #running-req: 119, #queue-req: 3, 
[2025-10-18 02:08:40 TP0] Prefill batch. #new-seq: 3, #new-token: 9597, #cached-token: 6, token usage: 0.20, #running-req: 124, #queue-req: 0, 
[2025-10-18 02:08:42 TP0] Decode batch. #running-req: 64, #token: 206120, token usage: 0.21, cuda graph: True, gen throughput (token/s): 213.03, #queue-req: 0, 
[2025-10-18 02:08:44 TP0] Decode batch. #running-req: 64, #token: 208680, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1561.26, #queue-req: 0, 
[2025-10-18 02:08:45 TP0] Decode batch. #running-req: 64, #token: 211240, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1542.15, #queue-req: 0, 
[2025-10-18 02:08:47 TP0] Decode batch. #running-req: 64, #token: 213800, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1533.72, #queue-req: 0, 
[2025-10-18 02:08:49 TP0] Decode batch. #running-req: 64, #token: 216360, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1529.75, #queue-req: 0, 
[2025-10-18 02:08:50 TP0] Decode batch. #running-req: 64, #token: 218920, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1527.23, #queue-req: 0, 
[2025-10-18 02:08:52 TP0] Decode batch. #running-req: 64, #token: 221480, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1524.78, #queue-req: 0, 
[2025-10-18 02:08:54 TP0] Decode batch. #running-req: 64, #token: 224040, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.52, #queue-req: 0, 
[2025-10-18 02:08:56 TP0] Decode batch. #running-req: 64, #token: 226600, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1526.77, #queue-req: 0, 
[2025-10-18 02:08:57 TP0] Decode batch. #running-req: 64, #token: 229160, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1526.44, #queue-req: 0, 
[2025-10-18 02:08:59 TP0] Decode batch. #running-req: 64, #token: 231720, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1525.82, #queue-req: 0, 
[2025-10-18 02:09:01 TP0] Decode batch. #running-req: 64, #token: 234280, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1527.92, #queue-req: 0, 
[2025-10-18 02:09:02 TP0] Decode batch. #running-req: 64, #token: 236840, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1529.27, #queue-req: 0, 
[2025-10-18 02:09:04 TP0] Decode batch. #running-req: 64, #token: 239400, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1526.91, #queue-req: 0, 
[2025-10-18 02:09:06 TP0] Decode batch. #running-req: 64, #token: 241960, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1524.44, #queue-req: 0, 
[2025-10-18 02:09:07 TP0] Decode batch. #running-req: 64, #token: 244520, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1525.05, #queue-req: 0, 
[2025-10-18 02:09:09 TP0] Decode batch. #running-req: 64, #token: 247080, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1519.85, #queue-req: 0, 
[2025-10-18 02:09:11 TP0] Decode batch. #running-req: 64, #token: 249640, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.73, #queue-req: 0, 
[2025-10-18 02:09:12 TP0] Decode batch. #running-req: 64, #token: 252200, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1513.24, #queue-req: 0, 
[2025-10-18 02:09:14 TP0] Decode batch. #running-req: 64, #token: 254760, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1514.70, #queue-req: 0, 
[2025-10-18 02:09:15] INFO:     127.0.0.1:45606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:09:15] INFO:     127.0.0.1:45620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45736 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45756 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:09:15] INFO:     127.0.0.1:45762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45792 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45804 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45884 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:45986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46032 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46036 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:09:15] INFO:     127.0.0.1:46092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46140 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:15] INFO:     127.0.0.1:46208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 48, 
[2025-10-18 02:09:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.05, #running-req: 16, #queue-req: 43, 
[2025-10-18 02:09:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.07, #running-req: 21, #queue-req: 38, 
[2025-10-18 02:09:18 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.09, #running-req: 26, #queue-req: 33, 
[2025-10-18 02:09:19 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.10, #running-req: 31, #queue-req: 28, 
[2025-10-18 02:09:20 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.12, #running-req: 36, #queue-req: 23, 
[2025-10-18 02:09:21 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.13, #running-req: 41, #queue-req: 18, 
[2025-10-18 02:09:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.15, #running-req: 46, #queue-req: 13, 
[2025-10-18 02:09:22 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.17, #running-req: 51, #queue-req: 8, 
[2025-10-18 02:09:23 TP0] Prefill batch. #new-seq: 5, #new-token: 15983, #cached-token: 22, token usage: 0.18, #running-req: 56, #queue-req: 3, 
[2025-10-18 02:09:24 TP0] Prefill batch. #new-seq: 3, #new-token: 9593, #cached-token: 10, token usage: 0.20, #running-req: 61, #queue-req: 0, 
[2025-10-18 02:09:26 TP0] Decode batch. #running-req: 64, #token: 206110, token usage: 0.21, cuda graph: True, gen throughput (token/s): 212.73, #queue-req: 0, 
[2025-10-18 02:09:28 TP0] Decode batch. #running-req: 64, #token: 208670, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1558.28, #queue-req: 0, 
[2025-10-18 02:09:29 TP0] Decode batch. #running-req: 64, #token: 211230, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1544.86, #queue-req: 0, 
[2025-10-18 02:09:31 TP0] Decode batch. #running-req: 64, #token: 213790, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1538.52, #queue-req: 0, 
[2025-10-18 02:09:33 TP0] Decode batch. #running-req: 64, #token: 216350, token usage: 0.22, cuda graph: True, gen throughput (token/s): 1531.25, #queue-req: 0, 
[2025-10-18 02:09:34 TP0] Decode batch. #running-req: 64, #token: 218910, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1526.60, #queue-req: 0, 
[2025-10-18 02:09:36 TP0] Decode batch. #running-req: 64, #token: 221470, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1523.12, #queue-req: 0, 
[2025-10-18 02:09:38 TP0] Decode batch. #running-req: 64, #token: 224030, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1520.32, #queue-req: 0, 
[2025-10-18 02:09:39 TP0] Decode batch. #running-req: 64, #token: 226590, token usage: 0.23, cuda graph: True, gen throughput (token/s): 1516.74, #queue-req: 0, 
[2025-10-18 02:09:41 TP0] Decode batch. #running-req: 64, #token: 229150, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1520.72, #queue-req: 0, 
[2025-10-18 02:09:43 TP0] Decode batch. #running-req: 64, #token: 231710, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1517.73, #queue-req: 0, 
[2025-10-18 02:09:44 TP0] Decode batch. #running-req: 64, #token: 234270, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1519.79, #queue-req: 0, 
[2025-10-18 02:09:46 TP0] Decode batch. #running-req: 64, #token: 236830, token usage: 0.24, cuda graph: True, gen throughput (token/s): 1517.63, #queue-req: 0, 
[2025-10-18 02:09:48 TP0] Decode batch. #running-req: 64, #token: 239390, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1517.28, #queue-req: 0, 
[2025-10-18 02:09:50 TP0] Decode batch. #running-req: 64, #token: 241950, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1516.97, #queue-req: 0, 
[2025-10-18 02:09:51 TP0] Decode batch. #running-req: 64, #token: 244510, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1512.73, #queue-req: 0, 
[2025-10-18 02:09:53 TP0] Decode batch. #running-req: 64, #token: 247070, token usage: 0.25, cuda graph: True, gen throughput (token/s): 1513.47, #queue-req: 0, 
[2025-10-18 02:09:55 TP0] Decode batch. #running-req: 64, #token: 249630, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1508.32, #queue-req: 0, 
[2025-10-18 02:09:56 TP0] Decode batch. #running-req: 64, #token: 252190, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1506.74, #queue-req: 0, 
[2025-10-18 02:09:58 TP0] Decode batch. #running-req: 64, #token: 254750, token usage: 0.26, cuda graph: True, gen throughput (token/s): 1504.83, #queue-req: 0, 
[2025-10-18 02:09:59] INFO:     127.0.0.1:39388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:09:59] INFO:     127.0.0.1:39390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39408 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39416 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39426 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39522 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:09:59] INFO:     127.0.0.1:39524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59] INFO:     127.0.0.1:39812 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:09:59 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.02, #running-req: 6, #queue-req: 38, 
[2025-10-18 02:09:59] INFO:     127.0.0.1:39820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:10:00 TP0] Prefill batch. #new-seq: 6, #new-token: 15988, #cached-token: 3218, token usage: 0.04, #running-req: 11, #queue-req: 35, 
[2025-10-18 02:10:01 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.06, #running-req: 17, #queue-req: 30, 
[2025-10-18 02:10:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.07, #running-req: 22, #queue-req: 25, 
[2025-10-18 02:10:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15982, #cached-token: 23, token usage: 0.09, #running-req: 27, #queue-req: 20, 
[2025-10-18 02:10:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.11, #running-req: 32, #queue-req: 15, 
[2025-10-18 02:10:04 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.12, #running-req: 37, #queue-req: 10, 
[2025-10-18 02:10:05 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.14, #running-req: 42, #queue-req: 5, 
[2025-10-18 02:10:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15981, #cached-token: 24, token usage: 0.15, #running-req: 47, #queue-req: 0, 
[2025-10-18 02:10:08 TP0] Decode batch. #running-req: 52, #token: 167466, token usage: 0.17, cuda graph: True, gen throughput (token/s): 232.94, #queue-req: 0, 
[2025-10-18 02:10:09 TP0] Decode batch. #running-req: 52, #token: 169546, token usage: 0.17, cuda graph: True, gen throughput (token/s): 1312.57, #queue-req: 0, 
[2025-10-18 02:10:11 TP0] Decode batch. #running-req: 52, #token: 171626, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1301.65, #queue-req: 0, 
[2025-10-18 02:10:13 TP0] Decode batch. #running-req: 52, #token: 173706, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1295.46, #queue-req: 0, 
[2025-10-18 02:10:14 TP0] Decode batch. #running-req: 52, #token: 175786, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1293.48, #queue-req: 0, 
[2025-10-18 02:10:16 TP0] Decode batch. #running-req: 52, #token: 177866, token usage: 0.18, cuda graph: True, gen throughput (token/s): 1289.03, #queue-req: 0, 
[2025-10-18 02:10:18 TP0] Decode batch. #running-req: 52, #token: 179946, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1284.48, #queue-req: 0, 
[2025-10-18 02:10:19 TP0] Decode batch. #running-req: 52, #token: 182026, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1286.19, #queue-req: 0, 
[2025-10-18 02:10:21 TP0] Decode batch. #running-req: 52, #token: 184106, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1284.38, #queue-req: 0, 
[2025-10-18 02:10:22 TP0] Decode batch. #running-req: 52, #token: 186186, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1282.96, #queue-req: 0, 
[2025-10-18 02:10:24 TP0] Decode batch. #running-req: 52, #token: 188266, token usage: 0.19, cuda graph: True, gen throughput (token/s): 1285.71, #queue-req: 0, 
[2025-10-18 02:10:26 TP0] Decode batch. #running-req: 52, #token: 190346, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1285.39, #queue-req: 0, 
[2025-10-18 02:10:27 TP0] Decode batch. #running-req: 52, #token: 192426, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1281.61, #queue-req: 0, 
[2025-10-18 02:10:29 TP0] Decode batch. #running-req: 52, #token: 194506, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1280.58, #queue-req: 0, 
[2025-10-18 02:10:31 TP0] Decode batch. #running-req: 52, #token: 196586, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1278.25, #queue-req: 0, 
[2025-10-18 02:10:32 TP0] Decode batch. #running-req: 52, #token: 198666, token usage: 0.20, cuda graph: True, gen throughput (token/s): 1274.65, #queue-req: 0, 
[2025-10-18 02:10:34 TP0] Decode batch. #running-req: 52, #token: 200746, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1273.31, #queue-req: 0, 
[2025-10-18 02:10:35 TP0] Decode batch. #running-req: 52, #token: 202826, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1269.95, #queue-req: 0, 
[2025-10-18 02:10:37 TP0] Decode batch. #running-req: 52, #token: 204906, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1267.59, #queue-req: 0, 
[2025-10-18 02:10:39 TP0] Decode batch. #running-req: 52, #token: 206986, token usage: 0.21, cuda graph: True, gen throughput (token/s): 1272.09, #queue-req: 0, 
[2025-10-18 02:10:39] INFO:     127.0.0.1:39902 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:10:58] INFO:     127.0.0.1:44090 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:11:04] INFO:     127.0.0.1:44106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:04 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:11:05 TP0] Decode batch. #running-req: 1, #token: 3223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 38.76, #queue-req: 0, 
[2025-10-18 02:11:06] INFO:     127.0.0.1:50532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:11:06] INFO:     127.0.0.1:50556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50604 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50632 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50664 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06] INFO:     127.0.0.1:50710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15995, #cached-token: 10, token usage: 0.00, #running-req: 1, #queue-req: 9, 
[2025-10-18 02:11:06 TP0] Prefill batch. #new-seq: 5, #new-token: 15993, #cached-token: 12, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:11:07 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:11:09 TP0] Decode batch. #running-req: 16, #token: 51666, token usage: 0.05, cuda graph: True, gen throughput (token/s): 107.07, #queue-req: 0, 
[2025-10-18 02:11:10 TP0] Decode batch. #running-req: 16, #token: 52306, token usage: 0.05, cuda graph: True, gen throughput (token/s): 626.04, #queue-req: 0, 
[2025-10-18 02:11:11 TP0] Decode batch. #running-req: 16, #token: 52946, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.27, #queue-req: 0, 
[2025-10-18 02:11:12 TP0] Decode batch. #running-req: 16, #token: 53586, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.51, #queue-req: 0, 
[2025-10-18 02:11:13 TP0] Decode batch. #running-req: 16, #token: 54226, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.51, #queue-req: 0, 
[2025-10-18 02:11:14 TP0] Decode batch. #running-req: 16, #token: 54866, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.57, #queue-req: 0, 
[2025-10-18 02:11:15 TP0] Decode batch. #running-req: 16, #token: 55506, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.59, #queue-req: 0, 
[2025-10-18 02:11:16 TP0] Decode batch. #running-req: 16, #token: 56146, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.92, #queue-req: 0, 
[2025-10-18 02:11:17 TP0] Decode batch. #running-req: 16, #token: 56786, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.50, #queue-req: 0, 
[2025-10-18 02:11:18 TP0] Decode batch. #running-req: 16, #token: 57426, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.36, #queue-req: 0, 
[2025-10-18 02:11:19 TP0] Decode batch. #running-req: 16, #token: 58066, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.02, #queue-req: 0, 
[2025-10-18 02:11:20 TP0] Decode batch. #running-req: 16, #token: 58706, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.32, #queue-req: 0, 
[2025-10-18 02:11:22 TP0] Decode batch. #running-req: 16, #token: 59346, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.35, #queue-req: 0, 
[2025-10-18 02:11:23 TP0] Decode batch. #running-req: 16, #token: 59986, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.10, #queue-req: 0, 
[2025-10-18 02:11:24 TP0] Decode batch. #running-req: 16, #token: 60626, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.95, #queue-req: 0, 
[2025-10-18 02:11:25 TP0] Decode batch. #running-req: 16, #token: 61266, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.96, #queue-req: 0, 
[2025-10-18 02:11:26 TP0] Decode batch. #running-req: 16, #token: 61906, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.17, #queue-req: 0, 
[2025-10-18 02:11:27 TP0] Decode batch. #running-req: 16, #token: 62546, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.29, #queue-req: 0, 
[2025-10-18 02:11:28 TP0] Decode batch. #running-req: 16, #token: 63186, token usage: 0.07, cuda graph: True, gen throughput (token/s): 617.60, #queue-req: 0, 
[2025-10-18 02:11:29 TP0] Decode batch. #running-req: 16, #token: 63826, token usage: 0.07, cuda graph: True, gen throughput (token/s): 615.78, #queue-req: 0, 
[2025-10-18 02:11:29] INFO:     127.0.0.1:35842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:11:29] INFO:     127.0.0.1:35870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35876 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29] INFO:     127.0.0.1:35996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:11:29 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:11:30 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:11:32 TP0] Decode batch. #running-req: 16, #token: 51660, token usage: 0.05, cuda graph: True, gen throughput (token/s): 177.12, #queue-req: 0, 
[2025-10-18 02:11:33 TP0] Decode batch. #running-req: 16, #token: 52300, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.34, #queue-req: 0, 
[2025-10-18 02:11:34 TP0] Decode batch. #running-req: 16, #token: 52940, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.58, #queue-req: 0, 
[2025-10-18 02:11:35 TP0] Decode batch. #running-req: 16, #token: 53580, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.48, #queue-req: 0, 
[2025-10-18 02:11:37 TP0] Decode batch. #running-req: 16, #token: 54220, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.67, #queue-req: 0, 
[2025-10-18 02:11:38 TP0] Decode batch. #running-req: 16, #token: 54860, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.64, #queue-req: 0, 
[2025-10-18 02:11:39 TP0] Decode batch. #running-req: 16, #token: 55500, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.62, #queue-req: 0, 
[2025-10-18 02:11:40 TP0] Decode batch. #running-req: 16, #token: 56140, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.12, #queue-req: 0, 
[2025-10-18 02:11:41 TP0] Decode batch. #running-req: 16, #token: 56780, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.16, #queue-req: 0, 
[2025-10-18 02:11:42 TP0] Decode batch. #running-req: 16, #token: 57420, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.88, #queue-req: 0, 
[2025-10-18 02:11:43 TP0] Decode batch. #running-req: 16, #token: 58060, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.26, #queue-req: 0, 
[2025-10-18 02:11:44 TP0] Decode batch. #running-req: 16, #token: 58700, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.22, #queue-req: 0, 
[2025-10-18 02:11:45 TP0] Decode batch. #running-req: 16, #token: 59340, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.88, #queue-req: 0, 
[2025-10-18 02:11:46 TP0] Decode batch. #running-req: 16, #token: 59980, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.94, #queue-req: 0, 
[2025-10-18 02:11:47 TP0] Decode batch. #running-req: 16, #token: 60620, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.32, #queue-req: 0, 
[2025-10-18 02:11:48 TP0] Decode batch. #running-req: 16, #token: 61260, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.19, #queue-req: 0, 
[2025-10-18 02:11:49 TP0] Decode batch. #running-req: 16, #token: 61900, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.48, #queue-req: 0, 
[2025-10-18 02:11:50 TP0] Decode batch. #running-req: 16, #token: 62540, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.65, #queue-req: 0, 
[2025-10-18 02:11:51 TP0] Decode batch. #running-req: 16, #token: 63180, token usage: 0.07, cuda graph: True, gen throughput (token/s): 619.15, #queue-req: 0, 
[2025-10-18 02:11:52 TP0] Decode batch. #running-req: 16, #token: 63820, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.53, #queue-req: 0, 
[2025-10-18 02:11:52] INFO:     127.0.0.1:35082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35092 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:11:52] INFO:     127.0.0.1:35104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52] INFO:     127.0.0.1:35228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:11:52 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:11:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:11:53 TP0] Prefill batch. #new-seq: 5, #new-token: 15985, #cached-token: 20, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:11:56 TP0] Decode batch. #running-req: 16, #token: 51662, token usage: 0.05, cuda graph: True, gen throughput (token/s): 176.37, #queue-req: 0, 
[2025-10-18 02:11:57 TP0] Decode batch. #running-req: 16, #token: 52302, token usage: 0.05, cuda graph: True, gen throughput (token/s): 631.71, #queue-req: 0, 
[2025-10-18 02:11:58 TP0] Decode batch. #running-req: 16, #token: 52942, token usage: 0.05, cuda graph: True, gen throughput (token/s): 628.37, #queue-req: 0, 
[2025-10-18 02:11:59 TP0] Decode batch. #running-req: 16, #token: 53582, token usage: 0.06, cuda graph: True, gen throughput (token/s): 627.14, #queue-req: 0, 
[2025-10-18 02:12:00 TP0] Decode batch. #running-req: 16, #token: 54222, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.31, #queue-req: 0, 
[2025-10-18 02:12:01 TP0] Decode batch. #running-req: 16, #token: 54862, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.74, #queue-req: 0, 
[2025-10-18 02:12:02 TP0] Decode batch. #running-req: 16, #token: 55502, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.60, #queue-req: 0, 
[2025-10-18 02:12:03 TP0] Decode batch. #running-req: 16, #token: 56142, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.16, #queue-req: 0, 
[2025-10-18 02:12:04 TP0] Decode batch. #running-req: 16, #token: 56782, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.97, #queue-req: 0, 
[2025-10-18 02:12:05 TP0] Decode batch. #running-req: 16, #token: 57422, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.75, #queue-req: 0, 
[2025-10-18 02:12:06 TP0] Decode batch. #running-req: 16, #token: 58062, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.13, #queue-req: 0, 
[2025-10-18 02:12:07 TP0] Decode batch. #running-req: 16, #token: 58702, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.46, #queue-req: 0, 
[2025-10-18 02:12:08 TP0] Decode batch. #running-req: 16, #token: 59342, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.09, #queue-req: 0, 
[2025-10-18 02:12:09 TP0] Decode batch. #running-req: 16, #token: 59982, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.47, #queue-req: 0, 
[2025-10-18 02:12:10 TP0] Decode batch. #running-req: 16, #token: 60622, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.51, #queue-req: 0, 
[2025-10-18 02:12:11 TP0] Decode batch. #running-req: 16, #token: 61262, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.36, #queue-req: 0, 
[2025-10-18 02:12:12 TP0] Decode batch. #running-req: 16, #token: 61902, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.55, #queue-req: 0, 
[2025-10-18 02:12:13 TP0] Decode batch. #running-req: 16, #token: 62542, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.44, #queue-req: 0, 
[2025-10-18 02:12:14 TP0] Decode batch. #running-req: 16, #token: 63182, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.64, #queue-req: 0, 
[2025-10-18 02:12:15 TP0] Decode batch. #running-req: 16, #token: 63822, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.33, #queue-req: 0, 
[2025-10-18 02:12:15] INFO:     127.0.0.1:36588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:15] INFO:     127.0.0.1:36592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 3196, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:12:15] INFO:     127.0.0.1:36600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36674 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16] INFO:     127.0.0.1:36730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:12:16 TP0] Prefill batch. #new-seq: 5, #new-token: 15989, #cached-token: 16, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:12:17 TP0] Prefill batch. #new-seq: 5, #new-token: 15992, #cached-token: 13, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:12:19 TP0] Decode batch. #running-req: 16, #token: 51665, token usage: 0.05, cuda graph: True, gen throughput (token/s): 177.31, #queue-req: 0, 
[2025-10-18 02:12:20 TP0] Decode batch. #running-req: 16, #token: 52305, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.68, #queue-req: 0, 
[2025-10-18 02:12:21 TP0] Decode batch. #running-req: 16, #token: 52945, token usage: 0.05, cuda graph: True, gen throughput (token/s): 623.43, #queue-req: 0, 
[2025-10-18 02:12:22 TP0] Decode batch. #running-req: 16, #token: 53585, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.29, #queue-req: 0, 
[2025-10-18 02:12:23 TP0] Decode batch. #running-req: 16, #token: 54225, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.85, #queue-req: 0, 
[2025-10-18 02:12:24 TP0] Decode batch. #running-req: 16, #token: 54865, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.14, #queue-req: 0, 
[2025-10-18 02:12:25 TP0] Decode batch. #running-req: 16, #token: 55505, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.57, #queue-req: 0, 
[2025-10-18 02:12:26 TP0] Decode batch. #running-req: 16, #token: 56145, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.29, #queue-req: 0, 
[2025-10-18 02:12:27 TP0] Decode batch. #running-req: 16, #token: 56785, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.19, #queue-req: 0, 
[2025-10-18 02:12:28 TP0] Decode batch. #running-req: 16, #token: 57425, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.59, #queue-req: 0, 
[2025-10-18 02:12:29 TP0] Decode batch. #running-req: 16, #token: 58065, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.62, #queue-req: 0, 
[2025-10-18 02:12:30 TP0] Decode batch. #running-req: 16, #token: 58705, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.71, #queue-req: 0, 
[2025-10-18 02:12:31 TP0] Decode batch. #running-req: 16, #token: 59345, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.28, #queue-req: 0, 
[2025-10-18 02:12:32 TP0] Decode batch. #running-req: 16, #token: 59985, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.26, #queue-req: 0, 
[2025-10-18 02:12:33 TP0] Decode batch. #running-req: 16, #token: 60625, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.25, #queue-req: 0, 
[2025-10-18 02:12:34 TP0] Decode batch. #running-req: 16, #token: 61265, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.07, #queue-req: 0, 
[2025-10-18 02:12:35 TP0] Decode batch. #running-req: 16, #token: 61905, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.40, #queue-req: 0, 
[2025-10-18 02:12:36 TP0] Decode batch. #running-req: 16, #token: 62545, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.61, #queue-req: 0, 
[2025-10-18 02:12:37 TP0] Decode batch. #running-req: 16, #token: 63185, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.82, #queue-req: 0, 
[2025-10-18 02:12:38 TP0] Decode batch. #running-req: 16, #token: 63825, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.10, #queue-req: 0, 
[2025-10-18 02:12:39] INFO:     127.0.0.1:54802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39 TP0] Prefill batch. #new-seq: 1, #new-token: 3195, #cached-token: 6, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:12:39] INFO:     127.0.0.1:54822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54858 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54890 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39] INFO:     127.0.0.1:54936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:12:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:12:39 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:12:40 TP0] Prefill batch. #new-seq: 5, #new-token: 15991, #cached-token: 14, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:12:42 TP0] Decode batch. #running-req: 16, #token: 51660, token usage: 0.05, cuda graph: True, gen throughput (token/s): 176.44, #queue-req: 0, 
[2025-10-18 02:12:43 TP0] Decode batch. #running-req: 16, #token: 52300, token usage: 0.05, cuda graph: True, gen throughput (token/s): 630.22, #queue-req: 0, 
[2025-10-18 02:12:44 TP0] Decode batch. #running-req: 16, #token: 52940, token usage: 0.05, cuda graph: True, gen throughput (token/s): 629.00, #queue-req: 0, 
[2025-10-18 02:12:45 TP0] Decode batch. #running-req: 16, #token: 53580, token usage: 0.06, cuda graph: True, gen throughput (token/s): 628.78, #queue-req: 0, 
[2025-10-18 02:12:46 TP0] Decode batch. #running-req: 16, #token: 54220, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.21, #queue-req: 0, 
[2025-10-18 02:12:47 TP0] Decode batch. #running-req: 16, #token: 54860, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.91, #queue-req: 0, 
[2025-10-18 02:12:48 TP0] Decode batch. #running-req: 16, #token: 55500, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.78, #queue-req: 0, 
[2025-10-18 02:12:49 TP0] Decode batch. #running-req: 16, #token: 56140, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.92, #queue-req: 0, 
[2025-10-18 02:12:50 TP0] Decode batch. #running-req: 16, #token: 56780, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.55, #queue-req: 0, 
[2025-10-18 02:12:51 TP0] Decode batch. #running-req: 16, #token: 57420, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.47, #queue-req: 0, 
[2025-10-18 02:12:52 TP0] Decode batch. #running-req: 16, #token: 58060, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.24, #queue-req: 0, 
[2025-10-18 02:12:53 TP0] Decode batch. #running-req: 16, #token: 58700, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.96, #queue-req: 0, 
[2025-10-18 02:12:54 TP0] Decode batch. #running-req: 16, #token: 59340, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.30, #queue-req: 0, 
[2025-10-18 02:12:55 TP0] Decode batch. #running-req: 16, #token: 59980, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.56, #queue-req: 0, 
[2025-10-18 02:12:56 TP0] Decode batch. #running-req: 16, #token: 60620, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.74, #queue-req: 0, 
[2025-10-18 02:12:57 TP0] Decode batch. #running-req: 16, #token: 61260, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.89, #queue-req: 0, 
[2025-10-18 02:12:58 TP0] Decode batch. #running-req: 16, #token: 61900, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.87, #queue-req: 0, 
[2025-10-18 02:12:59 TP0] Decode batch. #running-req: 16, #token: 62540, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.75, #queue-req: 0, 
[2025-10-18 02:13:00 TP0] Decode batch. #running-req: 16, #token: 63180, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.53, #queue-req: 0, 
[2025-10-18 02:13:02 TP0] Decode batch. #running-req: 16, #token: 63820, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.82, #queue-req: 0, 
[2025-10-18 02:13:02] INFO:     127.0.0.1:35462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02 TP0] Prefill batch. #new-seq: 1, #new-token: 3196, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:13:02] INFO:     127.0.0.1:35472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35546 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02] INFO:     127.0.0.1:35570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15978, #cached-token: 27, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:13:02 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:13:03 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:13:05 TP0] Decode batch. #running-req: 16, #token: 51660, token usage: 0.05, cuda graph: True, gen throughput (token/s): 175.69, #queue-req: 0, 
[2025-10-18 02:13:06 TP0] Decode batch. #running-req: 16, #token: 52300, token usage: 0.05, cuda graph: True, gen throughput (token/s): 627.68, #queue-req: 0, 
[2025-10-18 02:13:07 TP0] Decode batch. #running-req: 16, #token: 52940, token usage: 0.05, cuda graph: True, gen throughput (token/s): 623.92, #queue-req: 0, 
[2025-10-18 02:13:08 TP0] Decode batch. #running-req: 16, #token: 53580, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.98, #queue-req: 0, 
[2025-10-18 02:13:09 TP0] Decode batch. #running-req: 16, #token: 54220, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.99, #queue-req: 0, 
[2025-10-18 02:13:10 TP0] Decode batch. #running-req: 16, #token: 54860, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.41, #queue-req: 0, 
[2025-10-18 02:13:11 TP0] Decode batch. #running-req: 16, #token: 55500, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.15, #queue-req: 0, 
[2025-10-18 02:13:12 TP0] Decode batch. #running-req: 16, #token: 56140, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.87, #queue-req: 0, 
[2025-10-18 02:13:13 TP0] Decode batch. #running-req: 16, #token: 56780, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.71, #queue-req: 0, 
[2025-10-18 02:13:14 TP0] Decode batch. #running-req: 16, #token: 57420, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.68, #queue-req: 0, 
[2025-10-18 02:13:15 TP0] Decode batch. #running-req: 16, #token: 58060, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.54, #queue-req: 0, 
[2025-10-18 02:13:16 TP0] Decode batch. #running-req: 16, #token: 58700, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.88, #queue-req: 0, 
[2025-10-18 02:13:17 TP0] Decode batch. #running-req: 16, #token: 59340, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.15, #queue-req: 0, 
[2025-10-18 02:13:18 TP0] Decode batch. #running-req: 16, #token: 59980, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.13, #queue-req: 0, 
[2025-10-18 02:13:20 TP0] Decode batch. #running-req: 16, #token: 60620, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.38, #queue-req: 0, 
[2025-10-18 02:13:21 TP0] Decode batch. #running-req: 16, #token: 61260, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.89, #queue-req: 0, 
[2025-10-18 02:13:22 TP0] Decode batch. #running-req: 16, #token: 61900, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.44, #queue-req: 0, 
[2025-10-18 02:13:23 TP0] Decode batch. #running-req: 16, #token: 62540, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.85, #queue-req: 0, 
[2025-10-18 02:13:24 TP0] Decode batch. #running-req: 16, #token: 63180, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.62, #queue-req: 0, 
[2025-10-18 02:13:25 TP0] Decode batch. #running-req: 16, #token: 63820, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.97, #queue-req: 0, 
[2025-10-18 02:13:25] INFO:     127.0.0.1:47282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25 TP0] Prefill batch. #new-seq: 1, #new-token: 3197, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:13:25] INFO:     127.0.0.1:47294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47306 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25] INFO:     127.0.0.1:47410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:13:25 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:13:26 TP0] Prefill batch. #new-seq: 5, #new-token: 15987, #cached-token: 18, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:13:28 TP0] Decode batch. #running-req: 16, #token: 51662, token usage: 0.05, cuda graph: True, gen throughput (token/s): 175.84, #queue-req: 0, 
[2025-10-18 02:13:29 TP0] Decode batch. #running-req: 16, #token: 52302, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.98, #queue-req: 0, 
[2025-10-18 02:13:30 TP0] Decode batch. #running-req: 16, #token: 52942, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.69, #queue-req: 0, 
[2025-10-18 02:13:31 TP0] Decode batch. #running-req: 16, #token: 53582, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.45, #queue-req: 0, 
[2025-10-18 02:13:32 TP0] Decode batch. #running-req: 16, #token: 54222, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.42, #queue-req: 0, 
[2025-10-18 02:13:33 TP0] Decode batch. #running-req: 16, #token: 54862, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.36, #queue-req: 0, 
[2025-10-18 02:13:34 TP0] Decode batch. #running-req: 16, #token: 55502, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.34, #queue-req: 0, 
[2025-10-18 02:13:35 TP0] Decode batch. #running-req: 16, #token: 56142, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.26, #queue-req: 0, 
[2025-10-18 02:13:37 TP0] Decode batch. #running-req: 16, #token: 56782, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.78, #queue-req: 0, 
[2025-10-18 02:13:38 TP0] Decode batch. #running-req: 16, #token: 57422, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.72, #queue-req: 0, 
[2025-10-18 02:13:39 TP0] Decode batch. #running-req: 16, #token: 58062, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.63, #queue-req: 0, 
[2025-10-18 02:13:40 TP0] Decode batch. #running-req: 16, #token: 58702, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.66, #queue-req: 0, 
[2025-10-18 02:13:41 TP0] Decode batch. #running-req: 16, #token: 59342, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.89, #queue-req: 0, 
[2025-10-18 02:13:42 TP0] Decode batch. #running-req: 16, #token: 59982, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.00, #queue-req: 0, 
[2025-10-18 02:13:43 TP0] Decode batch. #running-req: 16, #token: 60622, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.86, #queue-req: 0, 
[2025-10-18 02:13:44 TP0] Decode batch. #running-req: 16, #token: 61262, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.30, #queue-req: 0, 
[2025-10-18 02:13:45 TP0] Decode batch. #running-req: 16, #token: 61902, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.97, #queue-req: 0, 
[2025-10-18 02:13:46 TP0] Decode batch. #running-req: 16, #token: 62542, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.34, #queue-req: 0, 
[2025-10-18 02:13:47 TP0] Decode batch. #running-req: 16, #token: 63182, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.53, #queue-req: 0, 
[2025-10-18 02:13:48 TP0] Decode batch. #running-req: 16, #token: 63822, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.18, #queue-req: 0, 
[2025-10-18 02:13:48] INFO:     127.0.0.1:46428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46430 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48 TP0] Prefill batch. #new-seq: 1, #new-token: 3199, #cached-token: 2, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:13:48] INFO:     127.0.0.1:46438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46506 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:13:48 TP0] Prefill batch. #new-seq: 5, #new-token: 15986, #cached-token: 19, token usage: 0.00, #running-req: 1, #queue-req: 10, 
[2025-10-18 02:13:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15990, #cached-token: 15, token usage: 0.02, #running-req: 6, #queue-req: 5, 
[2025-10-18 02:13:49 TP0] Prefill batch. #new-seq: 5, #new-token: 15988, #cached-token: 17, token usage: 0.04, #running-req: 11, #queue-req: 0, 
[2025-10-18 02:13:52 TP0] Decode batch. #running-req: 16, #token: 51663, token usage: 0.05, cuda graph: True, gen throughput (token/s): 176.00, #queue-req: 0, 
[2025-10-18 02:13:53 TP0] Decode batch. #running-req: 16, #token: 52303, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.24, #queue-req: 0, 
[2025-10-18 02:13:54 TP0] Decode batch. #running-req: 16, #token: 52943, token usage: 0.05, cuda graph: True, gen throughput (token/s): 620.98, #queue-req: 0, 
[2025-10-18 02:13:55 TP0] Decode batch. #running-req: 16, #token: 53583, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.62, #queue-req: 0, 
[2025-10-18 02:13:56 TP0] Decode batch. #running-req: 16, #token: 54223, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.66, #queue-req: 0, 
[2025-10-18 02:13:57 TP0] Decode batch. #running-req: 16, #token: 54863, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.79, #queue-req: 0, 
[2025-10-18 02:13:58 TP0] Decode batch. #running-req: 16, #token: 55503, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.34, #queue-req: 0, 
[2025-10-18 02:13:59 TP0] Decode batch. #running-req: 16, #token: 56143, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.01, #queue-req: 0, 
[2025-10-18 02:14:00 TP0] Decode batch. #running-req: 16, #token: 56783, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.16, #queue-req: 0, 
[2025-10-18 02:14:01 TP0] Decode batch. #running-req: 16, #token: 57423, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.20, #queue-req: 0, 
[2025-10-18 02:14:02 TP0] Decode batch. #running-req: 16, #token: 58063, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.12, #queue-req: 0, 
[2025-10-18 02:14:03 TP0] Decode batch. #running-req: 16, #token: 58703, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.99, #queue-req: 0, 
[2025-10-18 02:14:04 TP0] Decode batch. #running-req: 16, #token: 59343, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.65, #queue-req: 0, 
[2025-10-18 02:14:05 TP0] Decode batch. #running-req: 16, #token: 59983, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.74, #queue-req: 0, 
[2025-10-18 02:14:06 TP0] Decode batch. #running-req: 16, #token: 60623, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.01, #queue-req: 0, 
[2025-10-18 02:14:07 TP0] Decode batch. #running-req: 16, #token: 61263, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.45, #queue-req: 0, 
[2025-10-18 02:14:08 TP0] Decode batch. #running-req: 16, #token: 61903, token usage: 0.06, cuda graph: True, gen throughput (token/s): 616.52, #queue-req: 0, 
[2025-10-18 02:14:09 TP0] Decode batch. #running-req: 16, #token: 62543, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.90, #queue-req: 0, 
[2025-10-18 02:14:10 TP0] Decode batch. #running-req: 16, #token: 63183, token usage: 0.07, cuda graph: True, gen throughput (token/s): 616.72, #queue-req: 0, 
[2025-10-18 02:14:11 TP0] Decode batch. #running-req: 16, #token: 63823, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.53, #queue-req: 0, 
[2025-10-18 02:14:11] INFO:     127.0.0.1:42228 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:14:34] INFO:     127.0.0.1:44016 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:14:40] INFO:     127.0.0.1:44024 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:14:41 TP0] Decode batch. #running-req: 1, #token: 3231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6.93, #queue-req: 0, 
[2025-10-18 02:14:42] INFO:     127.0.0.1:44040 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44056 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:14:42] INFO:     127.0.0.1:44062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44126 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42] INFO:     127.0.0.1:44164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:14:42 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 44800, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:14:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.05, #running-req: 15, #queue-req: 0, 
[2025-10-18 02:14:43 TP0] Decode batch. #running-req: 16, #token: 51794, token usage: 0.05, cuda graph: True, gen throughput (token/s): 258.32, #queue-req: 0, 
[2025-10-18 02:14:44 TP0] Decode batch. #running-req: 16, #token: 52434, token usage: 0.05, cuda graph: True, gen throughput (token/s): 612.49, #queue-req: 0, 
[2025-10-18 02:14:45 TP0] Decode batch. #running-req: 16, #token: 53074, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.79, #queue-req: 0, 
[2025-10-18 02:14:46 TP0] Decode batch. #running-req: 16, #token: 53714, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.22, #queue-req: 0, 
[2025-10-18 02:14:47 TP0] Decode batch. #running-req: 16, #token: 54354, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.09, #queue-req: 0, 
[2025-10-18 02:14:48 TP0] Decode batch. #running-req: 16, #token: 54994, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.06, #queue-req: 0, 
[2025-10-18 02:14:49 TP0] Decode batch. #running-req: 16, #token: 55634, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.10, #queue-req: 0, 
[2025-10-18 02:14:50 TP0] Decode batch. #running-req: 16, #token: 56274, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.31, #queue-req: 0, 
[2025-10-18 02:14:51 TP0] Decode batch. #running-req: 16, #token: 56914, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.70, #queue-req: 0, 
[2025-10-18 02:14:52 TP0] Decode batch. #running-req: 16, #token: 57554, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.42, #queue-req: 0, 
[2025-10-18 02:14:53 TP0] Decode batch. #running-req: 16, #token: 58194, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.06, #queue-req: 0, 
[2025-10-18 02:14:54 TP0] Decode batch. #running-req: 16, #token: 58834, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.25, #queue-req: 0, 
[2025-10-18 02:14:55 TP0] Decode batch. #running-req: 16, #token: 59474, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.32, #queue-req: 0, 
[2025-10-18 02:14:56 TP0] Decode batch. #running-req: 16, #token: 60114, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.40, #queue-req: 0, 
[2025-10-18 02:14:58 TP0] Decode batch. #running-req: 16, #token: 60754, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.12, #queue-req: 0, 
[2025-10-18 02:14:59 TP0] Decode batch. #running-req: 16, #token: 61394, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.83, #queue-req: 0, 
[2025-10-18 02:15:00 TP0] Decode batch. #running-req: 16, #token: 62034, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.63, #queue-req: 0, 
[2025-10-18 02:15:01 TP0] Decode batch. #running-req: 16, #token: 62674, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.40, #queue-req: 0, 
[2025-10-18 02:15:02 TP0] Decode batch. #running-req: 16, #token: 63314, token usage: 0.07, cuda graph: True, gen throughput (token/s): 619.25, #queue-req: 0, 
[2025-10-18 02:15:03 TP0] Decode batch. #running-req: 16, #token: 63954, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.39, #queue-req: 0, 
[2025-10-18 02:15:03] INFO:     127.0.0.1:42244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:15:03] INFO:     127.0.0.1:42262 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42294 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03] INFO:     127.0.0.1:42392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:03 TP0] Prefill batch. #new-seq: 15, #new-token: 15, #cached-token: 48000, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:15:04 TP0] Decode batch. #running-req: 16, #token: 51788, token usage: 0.05, cuda graph: True, gen throughput (token/s): 506.39, #queue-req: 0, 
[2025-10-18 02:15:05 TP0] Decode batch. #running-req: 16, #token: 52428, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.91, #queue-req: 0, 
[2025-10-18 02:15:06 TP0] Decode batch. #running-req: 16, #token: 53068, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.67, #queue-req: 0, 
[2025-10-18 02:15:07 TP0] Decode batch. #running-req: 16, #token: 53708, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.67, #queue-req: 0, 
[2025-10-18 02:15:08 TP0] Decode batch. #running-req: 16, #token: 54348, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.24, #queue-req: 0, 
[2025-10-18 02:15:09 TP0] Decode batch. #running-req: 16, #token: 54988, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.88, #queue-req: 0, 
[2025-10-18 02:15:10 TP0] Decode batch. #running-req: 16, #token: 55628, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.38, #queue-req: 0, 
[2025-10-18 02:15:11 TP0] Decode batch. #running-req: 16, #token: 56268, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.34, #queue-req: 0, 
[2025-10-18 02:15:12 TP0] Decode batch. #running-req: 16, #token: 56908, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.46, #queue-req: 0, 
[2025-10-18 02:15:13 TP0] Decode batch. #running-req: 16, #token: 57548, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.99, #queue-req: 0, 
[2025-10-18 02:15:14 TP0] Decode batch. #running-req: 16, #token: 58188, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.50, #queue-req: 0, 
[2025-10-18 02:15:15 TP0] Decode batch. #running-req: 16, #token: 58828, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.09, #queue-req: 0, 
[2025-10-18 02:15:16 TP0] Decode batch. #running-req: 16, #token: 59468, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.29, #queue-req: 0, 
[2025-10-18 02:15:17 TP0] Decode batch. #running-req: 16, #token: 60108, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.44, #queue-req: 0, 
[2025-10-18 02:15:18 TP0] Decode batch. #running-req: 16, #token: 60748, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.16, #queue-req: 0, 
[2025-10-18 02:15:19 TP0] Decode batch. #running-req: 16, #token: 61388, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.47, #queue-req: 0, 
[2025-10-18 02:15:20 TP0] Decode batch. #running-req: 16, #token: 62028, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.07, #queue-req: 0, 
[2025-10-18 02:15:21 TP0] Decode batch. #running-req: 16, #token: 62668, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.91, #queue-req: 0, 
[2025-10-18 02:15:22 TP0] Decode batch. #running-req: 16, #token: 63308, token usage: 0.07, cuda graph: True, gen throughput (token/s): 619.66, #queue-req: 0, 
[2025-10-18 02:15:24 TP0] Decode batch. #running-req: 16, #token: 63948, token usage: 0.07, cuda graph: True, gen throughput (token/s): 619.88, #queue-req: 0, 
[2025-10-18 02:15:24] INFO:     127.0.0.1:54444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:15:24] INFO:     127.0.0.1:54464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54492 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24] INFO:     127.0.0.1:54564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:24 TP0] Prefill batch. #new-seq: 14, #new-token: 14, #cached-token: 44800, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:15:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.05, #running-req: 15, #queue-req: 0, 
[2025-10-18 02:15:25 TP0] Decode batch. #running-req: 16, #token: 51790, token usage: 0.05, cuda graph: True, gen throughput (token/s): 484.13, #queue-req: 0, 
[2025-10-18 02:15:26 TP0] Decode batch. #running-req: 16, #token: 52430, token usage: 0.05, cuda graph: True, gen throughput (token/s): 632.89, #queue-req: 0, 
[2025-10-18 02:15:27 TP0] Decode batch. #running-req: 16, #token: 53070, token usage: 0.05, cuda graph: True, gen throughput (token/s): 627.83, #queue-req: 0, 
[2025-10-18 02:15:28 TP0] Decode batch. #running-req: 16, #token: 53710, token usage: 0.06, cuda graph: True, gen throughput (token/s): 627.43, #queue-req: 0, 
[2025-10-18 02:15:29 TP0] Decode batch. #running-req: 16, #token: 54350, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.73, #queue-req: 0, 
[2025-10-18 02:15:30 TP0] Decode batch. #running-req: 16, #token: 54990, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.03, #queue-req: 0, 
[2025-10-18 02:15:31 TP0] Decode batch. #running-req: 16, #token: 55630, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.16, #queue-req: 0, 
[2025-10-18 02:15:32 TP0] Decode batch. #running-req: 16, #token: 56270, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.55, #queue-req: 0, 
[2025-10-18 02:15:33 TP0] Decode batch. #running-req: 16, #token: 56910, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.19, #queue-req: 0, 
[2025-10-18 02:15:34 TP0] Decode batch. #running-req: 16, #token: 57550, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.35, #queue-req: 0, 
[2025-10-18 02:15:35 TP0] Decode batch. #running-req: 16, #token: 58190, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.12, #queue-req: 0, 
[2025-10-18 02:15:36 TP0] Decode batch. #running-req: 16, #token: 58830, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.59, #queue-req: 0, 
[2025-10-18 02:15:37 TP0] Decode batch. #running-req: 16, #token: 59470, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.92, #queue-req: 0, 
[2025-10-18 02:15:38 TP0] Decode batch. #running-req: 16, #token: 60110, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.68, #queue-req: 0, 
[2025-10-18 02:15:39 TP0] Decode batch. #running-req: 16, #token: 60750, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.61, #queue-req: 0, 
[2025-10-18 02:15:40 TP0] Decode batch. #running-req: 16, #token: 61390, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.30, #queue-req: 0, 
[2025-10-18 02:15:41 TP0] Decode batch. #running-req: 16, #token: 62030, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.31, #queue-req: 0, 
[2025-10-18 02:15:42 TP0] Decode batch. #running-req: 16, #token: 62670, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.25, #queue-req: 0, 
[2025-10-18 02:15:43 TP0] Decode batch. #running-req: 16, #token: 63310, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.35, #queue-req: 0, 
[2025-10-18 02:15:44 TP0] Decode batch. #running-req: 16, #token: 63950, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.47, #queue-req: 0, 
[2025-10-18 02:15:44] INFO:     127.0.0.1:51472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:44] INFO:     127.0.0.1:51478 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:15:44] INFO:     127.0.0.1:51486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:44] INFO:     127.0.0.1:51488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:44] INFO:     127.0.0.1:51504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:44] INFO:     127.0.0.1:51514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51570 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45] INFO:     127.0.0.1:51616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:15:45 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:15:45 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:15:46 TP0] Decode batch. #running-req: 16, #token: 51793, token usage: 0.05, cuda graph: True, gen throughput (token/s): 486.05, #queue-req: 0, 
[2025-10-18 02:15:47 TP0] Decode batch. #running-req: 16, #token: 52433, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.12, #queue-req: 0, 
[2025-10-18 02:15:48 TP0] Decode batch. #running-req: 16, #token: 53073, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.57, #queue-req: 0, 
[2025-10-18 02:15:49 TP0] Decode batch. #running-req: 16, #token: 53713, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.90, #queue-req: 0, 
[2025-10-18 02:15:50 TP0] Decode batch. #running-req: 16, #token: 54353, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.10, #queue-req: 0, 
[2025-10-18 02:15:51 TP0] Decode batch. #running-req: 16, #token: 54993, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.28, #queue-req: 0, 
[2025-10-18 02:15:52 TP0] Decode batch. #running-req: 16, #token: 55633, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.26, #queue-req: 0, 
[2025-10-18 02:15:53 TP0] Decode batch. #running-req: 16, #token: 56273, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.47, #queue-req: 0, 
[2025-10-18 02:15:54 TP0] Decode batch. #running-req: 16, #token: 56913, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.12, #queue-req: 0, 
[2025-10-18 02:15:55 TP0] Decode batch. #running-req: 16, #token: 57553, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.24, #queue-req: 0, 
[2025-10-18 02:15:56 TP0] Decode batch. #running-req: 16, #token: 58193, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.85, #queue-req: 0, 
[2025-10-18 02:15:57 TP0] Decode batch. #running-req: 16, #token: 58833, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.77, #queue-req: 0, 
[2025-10-18 02:15:58 TP0] Decode batch. #running-req: 16, #token: 59473, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.84, #queue-req: 0, 
[2025-10-18 02:15:59 TP0] Decode batch. #running-req: 16, #token: 60113, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.81, #queue-req: 0, 
[2025-10-18 02:16:00 TP0] Decode batch. #running-req: 16, #token: 60753, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.78, #queue-req: 0, 
[2025-10-18 02:16:01 TP0] Decode batch. #running-req: 16, #token: 61393, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.23, #queue-req: 0, 
[2025-10-18 02:16:02 TP0] Decode batch. #running-req: 16, #token: 62033, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.40, #queue-req: 0, 
[2025-10-18 02:16:03 TP0] Decode batch. #running-req: 16, #token: 62673, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.14, #queue-req: 0, 
[2025-10-18 02:16:04 TP0] Decode batch. #running-req: 16, #token: 63313, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.78, #queue-req: 0, 
[2025-10-18 02:16:05 TP0] Decode batch. #running-req: 16, #token: 63953, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.88, #queue-req: 0, 
[2025-10-18 02:16:05] INFO:     127.0.0.1:46902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:16:05] INFO:     127.0.0.1:46906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:46996 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:47004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:47006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05] INFO:     127.0.0.1:47010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:05 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:16:05] INFO:     127.0.0.1:47022 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:16:07 TP0] Decode batch. #running-req: 16, #token: 51788, token usage: 0.05, cuda graph: True, gen throughput (token/s): 490.16, #queue-req: 0, 
[2025-10-18 02:16:08 TP0] Decode batch. #running-req: 16, #token: 52428, token usage: 0.05, cuda graph: True, gen throughput (token/s): 631.05, #queue-req: 0, 
[2025-10-18 02:16:09 TP0] Decode batch. #running-req: 16, #token: 53068, token usage: 0.05, cuda graph: True, gen throughput (token/s): 629.14, #queue-req: 0, 
[2025-10-18 02:16:10 TP0] Decode batch. #running-req: 16, #token: 53708, token usage: 0.06, cuda graph: True, gen throughput (token/s): 627.71, #queue-req: 0, 
[2025-10-18 02:16:11 TP0] Decode batch. #running-req: 16, #token: 54348, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.13, #queue-req: 0, 
[2025-10-18 02:16:12 TP0] Decode batch. #running-req: 16, #token: 54988, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.05, #queue-req: 0, 
[2025-10-18 02:16:13 TP0] Decode batch. #running-req: 16, #token: 55628, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.49, #queue-req: 0, 
[2025-10-18 02:16:14 TP0] Decode batch. #running-req: 16, #token: 56268, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.43, #queue-req: 0, 
[2025-10-18 02:16:15 TP0] Decode batch. #running-req: 16, #token: 56908, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.43, #queue-req: 0, 
[2025-10-18 02:16:16 TP0] Decode batch. #running-req: 16, #token: 57548, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.38, #queue-req: 0, 
[2025-10-18 02:16:17 TP0] Decode batch. #running-req: 16, #token: 58188, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.61, #queue-req: 0, 
[2025-10-18 02:16:18 TP0] Decode batch. #running-req: 16, #token: 58828, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.64, #queue-req: 0, 
[2025-10-18 02:16:19 TP0] Decode batch. #running-req: 16, #token: 59468, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.64, #queue-req: 0, 
[2025-10-18 02:16:20 TP0] Decode batch. #running-req: 16, #token: 60108, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.14, #queue-req: 0, 
[2025-10-18 02:16:21 TP0] Decode batch. #running-req: 16, #token: 60748, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.27, #queue-req: 0, 
[2025-10-18 02:16:22 TP0] Decode batch. #running-req: 16, #token: 61388, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.25, #queue-req: 0, 
[2025-10-18 02:16:23 TP0] Decode batch. #running-req: 16, #token: 62028, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.22, #queue-req: 0, 
[2025-10-18 02:16:24 TP0] Decode batch. #running-req: 16, #token: 62668, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.41, #queue-req: 0, 
[2025-10-18 02:16:25 TP0] Decode batch. #running-req: 16, #token: 63308, token usage: 0.07, cuda graph: True, gen throughput (token/s): 624.10, #queue-req: 0, 
[2025-10-18 02:16:26 TP0] Decode batch. #running-req: 16, #token: 63948, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.29, #queue-req: 0, 
[2025-10-18 02:16:26] INFO:     127.0.0.1:57824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:16:26] INFO:     127.0.0.1:57840 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26] INFO:     127.0.0.1:57956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:26 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:16:26 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:16:27 TP0] Decode batch. #running-req: 16, #token: 51788, token usage: 0.05, cuda graph: True, gen throughput (token/s): 484.00, #queue-req: 0, 
[2025-10-18 02:16:28 TP0] Decode batch. #running-req: 16, #token: 52428, token usage: 0.05, cuda graph: True, gen throughput (token/s): 627.53, #queue-req: 0, 
[2025-10-18 02:16:29 TP0] Decode batch. #running-req: 16, #token: 53068, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.33, #queue-req: 0, 
[2025-10-18 02:16:30 TP0] Decode batch. #running-req: 16, #token: 53708, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.74, #queue-req: 0, 
[2025-10-18 02:16:32 TP0] Decode batch. #running-req: 16, #token: 54348, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.52, #queue-req: 0, 
[2025-10-18 02:16:33 TP0] Decode batch. #running-req: 16, #token: 54988, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.36, #queue-req: 0, 
[2025-10-18 02:16:34 TP0] Decode batch. #running-req: 16, #token: 55628, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.77, #queue-req: 0, 
[2025-10-18 02:16:35 TP0] Decode batch. #running-req: 16, #token: 56268, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.80, #queue-req: 0, 
[2025-10-18 02:16:36 TP0] Decode batch. #running-req: 16, #token: 56908, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.80, #queue-req: 0, 
[2025-10-18 02:16:37 TP0] Decode batch. #running-req: 16, #token: 57548, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.53, #queue-req: 0, 
[2025-10-18 02:16:38 TP0] Decode batch. #running-req: 16, #token: 58188, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.28, #queue-req: 0, 
[2025-10-18 02:16:39 TP0] Decode batch. #running-req: 16, #token: 58828, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.21, #queue-req: 0, 
[2025-10-18 02:16:40 TP0] Decode batch. #running-req: 16, #token: 59468, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.19, #queue-req: 0, 
[2025-10-18 02:16:41 TP0] Decode batch. #running-req: 16, #token: 60108, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.70, #queue-req: 0, 
[2025-10-18 02:16:42 TP0] Decode batch. #running-req: 16, #token: 60748, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.59, #queue-req: 0, 
[2025-10-18 02:16:43 TP0] Decode batch. #running-req: 16, #token: 61388, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.13, #queue-req: 0, 
[2025-10-18 02:16:44 TP0] Decode batch. #running-req: 16, #token: 62028, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.00, #queue-req: 0, 
[2025-10-18 02:16:45 TP0] Decode batch. #running-req: 16, #token: 62668, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.27, #queue-req: 0, 
[2025-10-18 02:16:46 TP0] Decode batch. #running-req: 16, #token: 63308, token usage: 0.07, cuda graph: True, gen throughput (token/s): 624.26, #queue-req: 0, 
[2025-10-18 02:16:47 TP0] Decode batch. #running-req: 16, #token: 63948, token usage: 0.07, cuda graph: True, gen throughput (token/s): 624.30, #queue-req: 0, 
[2025-10-18 02:16:47] INFO:     127.0.0.1:59440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:16:47] INFO:     127.0.0.1:59458 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47] INFO:     127.0.0.1:59596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:16:47] INFO:     127.0.0.1:59606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:16:47 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:16:48 TP0] Decode batch. #running-req: 16, #token: 51790, token usage: 0.05, cuda graph: True, gen throughput (token/s): 488.76, #queue-req: 0, 
[2025-10-18 02:16:49 TP0] Decode batch. #running-req: 16, #token: 52430, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.98, #queue-req: 0, 
[2025-10-18 02:16:50 TP0] Decode batch. #running-req: 16, #token: 53070, token usage: 0.05, cuda graph: True, gen throughput (token/s): 623.08, #queue-req: 0, 
[2025-10-18 02:16:51 TP0] Decode batch. #running-req: 16, #token: 53710, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.00, #queue-req: 0, 
[2025-10-18 02:16:52 TP0] Decode batch. #running-req: 16, #token: 54350, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.39, #queue-req: 0, 
[2025-10-18 02:16:53 TP0] Decode batch. #running-req: 16, #token: 54990, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.42, #queue-req: 0, 
[2025-10-18 02:16:54 TP0] Decode batch. #running-req: 16, #token: 55630, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.23, #queue-req: 0, 
[2025-10-18 02:16:55 TP0] Decode batch. #running-req: 16, #token: 56270, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.88, #queue-req: 0, 
[2025-10-18 02:16:56 TP0] Decode batch. #running-req: 16, #token: 56910, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.69, #queue-req: 0, 
[2025-10-18 02:16:57 TP0] Decode batch. #running-req: 16, #token: 57550, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.69, #queue-req: 0, 
[2025-10-18 02:16:59 TP0] Decode batch. #running-req: 16, #token: 58190, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.94, #queue-req: 0, 
[2025-10-18 02:17:00 TP0] Decode batch. #running-req: 16, #token: 58830, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.99, #queue-req: 0, 
[2025-10-18 02:17:01 TP0] Decode batch. #running-req: 16, #token: 59470, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.87, #queue-req: 0, 
[2025-10-18 02:17:02 TP0] Decode batch. #running-req: 16, #token: 60110, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.32, #queue-req: 0, 
[2025-10-18 02:17:03 TP0] Decode batch. #running-req: 16, #token: 60750, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.98, #queue-req: 0, 
[2025-10-18 02:17:04 TP0] Decode batch. #running-req: 16, #token: 61390, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.28, #queue-req: 0, 
[2025-10-18 02:17:05 TP0] Decode batch. #running-req: 16, #token: 62030, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.26, #queue-req: 0, 
[2025-10-18 02:17:06 TP0] Decode batch. #running-req: 16, #token: 62670, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.63, #queue-req: 0, 
[2025-10-18 02:17:07 TP0] Decode batch. #running-req: 16, #token: 63310, token usage: 0.07, cuda graph: True, gen throughput (token/s): 617.25, #queue-req: 0, 
[2025-10-18 02:17:08 TP0] Decode batch. #running-req: 16, #token: 63950, token usage: 0.07, cuda graph: True, gen throughput (token/s): 617.76, #queue-req: 0, 
[2025-10-18 02:17:08] INFO:     127.0.0.1:50082 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:17:08] INFO:     127.0.0.1:50102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50118 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50156 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50206 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08] INFO:     127.0.0.1:50210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:17:08] INFO:     127.0.0.1:50216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:08 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:17:09 TP0] Decode batch. #running-req: 16, #token: 51791, token usage: 0.05, cuda graph: True, gen throughput (token/s): 487.02, #queue-req: 0, 
[2025-10-18 02:17:10 TP0] Decode batch. #running-req: 16, #token: 52431, token usage: 0.05, cuda graph: True, gen throughput (token/s): 623.19, #queue-req: 0, 
[2025-10-18 02:17:11 TP0] Decode batch. #running-req: 16, #token: 53071, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.53, #queue-req: 0, 
[2025-10-18 02:17:12 TP0] Decode batch. #running-req: 16, #token: 53711, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.63, #queue-req: 0, 
[2025-10-18 02:17:13 TP0] Decode batch. #running-req: 16, #token: 54351, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.20, #queue-req: 0, 
[2025-10-18 02:17:14 TP0] Decode batch. #running-req: 16, #token: 54991, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.83, #queue-req: 0, 
[2025-10-18 02:17:15 TP0] Decode batch. #running-req: 16, #token: 55631, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.90, #queue-req: 0, 
[2025-10-18 02:17:16 TP0] Decode batch. #running-req: 16, #token: 56271, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.97, #queue-req: 0, 
[2025-10-18 02:17:17 TP0] Decode batch. #running-req: 16, #token: 56911, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.74, #queue-req: 0, 
[2025-10-18 02:17:18 TP0] Decode batch. #running-req: 16, #token: 57551, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.38, #queue-req: 0, 
[2025-10-18 02:17:19 TP0] Decode batch. #running-req: 16, #token: 58191, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.60, #queue-req: 0, 
[2025-10-18 02:17:20 TP0] Decode batch. #running-req: 16, #token: 58831, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.59, #queue-req: 0, 
[2025-10-18 02:17:22 TP0] Decode batch. #running-req: 16, #token: 59471, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.83, #queue-req: 0, 
[2025-10-18 02:17:23 TP0] Decode batch. #running-req: 16, #token: 60111, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.43, #queue-req: 0, 
[2025-10-18 02:17:24 TP0] Decode batch. #running-req: 16, #token: 60751, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.34, #queue-req: 0, 
[2025-10-18 02:17:25 TP0] Decode batch. #running-req: 16, #token: 61391, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.12, #queue-req: 0, 
[2025-10-18 02:17:26 TP0] Decode batch. #running-req: 16, #token: 62031, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.93, #queue-req: 0, 
[2025-10-18 02:17:27 TP0] Decode batch. #running-req: 16, #token: 62671, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.76, #queue-req: 0, 
[2025-10-18 02:17:28 TP0] Decode batch. #running-req: 16, #token: 63311, token usage: 0.07, cuda graph: True, gen throughput (token/s): 617.04, #queue-req: 0, 
[2025-10-18 02:17:29 TP0] Decode batch. #running-req: 16, #token: 63951, token usage: 0.07, cuda graph: True, gen throughput (token/s): 617.37, #queue-req: 0, 
[2025-10-18 02:17:29] INFO:     127.0.0.1:52494 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:17:52] INFO:     127.0.0.1:55100 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:17:57] INFO:     127.0.0.1:44608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:17:59] INFO:     127.0.0.1:44610 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:17:59] INFO:     127.0.0.1:44640 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44650 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44684 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59] INFO:     127.0.0.1:44732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:17:59 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:17:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:18:00 TP0] Decode batch. #running-req: 16, #token: 51282, token usage: 0.05, cuda graph: True, gen throughput (token/s): 5.18, #queue-req: 0, 
[2025-10-18 02:18:01 TP0] Decode batch. #running-req: 16, #token: 51922, token usage: 0.05, cuda graph: True, gen throughput (token/s): 576.39, #queue-req: 0, 
[2025-10-18 02:18:02 TP0] Decode batch. #running-req: 16, #token: 52562, token usage: 0.05, cuda graph: True, gen throughput (token/s): 626.27, #queue-req: 0, 
[2025-10-18 02:18:03 TP0] Decode batch. #running-req: 16, #token: 53202, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.22, #queue-req: 0, 
[2025-10-18 02:18:04 TP0] Decode batch. #running-req: 16, #token: 53842, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.68, #queue-req: 0, 
[2025-10-18 02:18:05 TP0] Decode batch. #running-req: 16, #token: 54482, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.40, #queue-req: 0, 
[2025-10-18 02:18:06 TP0] Decode batch. #running-req: 16, #token: 55122, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.21, #queue-req: 0, 
[2025-10-18 02:18:07 TP0] Decode batch. #running-req: 16, #token: 55762, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.31, #queue-req: 0, 
[2025-10-18 02:18:08 TP0] Decode batch. #running-req: 16, #token: 56402, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.71, #queue-req: 0, 
[2025-10-18 02:18:09 TP0] Decode batch. #running-req: 16, #token: 57042, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.16, #queue-req: 0, 
[2025-10-18 02:18:10 TP0] Decode batch. #running-req: 16, #token: 57682, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.30, #queue-req: 0, 
[2025-10-18 02:18:11 TP0] Decode batch. #running-req: 16, #token: 58322, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.64, #queue-req: 0, 
[2025-10-18 02:18:12 TP0] Decode batch. #running-req: 16, #token: 58962, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.80, #queue-req: 0, 
[2025-10-18 02:18:13 TP0] Decode batch. #running-req: 16, #token: 59602, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.29, #queue-req: 0, 
[2025-10-18 02:18:14 TP0] Decode batch. #running-req: 16, #token: 60242, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.67, #queue-req: 0, 
[2025-10-18 02:18:15 TP0] Decode batch. #running-req: 16, #token: 60882, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.54, #queue-req: 0, 
[2025-10-18 02:18:16 TP0] Decode batch. #running-req: 16, #token: 61522, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.76, #queue-req: 0, 
[2025-10-18 02:18:17 TP0] Decode batch. #running-req: 16, #token: 62162, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.12, #queue-req: 0, 
[2025-10-18 02:18:18 TP0] Decode batch. #running-req: 16, #token: 62802, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.82, #queue-req: 0, 
[2025-10-18 02:18:19 TP0] Decode batch. #running-req: 16, #token: 63442, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.93, #queue-req: 0, 
[2025-10-18 02:18:20] INFO:     127.0.0.1:37490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:18:20] INFO:     127.0.0.1:37512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37538 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37558 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37564 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37574 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37576 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20] INFO:     127.0.0.1:37614 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:20 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:18:20 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:18:21 TP0] Decode batch. #running-req: 16, #token: 51276, token usage: 0.05, cuda graph: True, gen throughput (token/s): 481.04, #queue-req: 0, 
[2025-10-18 02:18:22 TP0] Decode batch. #running-req: 16, #token: 51916, token usage: 0.05, cuda graph: True, gen throughput (token/s): 628.92, #queue-req: 0, 
[2025-10-18 02:18:23 TP0] Decode batch. #running-req: 16, #token: 52556, token usage: 0.05, cuda graph: True, gen throughput (token/s): 623.85, #queue-req: 0, 
[2025-10-18 02:18:24 TP0] Decode batch. #running-req: 16, #token: 53196, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.73, #queue-req: 0, 
[2025-10-18 02:18:25 TP0] Decode batch. #running-req: 16, #token: 53836, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.64, #queue-req: 0, 
[2025-10-18 02:18:26 TP0] Decode batch. #running-req: 16, #token: 54476, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.46, #queue-req: 0, 
[2025-10-18 02:18:27 TP0] Decode batch. #running-req: 16, #token: 55116, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.70, #queue-req: 0, 
[2025-10-18 02:18:28 TP0] Decode batch. #running-req: 16, #token: 55756, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.39, #queue-req: 0, 
[2025-10-18 02:18:29 TP0] Decode batch. #running-req: 16, #token: 56396, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.59, #queue-req: 0, 
[2025-10-18 02:18:30 TP0] Decode batch. #running-req: 16, #token: 57036, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.32, #queue-req: 0, 
[2025-10-18 02:18:31 TP0] Decode batch. #running-req: 16, #token: 57676, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.81, #queue-req: 0, 
[2025-10-18 02:18:32 TP0] Decode batch. #running-req: 16, #token: 58316, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.72, #queue-req: 0, 
[2025-10-18 02:18:33 TP0] Decode batch. #running-req: 16, #token: 58956, token usage: 0.06, cuda graph: True, gen throughput (token/s): 606.23, #queue-req: 0, 
[2025-10-18 02:18:34 TP0] Decode batch. #running-req: 16, #token: 59596, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.73, #queue-req: 0, 
[2025-10-18 02:18:35 TP0] Decode batch. #running-req: 16, #token: 60236, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.58, #queue-req: 0, 
[2025-10-18 02:18:36 TP0] Decode batch. #running-req: 16, #token: 60876, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.55, #queue-req: 0, 
[2025-10-18 02:18:37 TP0] Decode batch. #running-req: 16, #token: 61516, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.02, #queue-req: 0, 
[2025-10-18 02:18:38 TP0] Decode batch. #running-req: 16, #token: 62156, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.10, #queue-req: 0, 
[2025-10-18 02:18:39 TP0] Decode batch. #running-req: 16, #token: 62796, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.62, #queue-req: 0, 
[2025-10-18 02:18:40 TP0] Decode batch. #running-req: 16, #token: 63436, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.50, #queue-req: 0, 
[2025-10-18 02:18:41] INFO:     127.0.0.1:47896 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:18:41] INFO:     127.0.0.1:47912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47968 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:47992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:48002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:48004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41] INFO:     127.0.0.1:48010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:18:41 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:18:41 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:18:42 TP0] Decode batch. #running-req: 16, #token: 51278, token usage: 0.05, cuda graph: True, gen throughput (token/s): 476.79, #queue-req: 0, 
[2025-10-18 02:18:43 TP0] Decode batch. #running-req: 16, #token: 51918, token usage: 0.05, cuda graph: True, gen throughput (token/s): 632.53, #queue-req: 0, 
[2025-10-18 02:18:44 TP0] Decode batch. #running-req: 16, #token: 52558, token usage: 0.05, cuda graph: True, gen throughput (token/s): 632.93, #queue-req: 0, 
[2025-10-18 02:18:45 TP0] Decode batch. #running-req: 16, #token: 53198, token usage: 0.05, cuda graph: True, gen throughput (token/s): 628.04, #queue-req: 0, 
[2025-10-18 02:18:46 TP0] Decode batch. #running-req: 16, #token: 53838, token usage: 0.06, cuda graph: True, gen throughput (token/s): 628.17, #queue-req: 0, 
[2025-10-18 02:18:47 TP0] Decode batch. #running-req: 16, #token: 54478, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.27, #queue-req: 0, 
[2025-10-18 02:18:48 TP0] Decode batch. #running-req: 16, #token: 55118, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.15, #queue-req: 0, 
[2025-10-18 02:18:49 TP0] Decode batch. #running-req: 16, #token: 55758, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.81, #queue-req: 0, 
[2025-10-18 02:18:50 TP0] Decode batch. #running-req: 16, #token: 56398, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.47, #queue-req: 0, 
[2025-10-18 02:18:51 TP0] Decode batch. #running-req: 16, #token: 57038, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.73, #queue-req: 0, 
[2025-10-18 02:18:52 TP0] Decode batch. #running-req: 16, #token: 57678, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.18, #queue-req: 0, 
[2025-10-18 02:18:53 TP0] Decode batch. #running-req: 16, #token: 58318, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.31, #queue-req: 0, 
[2025-10-18 02:18:54 TP0] Decode batch. #running-req: 16, #token: 58958, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.36, #queue-req: 0, 
[2025-10-18 02:18:55 TP0] Decode batch. #running-req: 16, #token: 59598, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.18, #queue-req: 0, 
[2025-10-18 02:18:56 TP0] Decode batch. #running-req: 16, #token: 60238, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.62, #queue-req: 0, 
[2025-10-18 02:18:57 TP0] Decode batch. #running-req: 16, #token: 60878, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.62, #queue-req: 0, 
[2025-10-18 02:18:58 TP0] Decode batch. #running-req: 16, #token: 61518, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.24, #queue-req: 0, 
[2025-10-18 02:18:59 TP0] Decode batch. #running-req: 16, #token: 62158, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.24, #queue-req: 0, 
[2025-10-18 02:19:00 TP0] Decode batch. #running-req: 16, #token: 62798, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.39, #queue-req: 0, 
[2025-10-18 02:19:01 TP0] Decode batch. #running-req: 16, #token: 63438, token usage: 0.07, cuda graph: True, gen throughput (token/s): 620.08, #queue-req: 0, 
[2025-10-18 02:19:02] INFO:     127.0.0.1:39194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:19:02] INFO:     127.0.0.1:39216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02] INFO:     127.0.0.1:39320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:19:02] INFO:     127.0.0.1:39330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:19:02 TP0] Decode batch. #running-req: 16, #token: 51281, token usage: 0.05, cuda graph: True, gen throughput (token/s): 485.08, #queue-req: 0, 
[2025-10-18 02:19:03 TP0] Decode batch. #running-req: 16, #token: 51921, token usage: 0.05, cuda graph: True, gen throughput (token/s): 628.68, #queue-req: 0, 
[2025-10-18 02:19:04 TP0] Decode batch. #running-req: 16, #token: 52561, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.34, #queue-req: 0, 
[2025-10-18 02:19:06 TP0] Decode batch. #running-req: 16, #token: 53201, token usage: 0.05, cuda graph: True, gen throughput (token/s): 613.98, #queue-req: 0, 
[2025-10-18 02:19:07 TP0] Decode batch. #running-req: 16, #token: 53841, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.73, #queue-req: 0, 
[2025-10-18 02:19:08 TP0] Decode batch. #running-req: 16, #token: 54481, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.35, #queue-req: 0, 
[2025-10-18 02:19:09 TP0] Decode batch. #running-req: 16, #token: 55121, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.55, #queue-req: 0, 
[2025-10-18 02:19:10 TP0] Decode batch. #running-req: 16, #token: 55761, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.90, #queue-req: 0, 
[2025-10-18 02:19:11 TP0] Decode batch. #running-req: 16, #token: 56401, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.29, #queue-req: 0, 
[2025-10-18 02:19:12 TP0] Decode batch. #running-req: 16, #token: 57041, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.54, #queue-req: 0, 
[2025-10-18 02:19:13 TP0] Decode batch. #running-req: 16, #token: 57681, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.97, #queue-req: 0, 
[2025-10-18 02:19:14 TP0] Decode batch. #running-req: 16, #token: 58321, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.56, #queue-req: 0, 
[2025-10-18 02:19:15 TP0] Decode batch. #running-req: 16, #token: 58961, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.34, #queue-req: 0, 
[2025-10-18 02:19:16 TP0] Decode batch. #running-req: 16, #token: 59601, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.12, #queue-req: 0, 
[2025-10-18 02:19:17 TP0] Decode batch. #running-req: 16, #token: 60241, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.05, #queue-req: 0, 
[2025-10-18 02:19:18 TP0] Decode batch. #running-req: 16, #token: 60881, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.77, #queue-req: 0, 
[2025-10-18 02:19:19 TP0] Decode batch. #running-req: 16, #token: 61521, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.02, #queue-req: 0, 
[2025-10-18 02:19:20 TP0] Decode batch. #running-req: 16, #token: 62161, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.26, #queue-req: 0, 
[2025-10-18 02:19:21 TP0] Decode batch. #running-req: 16, #token: 62801, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.09, #queue-req: 0, 
[2025-10-18 02:19:22 TP0] Decode batch. #running-req: 16, #token: 63441, token usage: 0.07, cuda graph: True, gen throughput (token/s): 619.48, #queue-req: 0, 
[2025-10-18 02:19:23] INFO:     127.0.0.1:59194 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:19:23] INFO:     127.0.0.1:59214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59260 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23] INFO:     127.0.0.1:59354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:19:23] INFO:     127.0.0.1:59368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:19:23 TP0] Decode batch. #running-req: 16, #token: 51276, token usage: 0.05, cuda graph: True, gen throughput (token/s): 479.96, #queue-req: 0, 
[2025-10-18 02:19:24 TP0] Decode batch. #running-req: 16, #token: 51916, token usage: 0.05, cuda graph: True, gen throughput (token/s): 632.43, #queue-req: 0, 
[2025-10-18 02:19:25 TP0] Decode batch. #running-req: 16, #token: 52556, token usage: 0.05, cuda graph: True, gen throughput (token/s): 631.15, #queue-req: 0, 
[2025-10-18 02:19:26 TP0] Decode batch. #running-req: 16, #token: 53196, token usage: 0.05, cuda graph: True, gen throughput (token/s): 629.65, #queue-req: 0, 
[2025-10-18 02:19:27 TP0] Decode batch. #running-req: 16, #token: 53836, token usage: 0.06, cuda graph: True, gen throughput (token/s): 627.19, #queue-req: 0, 
[2025-10-18 02:19:28 TP0] Decode batch. #running-req: 16, #token: 54476, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.69, #queue-req: 0, 
[2025-10-18 02:19:29 TP0] Decode batch. #running-req: 16, #token: 55116, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.15, #queue-req: 0, 
[2025-10-18 02:19:31 TP0] Decode batch. #running-req: 16, #token: 55756, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.65, #queue-req: 0, 
[2025-10-18 02:19:32 TP0] Decode batch. #running-req: 16, #token: 56396, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.19, #queue-req: 0, 
[2025-10-18 02:19:33 TP0] Decode batch. #running-req: 16, #token: 57036, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.09, #queue-req: 0, 
[2025-10-18 02:19:34 TP0] Decode batch. #running-req: 16, #token: 57676, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.48, #queue-req: 0, 
[2025-10-18 02:19:35 TP0] Decode batch. #running-req: 16, #token: 58316, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.44, #queue-req: 0, 
[2025-10-18 02:19:36 TP0] Decode batch. #running-req: 16, #token: 58956, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.51, #queue-req: 0, 
[2025-10-18 02:19:37 TP0] Decode batch. #running-req: 16, #token: 59596, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.54, #queue-req: 0, 
[2025-10-18 02:19:38 TP0] Decode batch. #running-req: 16, #token: 60236, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.58, #queue-req: 0, 
[2025-10-18 02:19:39 TP0] Decode batch. #running-req: 16, #token: 60876, token usage: 0.06, cuda graph: True, gen throughput (token/s): 614.96, #queue-req: 0, 
[2025-10-18 02:19:40 TP0] Decode batch. #running-req: 16, #token: 61516, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.32, #queue-req: 0, 
[2025-10-18 02:19:41 TP0] Decode batch. #running-req: 16, #token: 62156, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.01, #queue-req: 0, 
[2025-10-18 02:19:42 TP0] Decode batch. #running-req: 16, #token: 62796, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.09, #queue-req: 0, 
[2025-10-18 02:19:43 TP0] Decode batch. #running-req: 16, #token: 63436, token usage: 0.07, cuda graph: True, gen throughput (token/s): 623.27, #queue-req: 0, 
[2025-10-18 02:19:44] INFO:     127.0.0.1:58874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58886 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:19:44] INFO:     127.0.0.1:58902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58976 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:58992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:59008 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:59010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:59014 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44] INFO:     127.0.0.1:59016 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:19:44 TP0] Prefill batch. #new-seq: 13, #new-token: 13, #cached-token: 41600, token usage: 0.05, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:19:44 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.05, #running-req: 14, #queue-req: 0, 
[2025-10-18 02:19:44 TP0] Decode batch. #running-req: 16, #token: 51276, token usage: 0.05, cuda graph: True, gen throughput (token/s): 482.89, #queue-req: 0, 
[2025-10-18 02:19:45 TP0] Decode batch. #running-req: 16, #token: 51916, token usage: 0.05, cuda graph: True, gen throughput (token/s): 631.46, #queue-req: 0, 
[2025-10-18 02:19:46 TP0] Decode batch. #running-req: 16, #token: 52556, token usage: 0.05, cuda graph: True, gen throughput (token/s): 626.98, #queue-req: 0, 
[2025-10-18 02:19:47 TP0] Decode batch. #running-req: 16, #token: 53196, token usage: 0.05, cuda graph: True, gen throughput (token/s): 625.55, #queue-req: 0, 
[2025-10-18 02:19:48 TP0] Decode batch. #running-req: 16, #token: 53836, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.91, #queue-req: 0, 
[2025-10-18 02:19:49 TP0] Decode batch. #running-req: 16, #token: 54476, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.95, #queue-req: 0, 
[2025-10-18 02:19:50 TP0] Decode batch. #running-req: 16, #token: 55116, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.74, #queue-req: 0, 
[2025-10-18 02:19:51 TP0] Decode batch. #running-req: 16, #token: 55756, token usage: 0.06, cuda graph: True, gen throughput (token/s): 622.66, #queue-req: 0, 
[2025-10-18 02:19:52 TP0] Decode batch. #running-req: 16, #token: 56396, token usage: 0.06, cuda graph: True, gen throughput (token/s): 626.47, #queue-req: 0, 
[2025-10-18 02:19:53 TP0] Decode batch. #running-req: 16, #token: 57036, token usage: 0.06, cuda graph: True, gen throughput (token/s): 627.06, #queue-req: 0, 
[2025-10-18 02:19:54 TP0] Decode batch. #running-req: 16, #token: 57676, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.91, #queue-req: 0, 
[2025-10-18 02:19:55 TP0] Decode batch. #running-req: 16, #token: 58316, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.33, #queue-req: 0, 
[2025-10-18 02:19:56 TP0] Decode batch. #running-req: 16, #token: 58956, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.49, #queue-req: 0, 
[2025-10-18 02:19:58 TP0] Decode batch. #running-req: 16, #token: 59596, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.65, #queue-req: 0, 
[2025-10-18 02:19:59 TP0] Decode batch. #running-req: 16, #token: 60236, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.04, #queue-req: 0, 
[2025-10-18 02:20:00 TP0] Decode batch. #running-req: 16, #token: 60876, token usage: 0.06, cuda graph: True, gen throughput (token/s): 623.52, #queue-req: 0, 
[2025-10-18 02:20:01 TP0] Decode batch. #running-req: 16, #token: 61516, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.13, #queue-req: 0, 
[2025-10-18 02:20:02 TP0] Decode batch. #running-req: 16, #token: 62156, token usage: 0.06, cuda graph: True, gen throughput (token/s): 625.85, #queue-req: 0, 
[2025-10-18 02:20:03 TP0] Decode batch. #running-req: 16, #token: 62796, token usage: 0.06, cuda graph: True, gen throughput (token/s): 624.16, #queue-req: 0, 
[2025-10-18 02:20:04 TP0] Decode batch. #running-req: 16, #token: 63436, token usage: 0.07, cuda graph: True, gen throughput (token/s): 624.37, #queue-req: 0, 
[2025-10-18 02:20:05] INFO:     127.0.0.1:48702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:20:05] INFO:     127.0.0.1:48716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48732 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48742 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48762 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48768 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48774 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48796 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05] INFO:     127.0.0.1:48798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:20:05] INFO:     127.0.0.1:48806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:20:05 TP0] Decode batch. #running-req: 16, #token: 51278, token usage: 0.05, cuda graph: True, gen throughput (token/s): 482.70, #queue-req: 0, 
[2025-10-18 02:20:06 TP0] Decode batch. #running-req: 16, #token: 51918, token usage: 0.05, cuda graph: True, gen throughput (token/s): 629.19, #queue-req: 0, 
[2025-10-18 02:20:07 TP0] Decode batch. #running-req: 16, #token: 52558, token usage: 0.05, cuda graph: True, gen throughput (token/s): 624.82, #queue-req: 0, 
[2025-10-18 02:20:08 TP0] Decode batch. #running-req: 16, #token: 53198, token usage: 0.05, cuda graph: True, gen throughput (token/s): 621.11, #queue-req: 0, 
[2025-10-18 02:20:09 TP0] Decode batch. #running-req: 16, #token: 53838, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.40, #queue-req: 0, 
[2025-10-18 02:20:10 TP0] Decode batch. #running-req: 16, #token: 54478, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.44, #queue-req: 0, 
[2025-10-18 02:20:11 TP0] Decode batch. #running-req: 16, #token: 55118, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.10, #queue-req: 0, 
[2025-10-18 02:20:12 TP0] Decode batch. #running-req: 16, #token: 55758, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.93, #queue-req: 0, 
[2025-10-18 02:20:13 TP0] Decode batch. #running-req: 16, #token: 56398, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.77, #queue-req: 0, 
[2025-10-18 02:20:14 TP0] Decode batch. #running-req: 16, #token: 57038, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.02, #queue-req: 0, 
[2025-10-18 02:20:15 TP0] Decode batch. #running-req: 16, #token: 57678, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.89, #queue-req: 0, 
[2025-10-18 02:20:16 TP0] Decode batch. #running-req: 16, #token: 58318, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.72, #queue-req: 0, 
[2025-10-18 02:20:17 TP0] Decode batch. #running-req: 16, #token: 58958, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.69, #queue-req: 0, 
[2025-10-18 02:20:18 TP0] Decode batch. #running-req: 16, #token: 59598, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.79, #queue-req: 0, 
[2025-10-18 02:20:19 TP0] Decode batch. #running-req: 16, #token: 60238, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.44, #queue-req: 0, 
[2025-10-18 02:20:20 TP0] Decode batch. #running-req: 16, #token: 60878, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.12, #queue-req: 0, 
[2025-10-18 02:20:21 TP0] Decode batch. #running-req: 16, #token: 61518, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.38, #queue-req: 0, 
[2025-10-18 02:20:23 TP0] Decode batch. #running-req: 16, #token: 62158, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.07, #queue-req: 0, 
[2025-10-18 02:20:24 TP0] Decode batch. #running-req: 16, #token: 62798, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.58, #queue-req: 0, 
[2025-10-18 02:20:25 TP0] Decode batch. #running-req: 16, #token: 63438, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.99, #queue-req: 0, 
[2025-10-18 02:20:25] INFO:     127.0.0.1:46646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:20:25] INFO:     127.0.0.1:46654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46688 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46712 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26 TP0] Prefill batch. #new-seq: 12, #new-token: 12, #cached-token: 38400, token usage: 0.04, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:20:26] INFO:     127.0.0.1:46752 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26] INFO:     127.0.0.1:46758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:20:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.05, #running-req: 13, #queue-req: 0, 
[2025-10-18 02:20:26 TP0] Decode batch. #running-req: 16, #token: 51279, token usage: 0.05, cuda graph: True, gen throughput (token/s): 482.20, #queue-req: 0, 
[2025-10-18 02:20:27 TP0] Decode batch. #running-req: 16, #token: 51919, token usage: 0.05, cuda graph: True, gen throughput (token/s): 627.31, #queue-req: 0, 
[2025-10-18 02:20:28 TP0] Decode batch. #running-req: 16, #token: 52559, token usage: 0.05, cuda graph: True, gen throughput (token/s): 622.48, #queue-req: 0, 
[2025-10-18 02:20:29 TP0] Decode batch. #running-req: 16, #token: 53199, token usage: 0.05, cuda graph: True, gen throughput (token/s): 621.09, #queue-req: 0, 
[2025-10-18 02:20:30 TP0] Decode batch. #running-req: 16, #token: 53839, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.89, #queue-req: 0, 
[2025-10-18 02:20:31 TP0] Decode batch. #running-req: 16, #token: 54479, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.57, #queue-req: 0, 
[2025-10-18 02:20:32 TP0] Decode batch. #running-req: 16, #token: 55119, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.61, #queue-req: 0, 
[2025-10-18 02:20:33 TP0] Decode batch. #running-req: 16, #token: 55759, token usage: 0.06, cuda graph: True, gen throughput (token/s): 621.33, #queue-req: 0, 
[2025-10-18 02:20:34 TP0] Decode batch. #running-req: 16, #token: 56399, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.68, #queue-req: 0, 
[2025-10-18 02:20:35 TP0] Decode batch. #running-req: 16, #token: 57039, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.56, #queue-req: 0, 
[2025-10-18 02:20:36 TP0] Decode batch. #running-req: 16, #token: 57679, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.32, #queue-req: 0, 
[2025-10-18 02:20:37 TP0] Decode batch. #running-req: 16, #token: 58319, token usage: 0.06, cuda graph: True, gen throughput (token/s): 620.58, #queue-req: 0, 
[2025-10-18 02:20:38 TP0] Decode batch. #running-req: 16, #token: 58959, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.63, #queue-req: 0, 
[2025-10-18 02:20:39 TP0] Decode batch. #running-req: 16, #token: 59599, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.05, #queue-req: 0, 
[2025-10-18 02:20:40 TP0] Decode batch. #running-req: 16, #token: 60239, token usage: 0.06, cuda graph: True, gen throughput (token/s): 619.07, #queue-req: 0, 
[2025-10-18 02:20:41 TP0] Decode batch. #running-req: 16, #token: 60879, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.76, #queue-req: 0, 
[2025-10-18 02:20:42 TP0] Decode batch. #running-req: 16, #token: 61519, token usage: 0.06, cuda graph: True, gen throughput (token/s): 618.82, #queue-req: 0, 
[2025-10-18 02:20:43 TP0] Decode batch. #running-req: 16, #token: 62159, token usage: 0.06, cuda graph: True, gen throughput (token/s): 617.18, #queue-req: 0, 
[2025-10-18 02:20:45 TP0] Decode batch. #running-req: 16, #token: 62799, token usage: 0.06, cuda graph: True, gen throughput (token/s): 611.44, #queue-req: 0, 
[2025-10-18 02:20:46 TP0] Decode batch. #running-req: 16, #token: 63439, token usage: 0.07, cuda graph: True, gen throughput (token/s): 618.37, #queue-req: 0, 
[2025-10-18 02:20:46] INFO:     127.0.0.1:60064 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:21:04] INFO:     127.0.0.1:33796 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:21:10] INFO:     127.0.0.1:33798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:21:10 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 22.84, #queue-req: 0, 
[2025-10-18 02:21:12] INFO:     127.0.0.1:33810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:12] INFO:     127.0.0.1:33814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:21:12] INFO:     127.0.0.1:33816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:12] INFO:     127.0.0.1:33826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:21:12 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 39.79, #queue-req: 0, 
[2025-10-18 02:21:13 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:21:14 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:21:15 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:21:16 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:21:16 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:21:17 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.21, #queue-req: 0, 
[2025-10-18 02:21:18 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:21:19 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:21:20 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:21:21 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:21:21 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:21:22 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:21:23 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:21:24 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:21:25 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:21:25 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:21:26 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:21:27 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:21:28 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:21:29] INFO:     127.0.0.1:38678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:29] INFO:     127.0.0.1:38686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:29] INFO:     127.0.0.1:38694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:29 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:21:29] INFO:     127.0.0.1:38702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:29 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:21:29 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.05, #queue-req: 0, 
[2025-10-18 02:21:30 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:21:31 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:21:31 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:21:32 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:21:33 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:21:34 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:21:35 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:21:36 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:21:36 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:21:37 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:21:38 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:21:39 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:21:40 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:21:41 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:21:41 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:21:42 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:21:43 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:21:44 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:21:45 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:21:45] INFO:     127.0.0.1:46054 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:45] INFO:     127.0.0.1:46058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:45] INFO:     127.0.0.1:46074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:45 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:21:45] INFO:     127.0.0.1:46086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:21:45 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:21:46 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.12, #queue-req: 0, 
[2025-10-18 02:21:46 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:21:47 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:21:48 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:21:49 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:21:50 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:21:51 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:21:51 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:21:52 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:21:53 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:21:54 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:21:55 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:21:56 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:21:56 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:21:57 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:21:58 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:21:59 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:00 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:01 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:01 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:02] INFO:     127.0.0.1:39152 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:02] INFO:     127.0.0.1:39168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:02] INFO:     127.0.0.1:39176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:22:02] INFO:     127.0.0.1:39186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:22:02 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.10, #queue-req: 0, 
[2025-10-18 02:22:03 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:22:04 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:22:05 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:22:06 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:22:06 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:22:07 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:22:08 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:22:09 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:22:10 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:11 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:11 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:12 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:13 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:14 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:15 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:16 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:16 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:17 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:18 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:19] INFO:     127.0.0.1:39004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:19] INFO:     127.0.0.1:39018 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:19] INFO:     127.0.0.1:39020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:22:19] INFO:     127.0.0.1:39030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:22:19 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.51, #queue-req: 0, 
[2025-10-18 02:22:20 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:22:21 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:22:22 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:22:22 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:22:23 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:22:24 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:22:25 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:22:26 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:22:26 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:22:27 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:22:28 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:22:29 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.51, #queue-req: 0, 
[2025-10-18 02:22:30 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:22:31 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:31 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:32 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:33 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:34 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:35 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:35] INFO:     127.0.0.1:38208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:35] INFO:     127.0.0.1:38224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:22:35] INFO:     127.0.0.1:38236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:35] INFO:     127.0.0.1:38244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:35 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:22:36 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.03, #queue-req: 0, 
[2025-10-18 02:22:37 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:22:37 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:22:38 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:22:39 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:22:40 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:22:41 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:22:42 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:42 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:22:43 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:22:44 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:45 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:22:46 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:46 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:47 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:22:48 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:49 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:50 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:51 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:22:51 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:22:52] INFO:     127.0.0.1:59898 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:52] INFO:     127.0.0.1:59902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:52] INFO:     127.0.0.1:59912 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:22:52] INFO:     127.0.0.1:59926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:22:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:22:52 TP0] Decode batch. #running-req: 4, #token: 12852, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.09, #queue-req: 0, 
[2025-10-18 02:22:53 TP0] Decode batch. #running-req: 4, #token: 13012, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:22:54 TP0] Decode batch. #running-req: 4, #token: 13172, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:22:55 TP0] Decode batch. #running-req: 4, #token: 13332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.32, #queue-req: 0, 
[2025-10-18 02:22:56 TP0] Decode batch. #running-req: 4, #token: 13492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:22:57 TP0] Decode batch. #running-req: 4, #token: 13652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:22:57 TP0] Decode batch. #running-req: 4, #token: 13812, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:22:58 TP0] Decode batch. #running-req: 4, #token: 13972, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:22:59 TP0] Decode batch. #running-req: 4, #token: 14132, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:00 TP0] Decode batch. #running-req: 4, #token: 14292, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:23:01 TP0] Decode batch. #running-req: 4, #token: 14452, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:23:02 TP0] Decode batch. #running-req: 4, #token: 14612, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:23:02 TP0] Decode batch. #running-req: 4, #token: 14772, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:23:03 TP0] Decode batch. #running-req: 4, #token: 14932, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:23:04 TP0] Decode batch. #running-req: 4, #token: 15092, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.52, #queue-req: 0, 
[2025-10-18 02:23:05 TP0] Decode batch. #running-req: 4, #token: 15252, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:23:06 TP0] Decode batch. #running-req: 4, #token: 15412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:06 TP0] Decode batch. #running-req: 4, #token: 15572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:23:07 TP0] Decode batch. #running-req: 4, #token: 15732, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:23:08 TP0] Decode batch. #running-req: 4, #token: 15892, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:09] INFO:     127.0.0.1:34098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:09] INFO:     127.0.0.1:34100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:23:09] INFO:     127.0.0.1:34114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:09] INFO:     127.0.0.1:34116 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:09 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:23:09 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.72, #queue-req: 0, 
[2025-10-18 02:23:10 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:23:11 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:23:12 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:23:12 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:23:13 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:23:14 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:23:15 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:23:16 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:23:17 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:17 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:23:18 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:23:19 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:23:20 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:21 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:23:22 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:22 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:23 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:23:24 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:23:25 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:23:25] INFO:     127.0.0.1:60696 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:25] INFO:     127.0.0.1:60708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:25] INFO:     127.0.0.1:60710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:25 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:23:25] INFO:     127.0.0.1:60722 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:25 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:23:26 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.33, #queue-req: 0, 
[2025-10-18 02:23:27 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:23:27 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:23:28 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:23:29 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:23:30 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:23:31 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:23:32 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:23:32 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:33 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:23:34 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:23:35 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:36 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:23:37 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:37 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:38 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:23:39 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:40 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:23:41 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:23:42 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:23:42] INFO:     127.0.0.1:43074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:42] INFO:     127.0.0.1:43088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:42] INFO:     127.0.0.1:43096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:23:42] INFO:     127.0.0.1:43100 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:23:43 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.04, #queue-req: 0, 
[2025-10-18 02:23:43 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.87, #queue-req: 0, 
[2025-10-18 02:23:44 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:23:45 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:23:46 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:23:47 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:23:47 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:23:48 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:23:49 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:23:50 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:23:51 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:52 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:23:52 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:53 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:54 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:55 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:56 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:23:57 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:23:57 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:23:58 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:23:59] INFO:     127.0.0.1:44288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:59] INFO:     127.0.0.1:44304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:59] INFO:     127.0.0.1:44314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:23:59] INFO:     127.0.0.1:44328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:23:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:23:59 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.12, #queue-req: 0, 
[2025-10-18 02:24:00 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:24:01 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:24:02 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:24:03 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:24:03 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:24:04 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:24:05 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:24:06 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:24:07 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:24:07 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:24:08 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:24:09 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:24:10 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:24:11 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:24:12 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:24:12 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:24:13 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:24:14 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:24:15 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:24:15] INFO:     127.0.0.1:43904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:15] INFO:     127.0.0.1:43908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:15] INFO:     127.0.0.1:43916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:24:15] INFO:     127.0.0.1:43920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:24:16 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.97, #queue-req: 0, 
[2025-10-18 02:24:17 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:24:18 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:24:18 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:24:19 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:24:20 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:24:21 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:24:22 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:24:23 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:24:23 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:24:24 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:24:25 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:26 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:24:27 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:27 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:24:28 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:24:29 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:24:30 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:24:31 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:24:32 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:24:32] INFO:     127.0.0.1:48290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:32] INFO:     127.0.0.1:48298 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:32] INFO:     127.0.0.1:48310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:24:32] INFO:     127.0.0.1:48314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:24:33 TP0] Decode batch. #running-req: 4, #token: 12853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.21, #queue-req: 0, 
[2025-10-18 02:24:33 TP0] Decode batch. #running-req: 4, #token: 13013, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:24:34 TP0] Decode batch. #running-req: 4, #token: 13173, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:24:35 TP0] Decode batch. #running-req: 4, #token: 13333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:24:36 TP0] Decode batch. #running-req: 4, #token: 13493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:24:37 TP0] Decode batch. #running-req: 4, #token: 13653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:24:38 TP0] Decode batch. #running-req: 4, #token: 13813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:24:38 TP0] Decode batch. #running-req: 4, #token: 13973, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:24:39 TP0] Decode batch. #running-req: 4, #token: 14133, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:24:40 TP0] Decode batch. #running-req: 4, #token: 14293, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:24:41 TP0] Decode batch. #running-req: 4, #token: 14453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:24:42 TP0] Decode batch. #running-req: 4, #token: 14613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:42 TP0] Decode batch. #running-req: 4, #token: 14773, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:24:43 TP0] Decode batch. #running-req: 4, #token: 14933, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:44 TP0] Decode batch. #running-req: 4, #token: 15093, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:45 TP0] Decode batch. #running-req: 4, #token: 15253, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:24:46 TP0] Decode batch. #running-req: 4, #token: 15413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:24:47 TP0] Decode batch. #running-req: 4, #token: 15573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:24:47 TP0] Decode batch. #running-req: 4, #token: 15733, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:24:48 TP0] Decode batch. #running-req: 4, #token: 15893, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:24:49] INFO:     127.0.0.1:35204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:49] INFO:     127.0.0.1:35208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:49] INFO:     127.0.0.1:35218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:24:49] INFO:     127.0.0.1:35226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:24:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:24:49 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.95, #queue-req: 0, 
[2025-10-18 02:24:50 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 194.03, #queue-req: 0, 
[2025-10-18 02:24:51 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.99, #queue-req: 0, 
[2025-10-18 02:24:52 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.95, #queue-req: 0, 
[2025-10-18 02:24:53 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:24:53 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.87, #queue-req: 0, 
[2025-10-18 02:24:54 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:24:55 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.87, #queue-req: 0, 
[2025-10-18 02:24:56 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:24:57 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:24:58 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:24:58 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:24:59 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:25:00 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:25:01 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:25:02 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:25:02 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:25:03 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:25:04 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:25:05 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:25:06] INFO:     127.0.0.1:47300 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:06] INFO:     127.0.0.1:47316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:25:06] INFO:     127.0.0.1:47328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:06] INFO:     127.0.0.1:47344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:25:06 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.88, #queue-req: 0, 
[2025-10-18 02:25:07 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:25:08 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:25:08 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:25:09 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:25:10 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:11 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:12 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:13 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:13 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:14 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:15 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:16 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:25:17 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:25:18 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:18 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:19 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:20 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:25:21 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:25:22 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:22] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:22] INFO:     127.0.0.1:37090 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:22] INFO:     127.0.0.1:37094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:25:22] INFO:     127.0.0.1:37104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:25:23 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.07, #queue-req: 0, 
[2025-10-18 02:25:23 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:25:24 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:25:25 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:25:26 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:25:27 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:25:28 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:25:28 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:25:29 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:25:30 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:25:31 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:25:32 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:33 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:25:33 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:34 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:25:35 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:36 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:25:37 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:38 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:38 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:25:39] INFO:     127.0.0.1:44960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:39] INFO:     127.0.0.1:44966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:39] INFO:     127.0.0.1:44974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:39 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:25:39] INFO:     127.0.0.1:44986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:39 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:25:39 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.96, #queue-req: 0, 
[2025-10-18 02:25:40 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:25:41 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:25:42 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:25:43 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:25:43 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:25:44 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:25:45 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:25:46 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:25:47 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:25:48 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:48 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:25:49 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:25:50 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:51 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:25:52 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:25:53 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:25:53 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:25:54 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:25:55 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:25:56] INFO:     127.0.0.1:56484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:56] INFO:     127.0.0.1:56500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:56] INFO:     127.0.0.1:56510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:25:56] INFO:     127.0.0.1:56514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:25:56 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:25:56 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.15, #queue-req: 0, 
[2025-10-18 02:25:57 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.91, #queue-req: 0, 
[2025-10-18 02:25:58 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:25:59 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.87, #queue-req: 0, 
[2025-10-18 02:25:59 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:26:00 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:26:01 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:26:02 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:26:03 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:26:03 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:26:04 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:26:05 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:26:06 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:26:07 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:26:08 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:26:08 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:26:09 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:26:10 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:26:11 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:26:12 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.44, #queue-req: 0, 
[2025-10-18 02:26:12] INFO:     127.0.0.1:54636 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:12] INFO:     127.0.0.1:54648 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:12] INFO:     127.0.0.1:54656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:26:12] INFO:     127.0.0.1:54660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:26:13 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.37, #queue-req: 0, 
[2025-10-18 02:26:14 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:26:14 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:26:15 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:26:16 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:26:17 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:26:18 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:26:18 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:26:19 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:26:20 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:26:21 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:26:22 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:26:23 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:26:23 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:26:24 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:26:25 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:26:26 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:26:27 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:26:28 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:26:28 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:26:29] INFO:     127.0.0.1:41532 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:29] INFO:     127.0.0.1:41542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:26:29] INFO:     127.0.0.1:41548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:29] INFO:     127.0.0.1:41560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:29 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:26:29 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.29, #queue-req: 0, 
[2025-10-18 02:26:30 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:26:31 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:26:32 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:26:33 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:26:34 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:26:34 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:26:35 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:26:36 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:26:37 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:26:38 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:26:38 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:26:39 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:26:40 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:26:41 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:26:42 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:26:43 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:26:43 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:26:44 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:26:45 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:26:46] INFO:     127.0.0.1:41642 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:46] INFO:     127.0.0.1:41658 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:26:46] INFO:     127.0.0.1:41670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:46] INFO:     127.0.0.1:41672 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:26:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:26:46 TP0] Decode batch. #running-req: 4, #token: 12853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.18, #queue-req: 0, 
[2025-10-18 02:26:47 TP0] Decode batch. #running-req: 4, #token: 13013, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:26:48 TP0] Decode batch. #running-req: 4, #token: 13173, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:26:49 TP0] Decode batch. #running-req: 4, #token: 13333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:26:49 TP0] Decode batch. #running-req: 4, #token: 13493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:26:50 TP0] Decode batch. #running-req: 4, #token: 13653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:26:51 TP0] Decode batch. #running-req: 4, #token: 13813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:26:52 TP0] Decode batch. #running-req: 4, #token: 13973, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:26:53 TP0] Decode batch. #running-req: 4, #token: 14133, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:26:54 TP0] Decode batch. #running-req: 4, #token: 14293, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:26:54 TP0] Decode batch. #running-req: 4, #token: 14453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:26:55 TP0] Decode batch. #running-req: 4, #token: 14613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:26:56 TP0] Decode batch. #running-req: 4, #token: 14773, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:26:57 TP0] Decode batch. #running-req: 4, #token: 14933, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:26:58 TP0] Decode batch. #running-req: 4, #token: 15093, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:26:58 TP0] Decode batch. #running-req: 4, #token: 15253, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:26:59 TP0] Decode batch. #running-req: 4, #token: 15413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:00 TP0] Decode batch. #running-req: 4, #token: 15573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:01 TP0] Decode batch. #running-req: 4, #token: 15733, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:27:02 TP0] Decode batch. #running-req: 4, #token: 15893, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:02] INFO:     127.0.0.1:42128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:02] INFO:     127.0.0.1:42136 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:02] INFO:     127.0.0.1:42142 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:27:02] INFO:     127.0.0.1:42158 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:27:03 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.28, #queue-req: 0, 
[2025-10-18 02:27:04 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:27:04 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:27:05 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:27:06 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:27:07 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:27:08 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:27:09 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:09 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:27:10 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:11 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:12 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:27:13 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:14 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:27:14 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:27:15 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:16 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:17 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:18 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:18 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:27:19] INFO:     127.0.0.1:37652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:19] INFO:     127.0.0.1:37654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:19] INFO:     127.0.0.1:37660 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:27:19] INFO:     127.0.0.1:37670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:27:19 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.74, #queue-req: 0, 
[2025-10-18 02:27:20 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.94, #queue-req: 0, 
[2025-10-18 02:27:21 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:27:22 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:27:23 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:27:24 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:27:24 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:27:25 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:27:26 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:27:27 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:27:28 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:29 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:29 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:27:30 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:27:31 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:32 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:33 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:34 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:34 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:27:35 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:36] INFO:     127.0.0.1:40838 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:36] INFO:     127.0.0.1:40844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:36] INFO:     127.0.0.1:40860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:27:36] INFO:     127.0.0.1:40870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:27:36 TP0] Decode batch. #running-req: 4, #token: 12853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.19, #queue-req: 0, 
[2025-10-18 02:27:37 TP0] Decode batch. #running-req: 4, #token: 13013, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:27:38 TP0] Decode batch. #running-req: 4, #token: 13173, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:27:39 TP0] Decode batch. #running-req: 4, #token: 13333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:27:39 TP0] Decode batch. #running-req: 4, #token: 13493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:27:40 TP0] Decode batch. #running-req: 4, #token: 13653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:27:41 TP0] Decode batch. #running-req: 4, #token: 13813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:27:42 TP0] Decode batch. #running-req: 4, #token: 13973, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:27:43 TP0] Decode batch. #running-req: 4, #token: 14133, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:44 TP0] Decode batch. #running-req: 4, #token: 14293, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:27:44 TP0] Decode batch. #running-req: 4, #token: 14453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:27:45 TP0] Decode batch. #running-req: 4, #token: 14613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:46 TP0] Decode batch. #running-req: 4, #token: 14773, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:47 TP0] Decode batch. #running-req: 4, #token: 14933, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:27:48 TP0] Decode batch. #running-req: 4, #token: 15093, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:27:49 TP0] Decode batch. #running-req: 4, #token: 15253, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:27:49 TP0] Decode batch. #running-req: 4, #token: 15413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:27:50 TP0] Decode batch. #running-req: 4, #token: 15573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:51 TP0] Decode batch. #running-req: 4, #token: 15733, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:27:52 TP0] Decode batch. #running-req: 4, #token: 15893, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:27:52] INFO:     127.0.0.1:48030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:52] INFO:     127.0.0.1:48034 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:52] INFO:     127.0.0.1:48038 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:27:52] INFO:     127.0.0.1:48042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:27:53 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:27:53 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.25, #queue-req: 0, 
[2025-10-18 02:27:54 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:27:55 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:27:55 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:27:56 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:27:57 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:27:58 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:27:59 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:27:59 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:28:00 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:01 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:02 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:03 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:04 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:28:04 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:28:05 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:28:06 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:28:07 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:28:08 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:28:09 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:28:09] INFO:     127.0.0.1:51326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:09] INFO:     127.0.0.1:51334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:09] INFO:     127.0.0.1:51346 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:28:09] INFO:     127.0.0.1:51354 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:28:10 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.05, #queue-req: 0, 
[2025-10-18 02:28:10 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:28:11 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:28:12 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:28:13 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:28:14 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:28:15 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:28:15 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:16 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:28:17 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:18 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:19 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:28:19 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:28:20 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:21 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:28:22 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:23 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:28:24 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:28:24 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:25 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:26] INFO:     127.0.0.1:46852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:26] INFO:     127.0.0.1:46864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:28:26] INFO:     127.0.0.1:46878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:26] INFO:     127.0.0.1:46882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:28:26 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.20, #queue-req: 0, 
[2025-10-18 02:28:27 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:28:28 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:28:29 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:28:30 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:28:30 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:28:31 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:28:32 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:28:33 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:28:34 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:35 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:28:35 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:36 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:37 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:28:38 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:28:39 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:28:39 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:28:40 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:28:41 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:28:42 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:28:42] INFO:     127.0.0.1:38398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:42] INFO:     127.0.0.1:38406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:42] INFO:     127.0.0.1:38412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:28:43] INFO:     127.0.0.1:38428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:43 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:28:43 TP0] Decode batch. #running-req: 4, #token: 12853, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.09, #queue-req: 0, 
[2025-10-18 02:28:44 TP0] Decode batch. #running-req: 4, #token: 13013, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:28:45 TP0] Decode batch. #running-req: 4, #token: 13173, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:28:45 TP0] Decode batch. #running-req: 4, #token: 13333, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:28:46 TP0] Decode batch. #running-req: 4, #token: 13493, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:28:47 TP0] Decode batch. #running-req: 4, #token: 13653, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:28:48 TP0] Decode batch. #running-req: 4, #token: 13813, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:28:49 TP0] Decode batch. #running-req: 4, #token: 13973, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:28:50 TP0] Decode batch. #running-req: 4, #token: 14133, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:28:50 TP0] Decode batch. #running-req: 4, #token: 14293, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:28:51 TP0] Decode batch. #running-req: 4, #token: 14453, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:52 TP0] Decode batch. #running-req: 4, #token: 14613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:28:53 TP0] Decode batch. #running-req: 4, #token: 14773, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:28:54 TP0] Decode batch. #running-req: 4, #token: 14933, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:28:54 TP0] Decode batch. #running-req: 4, #token: 15093, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:28:55 TP0] Decode batch. #running-req: 4, #token: 15253, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:56 TP0] Decode batch. #running-req: 4, #token: 15413, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:57 TP0] Decode batch. #running-req: 4, #token: 15573, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:58 TP0] Decode batch. #running-req: 4, #token: 15733, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:28:59 TP0] Decode batch. #running-req: 4, #token: 15893, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:28:59] INFO:     127.0.0.1:33822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:59] INFO:     127.0.0.1:33828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:28:59] INFO:     127.0.0.1:33834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:59] INFO:     127.0.0.1:33842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:28:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:29:00 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.24, #queue-req: 0, 
[2025-10-18 02:29:00 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:29:01 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:29:02 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:03 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:29:04 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:29:05 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:29:05 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:29:06 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:29:07 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:29:08 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:09 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:10 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:10 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:11 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:12 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:29:13 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:29:14 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:29:14 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:29:15 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.52, #queue-req: 0, 
[2025-10-18 02:29:16] INFO:     127.0.0.1:34480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:16] INFO:     127.0.0.1:34488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:16] INFO:     127.0.0.1:34502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:29:16] INFO:     127.0.0.1:34512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:29:16 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.02, #queue-req: 0, 
[2025-10-18 02:29:17 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:18 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:29:19 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:29:20 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:29:20 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:21 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:29:22 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:29:23 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:29:24 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:29:25 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:29:25 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:29:26 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:29:27 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:29:28 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:29:29 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:30 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:29:30 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:31 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:29:32 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:29:33] INFO:     127.0.0.1:43242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:33] INFO:     127.0.0.1:43246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:29:33] INFO:     127.0.0.1:43258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:33] INFO:     127.0.0.1:43266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:33 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:29:33 TP0] Decode batch. #running-req: 4, #token: 12854, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.16, #queue-req: 0, 
[2025-10-18 02:29:34 TP0] Decode batch. #running-req: 4, #token: 13014, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:29:35 TP0] Decode batch. #running-req: 4, #token: 13174, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:29:35 TP0] Decode batch. #running-req: 4, #token: 13334, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:29:36 TP0] Decode batch. #running-req: 4, #token: 13494, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:29:37 TP0] Decode batch. #running-req: 4, #token: 13654, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:38 TP0] Decode batch. #running-req: 4, #token: 13814, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:29:39 TP0] Decode batch. #running-req: 4, #token: 13974, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:29:40 TP0] Decode batch. #running-req: 4, #token: 14134, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:29:40 TP0] Decode batch. #running-req: 4, #token: 14294, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:29:41 TP0] Decode batch. #running-req: 4, #token: 14454, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:29:42 TP0] Decode batch. #running-req: 4, #token: 14614, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:29:43 TP0] Decode batch. #running-req: 4, #token: 14774, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:29:44 TP0] Decode batch. #running-req: 4, #token: 14934, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:29:45 TP0] Decode batch. #running-req: 4, #token: 15094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:29:45 TP0] Decode batch. #running-req: 4, #token: 15254, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:29:46 TP0] Decode batch. #running-req: 4, #token: 15414, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:29:47 TP0] Decode batch. #running-req: 4, #token: 15574, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:48 TP0] Decode batch. #running-req: 4, #token: 15734, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:29:49 TP0] Decode batch. #running-req: 4, #token: 15894, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:29:49] INFO:     127.0.0.1:58730 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:49] INFO:     127.0.0.1:58734 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:29:49] INFO:     127.0.0.1:58738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:49] INFO:     127.0.0.1:58750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:29:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:29:50 TP0] Decode batch. #running-req: 4, #token: 12852, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.21, #queue-req: 0, 
[2025-10-18 02:29:51 TP0] Decode batch. #running-req: 4, #token: 13012, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:29:51 TP0] Decode batch. #running-req: 4, #token: 13172, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:29:52 TP0] Decode batch. #running-req: 4, #token: 13332, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:29:53 TP0] Decode batch. #running-req: 4, #token: 13492, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:29:54 TP0] Decode batch. #running-req: 4, #token: 13652, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:29:55 TP0] Decode batch. #running-req: 4, #token: 13812, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:29:55 TP0] Decode batch. #running-req: 4, #token: 13972, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:29:56 TP0] Decode batch. #running-req: 4, #token: 14132, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:29:57 TP0] Decode batch. #running-req: 4, #token: 14292, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:29:58 TP0] Decode batch. #running-req: 4, #token: 14452, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:29:59 TP0] Decode batch. #running-req: 4, #token: 14612, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:30:00 TP0] Decode batch. #running-req: 4, #token: 14772, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:30:00 TP0] Decode batch. #running-req: 4, #token: 14932, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:30:01 TP0] Decode batch. #running-req: 4, #token: 15092, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:30:02 TP0] Decode batch. #running-req: 4, #token: 15252, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:30:03 TP0] Decode batch. #running-req: 4, #token: 15412, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:30:04 TP0] Decode batch. #running-req: 4, #token: 15572, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:30:05 TP0] Decode batch. #running-req: 4, #token: 15732, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:30:05 TP0] Decode batch. #running-req: 4, #token: 15892, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:30:06] INFO:     127.0.0.1:37910 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:30:21] INFO:     127.0.0.1:34072 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:30:27] INFO:     127.0.0.1:34182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:30:27 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 5.61, #queue-req: 0, 
[2025-10-18 02:30:28] INFO:     127.0.0.1:34192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:28] INFO:     127.0.0.1:34204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:30:28] INFO:     127.0.0.1:34214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:28] INFO:     127.0.0.1:34222 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:28 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:30:29 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 51.82, #queue-req: 0, 
[2025-10-18 02:30:30 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:30:31 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:30:31 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:30:32 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:30:33 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:30:34 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.29, #queue-req: 0, 
[2025-10-18 02:30:35 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:30:36 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:30:36 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:30:37 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:30:38 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:30:39 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:30:40 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:30:41 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:30:41 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:30:42 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:30:43 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:30:44 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:30:45 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:30:45] INFO:     127.0.0.1:57536 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:45] INFO:     127.0.0.1:57550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:45] INFO:     127.0.0.1:57562 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:45 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:30:45] INFO:     127.0.0.1:57566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:30:45 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:30:46 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.93, #queue-req: 0, 
[2025-10-18 02:30:46 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:30:47 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:30:48 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:30:49 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:30:50 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:30:51 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:30:51 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:30:52 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:30:53 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:30:54 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:30:55 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:30:56 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:30:56 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:30:57 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:30:58 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:30:59 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:31:00 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:31:01 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:01 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:02] INFO:     127.0.0.1:53926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:02] INFO:     127.0.0.1:53932 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:02] INFO:     127.0.0.1:53940 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:31:02] INFO:     127.0.0.1:53946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:31:02 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.95, #queue-req: 0, 
[2025-10-18 02:31:03 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:31:04 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:31:05 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:31:06 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:31:06 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:31:07 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:31:08 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:31:09 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:31:10 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:31:11 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:31:11 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:31:12 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:31:13 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:31:14 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:31:15 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:16 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:31:16 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:31:17 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:31:18 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:31:18] INFO:     127.0.0.1:39420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:18] INFO:     127.0.0.1:39422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:18] INFO:     127.0.0.1:39436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:18 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:31:18] INFO:     127.0.0.1:39450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:19 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:31:19 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.16, #queue-req: 0, 
[2025-10-18 02:31:20 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:31:21 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:31:22 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:31:22 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:31:23 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:31:24 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:31:25 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:31:26 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:31:26 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:31:27 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:31:28 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:29 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:31:30 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:31:31 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:31:31 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:31:32 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:31:33 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:31:34 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:35 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:31:35] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:35] INFO:     127.0.0.1:35974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:35] INFO:     127.0.0.1:35978 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:35 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:31:35] INFO:     127.0.0.1:35986 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:35 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:31:36 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.92, #queue-req: 0, 
[2025-10-18 02:31:37 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:31:37 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:31:38 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:31:39 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:31:40 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:31:41 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:31:42 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:31:42 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:31:43 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:31:44 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:31:45 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:31:46 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:31:46 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:31:47 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:31:48 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:31:49 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:31:50 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:31:51 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:31:51 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:31:52] INFO:     127.0.0.1:35316 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:52] INFO:     127.0.0.1:35330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:31:52] INFO:     127.0.0.1:35340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:52] INFO:     127.0.0.1:35352 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:31:52 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:31:52 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.11, #queue-req: 0, 
[2025-10-18 02:31:53 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:31:54 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:31:55 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:31:56 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:31:57 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:31:57 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:31:58 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:31:59 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:32:00 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:32:01 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:02 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:32:02 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:32:03 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:04 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:05 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:06 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:32:06 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:32:07 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:32:08 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:08] INFO:     127.0.0.1:56878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:09] INFO:     127.0.0.1:56894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:09] INFO:     127.0.0.1:56908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:32:09] INFO:     127.0.0.1:56916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:32:09 TP0] Decode batch. #running-req: 4, #token: 12884, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.24, #queue-req: 0, 
[2025-10-18 02:32:10 TP0] Decode batch. #running-req: 4, #token: 13044, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:32:11 TP0] Decode batch. #running-req: 4, #token: 13204, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:32:12 TP0] Decode batch. #running-req: 4, #token: 13364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:32:12 TP0] Decode batch. #running-req: 4, #token: 13524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:32:13 TP0] Decode batch. #running-req: 4, #token: 13684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:32:14 TP0] Decode batch. #running-req: 4, #token: 13844, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:32:15 TP0] Decode batch. #running-req: 4, #token: 14004, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:32:16 TP0] Decode batch. #running-req: 4, #token: 14164, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:32:17 TP0] Decode batch. #running-req: 4, #token: 14324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:32:17 TP0] Decode batch. #running-req: 4, #token: 14484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:18 TP0] Decode batch. #running-req: 4, #token: 14644, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:19 TP0] Decode batch. #running-req: 4, #token: 14804, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:20 TP0] Decode batch. #running-req: 4, #token: 14964, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:32:21 TP0] Decode batch. #running-req: 4, #token: 15124, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:22 TP0] Decode batch. #running-req: 4, #token: 15284, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:32:22 TP0] Decode batch. #running-req: 4, #token: 15444, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:32:23 TP0] Decode batch. #running-req: 4, #token: 15604, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:24 TP0] Decode batch. #running-req: 4, #token: 15764, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:25 TP0] Decode batch. #running-req: 4, #token: 15924, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:32:25] INFO:     127.0.0.1:60396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:25] INFO:     127.0.0.1:60400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:25] INFO:     127.0.0.1:60406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:25 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:32:25] INFO:     127.0.0.1:60410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:25 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:32:26 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.98, #queue-req: 0, 
[2025-10-18 02:32:27 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:32:27 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:32:28 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:32:29 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:32:30 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:31 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:32 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:32 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:33 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:34 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:35 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:36 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:37 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:32:37 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:38 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:39 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:32:40 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:32:41 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:32:42 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:42] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:42] INFO:     127.0.0.1:55586 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:42] INFO:     127.0.0.1:55588 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:32:42] INFO:     127.0.0.1:55596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:32:43 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.99, #queue-req: 0, 
[2025-10-18 02:32:43 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:32:44 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:32:45 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:32:46 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:32:47 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:32:47 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:48 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:49 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:50 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:32:51 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:32:52 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:32:52 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:32:53 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:32:54 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:32:55 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:32:56 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:32:57 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:32:57 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:32:58 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:32:59] INFO:     127.0.0.1:40332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:59] INFO:     127.0.0.1:40348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:59] INFO:     127.0.0.1:40350 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:32:59] INFO:     127.0.0.1:40360 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:32:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:32:59 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.06, #queue-req: 0, 
[2025-10-18 02:33:00 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:33:01 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:33:02 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:33:03 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:33:03 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:33:04 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:33:05 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:33:06 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:33:07 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:33:07 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:33:08 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:33:09 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:33:10 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:33:11 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:33:12 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:12 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:13 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:14 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:15 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:33:15] INFO:     127.0.0.1:56814 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:15] INFO:     127.0.0.1:56828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:15] INFO:     127.0.0.1:56836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:33:15] INFO:     127.0.0.1:56850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:33:16 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.06, #queue-req: 0, 
[2025-10-18 02:33:17 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:33:18 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:33:18 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:33:19 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:33:20 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:33:21 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:22 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:33:23 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:33:23 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:33:24 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:33:25 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:33:26 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:33:27 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:33:27 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:33:28 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:33:29 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:33:30 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:33:31 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:33:32 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:33:32] INFO:     127.0.0.1:52062 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:32] INFO:     127.0.0.1:52074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:32] INFO:     127.0.0.1:52084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:32 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:33:32] INFO:     127.0.0.1:52086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:32 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:33:33 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.18, #queue-req: 0, 
[2025-10-18 02:33:33 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.91, #queue-req: 0, 
[2025-10-18 02:33:34 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:33:35 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:33:36 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:33:37 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:33:38 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:33:38 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:33:39 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:33:40 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:33:41 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:33:42 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:33:43 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:33:43 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:33:44 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:45 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:46 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:47 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:33:47 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:33:48 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:33:49] INFO:     127.0.0.1:52758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:49] INFO:     127.0.0.1:52766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:49] INFO:     127.0.0.1:52782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:33:49] INFO:     127.0.0.1:52790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:33:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:33:49 TP0] Decode batch. #running-req: 4, #token: 12885, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.12, #queue-req: 0, 
[2025-10-18 02:33:50 TP0] Decode batch. #running-req: 4, #token: 13045, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:33:51 TP0] Decode batch. #running-req: 4, #token: 13205, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.95, #queue-req: 0, 
[2025-10-18 02:33:52 TP0] Decode batch. #running-req: 4, #token: 13365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:33:53 TP0] Decode batch. #running-req: 4, #token: 13525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:33:53 TP0] Decode batch. #running-req: 4, #token: 13685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:33:54 TP0] Decode batch. #running-req: 4, #token: 13845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:33:55 TP0] Decode batch. #running-req: 4, #token: 14005, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:33:56 TP0] Decode batch. #running-req: 4, #token: 14165, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:33:57 TP0] Decode batch. #running-req: 4, #token: 14325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:33:58 TP0] Decode batch. #running-req: 4, #token: 14485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:33:58 TP0] Decode batch. #running-req: 4, #token: 14645, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:33:59 TP0] Decode batch. #running-req: 4, #token: 14805, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:34:00 TP0] Decode batch. #running-req: 4, #token: 14965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:34:01 TP0] Decode batch. #running-req: 4, #token: 15125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:34:02 TP0] Decode batch. #running-req: 4, #token: 15285, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:34:03 TP0] Decode batch. #running-req: 4, #token: 15445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:03 TP0] Decode batch. #running-req: 4, #token: 15605, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:34:04 TP0] Decode batch. #running-req: 4, #token: 15765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:05 TP0] Decode batch. #running-req: 4, #token: 15925, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:34:05] INFO:     127.0.0.1:50602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:05] INFO:     127.0.0.1:50606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:05] INFO:     127.0.0.1:50612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:34:05] INFO:     127.0.0.1:50616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:34:06 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.10, #queue-req: 0, 
[2025-10-18 02:34:07 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 194.02, #queue-req: 0, 
[2025-10-18 02:34:08 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.99, #queue-req: 0, 
[2025-10-18 02:34:08 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.92, #queue-req: 0, 
[2025-10-18 02:34:09 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.91, #queue-req: 0, 
[2025-10-18 02:34:10 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.89, #queue-req: 0, 
[2025-10-18 02:34:11 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.89, #queue-req: 0, 
[2025-10-18 02:34:12 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:34:13 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.87, #queue-req: 0, 
[2025-10-18 02:34:13 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:34:14 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:34:15 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:34:16 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:34:17 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:34:18 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:34:18 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:34:19 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:34:20 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:34:21 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:34:22 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:34:22] INFO:     127.0.0.1:60686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:22] INFO:     127.0.0.1:60700 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:34:22] INFO:     127.0.0.1:60702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:22] INFO:     127.0.0.1:60718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:34:23 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.22, #queue-req: 0, 
[2025-10-18 02:34:23 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:34:24 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:34:25 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:34:26 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:27 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:34:28 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:28 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:34:29 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:34:30 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:34:31 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:34:32 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:34:33 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:33 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:34:34 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:35 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:34:36 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:34:37 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:34:38 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:34:38 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:34:39] INFO:     127.0.0.1:58186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:39] INFO:     127.0.0.1:58200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:39] INFO:     127.0.0.1:58212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:39 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:34:39] INFO:     127.0.0.1:58216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:39 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:34:39 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.07, #queue-req: 0, 
[2025-10-18 02:34:40 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:34:41 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:34:42 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:34:43 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:34:43 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:34:44 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:34:45 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:34:46 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:34:47 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:34:48 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:48 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:34:49 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:34:50 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:51 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:52 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:34:53 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:34:53 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:54 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:55 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:34:55] INFO:     127.0.0.1:52094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:55] INFO:     127.0.0.1:52106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:55] INFO:     127.0.0.1:52112 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:55 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:34:55] INFO:     127.0.0.1:52120 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:34:56 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:34:56 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.22, #queue-req: 0, 
[2025-10-18 02:34:57 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:34:58 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:34:59 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:34:59 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:35:00 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:35:01 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:35:02 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:35:03 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:03 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:35:04 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:05 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:35:06 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:07 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:35:08 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:35:08 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:09 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:10 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:35:11 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:35:12 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:35:12] INFO:     127.0.0.1:52500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:12] INFO:     127.0.0.1:52510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:12] INFO:     127.0.0.1:52526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:35:12] INFO:     127.0.0.1:52542 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:12 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:35:13 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.69, #queue-req: 0, 
[2025-10-18 02:35:14 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.90, #queue-req: 0, 
[2025-10-18 02:35:14 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:35:15 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:35:16 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:35:17 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:35:18 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:35:19 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:35:19 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:35:20 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:35:21 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:22 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:23 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:35:23 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:35:24 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:35:25 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:35:26 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:35:27 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:35:28 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:28 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:29] INFO:     127.0.0.1:54282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:29] INFO:     127.0.0.1:54290 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:29] INFO:     127.0.0.1:54296 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:35:29] INFO:     127.0.0.1:54312 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:29 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:35:29 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.06, #queue-req: 0, 
[2025-10-18 02:35:30 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:35:31 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:35:32 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:35:33 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:35:34 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:35:34 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:35:35 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:35:36 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:35:37 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:35:38 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:35:39 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:35:39 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:40 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:35:41 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:35:42 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:35:43 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:35:43 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:35:44 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:35:45 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:35:45] INFO:     127.0.0.1:36496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:46] INFO:     127.0.0.1:36510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:35:46] INFO:     127.0.0.1:36524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:46] INFO:     127.0.0.1:36526 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:35:46 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:35:46 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.34, #queue-req: 0, 
[2025-10-18 02:35:47 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:35:48 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:35:49 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:35:49 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:35:50 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:35:51 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:35:52 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:35:53 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:35:54 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:35:54 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:35:55 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:35:56 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:35:57 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:35:58 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:35:59 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:35:59 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:36:00 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:36:01 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:36:02 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:36:02] INFO:     127.0.0.1:34692 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:02] INFO:     127.0.0.1:34706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:36:02] INFO:     127.0.0.1:34714 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:02] INFO:     127.0.0.1:34716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:36:03 TP0] Decode batch. #running-req: 4, #token: 12885, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.09, #queue-req: 0, 
[2025-10-18 02:36:04 TP0] Decode batch. #running-req: 4, #token: 13045, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:36:04 TP0] Decode batch. #running-req: 4, #token: 13205, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.90, #queue-req: 0, 
[2025-10-18 02:36:05 TP0] Decode batch. #running-req: 4, #token: 13365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:36:06 TP0] Decode batch. #running-req: 4, #token: 13525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:36:07 TP0] Decode batch. #running-req: 4, #token: 13685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:36:08 TP0] Decode batch. #running-req: 4, #token: 13845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:36:09 TP0] Decode batch. #running-req: 4, #token: 14005, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:36:09 TP0] Decode batch. #running-req: 4, #token: 14165, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:36:10 TP0] Decode batch. #running-req: 4, #token: 14325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:36:11 TP0] Decode batch. #running-req: 4, #token: 14485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:36:12 TP0] Decode batch. #running-req: 4, #token: 14645, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:36:13 TP0] Decode batch. #running-req: 4, #token: 14805, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:14 TP0] Decode batch. #running-req: 4, #token: 14965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:36:14 TP0] Decode batch. #running-req: 4, #token: 15125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:15 TP0] Decode batch. #running-req: 4, #token: 15285, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:36:16 TP0] Decode batch. #running-req: 4, #token: 15445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:36:17 TP0] Decode batch. #running-req: 4, #token: 15605, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:36:18 TP0] Decode batch. #running-req: 4, #token: 15765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:36:19 TP0] Decode batch. #running-req: 4, #token: 15925, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:36:19] INFO:     127.0.0.1:55504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:19] INFO:     127.0.0.1:55520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:19] INFO:     127.0.0.1:55524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:36:19] INFO:     127.0.0.1:55530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:19 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:36:20 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.07, #queue-req: 0, 
[2025-10-18 02:36:20 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:36:21 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:36:22 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:36:23 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:36:24 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:36:24 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:36:25 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:26 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:36:27 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:36:28 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:29 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:36:29 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:36:30 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:36:31 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:36:32 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:36:33 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:36:34 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:36:34 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:36:35 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:36:36] INFO:     127.0.0.1:49058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:36] INFO:     127.0.0.1:49064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:36] INFO:     127.0.0.1:49072 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:36:36] INFO:     127.0.0.1:49074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:36:36 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.00, #queue-req: 0, 
[2025-10-18 02:36:37 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:36:38 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:36:39 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:36:40 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:36:40 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:36:41 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:36:42 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:36:43 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:36:44 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:36:44 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:45 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:36:46 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:36:47 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:36:48 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:36:49 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:36:49 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:36:50 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:36:51 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:36:52 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:36:52] INFO:     127.0.0.1:57238 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:52] INFO:     127.0.0.1:57250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:52] INFO:     127.0.0.1:57258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:36:52] INFO:     127.0.0.1:57272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:36:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:36:53 TP0] Decode batch. #running-req: 4, #token: 12885, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.19, #queue-req: 0, 
[2025-10-18 02:36:54 TP0] Decode batch. #running-req: 4, #token: 13045, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:36:55 TP0] Decode batch. #running-req: 4, #token: 13205, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:36:55 TP0] Decode batch. #running-req: 4, #token: 13365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:36:56 TP0] Decode batch. #running-req: 4, #token: 13525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:36:57 TP0] Decode batch. #running-req: 4, #token: 13685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:36:58 TP0] Decode batch. #running-req: 4, #token: 13845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:36:59 TP0] Decode batch. #running-req: 4, #token: 14005, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:36:59 TP0] Decode batch. #running-req: 4, #token: 14165, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:00 TP0] Decode batch. #running-req: 4, #token: 14325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:37:01 TP0] Decode batch. #running-req: 4, #token: 14485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:37:02 TP0] Decode batch. #running-req: 4, #token: 14645, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:03 TP0] Decode batch. #running-req: 4, #token: 14805, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:04 TP0] Decode batch. #running-req: 4, #token: 14965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:37:04 TP0] Decode batch. #running-req: 4, #token: 15125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:37:05 TP0] Decode batch. #running-req: 4, #token: 15285, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:06 TP0] Decode batch. #running-req: 4, #token: 15445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:37:07 TP0] Decode batch. #running-req: 4, #token: 15605, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:08 TP0] Decode batch. #running-req: 4, #token: 15765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:09 TP0] Decode batch. #running-req: 4, #token: 15925, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:09] INFO:     127.0.0.1:37480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:09] INFO:     127.0.0.1:37496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:09] INFO:     127.0.0.1:37500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:37:09] INFO:     127.0.0.1:37512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:09 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:37:10 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.28, #queue-req: 0, 
[2025-10-18 02:37:10 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:37:11 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:37:12 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:13 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:37:14 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:15 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:15 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:16 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:17 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:18 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:19 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:19 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:20 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:37:21 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:22 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:37:23 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:37:24 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:37:24 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:37:25 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:37:26] INFO:     127.0.0.1:49476 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:26] INFO:     127.0.0.1:49486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:26] INFO:     127.0.0.1:49502 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:26 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:37:26] INFO:     127.0.0.1:49504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:26 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:37:26 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.08, #queue-req: 0, 
[2025-10-18 02:37:27 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:37:28 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:37:29 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:37:30 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:37:30 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:37:31 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:37:32 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:37:33 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:37:34 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:37:35 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:37:35 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:36 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:37 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:37:38 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:37:39 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:37:39 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:37:40 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:37:41 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:37:42 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:37:42] INFO:     127.0.0.1:43590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:42] INFO:     127.0.0.1:43598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:42] INFO:     127.0.0.1:43608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:37:42] INFO:     127.0.0.1:43624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:42 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:37:43 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.26, #queue-req: 0, 
[2025-10-18 02:37:44 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:37:45 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:37:45 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:37:46 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:37:47 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:37:48 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:37:49 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:37:50 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:37:50 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:37:51 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:37:52 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:37:53 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:37:54 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:37:55 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:37:55 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:56 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:37:57 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:37:58 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:37:59 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:37:59] INFO:     127.0.0.1:42202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:59] INFO:     127.0.0.1:42208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:59] INFO:     127.0.0.1:42212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:37:59] INFO:     127.0.0.1:42226 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:37:59 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:38:00 TP0] Decode batch. #running-req: 4, #token: 12885, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.37, #queue-req: 0, 
[2025-10-18 02:38:00 TP0] Decode batch. #running-req: 4, #token: 13045, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:38:01 TP0] Decode batch. #running-req: 4, #token: 13205, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:38:02 TP0] Decode batch. #running-req: 4, #token: 13365, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:38:03 TP0] Decode batch. #running-req: 4, #token: 13525, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:38:04 TP0] Decode batch. #running-req: 4, #token: 13685, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:38:05 TP0] Decode batch. #running-req: 4, #token: 13845, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:38:05 TP0] Decode batch. #running-req: 4, #token: 14005, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:38:06 TP0] Decode batch. #running-req: 4, #token: 14165, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:07 TP0] Decode batch. #running-req: 4, #token: 14325, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:08 TP0] Decode batch. #running-req: 4, #token: 14485, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:38:09 TP0] Decode batch. #running-req: 4, #token: 14645, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:38:10 TP0] Decode batch. #running-req: 4, #token: 14805, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:38:10 TP0] Decode batch. #running-req: 4, #token: 14965, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:38:11 TP0] Decode batch. #running-req: 4, #token: 15125, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:12 TP0] Decode batch. #running-req: 4, #token: 15285, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:13 TP0] Decode batch. #running-req: 4, #token: 15445, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:38:14 TP0] Decode batch. #running-req: 4, #token: 15605, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:38:15 TP0] Decode batch. #running-req: 4, #token: 15765, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:15 TP0] Decode batch. #running-req: 4, #token: 15925, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:16] INFO:     127.0.0.1:48254 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:16] INFO:     127.0.0.1:48270 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:38:16] INFO:     127.0.0.1:48272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:16] INFO:     127.0.0.1:48286 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:16 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:38:16 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.26, #queue-req: 0, 
[2025-10-18 02:38:17 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:38:18 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:38:19 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:38:20 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:20 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:38:21 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:38:22 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:23 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:38:24 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:25 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:38:25 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:38:26 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:27 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:28 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:29 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:38:30 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:38:30 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:38:31 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:38:32 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:38:32] INFO:     127.0.0.1:57240 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:32] INFO:     127.0.0.1:57244 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:32] INFO:     127.0.0.1:57250 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:32 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:38:32] INFO:     127.0.0.1:57266 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:33 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:38:33 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.10, #queue-req: 0, 
[2025-10-18 02:38:34 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:38:35 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:38:36 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:36 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:38:37 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:38:38 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:38:39 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:38:40 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:38:40 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:41 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:38:42 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:38:43 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:44 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:38:45 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:38:45 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:38:46 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:38:47 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:38:48 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:38:49 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:38:49] INFO:     127.0.0.1:58390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:49] INFO:     127.0.0.1:58396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:38:49] INFO:     127.0.0.1:58410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:49] INFO:     127.0.0.1:58420 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:38:49 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:38:50 TP0] Decode batch. #running-req: 4, #token: 12886, token usage: 0.01, cuda graph: True, gen throughput (token/s): 158.60, #queue-req: 0, 
[2025-10-18 02:38:51 TP0] Decode batch. #running-req: 4, #token: 13046, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:38:51 TP0] Decode batch. #running-req: 4, #token: 13206, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:38:52 TP0] Decode batch. #running-req: 4, #token: 13366, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:38:53 TP0] Decode batch. #running-req: 4, #token: 13526, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:38:54 TP0] Decode batch. #running-req: 4, #token: 13686, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:38:55 TP0] Decode batch. #running-req: 4, #token: 13846, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:38:56 TP0] Decode batch. #running-req: 4, #token: 14006, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:38:56 TP0] Decode batch. #running-req: 4, #token: 14166, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:38:57 TP0] Decode batch. #running-req: 4, #token: 14326, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:38:58 TP0] Decode batch. #running-req: 4, #token: 14486, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:38:59 TP0] Decode batch. #running-req: 4, #token: 14646, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:39:00 TP0] Decode batch. #running-req: 4, #token: 14806, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:39:00 TP0] Decode batch. #running-req: 4, #token: 14966, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:01 TP0] Decode batch. #running-req: 4, #token: 15126, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:39:02 TP0] Decode batch. #running-req: 4, #token: 15286, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:39:03 TP0] Decode batch. #running-req: 4, #token: 15446, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:04 TP0] Decode batch. #running-req: 4, #token: 15606, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:05 TP0] Decode batch. #running-req: 4, #token: 15766, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:05 TP0] Decode batch. #running-req: 4, #token: 15926, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:39:06] INFO:     127.0.0.1:56924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:06] INFO:     127.0.0.1:56938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:39:06] INFO:     127.0.0.1:56954 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:06] INFO:     127.0.0.1:56958 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:39:06 TP0] Decode batch. #running-req: 4, #token: 12884, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.24, #queue-req: 0, 
[2025-10-18 02:39:07 TP0] Decode batch. #running-req: 4, #token: 13044, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:39:08 TP0] Decode batch. #running-req: 4, #token: 13204, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:39:09 TP0] Decode batch. #running-req: 4, #token: 13364, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:39:10 TP0] Decode batch. #running-req: 4, #token: 13524, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:39:11 TP0] Decode batch. #running-req: 4, #token: 13684, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:39:11 TP0] Decode batch. #running-req: 4, #token: 13844, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:39:12 TP0] Decode batch. #running-req: 4, #token: 14004, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:39:13 TP0] Decode batch. #running-req: 4, #token: 14164, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:39:14 TP0] Decode batch. #running-req: 4, #token: 14324, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:39:15 TP0] Decode batch. #running-req: 4, #token: 14484, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:39:16 TP0] Decode batch. #running-req: 4, #token: 14644, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:39:16 TP0] Decode batch. #running-req: 4, #token: 14804, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:39:17 TP0] Decode batch. #running-req: 4, #token: 14964, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:39:18 TP0] Decode batch. #running-req: 4, #token: 15124, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:19 TP0] Decode batch. #running-req: 4, #token: 15284, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:20 TP0] Decode batch. #running-req: 4, #token: 15444, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:20 TP0] Decode batch. #running-req: 4, #token: 15604, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:39:21 TP0] Decode batch. #running-req: 4, #token: 15764, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:39:22 TP0] Decode batch. #running-req: 4, #token: 15924, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:23] INFO:     127.0.0.1:58792 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:39:37] INFO:     127.0.0.1:39978 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:39:43] INFO:     127.0.0.1:39982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:39:44 TP0] Decode batch. #running-req: 1, #token: 3223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.51, #queue-req: 0, 
[2025-10-18 02:39:45] INFO:     127.0.0.1:37828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:45] INFO:     127.0.0.1:37836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:39:45] INFO:     127.0.0.1:37848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:45] INFO:     127.0.0.1:37852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:39:45 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:39:46 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 63.90, #queue-req: 0, 
[2025-10-18 02:39:46 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:47 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:39:48 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:49 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:39:50 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:39:51 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.51, #queue-req: 0, 
[2025-10-18 02:39:51 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 192.83, #queue-req: 0, 
[2025-10-18 02:39:52 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:39:53 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:39:54 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:39:55 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:39:56 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:39:56 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:39:57 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:39:58 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:39:59 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:40:00 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:40:00 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:40:01 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:40:02] INFO:     127.0.0.1:56498 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:02] INFO:     127.0.0.1:56504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:02] INFO:     127.0.0.1:56508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:40:02] INFO:     127.0.0.1:56524 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:02 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:40:02 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.89, #queue-req: 0, 
[2025-10-18 02:40:03 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:40:04 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:40:05 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:40:06 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:40:06 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:40:07 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:40:08 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:40:09 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:40:10 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:40:11 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:40:11 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:40:12 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:40:13 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:14 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:15 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:16 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:40:16 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:17 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:40:18 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:40:18] INFO:     127.0.0.1:34830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:18] INFO:     127.0.0.1:34842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:18] INFO:     127.0.0.1:34854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:18 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:40:18] INFO:     127.0.0.1:34860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:18 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:40:19 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.95, #queue-req: 0, 
[2025-10-18 02:40:20 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:40:21 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:40:21 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:40:22 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:40:23 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:40:24 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:40:25 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:40:26 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:40:26 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:40:27 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:40:28 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:40:29 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:30 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:31 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:40:31 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:40:32 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:33 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:34 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:35 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:40:35] INFO:     127.0.0.1:40436 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:35] INFO:     127.0.0.1:40446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:35] INFO:     127.0.0.1:40448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:35 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:40:35] INFO:     127.0.0.1:40462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:35 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:40:36 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.93, #queue-req: 0, 
[2025-10-18 02:40:37 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:40:37 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:40:38 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:40:39 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:40:40 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:40:41 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:40:41 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:40:42 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:40:43 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.49, #queue-req: 0, 
[2025-10-18 02:40:44 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:40:45 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:40:46 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:40:46 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:40:47 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:40:48 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:40:49 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:40:50 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:40:51 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:40:51 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:40:52] INFO:     127.0.0.1:42936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:52] INFO:     127.0.0.1:42948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:52] INFO:     127.0.0.1:42962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:40:52] INFO:     127.0.0.1:42964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:40:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:40:52 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.99, #queue-req: 0, 
[2025-10-18 02:40:53 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:40:54 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:40:55 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:40:56 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:40:57 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:40:57 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:40:58 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:40:59 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:41:00 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:41:01 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:41:01 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:41:02 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:41:03 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:41:04 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:41:05 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:41:06 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:06 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:41:07 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:41:08 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:41:08] INFO:     127.0.0.1:38074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:08] INFO:     127.0.0.1:38078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:41:08] INFO:     127.0.0.1:38094 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:08] INFO:     127.0.0.1:38106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:08 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:41:09 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.06, #queue-req: 0, 
[2025-10-18 02:41:10 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:41:11 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:41:12 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:41:12 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:41:13 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:41:14 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:41:15 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:41:16 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:41:17 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:41:17 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:41:18 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:41:19 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:41:20 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:21 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:21 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:22 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:41:23 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:41:24 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:25 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:25] INFO:     127.0.0.1:34446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:25] INFO:     127.0.0.1:34450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:25] INFO:     127.0.0.1:34464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:41:25] INFO:     127.0.0.1:34472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:25 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:41:26 TP0] Decode batch. #running-req: 4, #token: 12916, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.49, #queue-req: 0, 
[2025-10-18 02:41:27 TP0] Decode batch. #running-req: 4, #token: 13076, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:41:27 TP0] Decode batch. #running-req: 4, #token: 13236, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:41:28 TP0] Decode batch. #running-req: 4, #token: 13396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:41:29 TP0] Decode batch. #running-req: 4, #token: 13556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.33, #queue-req: 0, 
[2025-10-18 02:41:30 TP0] Decode batch. #running-req: 4, #token: 13716, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:41:31 TP0] Decode batch. #running-req: 4, #token: 13876, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:41:32 TP0] Decode batch. #running-req: 4, #token: 14036, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:32 TP0] Decode batch. #running-req: 4, #token: 14196, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:33 TP0] Decode batch. #running-req: 4, #token: 14356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:41:34 TP0] Decode batch. #running-req: 4, #token: 14516, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:41:35 TP0] Decode batch. #running-req: 4, #token: 14676, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:41:36 TP0] Decode batch. #running-req: 4, #token: 14836, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:41:37 TP0] Decode batch. #running-req: 4, #token: 14996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:41:37 TP0] Decode batch. #running-req: 4, #token: 15156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.51, #queue-req: 0, 
[2025-10-18 02:41:38 TP0] Decode batch. #running-req: 4, #token: 15316, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:41:39 TP0] Decode batch. #running-req: 4, #token: 15476, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:41:40 TP0] Decode batch. #running-req: 4, #token: 15636, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:41:41 TP0] Decode batch. #running-req: 4, #token: 15796, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:41:41 TP0] Decode batch. #running-req: 4, #token: 15956, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.53, #queue-req: 0, 
[2025-10-18 02:41:42] INFO:     127.0.0.1:56402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:42] INFO:     127.0.0.1:56418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:42] INFO:     127.0.0.1:56428 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:41:42] INFO:     127.0.0.1:56434 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:41:42 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.93, #queue-req: 0, 
[2025-10-18 02:41:43 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:41:44 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:41:45 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:41:46 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:41:47 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:41:47 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:41:48 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:49 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:41:50 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:41:51 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:41:52 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:41:52 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:41:53 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:41:54 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:55 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:41:56 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:41:57 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:41:57 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:41:58 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:41:58] INFO:     127.0.0.1:52806 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:58] INFO:     127.0.0.1:52820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:58] INFO:     127.0.0.1:52836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:41:58] INFO:     127.0.0.1:52846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:41:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:41:59 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.94, #queue-req: 0, 
[2025-10-18 02:42:00 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:42:01 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:42:02 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:42:02 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:42:03 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:42:04 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:05 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:06 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:42:07 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:42:07 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:42:08 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:42:09 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:10 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:11 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:12 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:42:12 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:13 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:14 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:42:15 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:15] INFO:     127.0.0.1:37516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:15] INFO:     127.0.0.1:37520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:15] INFO:     127.0.0.1:37528 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:42:15] INFO:     127.0.0.1:37530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:15 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:42:16 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.92, #queue-req: 0, 
[2025-10-18 02:42:17 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.91, #queue-req: 0, 
[2025-10-18 02:42:18 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:42:18 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:42:19 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:42:20 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:42:21 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:22 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:22 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:23 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:24 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:25 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:42:26 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:27 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:27 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:28 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:42:29 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:42:30 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:42:31 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:42:32 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:42:32] INFO:     127.0.0.1:45916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:32] INFO:     127.0.0.1:45920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:32] INFO:     127.0.0.1:45936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:42:32] INFO:     127.0.0.1:45950 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:42:33 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.22, #queue-req: 0, 
[2025-10-18 02:42:33 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:42:34 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:42:35 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:36 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:42:37 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:42:38 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:42:38 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:42:39 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:42:40 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:42:41 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:42:42 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:42:42 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:42:43 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:42:44 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:42:45 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:42:46 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:42:47 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:42:47 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:42:48 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:42:48] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:48] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:48] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:48 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:42:48] INFO:     127.0.0.1:53602 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:42:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:42:49 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.01, #queue-req: 0, 
[2025-10-18 02:42:50 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:42:51 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:42:52 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:42:53 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:42:53 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:42:54 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:42:55 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:42:56 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:42:57 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:42:57 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:42:58 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:42:59 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:43:00 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:43:01 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:43:02 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:43:02 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:03 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:43:04 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:43:05 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:43:05] INFO:     127.0.0.1:45844 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:05] INFO:     127.0.0.1:45848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:05] INFO:     127.0.0.1:45850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:43:05] INFO:     127.0.0.1:45866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:05 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:43:06 TP0] Decode batch. #running-req: 4, #token: 12917, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.95, #queue-req: 0, 
[2025-10-18 02:43:07 TP0] Decode batch. #running-req: 4, #token: 13077, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:43:08 TP0] Decode batch. #running-req: 4, #token: 13237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:43:08 TP0] Decode batch. #running-req: 4, #token: 13397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:43:09 TP0] Decode batch. #running-req: 4, #token: 13557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:43:10 TP0] Decode batch. #running-req: 4, #token: 13717, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:43:11 TP0] Decode batch. #running-req: 4, #token: 13877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:43:12 TP0] Decode batch. #running-req: 4, #token: 14037, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:43:13 TP0] Decode batch. #running-req: 4, #token: 14197, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:43:13 TP0] Decode batch. #running-req: 4, #token: 14357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:43:14 TP0] Decode batch. #running-req: 4, #token: 14517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:43:15 TP0] Decode batch. #running-req: 4, #token: 14677, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:43:16 TP0] Decode batch. #running-req: 4, #token: 14837, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:43:17 TP0] Decode batch. #running-req: 4, #token: 14997, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:43:17 TP0] Decode batch. #running-req: 4, #token: 15157, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:43:18 TP0] Decode batch. #running-req: 4, #token: 15317, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:43:19 TP0] Decode batch. #running-req: 4, #token: 15477, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:43:20 TP0] Decode batch. #running-req: 4, #token: 15637, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:43:21 TP0] Decode batch. #running-req: 4, #token: 15797, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:43:22 TP0] Decode batch. #running-req: 4, #token: 15957, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:22] INFO:     127.0.0.1:34516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:22] INFO:     127.0.0.1:34518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:22] INFO:     127.0.0.1:34530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:43:22] INFO:     127.0.0.1:34534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:43:23 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.04, #queue-req: 0, 
[2025-10-18 02:43:23 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 194.00, #queue-req: 0, 
[2025-10-18 02:43:24 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.96, #queue-req: 0, 
[2025-10-18 02:43:25 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.89, #queue-req: 0, 
[2025-10-18 02:43:26 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:43:27 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.88, #queue-req: 0, 
[2025-10-18 02:43:28 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:43:28 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:43:29 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:43:30 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:43:31 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:43:32 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:43:33 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:43:33 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:43:34 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:43:35 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:43:36 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.85, #queue-req: 0, 
[2025-10-18 02:43:37 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:43:37 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:43:38 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:43:39] INFO:     127.0.0.1:57788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:39] INFO:     127.0.0.1:57802 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:43:39] INFO:     127.0.0.1:57810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:39] INFO:     127.0.0.1:57824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:39 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:43:39 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.20, #queue-req: 0, 
[2025-10-18 02:43:40 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:43:41 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:43:42 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:43:43 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:43 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:44 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:45 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:43:46 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:47 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:48 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:43:48 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:49 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:43:50 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:43:51 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:43:52 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:43:53 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:43:53 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:43:54 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:43:55 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:43:55] INFO:     127.0.0.1:51440 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:55] INFO:     127.0.0.1:51456 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:55] INFO:     127.0.0.1:51464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:55 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:43:55] INFO:     127.0.0.1:51466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:43:55 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:43:56 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.83, #queue-req: 0, 
[2025-10-18 02:43:57 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:43:58 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:43:58 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:43:59 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:44:00 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:44:01 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:44:02 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:44:03 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:44:03 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:44:04 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:05 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:44:06 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:44:07 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:08 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:08 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:09 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:44:10 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:11 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:44:12 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:12] INFO:     127.0.0.1:54904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:12] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:12] INFO:     127.0.0.1:54922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:12 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:44:12] INFO:     127.0.0.1:54936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:12 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:44:13 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.96, #queue-req: 0, 
[2025-10-18 02:44:14 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.39, #queue-req: 0, 
[2025-10-18 02:44:14 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:44:15 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:44:16 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:44:17 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:44:18 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:44:18 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:44:19 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:44:20 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:44:21 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:44:22 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:23 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:23 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:24 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:25 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:26 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:27 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:28 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:28 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:44:29] INFO:     127.0.0.1:35044 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:29] INFO:     127.0.0.1:35060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:29] INFO:     127.0.0.1:35074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:44:29] INFO:     127.0.0.1:35080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:29 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:44:29 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.19, #queue-req: 0, 
[2025-10-18 02:44:30 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.89, #queue-req: 0, 
[2025-10-18 02:44:31 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:44:32 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:44:33 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:44:34 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:44:34 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:44:35 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:44:36 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:44:37 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:44:38 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:44:38 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:44:39 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:44:40 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:44:41 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:44:42 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:44:43 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:44:43 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:44:44 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:44:45 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:44:45] INFO:     127.0.0.1:40892 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:45] INFO:     127.0.0.1:40908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:45] INFO:     127.0.0.1:40910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:44:45] INFO:     127.0.0.1:40916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:44:45 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:44:46 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.91, #queue-req: 0, 
[2025-10-18 02:44:47 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:44:48 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:44:49 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:44:49 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:44:50 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:44:51 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:44:52 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:44:53 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:44:53 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:54 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:44:55 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:44:56 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:57 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.55, #queue-req: 0, 
[2025-10-18 02:44:58 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:58 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:44:59 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:45:00 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:45:01 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:45:02 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:45:02] INFO:     127.0.0.1:37164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:02] INFO:     127.0.0.1:37178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:45:02] INFO:     127.0.0.1:37186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:02] INFO:     127.0.0.1:37198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:02 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:45:03 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 159.37, #queue-req: 0, 
[2025-10-18 02:45:04 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:45:04 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:45:05 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:45:06 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:45:07 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:45:08 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:09 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:09 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:45:10 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:45:11 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:45:12 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:45:13 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:45:14 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:45:14 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:45:15 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:45:16 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:45:17 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.52, #queue-req: 0, 
[2025-10-18 02:45:18 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:45:18 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:45:19] INFO:     127.0.0.1:34308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:19] INFO:     127.0.0.1:34314 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:45:19] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:19] INFO:     127.0.0.1:34320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:19 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:45:19 TP0] Decode batch. #running-req: 4, #token: 12917, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.14, #queue-req: 0, 
[2025-10-18 02:45:20 TP0] Decode batch. #running-req: 4, #token: 13077, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:45:21 TP0] Decode batch. #running-req: 4, #token: 13237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:45:22 TP0] Decode batch. #running-req: 4, #token: 13397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.83, #queue-req: 0, 
[2025-10-18 02:45:23 TP0] Decode batch. #running-req: 4, #token: 13557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:45:24 TP0] Decode batch. #running-req: 4, #token: 13717, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:45:24 TP0] Decode batch. #running-req: 4, #token: 13877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.76, #queue-req: 0, 
[2025-10-18 02:45:25 TP0] Decode batch. #running-req: 4, #token: 14037, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:45:26 TP0] Decode batch. #running-req: 4, #token: 14197, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:45:27 TP0] Decode batch. #running-req: 4, #token: 14357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:45:28 TP0] Decode batch. #running-req: 4, #token: 14517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:45:29 TP0] Decode batch. #running-req: 4, #token: 14677, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:45:29 TP0] Decode batch. #running-req: 4, #token: 14837, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:45:30 TP0] Decode batch. #running-req: 4, #token: 14997, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:31 TP0] Decode batch. #running-req: 4, #token: 15157, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:45:32 TP0] Decode batch. #running-req: 4, #token: 15317, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:45:33 TP0] Decode batch. #running-req: 4, #token: 15477, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:45:33 TP0] Decode batch. #running-req: 4, #token: 15637, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:45:34 TP0] Decode batch. #running-req: 4, #token: 15797, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:45:35 TP0] Decode batch. #running-req: 4, #token: 15957, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:45:35] INFO:     127.0.0.1:45824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:35] INFO:     127.0.0.1:45826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:35] INFO:     127.0.0.1:45842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:45:35] INFO:     127.0.0.1:45854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:35 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:45:36 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.24, #queue-req: 0, 
[2025-10-18 02:45:37 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.79, #queue-req: 0, 
[2025-10-18 02:45:38 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:45:39 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:45:39 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:45:40 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:45:41 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:45:42 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:45:43 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:45:44 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:45:44 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:45 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:45:46 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.51, #queue-req: 0, 
[2025-10-18 02:45:47 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:45:48 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:45:49 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:45:49 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:50 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:45:51 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:45:52 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:45:52] INFO:     127.0.0.1:37192 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:52] INFO:     127.0.0.1:37204 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:52] INFO:     127.0.0.1:37214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:45:52] INFO:     127.0.0.1:37218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:45:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:45:53 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.06, #queue-req: 0, 
[2025-10-18 02:45:54 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:45:54 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:45:55 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:45:56 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:45:57 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:45:58 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:45:59 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:45:59 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:46:00 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:46:01 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:46:02 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:46:03 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:46:04 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:04 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:05 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:06 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:46:07 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:46:08 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:46:09 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:09] INFO:     127.0.0.1:33540 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:09] INFO:     127.0.0.1:33548 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:09] INFO:     127.0.0.1:33556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:46:09] INFO:     127.0.0.1:33572 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:09 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:46:10 TP0] Decode batch. #running-req: 4, #token: 12917, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.19, #queue-req: 0, 
[2025-10-18 02:46:10 TP0] Decode batch. #running-req: 4, #token: 13077, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.84, #queue-req: 0, 
[2025-10-18 02:46:11 TP0] Decode batch. #running-req: 4, #token: 13237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:46:12 TP0] Decode batch. #running-req: 4, #token: 13397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:46:13 TP0] Decode batch. #running-req: 4, #token: 13557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:46:14 TP0] Decode batch. #running-req: 4, #token: 13717, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:46:14 TP0] Decode batch. #running-req: 4, #token: 13877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:15 TP0] Decode batch. #running-req: 4, #token: 14037, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:16 TP0] Decode batch. #running-req: 4, #token: 14197, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:46:17 TP0] Decode batch. #running-req: 4, #token: 14357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:46:18 TP0] Decode batch. #running-req: 4, #token: 14517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:46:19 TP0] Decode batch. #running-req: 4, #token: 14677, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:19 TP0] Decode batch. #running-req: 4, #token: 14837, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:46:20 TP0] Decode batch. #running-req: 4, #token: 14997, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:46:21 TP0] Decode batch. #running-req: 4, #token: 15157, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:46:22 TP0] Decode batch. #running-req: 4, #token: 15317, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:46:23 TP0] Decode batch. #running-req: 4, #token: 15477, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:46:24 TP0] Decode batch. #running-req: 4, #token: 15637, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:46:24 TP0] Decode batch. #running-req: 4, #token: 15797, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.29, #queue-req: 0, 
[2025-10-18 02:46:25 TP0] Decode batch. #running-req: 4, #token: 15957, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:25] INFO:     127.0.0.1:33698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:25] INFO:     127.0.0.1:33706 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:25] INFO:     127.0.0.1:33716 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:46:25] INFO:     127.0.0.1:33720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:26 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:46:26 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.15, #queue-req: 0, 
[2025-10-18 02:46:27 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:46:28 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:46:29 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:46:30 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:30 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:46:31 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:46:32 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:33 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:46:34 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:34 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:35 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:46:36 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:46:37 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:46:38 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:46:39 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:46:39 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:46:40 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.52, #queue-req: 0, 
[2025-10-18 02:46:41 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:46:42 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.52, #queue-req: 0, 
[2025-10-18 02:46:42] INFO:     127.0.0.1:47066 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:42] INFO:     127.0.0.1:47068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:42] INFO:     127.0.0.1:47076 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:46:42] INFO:     127.0.0.1:47086 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:42 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:46:43 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.05, #queue-req: 0, 
[2025-10-18 02:46:44 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:46:45 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:46:45 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:46:46 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:47 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:46:48 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:46:49 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:46:50 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:50 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:46:51 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:52 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:53 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:46:54 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:46:54 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:55 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:46:56 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:46:57 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.26, #queue-req: 0, 
[2025-10-18 02:46:58 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:46:59 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:46:59] INFO:     127.0.0.1:60922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:59] INFO:     127.0.0.1:60924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:59] INFO:     127.0.0.1:60928 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:46:59] INFO:     127.0.0.1:60942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:46:59 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:47:00 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.18, #queue-req: 0, 
[2025-10-18 02:47:00 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.74, #queue-req: 0, 
[2025-10-18 02:47:01 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:47:02 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:47:03 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:47:04 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:47:05 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:47:05 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:47:06 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:47:07 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:08 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:47:09 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:47:10 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:10 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:47:11 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:12 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:47:13 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:47:14 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:47:14 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:47:15 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:47:16] INFO:     127.0.0.1:53854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:16] INFO:     127.0.0.1:53862 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:16] INFO:     127.0.0.1:53868 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:47:16] INFO:     127.0.0.1:53882 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:16 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:47:16 TP0] Decode batch. #running-req: 4, #token: 12917, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.21, #queue-req: 0, 
[2025-10-18 02:47:17 TP0] Decode batch. #running-req: 4, #token: 13077, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-10-18 02:47:18 TP0] Decode batch. #running-req: 4, #token: 13237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.82, #queue-req: 0, 
[2025-10-18 02:47:19 TP0] Decode batch. #running-req: 4, #token: 13397, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.81, #queue-req: 0, 
[2025-10-18 02:47:20 TP0] Decode batch. #running-req: 4, #token: 13557, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:47:20 TP0] Decode batch. #running-req: 4, #token: 13717, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:47:21 TP0] Decode batch. #running-req: 4, #token: 13877, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.75, #queue-req: 0, 
[2025-10-18 02:47:22 TP0] Decode batch. #running-req: 4, #token: 14037, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:47:23 TP0] Decode batch. #running-req: 4, #token: 14197, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:47:24 TP0] Decode batch. #running-req: 4, #token: 14357, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:47:25 TP0] Decode batch. #running-req: 4, #token: 14517, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:47:25 TP0] Decode batch. #running-req: 4, #token: 14677, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:47:26 TP0] Decode batch. #running-req: 4, #token: 14837, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:47:27 TP0] Decode batch. #running-req: 4, #token: 14997, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:47:28 TP0] Decode batch. #running-req: 4, #token: 15157, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:47:29 TP0] Decode batch. #running-req: 4, #token: 15317, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:30 TP0] Decode batch. #running-req: 4, #token: 15477, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.31, #queue-req: 0, 
[2025-10-18 02:47:30 TP0] Decode batch. #running-req: 4, #token: 15637, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:31 TP0] Decode batch. #running-req: 4, #token: 15797, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:32 TP0] Decode batch. #running-req: 4, #token: 15957, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:32] INFO:     127.0.0.1:53826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:32] INFO:     127.0.0.1:53830 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:47:32] INFO:     127.0.0.1:53836 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:32] INFO:     127.0.0.1:53842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:32 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:47:33 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 160.82, #queue-req: 0, 
[2025-10-18 02:47:34 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:47:35 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:47:35 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:47:36 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:47:37 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:47:38 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:47:39 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:47:40 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:40 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:41 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:47:42 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:43 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:44 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:47:45 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:47:45 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:47:46 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:47:47 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.57, #queue-req: 0, 
[2025-10-18 02:47:48 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:47:49 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:47:49] INFO:     127.0.0.1:59930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:49] INFO:     127.0.0.1:59944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:49] INFO:     127.0.0.1:59956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:47:49] INFO:     127.0.0.1:59972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:47:49 TP0] Prefill batch. #new-seq: 2, #new-token: 2, #cached-token: 6400, token usage: 0.01, #running-req: 2, #queue-req: 0, 
[2025-10-18 02:47:50 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.03, #queue-req: 0, 
[2025-10-18 02:47:51 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:47:51 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.68, #queue-req: 0, 
[2025-10-18 02:47:52 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:47:53 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:47:54 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:47:55 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:47:55 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:47:56 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:47:57 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:47:58 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:47:59 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.61, #queue-req: 0, 
[2025-10-18 02:48:00 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:48:00 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.59, #queue-req: 0, 
[2025-10-18 02:48:01 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:48:02 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:48:03 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.23, #queue-req: 0, 
[2025-10-18 02:48:04 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.54, #queue-req: 0, 
[2025-10-18 02:48:05 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.56, #queue-req: 0, 
[2025-10-18 02:48:05 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.58, #queue-req: 0, 
[2025-10-18 02:48:06] INFO:     127.0.0.1:53590 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:06] INFO:     127.0.0.1:53598 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:48:06] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:06] INFO:     127.0.0.1:53612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:06 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:48:06 TP0] Decode batch. #running-req: 4, #token: 12918, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.20, #queue-req: 0, 
[2025-10-18 02:48:07 TP0] Decode batch. #running-req: 4, #token: 13078, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:48:08 TP0] Decode batch. #running-req: 4, #token: 13238, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.80, #queue-req: 0, 
[2025-10-18 02:48:09 TP0] Decode batch. #running-req: 4, #token: 13398, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:48:10 TP0] Decode batch. #running-req: 4, #token: 13558, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.77, #queue-req: 0, 
[2025-10-18 02:48:11 TP0] Decode batch. #running-req: 4, #token: 13718, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:48:11 TP0] Decode batch. #running-req: 4, #token: 13878, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.70, #queue-req: 0, 
[2025-10-18 02:48:12 TP0] Decode batch. #running-req: 4, #token: 14038, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.69, #queue-req: 0, 
[2025-10-18 02:48:13 TP0] Decode batch. #running-req: 4, #token: 14198, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:48:14 TP0] Decode batch. #running-req: 4, #token: 14358, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:48:15 TP0] Decode batch. #running-req: 4, #token: 14518, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:15 TP0] Decode batch. #running-req: 4, #token: 14678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:48:16 TP0] Decode batch. #running-req: 4, #token: 14838, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:48:17 TP0] Decode batch. #running-req: 4, #token: 14998, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:18 TP0] Decode batch. #running-req: 4, #token: 15158, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.65, #queue-req: 0, 
[2025-10-18 02:48:19 TP0] Decode batch. #running-req: 4, #token: 15318, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:48:20 TP0] Decode batch. #running-req: 4, #token: 15478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:20 TP0] Decode batch. #running-req: 4, #token: 15638, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:21 TP0] Decode batch. #running-req: 4, #token: 15798, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:48:22 TP0] Decode batch. #running-req: 4, #token: 15958, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:48:22] INFO:     127.0.0.1:46952 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:22] INFO:     127.0.0.1:46966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:48:22] INFO:     127.0.0.1:46982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:22] INFO:     127.0.0.1:46984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:48:22 TP0] Prefill batch. #new-seq: 3, #new-token: 3, #cached-token: 9600, token usage: 0.01, #running-req: 1, #queue-req: 0, 
[2025-10-18 02:48:23 TP0] Decode batch. #running-req: 4, #token: 12916, token usage: 0.01, cuda graph: True, gen throughput (token/s): 161.19, #queue-req: 0, 
[2025-10-18 02:48:24 TP0] Decode batch. #running-req: 4, #token: 13076, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.78, #queue-req: 0, 
[2025-10-18 02:48:25 TP0] Decode batch. #running-req: 4, #token: 13236, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:48:26 TP0] Decode batch. #running-req: 4, #token: 13396, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.72, #queue-req: 0, 
[2025-10-18 02:48:26 TP0] Decode batch. #running-req: 4, #token: 13556, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-10-18 02:48:27 TP0] Decode batch. #running-req: 4, #token: 13716, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.71, #queue-req: 0, 
[2025-10-18 02:48:28 TP0] Decode batch. #running-req: 4, #token: 13876, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:48:29 TP0] Decode batch. #running-req: 4, #token: 14036, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:48:30 TP0] Decode batch. #running-req: 4, #token: 14196, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:48:31 TP0] Decode batch. #running-req: 4, #token: 14356, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:48:31 TP0] Decode batch. #running-req: 4, #token: 14516, token usage: 0.01, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:48:32 TP0] Decode batch. #running-req: 4, #token: 14676, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-10-18 02:48:33 TP0] Decode batch. #running-req: 4, #token: 14836, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.66, #queue-req: 0, 
[2025-10-18 02:48:34 TP0] Decode batch. #running-req: 4, #token: 14996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.64, #queue-req: 0, 
[2025-10-18 02:48:35 TP0] Decode batch. #running-req: 4, #token: 15156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:35 TP0] Decode batch. #running-req: 4, #token: 15316, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.26, #queue-req: 0, 
[2025-10-18 02:48:36 TP0] Decode batch. #running-req: 4, #token: 15476, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:48:37 TP0] Decode batch. #running-req: 4, #token: 15636, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.60, #queue-req: 0, 
[2025-10-18 02:48:38 TP0] Decode batch. #running-req: 4, #token: 15796, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.62, #queue-req: 0, 
[2025-10-18 02:48:39 TP0] Decode batch. #running-req: 4, #token: 15956, token usage: 0.02, cuda graph: True, gen throughput (token/s): 193.63, #queue-req: 0, 
[2025-10-18 02:48:39] INFO:     127.0.0.1:51100 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 02:48:57] INFO:     127.0.0.1:40802 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 02:49:03] INFO:     127.0.0.1:40816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:49:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:49:04 TP0] Decode batch. #running-req: 1, #token: 3231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2.94, #queue-req: 0, 
[2025-10-18 02:49:05] INFO:     127.0.0.1:51424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:49:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:49:06 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.08, #queue-req: 0, 
[2025-10-18 02:49:06 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:49:07 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:49:08 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.64, #queue-req: 0, 
[2025-10-18 02:49:09 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:10 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:49:10 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:11 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:12 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:13 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:14 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:15 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:15 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:16 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:17 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:18 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:19 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:19 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:20 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:21 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:21] INFO:     127.0.0.1:44906 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:49:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:49:22 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:49:23 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:49:24 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:49:24 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:49:25 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:49:26 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:49:27 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:28 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:49:29 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:29 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:30 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:31 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:32 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:33 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:33 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:34 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:35 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:36 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:37 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:38 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:38] INFO:     127.0.0.1:55798 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:49:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:49:38 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:49:39 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:49:40 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:49:41 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.69, #queue-req: 0, 
[2025-10-18 02:49:42 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:43 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:49:43 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:49:44 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:45 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:49:46 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:47 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:47 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:48 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:49 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:49:50 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:51 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:52 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:52 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:53 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:54 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:49:54] INFO:     127.0.0.1:34490 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:49:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:49:55 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 02:49:56 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:49:57 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:49:57 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:49:58 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:49:59 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:00 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:01 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:02 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:02 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:03 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:50:04 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:05 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:06 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:50:06 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:50:07 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:08 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:50:09 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:10 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:50:11 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:11] INFO:     127.0.0.1:36962 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:50:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:50:11 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:50:12 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:50:13 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:50:14 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:50:15 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:50:16 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:50:16 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:17 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:18 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:19 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:20 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:20 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:21 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:22 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:23 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:24 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:25 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:25 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:26 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:27 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:27] INFO:     127.0.0.1:59842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:50:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:50:28 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 02:50:29 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:30 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:30 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:31 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:32 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:33 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:34 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:34 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:35 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:36 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:37 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:38 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:39 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:39 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:40 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:41 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:42 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:43 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:44 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:50:44] INFO:     127.0.0.1:42484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:50:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:50:44 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:50:45 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:50:46 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:50:47 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:48 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:50:49 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:50:49 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:50 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:50:51 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:52 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:50:53 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:53 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:54 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:55 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:56 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:50:57 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:50:58 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:58 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:50:59 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:00 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:51:00] INFO:     127.0.0.1:44786 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:51:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:51:01 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 02:51:02 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:51:03 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:51:03 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:04 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:51:05 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:06 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:07 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:07 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:08 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:09 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:10 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:11 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:12 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:12 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:13 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:14 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:15 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:16 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:16 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:17] INFO:     127.0.0.1:44666 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:51:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:51:17 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.37, #queue-req: 0, 
[2025-10-18 02:51:18 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:19 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:20 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:21 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:21 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:22 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:23 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:24 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:25 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:26 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:26 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:27 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:28 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:51:29 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:30 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:30 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:51:31 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:32 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:33 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:51:33] INFO:     127.0.0.1:50442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:51:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:51:34 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:51:35 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:51:35 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:51:36 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:37 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:38 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:39 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:40 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:40 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:41 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:51:42 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:43 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:44 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:45 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:45 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:46 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:47 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:48 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:49 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:51:49 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:49] INFO:     127.0.0.1:60098 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:51:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:51:50 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:51:51 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:52 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:51:53 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:54 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:51:54 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:51:55 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:56 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:57 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:58 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:51:59 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:51:59 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:00 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:01 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:02 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:03 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:03 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:04 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:05 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:06 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:52:06] INFO:     127.0.0.1:57560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:52:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:52:07 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 02:52:08 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 02:52:08 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:52:09 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:52:10 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:52:11 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:52:12 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:52:13 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:13 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:14 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:15 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:16 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:17 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:17 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:18 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:19 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:20 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:21 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:22 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:22 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:22] INFO:     127.0.0.1:59288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:52:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:52:23 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 02:52:24 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:52:25 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:52:26 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:52:27 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:27 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:28 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:29 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:30 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:31 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:31 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:32 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:33 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:34 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:35 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:36 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:36 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:37 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:38 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:39 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:39] INFO:     127.0.0.1:39810 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:52:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:52:40 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:52:41 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:52:41 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:52:42 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:52:43 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:52:44 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:52:45 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:46 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:52:46 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:47 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:48 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:49 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:50 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:50 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:51 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:52 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:52:53 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:52:54 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:55 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:55 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:52:55] INFO:     127.0.0.1:43382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:52:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:52:56 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:52:57 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:52:58 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:52:59 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:53:00 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:00 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:01 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:02 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:03 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:04 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:04 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:53:05 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:53:06 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:07 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:53:08 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:53:09 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:09 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:53:10 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:53:11 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:53:12 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:53:12] INFO:     127.0.0.1:42410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:53:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:53:13 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:53:14 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:53:14 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:53:15 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:53:16 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:53:17 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:18 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:18 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:19 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:20 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:21 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:22 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:23 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:23 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:24 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:25 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:26 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:53:27 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:28 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:28 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:53:28] INFO:     127.0.0.1:54330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:53:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:53:29 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:53:30 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:53:31 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:53:32 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:53:33 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:53:33 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:53:34 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:35 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:36 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:37 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:37 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:38 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:39 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:40 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:41 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:42 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:42 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:43 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:44 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:45 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:45] INFO:     127.0.0.1:60318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:53:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:53:46 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:53:47 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:53:47 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 02:53:48 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:53:49 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:53:50 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:53:51 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:51 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:53:52 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:53 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:54 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:55 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:56 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:53:56 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:53:57 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:53:58 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:53:59 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:00 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:00 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:01 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:01] INFO:     127.0.0.1:39620 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:54:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:54:02 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 02:54:03 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 02:54:04 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:54:05 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:54:05 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:54:06 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:54:07 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:54:08 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:09 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:10 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:10 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:11 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:12 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:13 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:14 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:14 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:15 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:16 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:17 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:18 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:18] INFO:     127.0.0.1:39824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:54:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:54:19 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 02:54:19 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:54:20 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:54:21 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:22 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:54:23 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:24 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:54:24 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:25 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:26 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:27 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:28 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:29 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:29 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:30 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:31 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:32 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:33 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:33 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:34 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:34] INFO:     127.0.0.1:41048 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:54:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:54:35 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 02:54:36 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:37 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:54:38 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:38 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:39 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:40 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:41 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:42 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:43 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:43 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:44 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:45 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:46 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:47 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:47 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:48 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:49 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:54:50 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:54:51 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:54:51] INFO:     127.0.0.1:59200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:54:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:54:52 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 02:54:52 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:54:53 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:54:54 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:54:55 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:54:56 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:54:57 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:54:57 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:58 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:54:59 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:00 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:01 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:01 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:02 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:03 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:04 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:05 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:06 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:06 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:07 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:07] INFO:     127.0.0.1:43002 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:55:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:55:08 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:55:09 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:10 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:55:11 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:11 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:55:12 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:55:13 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:14 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:15 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:16 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:16 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:17 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:18 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:19 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:20 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:20 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:21 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:22 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:23 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:24 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:24] INFO:     127.0.0.1:57358 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:55:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:55:25 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 02:55:25 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:55:26 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:55:27 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:55:28 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:55:29 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:55:30 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:30 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:31 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:32 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:33 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:55:34 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:34 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:35 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:36 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:37 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:38 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:39 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:39 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:40 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:55:40] INFO:     127.0.0.1:42894 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:55:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:55:41 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 02:55:42 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:55:43 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:55:44 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:44 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:55:45 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:46 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:47 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:48 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:48 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:49 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:50 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:55:51 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:55:52 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:55:53 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:55:53 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:54 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:55:55 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:56 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:55:57 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:55:57] INFO:     127.0.0.1:38414 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:55:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:55:58 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 02:55:58 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:55:59 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:00 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:01 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:02 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:03 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:03 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:04 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:05 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:06 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:07 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:07 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:08 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:09 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:10 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:11 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:12 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:12 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:56:13 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:56:13] INFO:     127.0.0.1:37060 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:56:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:56:14 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 02:56:15 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:16 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:17 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:17 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:18 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:19 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:20 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:21 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:21 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:22 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:23 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:24 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:25 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:26 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:26 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:27 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:28 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:29 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:30 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:30] INFO:     127.0.0.1:35068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:56:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:56:31 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 02:56:31 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:56:32 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:56:33 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:34 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:35 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:35 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:36 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:37 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:38 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:39 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:40 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:40 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:41 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:42 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:56:43 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:44 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:44 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:45 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:46 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:46] INFO:     127.0.0.1:52000 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:56:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:56:47 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 02:56:48 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:56:49 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:50 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:50 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:51 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:56:52 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:56:53 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:54 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:54 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:56:55 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:56 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:57 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:56:58 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:59 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:56:59 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:00 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:01 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:02 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:03 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:03] INFO:     127.0.0.1:33512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:57:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:57:04 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 02:57:04 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:57:05 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:57:06 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:57:07 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:57:08 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:57:08 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:09 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:10 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:57:11 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:12 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:13 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:13 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:14 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:15 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:16 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:17 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:17 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:18 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:19 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:19] INFO:     127.0.0.1:56058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:57:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:57:20 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 02:57:21 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:57:22 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:57:22 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:57:23 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:57:24 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:57:25 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:57:26 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:57:27 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:27 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:57:28 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:29 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:30 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:31 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:31 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:32 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:33 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:34 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:35 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:36 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:36] INFO:     127.0.0.1:39074 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:57:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:57:36 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 02:57:37 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:38 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:39 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:40 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:41 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:41 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:42 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:43 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:44 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:57:45 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:46 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:46 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:47 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:57:48 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:57:49 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:57:50 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:50 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:57:51 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:57:52 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 02:57:52] INFO:     127.0.0.1:40676 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:57:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:57:53 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 02:57:54 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:57:55 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:57:55 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:57:56 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:57:57 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:58 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:57:59 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:00 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:00 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:01 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:02 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:03 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:04 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:04 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:05 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:06 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:07 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:08 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:58:09 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:09] INFO:     127.0.0.1:42122 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:58:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:58:09 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 02:58:10 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:58:11 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:58:12 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:13 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:58:14 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:14 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:58:15 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:16 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:17 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:18 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:18 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:19 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:20 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:21 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:22 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:23 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:23 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:24 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:58:25 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 02:58:25] INFO:     127.0.0.1:35552 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:58:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:58:26 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 02:58:27 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:58:28 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:58:28 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:29 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:58:30 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:58:31 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:32 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:58:33 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:33 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:34 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:35 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:36 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:37 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:37 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:38 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:39 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:40 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:41 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:42 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:42] INFO:     127.0.0.1:43826 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:58:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:58:42 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 02:58:43 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:44 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:58:45 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:46 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:47 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:47 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:48 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:49 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:50 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:51 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:51 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:52 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:53 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:54 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:58:55 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:56 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:56 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:58:57 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 02:58:58 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:58:58] INFO:     127.0.0.1:40104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:58:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:58:59 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 02:59:00 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 02:59:01 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:59:01 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:59:02 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:59:03 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:59:04 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:05 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:05 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:06 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:07 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:08 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:09 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:10 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:10 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:11 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:12 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:13 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:14 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:14 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:15] INFO:     127.0.0.1:53824 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:59:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:59:15 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.12, #queue-req: 0, 
[2025-10-18 02:59:16 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:59:17 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:18 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:59:19 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:19 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:20 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:21 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:22 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:23 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:24 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:24 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:25 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:26 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:27 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:28 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:29 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:29 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:30 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:31 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:31] INFO:     127.0.0.1:35442 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:59:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:59:32 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 02:59:33 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:59:34 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:59:34 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:35 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:59:36 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:37 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:38 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:38 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:39 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:40 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:41 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:59:42 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:43 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 02:59:43 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:44 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 02:59:45 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:59:46 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:59:47 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:59:47 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 02:59:47] INFO:     127.0.0.1:52052 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 02:59:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 02:59:48 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.87, #queue-req: 0, 
[2025-10-18 02:59:49 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 02:59:50 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 02:59:51 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 02:59:52 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 02:59:52 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 02:59:53 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:54 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:55 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 02:59:56 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:57 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 02:59:57 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:58 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 02:59:59 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:00 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:01 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:01 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:02 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:03 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:04 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:04] INFO:     127.0.0.1:59864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:00:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:00:05 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:00:06 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:00:06 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:00:07 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:00:08 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:00:09 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:00:10 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:11 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:11 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:12 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:13 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:14 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:15 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:15 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:16 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:17 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:18 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:19 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:00:20 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:20 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:20] INFO:     127.0.0.1:34974 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:00:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:00:21 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.39, #queue-req: 0, 
[2025-10-18 03:00:22 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:00:23 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:00:24 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:00:25 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:00:25 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:26 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:27 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:28 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:29 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:30 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:30 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:31 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:32 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:33 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:34 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:34 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:35 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:36 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:37 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:37] INFO:     127.0.0.1:43680 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:00:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:00:38 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:00:39 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:00:39 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:00:40 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:00:41 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:00:42 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:43 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:44 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:44 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:45 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:46 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:00:47 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:48 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:48 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:00:49 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:50 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:51 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:52 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:53 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:00:53 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:53] INFO:     127.0.0.1:45972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:00:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:00:54 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:00:55 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:56 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:00:57 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:00:58 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:00:58 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:00:59 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:00 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:01:01 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:02 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:02 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:01:03 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:04 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:01:05 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:01:06 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:07 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:01:07 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:01:08 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:01:09 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:01:10 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:01:10] INFO:     127.0.0.1:47380 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:01:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:01:11 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:01:12 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:01:12 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:01:13 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:01:14 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:15 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:16 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:17 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:17 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:01:18 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:19 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:20 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:21 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:01:21 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:22 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:23 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:24 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:25 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:26 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:26 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:26] INFO:     127.0.0.1:44936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:01:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:01:27 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.39, #queue-req: 0, 
[2025-10-18 03:01:28 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:01:29 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:01:30 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:01:31 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:01:31 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:32 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:33 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:34 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:35 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:35 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:36 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:37 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:38 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:39 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:40 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:40 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:41 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:01:42 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.67, #queue-req: 0, 
[2025-10-18 03:01:43 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:01:43] INFO:     127.0.0.1:45638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:01:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:01:44 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:01:45 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:01:45 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:01:46 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:01:47 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:01:48 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:01:49 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:49 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:01:50 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:51 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:52 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:01:53 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:01:54 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:54 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:55 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:56 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:57 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:01:58 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:58 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:01:59 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:01:59] INFO:     127.0.0.1:50154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:01:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:02:00 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:02:01 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:02 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:03 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:03 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:04 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:05 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:06 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:07 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:08 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:08 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:09 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:10 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:11 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:12 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:13 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:02:13 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:14 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:15 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:16 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:02:16] INFO:     127.0.0.1:44918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:02:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:02:17 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.04, #queue-req: 0, 
[2025-10-18 03:02:18 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:02:18 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:19 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:20 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:21 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:22 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:22 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:23 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:24 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:25 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:26 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:27 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:27 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:28 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:29 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:30 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:31 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:31 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:02:32 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:02:32] INFO:     127.0.0.1:36292 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:02:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:02:33 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.37, #queue-req: 0, 
[2025-10-18 03:02:34 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:02:35 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:02:36 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:36 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:37 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:38 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:39 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:40 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:41 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:41 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:42 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:43 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:44 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:02:45 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:45 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:46 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:47 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:48 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:49 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:02:49] INFO:     127.0.0.1:34398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:02:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:02:50 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:02:50 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:02:51 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:52 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:53 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:02:54 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:55 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:55 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:02:56 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:57 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:58 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:02:59 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:02:59 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:00 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:01 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:02 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:03 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:04 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:04 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:05 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:05] INFO:     127.0.0.1:44410 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:03:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:03:06 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:03:07 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:03:08 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:03:09 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:09 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:10 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:03:11 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:12 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:13 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:14 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:14 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:15 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:16 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:17 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:18 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:18 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:19 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:20 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:21 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:22 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:22] INFO:     127.0.0.1:43444 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:03:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:03:23 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:03:23 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:03:24 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:03:25 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:03:26 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:03:27 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:03:28 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:28 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:03:29 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:30 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:31 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:32 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:32 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:33 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:34 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:35 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:36 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:37 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:37 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:38 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:03:38] INFO:     127.0.0.1:33874 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:03:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:03:39 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:03:40 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:03:41 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:03:42 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:42 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:43 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:03:44 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:45 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:03:46 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:46 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:47 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:48 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:49 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:03:50 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:51 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:51 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:52 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:53 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:03:54 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:03:55 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:03:55] INFO:     127.0.0.1:52556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:03:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:03:56 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.40, #queue-req: 0, 
[2025-10-18 03:03:56 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 03:03:57 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 03:03:58 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 03:03:59 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 03:04:00 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 03:04:00 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-10-18 03:04:01 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 03:04:02 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-10-18 03:04:03 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 03:04:04 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 03:04:05 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 03:04:05 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-10-18 03:04:06 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:04:07 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 03:04:08 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 03:04:09 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:04:09 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:04:10 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:04:11 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.88, #queue-req: 0, 
[2025-10-18 03:04:11] INFO:     127.0.0.1:58852 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:04:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:04:12 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.39, #queue-req: 0, 
[2025-10-18 03:04:13 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:04:14 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:04:14 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:04:15 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:04:16 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:04:17 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:04:18 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:04:19 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:04:19 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:04:20 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:04:21 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:22 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:04:23 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:23 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:04:24 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:04:25 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:26 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:27 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:28 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:28] INFO:     127.0.0.1:56920 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:04:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:04:28 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-10-18 03:04:29 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:04:30 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:04:31 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:32 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:33 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:33 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:34 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:35 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:36 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:37 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:38 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:38 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:39 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:40 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:41 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:42 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:42 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:43 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:44 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:04:44] INFO:     127.0.0.1:58560 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:04:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:04:45 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:04:46 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:47 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:47 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:48 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:49 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:04:50 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:51 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:52 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:52 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:04:53 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:54 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:55 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:56 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:56 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:04:57 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:04:58 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:04:59 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:05:00 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:05:01 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:05:01] INFO:     127.0.0.1:42530 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:05:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:05:01 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:05:02 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:05:03 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:05:04 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:05:05 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:05:06 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:06 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:07 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:08 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:09 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:10 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:10 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:11 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:12 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:13 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:14 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:15 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:15 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:16 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:05:17 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:17] INFO:     127.0.0.1:45584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:05:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:05:18 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:05:19 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:05:20 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:05:20 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:05:21 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:05:22 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:05:23 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:24 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:25 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:25 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:26 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:27 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:28 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:29 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:29 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:30 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:31 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:32 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:33 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:34 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:34] INFO:     127.0.0.1:40328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:05:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:05:34 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:05:35 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:05:36 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:05:37 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:05:38 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:05:39 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:05:39 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:05:40 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:41 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:42 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:43 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:43 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:44 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:45 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:46 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:47 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:48 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:48 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:05:49 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:50 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:05:50] INFO:     127.0.0.1:37378 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:05:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:05:51 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:05:52 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:05:53 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:05:53 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:05:54 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:55 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:56 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:05:57 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:57 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:05:58 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:05:59 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:00 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:01 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:02 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:02 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:03 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:04 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:05 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:06 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:06 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:07] INFO:     127.0.0.1:57246 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:06:07 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:06:08 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:06:09 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:06:10 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:06:11 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:06:11 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:06:12 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:06:13 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:14 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:15 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:16 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:16 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:17 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:18 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:19 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:20 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:21 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:21 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:22 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:06:23 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:06:23] INFO:     127.0.0.1:53308 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:06:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:06:24 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:06:25 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:06:26 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:26 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:27 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:06:28 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:29 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:30 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:30 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:31 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:32 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:06:33 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:34 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:06:35 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:35 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:06:36 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:37 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.62, #queue-req: 0, 
[2025-10-18 03:06:38 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:39 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:06:39 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:06:40] INFO:     127.0.0.1:46964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:06:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:06:40 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:06:41 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:06:42 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:06:43 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:06:44 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:06:44 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:06:45 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:06:46 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:06:47 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:48 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:49 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:49 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:50 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:51 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:52 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:53 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:06:53 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:06:54 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:55 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:06:56 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:06:56] INFO:     127.0.0.1:60348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:06:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:06:57 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:06:58 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:06:58 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:06:59 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:07:00 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:01 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:02 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:03 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:03 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:04 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:05 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:06 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:07 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:08 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:08 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:09 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:10 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:11 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:12 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:12 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:12] INFO:     127.0.0.1:53376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:07:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:07:13 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:07:14 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:15 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:16 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:07:17 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:17 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:18 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:19 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:20 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:21 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:22 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:22 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:23 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:24 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:25 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:26 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:26 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:27 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:07:28 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:29 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:29] INFO:     127.0.0.1:50214 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:07:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:07:30 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.90, #queue-req: 0, 
[2025-10-18 03:07:31 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:31 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:32 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:33 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:34 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:35 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:36 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:36 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:37 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:38 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:07:39 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:40 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:07:40 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:41 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:42 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.65, #queue-req: 0, 
[2025-10-18 03:07:43 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:07:44 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:07:45 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:45 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:07:45] INFO:     127.0.0.1:52794 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:07:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:07:46 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:07:47 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:48 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:07:49 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:50 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:50 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:07:51 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:52 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:07:53 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:54 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:07:55 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:55 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:56 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:07:57 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:07:58 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:07:59 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:07:59 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:00 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:01 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:02 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:08:02] INFO:     127.0.0.1:60310 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:08:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:08:03 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:08:04 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:08:04 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:05 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:06 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:07 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:08 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:09 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:09 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:10 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:11 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:12 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:13 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:13 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:14 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:15 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:16 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:17 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:18 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:18 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:08:18] INFO:     127.0.0.1:42790 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:08:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:08:19 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:08:20 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:21 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:08:22 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:23 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:08:23 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:24 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:25 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:26 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:27 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:27 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:28 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:29 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:30 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:31 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:32 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:32 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:33 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:34 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:35 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:35] INFO:     127.0.0.1:43124 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:08:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:08:36 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:08:37 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:37 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:38 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:39 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:40 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:41 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:41 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:42 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:43 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:44 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:45 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:46 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:46 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:08:47 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:48 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.64, #queue-req: 0, 
[2025-10-18 03:08:49 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:08:50 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:08:51 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:08:51 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:08:51] INFO:     127.0.0.1:43510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:08:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:08:52 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:08:53 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:08:54 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:08:55 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:56 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:56 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:08:57 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:08:58 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:08:59 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:00 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:09:00 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:01 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:02 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:03 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:04 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:05 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:05 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:06 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:07 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:09:08 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:08] INFO:     127.0.0.1:53750 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:09:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:09:09 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:09:10 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:10 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:11 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:12 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:13 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:14 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:09:14 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:09:15 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:16 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:09:17 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:09:18 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:19 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:09:19 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:09:20 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:09:21 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:22 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:23 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:09:23 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:24 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:24] INFO:     127.0.0.1:57088 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:09:25 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:09:26 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:09:27 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:09:28 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:09:28 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:09:29 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:09:30 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:31 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:32 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:33 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:33 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:34 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:35 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:36 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:37 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:38 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:38 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:39 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:40 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:41 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:41] INFO:     127.0.0.1:36184 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:09:42 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:09:43 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:09:43 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:09:44 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:09:45 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:09:46 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:09:47 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:09:47 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:48 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:09:49 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:50 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:51 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:52 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:09:52 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:09:53 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.67, #queue-req: 0, 
[2025-10-18 03:09:54 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:55 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:09:56 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:09:56 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:09:57 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:09:57] INFO:     127.0.0.1:38922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:09:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:09:58 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:09:59 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:00 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:01 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:01 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:10:02 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:03 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:04 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:10:05 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:10:06 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:06 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:07 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:08 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:09 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:10 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:10 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:10:11 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:10:12 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:10:13 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:10:14 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:10:14] INFO:     127.0.0.1:57176 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:10:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:10:15 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:10:15 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:10:16 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:10:17 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:10:18 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:10:19 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:20 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:20 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:21 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:22 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:23 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:24 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:25 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:25 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:26 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:27 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:28 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:29 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:29 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:30 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:30] INFO:     127.0.0.1:46162 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:10:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:10:31 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:10:32 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:10:33 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:34 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:10:34 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:35 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:36 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:37 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:38 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:39 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:39 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:40 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:41 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:42 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:43 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:43 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:44 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:45 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:46 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:47 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:10:47] INFO:     127.0.0.1:34178 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:10:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:10:48 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:10:48 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:10:49 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:10:50 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:51 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:10:52 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:10:53 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:53 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:10:54 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:10:55 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:56 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:10:57 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:57 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:10:58 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:10:59 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:00 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:01 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:02 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:02 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:03 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:03] INFO:     127.0.0.1:41196 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:11:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:11:04 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:11:05 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:11:06 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:07 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:07 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:08 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:09 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:10 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:11 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:11 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:12 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:13 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:14 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:15 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:16 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:16 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:17 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:18 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:19 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:20 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:20] INFO:     127.0.0.1:52030 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:11:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:11:21 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.87, #queue-req: 0, 
[2025-10-18 03:11:21 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:11:22 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:23 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:11:24 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:25 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:26 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:26 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:27 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:28 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:29 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:30 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:30 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:31 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:32 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:11:33 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:34 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:35 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:35 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:36 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:36] INFO:     127.0.0.1:44592 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:11:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:11:37 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:11:38 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:39 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:40 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:40 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:11:41 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:11:42 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:43 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:44 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:11:44 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:45 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:11:46 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:11:47 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:48 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:11:49 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:49 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:50 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:11:51 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:11:52 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:11:53 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:11:53] INFO:     127.0.0.1:40318 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:11:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:11:54 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.82, #queue-req: 0, 
[2025-10-18 03:11:54 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:11:55 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:11:56 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:11:57 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:11:58 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:59 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:11:59 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:00 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:01 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:02 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:12:03 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:03 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:04 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:05 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:06 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:07 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:08 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:08 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:09 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:09] INFO:     127.0.0.1:44466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:12:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:12:10 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:12:11 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:12:12 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:12:13 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:12:13 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:12:14 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:15 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:16 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:17 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:17 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:18 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:19 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:20 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:21 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:22 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:22 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:23 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:24 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:25 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:26 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:26] INFO:     127.0.0.1:57550 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:12:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:12:27 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:12:27 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:12:28 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:12:29 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:12:30 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:12:31 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:31 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:32 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:33 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:34 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:35 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:36 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:36 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:37 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:38 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:39 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:40 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:12:40 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:41 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:42 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:42] INFO:     127.0.0.1:59638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:12:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:12:43 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:12:44 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:12:45 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:12:45 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:12:46 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:12:47 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:48 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:12:49 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:50 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:50 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:51 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:52 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:53 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:54 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:12:55 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:12:55 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:56 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:57 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:12:58 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:59 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:12:59] INFO:     127.0.0.1:51212 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:12:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:13:00 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:13:00 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:01 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:02 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:03 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:04 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:13:04 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:05 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:06 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:07 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:08 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:09 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:09 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:10 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:13:11 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:12 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:13 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:13:13 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:14 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:13:15 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:13:15] INFO:     127.0.0.1:54282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:13:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:13:16 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:13:17 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:13:18 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:13:18 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:19 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:20 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:21 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:22 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:23 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:23 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:13:24 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:25 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:13:26 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:27 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:27 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:28 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:29 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:30 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:31 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:32 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:32] INFO:     127.0.0.1:60332 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:13:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:13:32 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:13:33 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:34 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:35 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:36 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:37 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:37 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:38 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:39 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:40 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:13:41 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:42 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:42 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:43 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:44 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:45 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:46 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:46 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:47 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:13:48 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:13:48] INFO:     127.0.0.1:60134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:13:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:13:49 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:13:50 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:51 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:13:51 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:52 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:53 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:13:54 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:55 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:13:56 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:13:56 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:57 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:13:58 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:13:59 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:00 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:00 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:01 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:02 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:03 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:04 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:05 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:05] INFO:     127.0.0.1:60984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:14:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:14:05 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:14:06 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:07 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:08 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:09 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:10 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:10 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:11 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:12 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:13 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:14 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:14 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:15 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:16 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:17 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:18 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:19 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:19 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:20 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:21 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:21] INFO:     127.0.0.1:34424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:14:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:14:22 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:14:23 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:24 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:14:24 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:25 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:26 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:27 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:28 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:28 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:29 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:30 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:31 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:32 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:33 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:33 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:34 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:35 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:36 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:14:37 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:38 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:14:38] INFO:     127.0.0.1:43784 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:14:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:14:38 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:14:39 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:40 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:14:41 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:42 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:43 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:43 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:44 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:45 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:46 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:47 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:14:47 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:48 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:49 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:50 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:51 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:52 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:52 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:14:53 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:14:54 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:14:54] INFO:     127.0.0.1:52694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:14:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:14:55 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.91, #queue-req: 0, 
[2025-10-18 03:14:56 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:14:57 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:14:57 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:14:58 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:14:59 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:00 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:01 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:01 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:02 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:03 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:04 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:05 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:06 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:06 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:07 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:08 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:09 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:10 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:10 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:11] INFO:     127.0.0.1:41828 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:15:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:15:11 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.18, #queue-req: 0, 
[2025-10-18 03:15:12 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:15:13 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:14 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:15 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:15 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:16 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:17 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:18 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:19 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:20 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:20 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:21 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:22 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:15:23 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:24 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:25 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:25 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:15:26 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:27 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:15:27] INFO:     127.0.0.1:46450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:15:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:15:28 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:15:29 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:30 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:30 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:31 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:15:32 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:33 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:34 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:34 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:35 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:36 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:37 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:38 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:39 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:39 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:40 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:41 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:42 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:43 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:43 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:43] INFO:     127.0.0.1:41080 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:15:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:15:44 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:15:45 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:15:46 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:15:47 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:15:48 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:48 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:49 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:15:50 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:51 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:52 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:53 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:53 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:15:54 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:15:55 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:15:56 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:57 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:57 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:15:58 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:15:59 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:00 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:00] INFO:     127.0.0.1:47198 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:16:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:16:01 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:16:02 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:02 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:03 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:16:04 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:16:05 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:16:06 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:16:07 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:16:07 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:16:08 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:16:09 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:16:10 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:16:11 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:16:12 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:16:12 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:16:13 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.70, #queue-req: 0, 
[2025-10-18 03:16:14 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:16:15 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:16:16 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:16:16 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.70, #queue-req: 0, 
[2025-10-18 03:16:16] INFO:     127.0.0.1:53068 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:16:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:16:17 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.37, #queue-req: 0, 
[2025-10-18 03:16:18 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:19 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:16:20 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:21 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:21 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:22 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:23 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:24 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:25 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:26 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:26 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:27 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:28 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:29 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:30 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:30 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:16:31 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:16:32 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:33 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:16:33] INFO:     127.0.0.1:33160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:16:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:16:34 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:16:35 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:16:35 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:16:36 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:16:37 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:16:38 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:39 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:40 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:40 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:41 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:42 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:43 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:44 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:44 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:45 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:46 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:47 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:48 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:49 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:49 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:16:49] INFO:     127.0.0.1:49108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:16:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:16:50 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:16:51 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:16:52 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:16:53 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:16:54 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:16:54 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:16:55 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:56 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:57 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:16:58 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:16:58 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:16:59 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:00 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:01 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:02 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:03 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:03 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:04 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:05 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:06 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:06] INFO:     127.0.0.1:35686 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:17:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:17:07 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:17:08 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:08 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:09 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:10 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:17:11 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:12 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:13 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:13 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:14 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:15 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:16 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:17 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:17 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:18 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:19 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:20 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:21 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:22 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:22 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:22] INFO:     127.0.0.1:36944 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:17:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:17:23 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:17:24 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:25 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:26 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:27 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:27 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:28 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:29 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:30 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:31 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:31 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:32 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:33 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:34 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:35 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:36 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:36 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:37 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:38 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:17:39 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:17:39] INFO:     127.0.0.1:34070 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:17:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:17:40 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:17:41 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:41 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:42 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:43 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:17:44 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:45 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:45 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:46 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:17:47 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:48 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:49 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:50 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:50 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:51 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:52 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:17:53 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:54 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:55 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:17:55 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:17:55] INFO:     127.0.0.1:40994 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:17:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:17:56 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:17:57 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:58 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:17:59 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:00 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:00 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:01 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:02 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:03 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:04 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:04 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:05 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:06 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:07 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:08 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:09 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:09 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:10 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:11 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:12 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:12] INFO:     127.0.0.1:50934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:18:13 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:18:14 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:14 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:18:15 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:16 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:17 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:18 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:18 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:19 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:20 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:21 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:22 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:23 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:23 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:24 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:25 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:26 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:27 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:27 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:28 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:28] INFO:     127.0.0.1:37930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:18:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:18:29 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:18:30 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:31 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:32 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:32 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:33 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:34 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:35 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:36 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:37 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:37 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:18:38 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:39 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:40 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:41 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:41 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:42 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:18:43 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:44 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:18:45 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:18:45] INFO:     127.0.0.1:43058 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:18:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:18:46 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:18:47 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:18:47 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:18:48 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:49 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:50 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:18:51 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:51 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:18:52 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:18:53 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:54 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:55 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:56 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:56 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:57 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:58 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:18:59 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:00 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:00 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:19:01 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:19:01] INFO:     127.0.0.1:51348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:19:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:19:02 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:19:03 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:19:04 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:19:05 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:05 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:19:06 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:07 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:08 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:09 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:10 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:10 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:11 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:12 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:13 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:19:14 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:14 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:15 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:16 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:17 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:18 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:19:18] INFO:     127.0.0.1:36628 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:19:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:19:19 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:19:19 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:19:20 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:19:21 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:22 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:19:23 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:24 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:24 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:25 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:26 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:27 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:28 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:28 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:29 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:30 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:31 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:32 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:33 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:33 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:34 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:19:34] INFO:     127.0.0.1:57248 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:19:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:19:35 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:19:36 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:19:37 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:19:38 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:38 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:39 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:40 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:41 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:42 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:42 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:43 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:44 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:45 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:46 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:47 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:47 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:48 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:49 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:50 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:51 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:19:51] INFO:     127.0.0.1:59516 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:19:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:19:52 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:19:52 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:19:53 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:19:54 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:55 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:56 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:19:57 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:57 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:19:58 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:19:59 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:00 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:01 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:01 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:02 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:03 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:04 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:05 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:06 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:06 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:07 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:07] INFO:     127.0.0.1:60108 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:20:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:20:08 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.86, #queue-req: 0, 
[2025-10-18 03:20:09 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:10 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:20:11 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:11 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:12 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:20:13 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:20:14 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:15 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:15 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:16 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:17 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:20:18 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:19 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:20:20 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:20 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:20:21 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:20:22 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:23 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:20:24 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:20:24] INFO:     127.0.0.1:45144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:20:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:20:25 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:20:25 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:26 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:20:27 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:28 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:29 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:20:30 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:20:30 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:31 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:20:32 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:33 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:34 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:34 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:35 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:36 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:37 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:38 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:39 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:39 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:40 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:40] INFO:     127.0.0.1:47964 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:20:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:20:41 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:20:42 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:20:43 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:44 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:44 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:45 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:20:46 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:47 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:48 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:48 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:49 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:50 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:51 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:52 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:53 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:53 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:20:54 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:20:55 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:56 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:20:57 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:20:57] INFO:     127.0.0.1:55856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:20:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:20:58 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:20:58 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:20:59 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:21:00 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:21:01 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:21:02 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:21:02 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:21:03 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:04 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:05 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:06 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:07 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:07 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:08 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:09 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:10 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:11 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:11 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:12 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:13 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:13] INFO:     127.0.0.1:41042 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:21:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:21:14 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 03:21:15 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:21:16 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:21:16 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:17 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:18 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:19 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:20 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:21 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:21 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:22 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:23 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:24 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:25 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:26 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:26 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:27 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:28 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:21:29 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:30 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:30] INFO:     127.0.0.1:58584 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:21:31 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:21:31 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:21:32 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:21:33 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:34 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:35 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:35 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:36 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:37 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:38 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:39 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:40 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:40 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:41 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:42 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:43 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:44 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:44 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:45 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:46 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:46] INFO:     127.0.0.1:42064 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:21:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:21:47 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-10-18 03:21:48 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:49 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:49 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:21:50 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:51 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:52 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:53 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:21:54 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:54 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:55 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:21:56 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:57 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:21:58 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:58 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:21:59 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:00 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:22:01 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:02 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:22:03 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:03] INFO:     127.0.0.1:59566 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:22:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:22:03 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:22:04 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:22:05 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:06 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:07 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:08 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:08 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:09 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:10 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:11 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:12 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:13 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:13 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:14 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:15 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:16 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:17 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:17 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:18 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:19 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:19] INFO:     127.0.0.1:43850 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:22:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:22:20 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.38, #queue-req: 0, 
[2025-10-18 03:22:21 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:22:22 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:22:22 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:22:23 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:22:24 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:22:25 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:26 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:27 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:22:27 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:22:28 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:29 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:30 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:31 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:31 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:32 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:33 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:34 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:22:35 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:36 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:36] INFO:     127.0.0.1:44134 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:22:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:22:36 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:22:37 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:38 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:39 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:40 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:41 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:22:41 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:42 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:43 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:44 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:45 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:45 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:46 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:47 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:48 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:49 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:50 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:50 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:22:51 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:22:52 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:22:52] INFO:     127.0.0.1:46474 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:22:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:22:53 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.37, #queue-req: 0, 
[2025-10-18 03:22:54 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:55 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:22:55 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:56 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:57 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:22:58 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:22:59 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:22:59 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.68, #queue-req: 0, 
[2025-10-18 03:23:00 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:01 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:02 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:03 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:04 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:04 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:05 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:06 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:07 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:08 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:09 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:09] INFO:     127.0.0.1:52758 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:23:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:23:09 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.03, #queue-req: 0, 
[2025-10-18 03:23:10 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:23:11 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:23:12 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:23:13 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:23:14 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:23:14 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:23:15 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:23:16 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:17 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:18 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:18 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:19 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:20 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:21 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:22 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:23 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:23 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:24 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:25 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:25] INFO:     127.0.0.1:48918 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:23:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:23:26 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.96, #queue-req: 0, 
[2025-10-18 03:23:27 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:23:28 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:23:28 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:23:29 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:23:30 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:23:31 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:23:32 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:32 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.70, #queue-req: 0, 
[2025-10-18 03:23:33 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:34 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:35 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:36 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:37 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:37 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:38 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:39 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:40 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:41 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:41 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:42] INFO:     127.0.0.1:56338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:23:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:23:42 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:23:43 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:44 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:45 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:46 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:46 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:47 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:48 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:23:49 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:50 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:51 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:51 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:52 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:23:53 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:23:54 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:55 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:56 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:56 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:57 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:23:58 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:23:58] INFO:     127.0.0.1:51652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:23:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:23:59 TP0] Decode batch. #running-req: 1, #token: 3239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:24:00 TP0] Decode batch. #running-req: 1, #token: 3279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:01 TP0] Decode batch. #running-req: 1, #token: 3319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:01 TP0] Decode batch. #running-req: 1, #token: 3359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:02 TP0] Decode batch. #running-req: 1, #token: 3399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:03 TP0] Decode batch. #running-req: 1, #token: 3439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:04 TP0] Decode batch. #running-req: 1, #token: 3479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:05 TP0] Decode batch. #running-req: 1, #token: 3519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:05 TP0] Decode batch. #running-req: 1, #token: 3559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:06 TP0] Decode batch. #running-req: 1, #token: 3599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:07 TP0] Decode batch. #running-req: 1, #token: 3639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:08 TP0] Decode batch. #running-req: 1, #token: 3679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:09 TP0] Decode batch. #running-req: 1, #token: 3719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:10 TP0] Decode batch. #running-req: 1, #token: 3759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:10 TP0] Decode batch. #running-req: 1, #token: 3799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:11 TP0] Decode batch. #running-req: 1, #token: 3839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:12 TP0] Decode batch. #running-req: 1, #token: 3879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:13 TP0] Decode batch. #running-req: 1, #token: 3919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:24:14 TP0] Decode batch. #running-req: 1, #token: 3959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:14 TP0] Decode batch. #running-req: 1, #token: 3999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:24:15] INFO:     127.0.0.1:50122 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 03:24:29] INFO:     127.0.0.1:57280 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 03:24:35] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:24:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:24:37] INFO:     127.0.0.1:43484 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:24:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:24:37 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1.77, #queue-req: 0, 
[2025-10-18 03:24:38 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:24:39 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:39 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:24:40 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:41 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:24:42 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:43 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:44 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:44 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:45 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:24:46 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:24:47 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:48 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:49 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:49 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:50 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:51 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:52 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:24:53 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:24:53] INFO:     127.0.0.1:33922 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:24:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:24:54 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:24:54 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:24:55 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:24:56 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:24:57 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:24:58 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:24:58 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:24:59 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:00 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:01 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:02 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:03 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:03 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:04 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:05 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:06 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:25:07 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:07 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:08 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:09 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:10] INFO:     127.0.0.1:51348 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:25:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:25:10 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.76, #queue-req: 0, 
[2025-10-18 03:25:11 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:25:12 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:12 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:25:13 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:14 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:15 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:16 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:17 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:17 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:18 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:19 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:20 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:25:21 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:21 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:22 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:23 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:24 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:25 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:26 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:26] INFO:     127.0.0.1:39496 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:25:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:25:26 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:25:27 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:28 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:29 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:30 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:31 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:31 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:25:32 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:33 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:34 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:35 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:36 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:36 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:37 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:38 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:39 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:40 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:40 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:41 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:25:42 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:25:43] INFO:     127.0.0.1:39470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:25:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:25:43 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:25:44 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:25:45 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:25:45 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:25:46 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:47 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:25:48 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:49 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:50 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:50 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:25:51 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:52 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:53 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:25:54 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:54 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:55 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:56 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:57 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:25:58 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:59 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:25:59] INFO:     127.0.0.1:42208 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:25:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:25:59 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:26:00 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:01 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:26:02 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:03 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:04 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:04 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:05 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:06 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:07 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:08 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:08 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:09 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:10 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:11 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:12 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:13 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:13 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:14 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:15 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:16] INFO:     127.0.0.1:39186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:26:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:26:16 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:26:17 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:26:18 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:26:18 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:26:19 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:26:20 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:21 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:26:22 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:22 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:23 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:24 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:25 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:26 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:27 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:27 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:28 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:29 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:30 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:31 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:31 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:32] INFO:     127.0.0.1:34766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:26:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:26:32 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:26:33 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:26:34 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:26:35 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:26:36 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:36 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:37 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:38 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:39 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:40 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:41 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:41 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:42 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:43 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:44 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:45 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:46 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:46 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:47 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:48 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:49] INFO:     127.0.0.1:51448 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:26:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:26:49 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:26:50 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:51 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:51 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:52 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:26:53 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:26:54 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:26:55 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:55 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:56 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:26:57 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:26:58 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:26:59 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:00 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:00 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:01 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:02 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:03 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:27:04 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:04 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:05] INFO:     127.0.0.1:45946 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:27:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:27:05 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:27:06 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:27:07 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:08 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:09 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:27:09 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:27:10 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:11 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:12 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:13 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:14 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:14 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:15 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:16 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:17 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:18 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:18 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:19 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:20 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:21 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:27:22] INFO:     127.0.0.1:58834 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:27:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:27:22 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:27:23 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:27:23 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:27:24 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:25 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:26 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:27:27 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:28 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:28 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:29 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:30 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:31 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:32 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:33 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:33 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:34 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:35 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:36 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:37 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:37 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:38] INFO:     127.0.0.1:51816 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:27:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:27:38 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:27:39 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:27:40 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:27:41 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:27:42 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:27:42 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:27:43 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:27:44 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:45 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:27:46 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:47 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:47 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:48 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:27:49 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:50 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:51 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:51 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:52 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:27:53 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:27:54 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:27:55] INFO:     127.0.0.1:51782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:27:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:27:55 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:27:56 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:56 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:27:57 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:27:58 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:27:59 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:00 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:01 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:01 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:02 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:03 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:04 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:05 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:05 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:06 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:07 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:08 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:09 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:10 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:10 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:11] INFO:     127.0.0.1:53096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:28:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:28:11 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:28:12 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:28:13 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:28:14 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:28:15 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:28:15 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:28:16 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:17 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:28:18 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:19 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:19 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:20 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:21 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:22 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:23 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:24 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:24 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:25 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:26 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:27 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:28] INFO:     127.0.0.1:49374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:28:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:28:28 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:28:29 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:28:29 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:28:30 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:28:31 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:32 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:33 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:34 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:34 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:35 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:36 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:37 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:38 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:38 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:28:39 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:28:40 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:28:41 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:28:42 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:28:43 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:28:43 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:28:44] INFO:     127.0.0.1:54860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:28:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:28:44 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:28:45 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:28:46 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:28:47 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:28:48 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:28:48 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:28:49 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:50 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:28:51 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:52 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:52 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:53 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:54 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:55 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:56 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:57 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:28:57 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:28:58 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:28:59 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:29:00 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:01] INFO:     127.0.0.1:56720 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:29:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:29:01 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:29:02 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:29:02 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:29:03 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:04 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:05 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:06 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:06 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:07 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:08 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:09 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:10 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:11 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:11 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:12 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:13 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:14 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:15 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:15 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:16 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:17] INFO:     127.0.0.1:47280 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:29:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:29:17 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:29:18 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.87, #queue-req: 0, 
[2025-10-18 03:29:19 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:29:20 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:29:20 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:29:21 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:29:22 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:29:23 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:24 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:25 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:25 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:26 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:27 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:28 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:29 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:29 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:30 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:31 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:32 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:33 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:33] INFO:     127.0.0.1:40210 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:29:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:29:34 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:29:35 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:29:35 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:36 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:37 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:38 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:39 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:39 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:40 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:41 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:42 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:43 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:44 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:44 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:45 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:46 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:47 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:48 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:29:48 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:49 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:29:50] INFO:     127.0.0.1:45154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:29:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:29:50 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:29:51 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:52 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:29:53 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:29:53 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:54 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:29:55 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:56 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:57 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:58 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:29:58 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:29:59 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:00 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:01 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:02 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:02 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:03 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:04 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:05 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:06 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:06] INFO:     127.0.0.1:43908 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:30:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:30:07 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:30:07 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:08 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:09 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:10 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:11 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:12 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:12 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:13 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:14 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:15 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:16 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:16 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:17 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:18 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:19 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:20 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:21 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:21 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:22 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:23] INFO:     127.0.0.1:43910 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:30:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:30:23 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:30:24 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:30:25 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:30:26 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:30:26 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:27 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:30:28 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:29 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:30 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:31 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:30:31 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:32 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:33 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:34 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:35 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:35 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:36 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:37 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:38 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:39 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:39] INFO:     127.0.0.1:45486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:30:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:30:40 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:30:40 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:30:41 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:30:42 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:30:43 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:44 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:45 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:30:45 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:46 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:30:47 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:48 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:49 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:49 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:30:50 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:51 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:52 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:53 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:54 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:30:54 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:30:55 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:30:56] INFO:     127.0.0.1:49766 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:30:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:30:56 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:30:57 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:30:58 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:30:59 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:30:59 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:00 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:01 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:02 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:31:03 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:03 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:31:04 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:05 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:06 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:07 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:31:08 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:08 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:09 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:10 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:11 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:12 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:12] INFO:     127.0.0.1:53374 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:31:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:31:13 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:31:13 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:31:14 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:31:15 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:16 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:17 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:17 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:31:18 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:31:19 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:31:20 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:21 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:22 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:22 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:23 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:31:24 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:25 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:31:26 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:27 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:27 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:31:28 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:31:29] INFO:     127.0.0.1:56554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:31:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:31:29 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:31:30 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:31 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:31:32 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:32 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:33 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:34 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:35 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:36 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:36 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:37 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:38 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:39 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:40 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:41 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:41 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:42 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:43 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:44 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:45 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:31:45] INFO:     127.0.0.1:41914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:31:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:31:46 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:31:46 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:31:47 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:31:48 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:49 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:50 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:31:50 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:31:51 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:31:52 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:31:53 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:54 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:31:55 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:55 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:56 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:57 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:58 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:31:59 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:31:59 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:00 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:01 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:02] INFO:     127.0.0.1:40186 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:32:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:32:02 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:32:03 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:32:04 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:32:04 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:05 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:06 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:32:07 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:32:08 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:32:09 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:09 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:10 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:11 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:12 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:13 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:14 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:14 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:15 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:16 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:17 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:18 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:32:18] INFO:     127.0.0.1:39652 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:32:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:32:19 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:32:19 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:20 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:21 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:22 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:23 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:23 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:24 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:32:25 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:26 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:27 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:28 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:28 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:29 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:30 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:32:31 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:32 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:32 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:32:33 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:34 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:32:35] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:32:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:32:35 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:32:36 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:37 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:37 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:38 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:39 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:40 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:32:41 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:42 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:42 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:43 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:44 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:45 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:46 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:46 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:47 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:48 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:49 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:32:50 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:32:51 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:32:51] INFO:     127.0.0.1:37992 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:32:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:32:51 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:32:52 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:32:53 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:32:54 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:32:55 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:56 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:32:56 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:57 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:32:58 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:32:59 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:33:00 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:33:00 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:01 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:33:02 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:03 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:04 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:05 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:33:05 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:06 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:07 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:08] INFO:     127.0.0.1:55396 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:33:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:33:08 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:33:09 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:10 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:10 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:11 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:12 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:13 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:14 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:15 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:15 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:16 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:17 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:18 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:19 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:19 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:33:20 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:21 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:22 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:33:23 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:33:24 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:33:24] INFO:     127.0.0.1:50010 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:33:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:33:24 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.87, #queue-req: 0, 
[2025-10-18 03:33:25 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:33:26 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:33:27 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:33:28 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:33:29 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:33:29 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:33:30 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:31 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:32 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:33 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:33 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:34 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:35 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:36 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:37 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:38 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:38 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:39 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:40 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:41] INFO:     127.0.0.1:45544 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:33:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:33:41 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:33:42 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:33:43 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:33:43 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:33:44 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:33:45 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:33:46 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:33:47 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:33:48 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:48 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:49 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:33:50 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:51 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:33:52 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:52 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:53 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:54 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:33:55 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:33:56 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:33:57 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:33:57] INFO:     127.0.0.1:55006 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:33:57 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:33:58 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:33:59 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:00 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:34:01 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:02 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:02 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:03 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:04 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:05 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:06 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:06 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:07 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:08 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:09 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:10 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:11 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:11 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:12 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:13 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:14] INFO:     127.0.0.1:39412 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:34:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:34:14 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:34:15 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:16 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:16 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:17 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:18 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:19 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:20 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:20 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:21 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:22 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:23 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:24 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:25 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:25 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:26 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:34:27 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:28 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:34:29 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:34:29 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:34:30] INFO:     127.0.0.1:38400 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:34:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:34:30 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:34:31 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:34:32 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:34:33 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:34:34 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:34:34 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:35 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:36 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:37 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:38 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:34:39 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:39 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:40 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:41 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:42 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:43 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:44 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:44 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:45 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:46 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:47] INFO:     127.0.0.1:50486 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:34:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:34:47 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:34:48 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:49 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:34:49 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:34:50 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:51 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:34:52 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:34:53 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:53 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:54 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:34:55 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:56 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:57 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:58 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:34:58 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:34:59 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:00 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:01 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:02 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:02 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:03] INFO:     127.0.0.1:49398 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:35:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:35:03 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:35:04 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:35:05 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:35:06 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:07 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:07 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:08 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:09 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:10 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:11 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:12 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:12 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:13 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:14 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:15 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:16 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:16 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:17 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:35:18 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:19 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:35:20] INFO:     127.0.0.1:53276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:35:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:35:20 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:35:21 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:35:21 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:35:22 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:35:23 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:24 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:25 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:35:26 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:26 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:27 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:28 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:29 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:30 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:30 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:31 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:32 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:33 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:34 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:35 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:35 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:36] INFO:     127.0.0.1:34854 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:35:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:35:36 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:35:37 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:35:38 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:39 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:35:40 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:40 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:41 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:42 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:43 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:44 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:45 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:45 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:46 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:47 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:48 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:49 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:35:49 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:50 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:51 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:52 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:35:53] INFO:     127.0.0.1:34326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:35:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:35:53 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:35:54 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:54 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:55 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:35:56 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:57 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:35:58 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:35:59 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:35:59 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:00 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:01 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:02 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:03 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:03 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:04 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:05 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:06 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:07 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:08 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:36:08 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:09] INFO:     127.0.0.1:46180 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:36:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:36:09 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:36:10 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:36:11 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:36:12 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:36:13 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:13 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:36:14 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:15 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:16 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:17 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:17 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:18 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:19 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:20 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:21 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:36:22 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:22 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:23 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:36:24 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:36:25 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:36:26] INFO:     127.0.0.1:49984 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:36:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:36:26 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.96, #queue-req: 0, 
[2025-10-18 03:36:27 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:27 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:28 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:29 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:30 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:36:31 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:36:32 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:32 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:33 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:34 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:35 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:36:36 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:36 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:37 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:36:38 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:39 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:40 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:41 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:41 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:36:42] INFO:     127.0.0.1:57114 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:36:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:36:42 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:36:43 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:36:44 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:45 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:36:46 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:46 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:47 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:36:48 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:49 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:50 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:50 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:36:51 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:52 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:53 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:54 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:55 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:36:55 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:56 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:57 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:36:58 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:36:59] INFO:     127.0.0.1:56924 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:36:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:36:59 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:37:00 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:37:00 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:01 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:37:02 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:03 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:04 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:04 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:05 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:06 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:07 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:08 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:09 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:09 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:10 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:11 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:12 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:13 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:13 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:14 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:15] INFO:     127.0.0.1:58020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:37:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:37:15 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:37:16 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:17 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:18 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:18 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:19 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:37:20 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:21 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:22 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:23 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:23 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:24 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:25 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:26 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:27 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:28 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:28 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:29 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:30 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:31 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:31] INFO:     127.0.0.1:49724 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:37:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:37:32 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:37:33 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:33 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:34 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:37:35 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:36 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:37:37 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:37 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:38 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:39 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:40 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:41 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:42 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:42 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:43 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:44 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:37:45 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:46 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:46 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:37:47 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:48] INFO:     127.0.0.1:49510 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:37:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:37:48 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:37:49 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:50 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:51 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:37:51 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:37:52 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:37:53 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:54 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:55 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:37:56 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:56 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:57 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:58 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:37:59 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:38:00 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:00 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:01 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:38:02 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:03 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:38:04 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:38:04] INFO:     127.0.0.1:41282 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:38:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:38:05 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:38:05 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:38:06 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:38:07 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:08 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:38:09 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:38:10 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:38:10 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:11 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:12 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:13 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:14 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:14 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:15 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:16 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:17 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:18 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:19 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:19 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:20 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:21] INFO:     127.0.0.1:50748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:38:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:38:21 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-10-18 03:38:22 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:23 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:24 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:24 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:38:25 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:38:26 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:27 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:28 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:29 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:29 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:30 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:31 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:32 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:33 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:33 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:34 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:35 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:36 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:37 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:37] INFO:     127.0.0.1:38096 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:38:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:38:38 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:38:38 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:38:39 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:38:40 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:41 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:38:42 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:38:43 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:38:43 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:38:44 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:38:45 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:46 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:47 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:47 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:38:48 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:49 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:50 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:51 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:52 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:38:52 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:38:53 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:38:54] INFO:     127.0.0.1:53446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:38:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:38:54 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:38:55 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:56 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:38:57 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:38:57 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:58 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:38:59 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:00 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:39:01 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:01 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:02 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:03 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:04 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:05 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:06 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:06 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:07 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:08 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:09 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:39:10 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:10] INFO:     127.0.0.1:58276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:39:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:39:11 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:39:11 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:39:12 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:39:13 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:39:14 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:39:15 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:39:15 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:39:16 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:17 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:18 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:19 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:20 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:20 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:21 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:22 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:23 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:24 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:25 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:25 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:26 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:27] INFO:     127.0.0.1:53394 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:39:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:39:27 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.36, #queue-req: 0, 
[2025-10-18 03:39:28 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.96, #queue-req: 0, 
[2025-10-18 03:39:29 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 03:39:30 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 03:39:30 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 03:39:31 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-10-18 03:39:32 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.93, #queue-req: 0, 
[2025-10-18 03:39:33 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 03:39:34 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 03:39:34 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 03:39:35 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 03:39:36 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:39:37 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 03:39:38 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:39:39 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.89, #queue-req: 0, 
[2025-10-18 03:39:39 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 03:39:40 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.89, #queue-req: 0, 
[2025-10-18 03:39:41 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.88, #queue-req: 0, 
[2025-10-18 03:39:42 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.88, #queue-req: 0, 
[2025-10-18 03:39:43 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.88, #queue-req: 0, 
[2025-10-18 03:39:43] INFO:     127.0.0.1:47662 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:39:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:39:43 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.39, #queue-req: 0, 
[2025-10-18 03:39:44 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:39:45 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:39:46 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:39:47 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:39:48 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:39:48 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:39:49 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:50 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:51 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:39:52 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:53 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:53 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:54 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:55 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:56 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:39:57 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:39:57 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:39:58 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:39:59 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:00] INFO:     127.0.0.1:50224 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:40:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:40:00 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:40:01 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:02 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:02 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:03 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:40:04 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:05 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:40:06 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:07 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:07 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:08 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:09 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:10 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:11 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:11 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:12 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:13 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:14 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:40:15 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:40:16 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:16] INFO:     127.0.0.1:46464 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:40:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:40:16 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:40:17 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:18 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:19 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:20 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:21 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:21 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:22 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:23 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:24 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:25 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:25 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:26 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:27 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:28 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:29 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:30 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:30 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:40:31 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:40:32 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:40:33] INFO:     127.0.0.1:54514 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:40:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:40:33 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:40:34 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:40:35 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:40:35 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:40:36 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:40:37 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:40:38 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:39 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:40 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:40 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:41 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:40:42 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:43 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:44 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:44 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:45 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:46 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:47 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:48 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:40:49 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:49] INFO:     127.0.0.1:53518 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:40:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:40:49 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:40:50 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:40:51 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:40:52 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:40:53 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:40:54 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:40:54 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:40:55 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:40:56 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:40:57 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:58 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:40:58 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:40:59 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:00 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:01 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:02 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:03 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:03 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:04 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:05 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:06] INFO:     127.0.0.1:53582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:41:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:41:06 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:41:07 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:41:08 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:41:08 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:41:09 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:41:10 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:41:11 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:12 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:12 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:13 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:14 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:15 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:16 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:17 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:17 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:18 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:19 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:20 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:21 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:22 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:22] INFO:     127.0.0.1:37500 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:41:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:41:22 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:41:23 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:41:24 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:41:25 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:41:26 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:41:26 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:27 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:28 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:29 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:30 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:31 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:31 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:32 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:33 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:34 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:35 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:36 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:36 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:37 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:38 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:39] INFO:     127.0.0.1:58654 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:41:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:41:39 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:41:40 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:41:41 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:41:41 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:42 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:43 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:44 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:45 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:41:45 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:41:46 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:47 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:48 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:49 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:50 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:41:50 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:51 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:52 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:53 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:41:54 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:41:54 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:41:55] INFO:     127.0.0.1:46406 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:41:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:41:55 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:41:56 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:41:57 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:41:58 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:59 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:41:59 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:42:00 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:01 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:02 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:03 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:42:04 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:04 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:05 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:06 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:07 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:08 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:08 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:09 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:42:10 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:42:11 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:42:12] INFO:     127.0.0.1:59776 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:42:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:42:12 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:42:13 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:42:13 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:42:14 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:42:15 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:42:16 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:17 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:18 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:18 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:19 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:20 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:21 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:22 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:23 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:23 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:24 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:25 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:26 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:42:27 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:27 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:28] INFO:     127.0.0.1:37166 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:42:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:42:28 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:42:29 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:42:30 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:42:31 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:42:32 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:32 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:33 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:34 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:42:35 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:36 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:37 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:37 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:38 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:39 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:40 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:41 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:41 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:42 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:43 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:44 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:42:45] INFO:     127.0.0.1:34860 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:42:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:42:45 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:42:46 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:42:46 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:42:47 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:42:48 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:42:49 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:42:50 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:51 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:51 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:52 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:53 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:54 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:55 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:42:55 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:42:56 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:57 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:58 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:42:59 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:00 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:00 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:01] INFO:     127.0.0.1:37966 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:43:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:43:01 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:43:02 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:03 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:04 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:05 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:05 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:06 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:07 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:08 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:09 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:09 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:43:10 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:11 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:12 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:13 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:14 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:14 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:15 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:16 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:17 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:18] INFO:     127.0.0.1:47582 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:43:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:43:18 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:43:19 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:43:19 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:43:20 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:43:21 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:22 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:23 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:24 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:24 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:25 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:26 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:27 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:28 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:28 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:29 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:43:30 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:31 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:43:32 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:33 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:33 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:43:34] INFO:     127.0.0.1:58772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:43:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:43:34 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:43:35 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:43:36 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:43:37 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:38 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:43:38 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:39 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:40 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:41 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:42 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:42 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:43 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:44 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:43:45 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:46 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:47 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:47 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:43:48 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:49 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:43:50 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:43:51] INFO:     127.0.0.1:35788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:43:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:43:51 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 03:43:52 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:43:52 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:43:53 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:43:54 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:43:55 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:56 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:43:56 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:57 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:58 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:43:59 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:00 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:01 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:01 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:02 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:03 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:04 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:05 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:05 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:06 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:07] INFO:     127.0.0.1:40268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:44:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:44:07 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:44:08 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:44:09 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:44:10 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:44:10 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:11 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:12 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:13 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:14 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:15 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:15 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:16 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:17 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:18 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:19 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:20 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:20 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:21 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:22 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:23 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:23] INFO:     127.0.0.1:46568 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:44:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:44:24 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:44:25 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:44:25 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:44:26 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:44:27 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:44:28 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:29 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:29 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:30 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:31 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:32 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:33 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:34 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:34 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:35 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:36 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:37 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:38 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:44:38 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:39 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:40] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:44:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:44:40 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 03:44:41 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:42 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:43 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:44:43 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:44 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:45 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:44:46 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:44:47 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:48 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:48 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:44:49 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:50 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:44:51 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:52 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:44:52 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:53 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:44:54 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:44:55 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:44:56 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:44:56] INFO:     127.0.0.1:34982 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:44:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:44:57 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:44:57 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:44:58 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:44:59 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:00 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:01 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:02 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:45:02 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:45:03 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:04 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:05 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:06 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:07 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:07 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:08 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:09 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:10 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:11 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:11 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:12 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:13] INFO:     127.0.0.1:39372 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:45:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:45:13 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:45:14 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:45:15 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:45:16 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:45:16 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:17 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:18 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:19 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:20 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:21 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:21 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:22 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:23 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:24 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:25 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:25 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:26 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:27 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:28 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:29 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:29] INFO:     127.0.0.1:40342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:45:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:45:30 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:45:30 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:31 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:32 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:33 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:34 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:35 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:35 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:36 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:37 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:45:38 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:39 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:45:39 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:40 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:41 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:45:42 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:43 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:45:44 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:45:44 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:45:45 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:45:46] INFO:     127.0.0.1:42956 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:45:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:45:46 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:45:47 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:45:48 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:45:49 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:45:49 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:45:50 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:51 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:45:52 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:45:53 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:45:54 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:54 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:55 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:56 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:45:57 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:58 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:45:58 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:45:59 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:00 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:01 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:46:02 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:02] INFO:     127.0.0.1:33362 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:46:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:46:03 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:46:03 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:46:04 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:05 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:06 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:07 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:08 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:08 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:09 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:10 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:11 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:12 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:12 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:13 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:14 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:15 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:16 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:17 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:17 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:18 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:19] INFO:     127.0.0.1:54668 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:46:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:46:19 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:46:20 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:46:21 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:46:22 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:46:22 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:23 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:24 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:25 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:26 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:26 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:27 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:28 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:29 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:30 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:31 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:31 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:32 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:33 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:34 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:35 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:35] INFO:     127.0.0.1:56832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:46:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:46:36 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:46:36 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:37 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:38 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:46:39 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:40 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:40 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:41 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:42 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:43 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:44 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:45 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:45 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:46 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:47 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:46:48 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:49 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:49 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:50 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:46:51 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:46:52] INFO:     127.0.0.1:35820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:46:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:46:52 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:46:53 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:46:54 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:46:54 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:55 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:56 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:46:57 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:46:58 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:46:59 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:46:59 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:47:00 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:01 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:02 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:03 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:04 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:04 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:05 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:06 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:07 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:08 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:08] INFO:     127.0.0.1:45990 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:47:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:47:09 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:47:09 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:10 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:47:11 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:12 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:47:13 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:13 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:47:14 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:15 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:16 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:17 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:18 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:18 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:19 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:20 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:47:21 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:47:22 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:22 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:23 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:24 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:47:25] INFO:     127.0.0.1:41888 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:47:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:47:25 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:47:26 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:47:27 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:47:27 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:47:28 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:47:29 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:47:30 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:31 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:32 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:32 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:33 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:34 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:35 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:36 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:36 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:37 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:38 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:39 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:40 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:41 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:41] INFO:     127.0.0.1:56744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:47:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:47:41 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:47:42 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:47:43 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:47:44 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:47:45 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:47:46 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:46 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:47 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:48 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:47:49 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:50 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:50 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:51 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:52 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:53 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:54 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:47:55 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:55 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:47:56 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:57 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:47:58] INFO:     127.0.0.1:46494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:47:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:47:58 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:47:59 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:48:00 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:48:00 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:01 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:02 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:03 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:04 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:05 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:05 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:06 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:07 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:08 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:09 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:09 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:10 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:11 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:12 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:13 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:14 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:14] INFO:     127.0.0.1:57334 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:48:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:48:14 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:48:15 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:48:16 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:48:17 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:48:18 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:19 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:19 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:20 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:21 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:22 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:23 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:23 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:24 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:25 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:26 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:27 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:28 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:28 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:29 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:30 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:31] INFO:     127.0.0.1:50174 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:48:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:48:31 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:48:32 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:33 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:33 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:48:34 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:35 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:36 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:37 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:37 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:38 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:39 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:48:40 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:41 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:42 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:42 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:43 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:44 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:45 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:46 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:47 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:48:47] INFO:     127.0.0.1:49938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:48:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:48:47 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:48:48 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:48:49 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:50 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:48:51 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:52 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:48:52 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:48:53 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:54 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:55 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:48:56 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:56 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:48:57 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:48:58 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:48:59 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:00 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:01 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:01 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:02 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:03 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:04] INFO:     127.0.0.1:60172 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:49:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:49:04 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.74, #queue-req: 0, 
[2025-10-18 03:49:05 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:49:06 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:49:06 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:49:07 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:49:08 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:09 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:49:10 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:10 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:11 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:12 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:13 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:14 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:15 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:15 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:16 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:17 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:49:18 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:49:19 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:49:19 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:20] INFO:     127.0.0.1:49164 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:49:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:49:20 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:49:21 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:22 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:49:23 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:49:24 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:49:24 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:25 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:49:26 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:27 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:49:28 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:29 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:29 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:30 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:31 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:32 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:33 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:34 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:34 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:35 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:36 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:37] INFO:     127.0.0.1:39154 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:49:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:49:37 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:49:38 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:39 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:39 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:49:40 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:41 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:42 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:43 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:43 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:49:44 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:45 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:49:46 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:47 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:48 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:48 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:49 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:50 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:51 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:49:52 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:52 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:49:53] INFO:     127.0.0.1:56748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:49:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:49:53 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.95, #queue-req: 0, 
[2025-10-18 03:49:54 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:49:55 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:49:56 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:49:57 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:57 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:58 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:49:59 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:00 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:01 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:02 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:02 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:03 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:04 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:05 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:06 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:06 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:07 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:08 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:09 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:10] INFO:     127.0.0.1:54020 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:50:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:50:10 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.26, #queue-req: 0, 
[2025-10-18 03:50:11 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:11 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:12 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:13 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:50:14 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:15 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:50:16 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:16 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:17 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:18 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:19 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:20 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:20 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:21 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:22 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:23 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:24 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:25 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:25 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:26] INFO:     127.0.0.1:36232 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:50:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:50:26 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:50:27 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:28 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:50:29 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:30 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:30 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:31 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:50:32 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:33 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:34 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:35 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:35 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:36 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:37 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:38 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:39 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:39 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:40 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:41 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:42 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:43] INFO:     127.0.0.1:47772 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:50:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:50:43 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:50:44 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:44 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:50:45 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:50:46 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:47 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:48 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:50:49 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:49 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:50 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:50:51 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:52 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:50:53 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:53 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:54 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:55 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:56 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:50:57 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:58 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:50:58 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:50:59] INFO:     127.0.0.1:37738 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:50:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:50:59 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:51:00 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:51:01 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:51:02 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:51:03 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:03 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:51:04 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:05 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:06 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:07 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:07 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:08 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:09 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:10 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:11 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:12 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:12 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:13 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:14 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:15 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:16] INFO:     127.0.0.1:59710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:51:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:51:16 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:51:17 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:17 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:51:18 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:19 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:51:20 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:21 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:21 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:22 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:23 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:24 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:25 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:26 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:26 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:27 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:28 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:29 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:30 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:31 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:31 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:32] INFO:     127.0.0.1:59718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:51:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:51:32 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:51:33 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:34 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:35 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:36 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:36 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:37 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:51:38 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:51:39 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:51:40 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:40 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:51:41 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:51:42 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:51:43 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:51:44 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:51:45 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 03:51:45 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:51:46 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:51:47 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:51:48 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 03:51:49] INFO:     127.0.0.1:45392 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:51:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:51:49 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.26, #queue-req: 0, 
[2025-10-18 03:51:50 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:50 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:51 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:52 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:53 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:51:54 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:51:54 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:55 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:56 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:57 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:51:58 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:51:59 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:51:59 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:00 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:01 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:02 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:03 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:04 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:52:04 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:05] INFO:     127.0.0.1:54376 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:52:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:52:05 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 03:52:06 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:07 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:08 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:52:09 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:09 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:10 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:11 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:12 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:13 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:13 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:14 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:15 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:16 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:17 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:18 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:18 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:19 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:20 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:52:21 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:22] INFO:     127.0.0.1:38554 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:52:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:52:22 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:52:23 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:52:23 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:24 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:25 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:26 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:27 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:27 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:28 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:29 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:30 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:31 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:32 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:32 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:33 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:34 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:35 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:36 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:36 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:37 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:38] INFO:     127.0.0.1:44338 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:52:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:52:38 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:52:39 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:52:40 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:52:41 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:41 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:52:42 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:52:43 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:44 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:45 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:46 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:46 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:47 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:48 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:49 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:50 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:50 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:51 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:52:52 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:53 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:54 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:54] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:52:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:52:55 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:52:55 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:52:56 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:52:57 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:52:58 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:52:59 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:00 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:00 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:01 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:02 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:03 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:04 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:05 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:05 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:06 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:53:07 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:08 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:09 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:09 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:10 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:53:11] INFO:     127.0.0.1:55272 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:53:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:53:11 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:53:12 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:53:13 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:14 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:14 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:53:15 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:53:16 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:53:17 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:18 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:19 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:19 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:20 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:21 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:22 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:23 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:23 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:24 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:25 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:26 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:27 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:27] INFO:     127.0.0.1:58268 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:53:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:53:28 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:53:28 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:29 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:30 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:53:31 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:32 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:33 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:33 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:34 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:35 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:36 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:37 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:37 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:38 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:39 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:53:40 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:41 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:53:42 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:53:42 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:53:43 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:53:44] INFO:     127.0.0.1:40274 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:53:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:53:44 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:53:45 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:53:46 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:53:47 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:53:47 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:48 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:53:49 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:53:50 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:51 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:53:52 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:52 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:53 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:54 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:55 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:53:56 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:56 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:57 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:53:58 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:53:59 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:00 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:00] INFO:     127.0.0.1:58934 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:54:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:54:01 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.78, #queue-req: 0, 
[2025-10-18 03:54:01 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:02 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:03 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:04 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:05 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:06 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:06 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:07 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:08 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:09 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:10 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:10 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:11 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:12 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:13 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:14 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:15 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:15 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:16 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:17] INFO:     127.0.0.1:60482 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:54:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:54:17 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:54:18 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:19 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:20 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:20 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:54:21 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:22 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:23 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:24 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:24 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:25 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:26 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:27 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:28 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:29 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:54:29 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:30 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:31 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:32 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:33 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:54:33] INFO:     127.0.0.1:37236 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:54:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:54:34 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:54:34 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:54:35 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:54:36 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:37 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:54:38 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:54:39 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:39 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:40 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:41 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:42 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:43 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:43 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:44 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:45 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:46 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:47 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:48 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:48 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:54:49 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:50] INFO:     127.0.0.1:35004 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:54:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:54:50 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:54:51 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:52 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:53 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:54:53 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:54:54 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:54:55 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:54:56 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:57 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:57 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:54:58 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:54:59 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:00 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:01 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:02 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:02 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:03 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:04 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:05 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:06 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:06] INFO:     127.0.0.1:33466 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:55:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:55:07 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:55:07 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:55:08 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:55:09 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:55:10 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:55:11 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:55:11 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:55:12 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:55:13 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:55:14 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:15 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:55:16 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:16 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:17 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:18 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:19 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:20 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:20 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:21 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:22 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:23] INFO:     127.0.0.1:44330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:55:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:55:23 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:55:24 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:55:25 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:55:25 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:55:26 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:55:27 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:28 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:29 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:30 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:30 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:31 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:32 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:33 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:34 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:35 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:35 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:36 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:37 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:38 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:39 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:39] INFO:     127.0.0.1:50800 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:55:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:55:40 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:55:40 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:41 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:55:42 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:43 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:44 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:55:44 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:55:45 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:46 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:55:47 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:55:48 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:55:49 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:55:49 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:50 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:51 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:52 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:53 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:55:53 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:54 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 03:55:55 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:55:56] INFO:     127.0.0.1:47942 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:55:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:55:56 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:55:57 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:55:58 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:55:58 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:55:59 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:56:00 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:01 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:02 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:03 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:03 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:04 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:05 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:06 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:07 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:07 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:08 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:09 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:10 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:11 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:12 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:12] INFO:     127.0.0.1:60616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:56:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:56:12 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:56:13 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:56:14 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:56:15 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:56:16 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:56:17 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:17 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:18 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:19 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:20 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:21 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:21 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:22 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:23 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:24 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:25 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:26 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:26 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:27 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:28 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:29] INFO:     127.0.0.1:43012 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:56:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:56:29 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:56:30 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:56:31 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:56:31 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:32 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:33 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:34 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:35 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:36 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:36 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:37 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:38 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:39 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:40 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:40 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:41 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:42 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:43 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:44 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:45 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:45] INFO:     127.0.0.1:40780 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:56:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:56:45 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:56:46 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:47 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:56:48 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:49 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:56:50 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:50 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:51 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:56:52 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:53 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:54 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:54 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:56:55 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:56:56 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:57 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:58 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:59 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:56:59 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:00 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:01 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:02] INFO:     127.0.0.1:56264 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:57:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:57:02 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:57:03 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:04 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:57:04 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:57:05 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:57:06 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:07 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:08 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:57:08 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:09 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:10 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:11 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:12 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:13 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:13 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:14 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:15 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:16 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:57:17 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:17 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:18] INFO:     127.0.0.1:39438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:57:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:57:18 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:57:19 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:20 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:21 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:22 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:23 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:57:23 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:24 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:25 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:26 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:27 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:27 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:57:28 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:29 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:30 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:31 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:57:32 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:32 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:33 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:57:34 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:35] INFO:     127.0.0.1:38520 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:57:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:57:35 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 03:57:36 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:57:37 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:57:37 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:57:38 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:57:39 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:57:40 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:57:41 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:41 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:42 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:43 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:57:44 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:45 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:57:46 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:46 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:47 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:48 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:57:49 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:57:50 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:50 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:57:51] INFO:     127.0.0.1:60606 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:57:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:57:51 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:57:52 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:57:53 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:57:54 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:57:55 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:57:55 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:57:56 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:57:57 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:57:58 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:57:59 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:00 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:00 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:01 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:02 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:03 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:04 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:04 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:05 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:06 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:07 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:08] INFO:     127.0.0.1:57848 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:58:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:58:08 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:58:09 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:09 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:58:10 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:11 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:12 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:13 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:14 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:14 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:15 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:16 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:17 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:18 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:18 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:19 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:20 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:21 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:22 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:23 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 03:58:23 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:24] INFO:     127.0.0.1:43382 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:58:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:58:24 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:58:25 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:58:26 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 03:58:27 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:58:28 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:58:28 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:29 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:30 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:31 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:32 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:33 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:33 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:34 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:35 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:36 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:37 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:37 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:38 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:39 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:58:40 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:41] INFO:     127.0.0.1:60404 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:58:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:58:41 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 03:58:42 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:58:42 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:58:43 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:58:44 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:58:45 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:46 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:58:47 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:47 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:48 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:58:49 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:50 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:51 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:51 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:58:52 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:53 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:54 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:58:55 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:56 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:58:56 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:58:57] INFO:     127.0.0.1:57726 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:58:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:58:57 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 03:58:58 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:58:59 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 03:59:00 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:59:01 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 03:59:01 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 03:59:02 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:59:03 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:59:04 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:05 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:59:05 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:06 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:07 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:08 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:09 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:10 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:10 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:11 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:12 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:13 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:14] INFO:     127.0.0.1:43902 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:59:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:59:14 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 03:59:15 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:15 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:16 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:17 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:18 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:19 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:19 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:20 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:21 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:22 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:23 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:24 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:24 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:25 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:26 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:27 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:28 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:29 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 03:59:29 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:30] INFO:     127.0.0.1:48512 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 03:59:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 03:59:30 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 03:59:31 TP0] Decode batch. #running-req: 1, #token: 3247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:59:32 TP0] Decode batch. #running-req: 1, #token: 3287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:33 TP0] Decode batch. #running-req: 1, #token: 3327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 03:59:34 TP0] Decode batch. #running-req: 1, #token: 3367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:34 TP0] Decode batch. #running-req: 1, #token: 3407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 03:59:35 TP0] Decode batch. #running-req: 1, #token: 3447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 03:59:36 TP0] Decode batch. #running-req: 1, #token: 3487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 03:59:37 TP0] Decode batch. #running-req: 1, #token: 3527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:38 TP0] Decode batch. #running-req: 1, #token: 3567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:38 TP0] Decode batch. #running-req: 1, #token: 3607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 03:59:39 TP0] Decode batch. #running-req: 1, #token: 3647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:40 TP0] Decode batch. #running-req: 1, #token: 3687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:41 TP0] Decode batch. #running-req: 1, #token: 3727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:42 TP0] Decode batch. #running-req: 1, #token: 3767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:43 TP0] Decode batch. #running-req: 1, #token: 3807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:43 TP0] Decode batch. #running-req: 1, #token: 3847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:44 TP0] Decode batch. #running-req: 1, #token: 3887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:45 TP0] Decode batch. #running-req: 1, #token: 3927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 03:59:46 TP0] Decode batch. #running-req: 1, #token: 3967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 03:59:47] INFO:     127.0.0.1:38554 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 04:00:02] INFO:     127.0.0.1:59766 - "GET /v1/models HTTP/1.1" 200 OK
[2025-10-18 04:00:08] INFO:     127.0.0.1:55342 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:00:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:00:08 TP0] Decode batch. #running-req: 1, #token: 3207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1.82, #queue-req: 0, 
[2025-10-18 04:00:09] INFO:     127.0.0.1:55356 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:00:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:00:10 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.08, #queue-req: 0, 
[2025-10-18 04:00:11 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:11 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:12 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:00:13 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:00:14 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:00:15 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:15 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:16 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:17 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:18 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:19 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:20 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:20 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:21 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:00:22 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:23 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:00:24 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:24 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:00:25 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:26] INFO:     127.0.0.1:42916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:00:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:00:26 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.18, #queue-req: 0, 
[2025-10-18 04:00:27 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:00:28 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:29 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:00:29 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:30 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:31 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:00:32 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:00:33 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:34 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:34 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:35 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:36 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:37 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:38 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:38 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:39 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:40 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:41 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:42 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:00:42] INFO:     127.0.0.1:40866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:00:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:00:43 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:00:43 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:00:44 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:45 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:46 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:47 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:00:48 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:00:48 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:00:49 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:50 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:51 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:52 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:53 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:53 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:54 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:55 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:56 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:00:57 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:00:57 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:00:58 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:00:59] INFO:     127.0.0.1:59168 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:00:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:00:59 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 04:01:00 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:01 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:02 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:02 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:03 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:04 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:05 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:06 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:07 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:07 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:08 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:09 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:10 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:11 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:11 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:12 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:01:13 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:14 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:01:15 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:01:15] INFO:     127.0.0.1:46656 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:01:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:01:16 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:01:16 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:01:17 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:01:18 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:19 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:01:20 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:01:21 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:21 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:22 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:23 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:24 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:25 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:25 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:26 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:27 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:28 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:29 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:30 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:30 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:31 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:32] INFO:     127.0.0.1:57926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:01:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:01:32 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.19, #queue-req: 0, 
[2025-10-18 04:01:33 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:34 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:35 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:35 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:36 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:37 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:38 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:39 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:39 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:40 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:41 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:42 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:43 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:44 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:44 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:45 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:46 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:47 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:48 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:01:48] INFO:     127.0.0.1:53202 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:01:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:01:49 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:01:49 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:01:50 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:01:51 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:01:52 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:53 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:54 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:01:54 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:55 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:01:56 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:01:57 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:58 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:01:58 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:01:59 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:00 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:01 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:02 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:02:03 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:03 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:02:04 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:05] INFO:     127.0.0.1:58324 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:02:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:02:05 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:02:06 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:02:07 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:02:08 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:02:08 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:02:09 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:02:10 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:11 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:12 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:12 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:13 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:14 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:15 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:16 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:17 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:17 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:18 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:19 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:20 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:21 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:21] INFO:     127.0.0.1:38402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:02:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:02:22 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.24, #queue-req: 0, 
[2025-10-18 04:02:22 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:02:23 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:24 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:25 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:26 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:26 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:27 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:28 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:29 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:30 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:31 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:31 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:32 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:33 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:34 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:35 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:02:35 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:02:36 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:37 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:02:38] INFO:     127.0.0.1:43330 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:02:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:02:38 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:02:39 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:02:40 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:02:40 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:02:41 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:42 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:02:43 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:44 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:45 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:45 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:46 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:47 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:48 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:49 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:50 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:50 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:51 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:52 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:53 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:02:54 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:02:54] INFO:     127.0.0.1:51344 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:02:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:02:55 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:02:55 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:56 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:57 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:02:58 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:02:59 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:02:59 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:03:00 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:01 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:02 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:03 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:04 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:04 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:05 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:06 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:07 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:08 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:08 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:09 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:10 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:03:11] INFO:     127.0.0.1:50678 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:03:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:03:11 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:03:12 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:03:13 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:13 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:14 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:03:15 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:03:16 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:17 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:18 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:18 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:19 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:20 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:21 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:22 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:22 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:23 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:24 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:25 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:26 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:27 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:27] INFO:     127.0.0.1:42452 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:03:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:03:27 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:03:28 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:29 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:30 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:31 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:03:32 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:03:32 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:03:33 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:34 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:03:35 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:36 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:36 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:37 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:38 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:39 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:40 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:41 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:03:41 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:42 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:43 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:03:44] INFO:     127.0.0.1:46288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:03:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:03:44 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:03:45 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:03:46 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:46 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:03:47 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:48 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:49 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:50 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:03:51 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:03:51 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:52 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:53 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:54 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:55 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:55 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:56 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:03:57 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:03:58 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:03:59 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:00 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:04:00] INFO:     127.0.0.1:55744 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:04:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:04:00 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:04:01 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:02 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:04:03 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:04 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:05 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:05 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:04:06 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:07 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:08 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:09 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:09 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:10 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:11 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:12 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:13 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:14 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:14 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:15 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:16 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:04:17] INFO:     127.0.0.1:58188 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:04:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:04:17 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:04:18 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:04:19 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:04:19 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:20 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:04:21 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:04:22 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:23 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:23 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:04:24 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:25 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:26 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:27 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:28 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:28 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:29 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:30 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:31 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:32 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:32 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:33] INFO:     127.0.0.1:43182 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:04:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:04:33 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:04:34 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:04:35 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:04:36 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:37 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:37 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:38 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:39 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:40 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:41 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:42 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:04:42 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:43 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:44 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:04:45 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:46 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:47 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:04:47 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:04:48 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:04:49 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:04:50] INFO:     127.0.0.1:40846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:04:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:04:50 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:04:51 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:04:52 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:04:52 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:04:53 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:54 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:55 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:04:56 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:04:56 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:04:57 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:58 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:04:59 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:00 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:01 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:01 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:02 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:03 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:04 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:05 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:05 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:06] INFO:     127.0.0.1:47106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:05:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:05:06 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:05:07 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:08 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:05:09 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:05:10 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:05:10 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:11 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:12 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:13 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:14 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:15 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:15 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:16 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:17 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:18 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:19 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:19 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:20 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:21 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:22 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:22] INFO:     127.0.0.1:60336 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:05:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:05:23 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:05:24 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:05:24 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:25 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:26 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:27 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:28 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:29 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:29 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:30 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:31 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:32 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:33 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:33 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:34 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:35 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:36 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:37 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:38 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:38 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:39] INFO:     127.0.0.1:40472 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:05:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:05:39 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:05:40 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:41 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:05:42 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:43 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:05:43 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:44 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:45 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:46 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:05:47 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:48 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:48 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:49 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:50 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:51 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:52 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:05:52 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:53 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:05:54 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:05:55 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:05:55] INFO:     127.0.0.1:48218 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:05:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:05:56 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 04:05:57 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:05:57 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:05:58 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:05:59 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:00 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:01 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:02 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:02 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:06:03 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:04 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:05 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:06 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:06 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:07 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:08 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:09 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:10 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:11 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:11 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:12] INFO:     127.0.0.1:59470 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:06:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:06:12 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:06:13 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:14 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:06:15 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:16 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:16 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:06:17 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:06:18 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:06:19 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:20 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:20 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:21 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:22 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:23 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:24 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:25 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:25 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:06:26 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:27 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:06:28 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:28] INFO:     127.0.0.1:55938 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:06:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:06:29 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:06:30 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:06:30 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:06:31 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:32 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:06:33 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:34 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:06:34 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:35 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:36 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:06:37 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:38 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:39 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:39 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:40 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:41 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:42 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:06:43 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:44 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:44 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:45] INFO:     127.0.0.1:45402 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:06:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:06:45 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:06:46 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:06:47 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:06:48 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:49 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:06:49 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:06:50 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:06:51 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:52 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:06:53 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:53 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:06:54 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:55 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:56 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:57 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:06:58 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:06:58 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:06:59 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:07:00 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:07:01 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:07:01] INFO:     127.0.0.1:57556 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:07:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:07:02 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.22, #queue-req: 0, 
[2025-10-18 04:07:03 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:03 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:04 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:07:05 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:06 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:07 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:07 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:08 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:09 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:10 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:11 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:12 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:12 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:13 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:14 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:15 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:16 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:16 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:07:17 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:18] INFO:     127.0.0.1:50754 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:07:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:07:18 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:07:19 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:20 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:07:21 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:07:21 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:22 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:23 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:24 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:25 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:26 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:26 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:27 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:28 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:29 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:30 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:31 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:31 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:32 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:33 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:34 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:34] INFO:     127.0.0.1:53084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:07:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:07:35 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:07:36 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:07:36 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:37 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:07:38 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:39 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:40 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:40 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:41 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:42 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:43 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:44 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:45 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:45 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:46 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:47 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:48 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:07:49 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:07:49 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:50 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:07:51] INFO:     127.0.0.1:32936 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:07:51 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:07:52 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:53 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:54 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:54 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:07:55 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:07:56 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:07:57 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:58 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:07:59 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:07:59 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:00 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:01 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:02 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:03 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:03 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:04 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:05 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:06 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:08:07 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:07] INFO:     127.0.0.1:53302 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:08:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:08:08 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:08:08 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:09 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:10 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:08:11 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:08:12 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:13 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:08:13 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:14 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:15 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:08:16 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:17 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:18 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:18 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:19 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:20 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:21 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:22 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:22 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:23 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:24] INFO:     127.0.0.1:45146 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:08:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:08:24 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:08:25 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:26 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:08:27 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:08:27 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:28 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:08:29 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:30 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:31 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:32 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:32 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:33 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:34 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:35 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:36 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:36 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:37 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:38 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:39 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:40 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:40] INFO:     127.0.0.1:37450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:08:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:08:41 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 04:08:41 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:42 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:43 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:08:44 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:45 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:46 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:46 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:47 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:48 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:49 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:50 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:50 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:08:51 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:52 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:53 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:54 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:55 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:08:55 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:08:56 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:08:57] INFO:     127.0.0.1:36638 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:08:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:08:57 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:08:58 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:08:59 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:09:00 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:09:00 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:09:01 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:09:02 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:09:03 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:09:04 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:04 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:05 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:06 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:07 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:08 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:09 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:09 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:10 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:11 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:12 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:13 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:13] INFO:     127.0.0.1:49822 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:09:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:09:14 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:09:14 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:09:15 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:09:16 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:09:17 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:18 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:19 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:09:19 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:20 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:21 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:22 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:23 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:23 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:24 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:25 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:26 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:27 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:28 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:28 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:29 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:30] INFO:     127.0.0.1:53424 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:09:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:09:30 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:09:31 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:09:32 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:33 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:33 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:34 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:35 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:09:36 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:37 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:37 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:38 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:39 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:40 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:41 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:42 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:42 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:43 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:44 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:45 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:46 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:46] INFO:     127.0.0.1:35388 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:09:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:09:47 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:09:47 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:09:48 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:49 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:09:50 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:51 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:51 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:09:52 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:53 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:54 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:55 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:56 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:56 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:09:57 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:09:58 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:09:59 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:00 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:01 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:10:01 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:10:02 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:03] INFO:     127.0.0.1:47216 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:10:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:10:03 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:10:04 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:10:05 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:10:06 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:10:06 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:07 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:08 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:09 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:10 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:10 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:10:11 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:12 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:13 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:14 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:15 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:15 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:16 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:17 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:18 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:19 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:19] INFO:     127.0.0.1:55866 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:10:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:10:20 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:10:20 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:10:21 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:22 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:23 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:24 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:24 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:25 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:26 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:27 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:28 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:29 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:29 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:30 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:31 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:32 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:33 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:33 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:34 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:35 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:36] INFO:     127.0.0.1:56368 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:10:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:10:36 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:10:37 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:38 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:10:38 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:39 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:10:40 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:41 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:10:42 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:43 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:10:43 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:44 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:45 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:46 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:10:47 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:10:47 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:48 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:49 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:50 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:51 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:10:52 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:10:52] INFO:     127.0.0.1:54820 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:10:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:10:52 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:10:53 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:10:54 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:10:55 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:10:56 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:57 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:10:57 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:10:58 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:10:59 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:00 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:01 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:01 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:02 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:03 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:04 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:05 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:06 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:06 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:07 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:08 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:09] INFO:     127.0.0.1:32870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:11:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:11:09 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:11:10 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:11:11 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:11:11 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:12 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:13 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:14 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:15 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:16 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:16 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:17 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:18 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:19 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:20 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:20 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:21 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:22 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:23 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:24 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:25 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:25] INFO:     127.0.0.1:58340 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:11:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:11:25 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:11:26 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:11:27 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:11:28 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:11:29 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:30 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:30 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:31 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:32 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:33 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:11:34 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:34 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:35 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:36 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:37 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:38 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:39 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:39 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:40 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:41 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:42] INFO:     127.0.0.1:59808 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:11:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:11:42 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 04:11:43 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:11:44 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:11:44 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:45 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:46 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:11:47 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:11:48 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:48 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:49 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:50 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:11:51 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:52 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:53 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:53 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:54 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:11:55 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:11:56 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:57 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:11:57 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:11:58] INFO:     127.0.0.1:51078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:11:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:11:58 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:11:59 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:00 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:01 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:02 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:02 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:12:03 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:12:04 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:12:05 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:12:06 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:12:07 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:12:07 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:12:08 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:12:09 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:12:10 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:12:11 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:12:12 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:12:12 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:12:13 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:12:14 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:12:15] INFO:     127.0.0.1:44130 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:12:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:12:15 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:12:16 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:17 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:17 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:18 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:12:19 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:20 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:21 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:21 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:12:22 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:23 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:24 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:12:25 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:26 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:26 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:27 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:28 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:29 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:30 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:30 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:31] INFO:     127.0.0.1:49276 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:12:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:12:31 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:12:32 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:12:33 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:12:34 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:12:35 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:12:35 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:12:36 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:12:37 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:38 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:39 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:40 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:40 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:41 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:42 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:12:43 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:44 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:44 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:45 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:46 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:47 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:12:47] INFO:     127.0.0.1:35646 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:12:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:12:48 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:12:49 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:49 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:50 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:12:51 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:52 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:53 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:12:54 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:54 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:12:55 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:56 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:12:57 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:58 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:12:58 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:12:59 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:00 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:01 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:02 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:03 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:03 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:04] INFO:     127.0.0.1:37926 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:13:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:13:04 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:13:05 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:06 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:07 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:13:08 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:13:08 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:09 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:10 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:11 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:12 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:13:13 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:13 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:14 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:15 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:16 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:17 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:17 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:18 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:19 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:13:20 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:20] INFO:     127.0.0.1:33450 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:13:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:13:21 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:13:22 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:22 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:23 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:24 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:25 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:13:26 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:27 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:27 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:28 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:29 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:30 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:31 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:31 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:32 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:33 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:34 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:35 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:13:36 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:36 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:13:37] INFO:     127.0.0.1:48930 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:13:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:13:37 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:13:38 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:13:39 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:13:40 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:13:41 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:41 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:13:42 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:43 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:44 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:45 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:45 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:46 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:47 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:48 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:49 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:50 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:50 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:51 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:13:52 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:53 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:13:53] INFO:     127.0.0.1:56462 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:13:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:13:54 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:13:55 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:13:55 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:56 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:13:57 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:13:58 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:59 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:13:59 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:00 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:01 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:02 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:03 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:04 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:04 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:05 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:06 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:07 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:08 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:09 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:14:09 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:10] INFO:     127.0.0.1:33128 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:14:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:14:10 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:14:11 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:14:12 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:14:13 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:14 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:14:14 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:15 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:16 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:17 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:18 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:18 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:19 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:20 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:21 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:22 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:14:23 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:23 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:24 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:14:25 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:26 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:26] INFO:     127.0.0.1:47534 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:14:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:14:27 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.04, #queue-req: 0, 
[2025-10-18 04:14:28 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:14:28 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:14:29 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:14:30 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:14:31 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:32 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:32 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:33 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:34 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:35 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:36 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:37 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:37 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:38 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:39 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:40 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:14:41 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:41 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:42 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:43] INFO:     127.0.0.1:58864 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:14:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:14:43 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 04:14:44 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:14:45 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:46 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:46 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:47 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:48 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:14:49 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:50 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:51 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:51 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:52 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:14:53 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:54 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:55 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:55 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:56 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:57 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:14:58 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:14:59 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:14:59] INFO:     127.0.0.1:45160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:14:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:15:00 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 04:15:00 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.96, #queue-req: 0, 
[2025-10-18 04:15:01 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 04:15:02 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 04:15:03 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.95, #queue-req: 0, 
[2025-10-18 04:15:04 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 04:15:05 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 04:15:05 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 04:15:06 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.94, #queue-req: 0, 
[2025-10-18 04:15:07 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 04:15:08 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 04:15:09 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:15:09 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 04:15:10 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 04:15:11 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
[2025-10-18 04:15:12 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:15:13 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-10-18 04:15:14 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:15:14 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:15:15 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:15:16] INFO:     127.0.0.1:51842 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:15:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:15:16 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 04:15:17 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:15:18 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:15:19 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:15:19 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:15:20 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:15:21 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:15:22 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:15:23 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:23 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:24 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:15:25 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:26 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:27 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:28 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:28 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:29 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:30 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:31 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:32 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:32] INFO:     127.0.0.1:55454 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:15:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:15:33 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:15:33 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:34 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:35 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:36 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:37 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:37 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:38 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:39 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:40 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:41 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:42 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:42 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:43 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:44 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:15:45 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:46 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:47 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:47 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:15:48 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:49] INFO:     127.0.0.1:35304 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:15:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:15:49 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.26, #queue-req: 0, 
[2025-10-18 04:15:50 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:51 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:52 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:52 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:15:53 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:54 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:55 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:15:56 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:15:56 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:57 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:58 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:15:59 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:16:00 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:16:01 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:16:01 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:16:02 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:16:03 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:16:04 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:16:05 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:16:05] INFO:     127.0.0.1:60870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:16:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:16:06 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:16:06 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:16:07 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:08 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:16:09 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:10 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:10 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:11 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:12 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:13 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:14 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:15 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:15 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:16 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:17 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:18 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:19 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:19 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:16:20 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:21 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:16:22] INFO:     127.0.0.1:37418 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:16:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:16:22 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:16:23 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.90, #queue-req: 0, 
[2025-10-18 04:16:24 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.87, #queue-req: 0, 
[2025-10-18 04:16:24 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:16:25 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:16:26 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:16:27 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:16:28 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:29 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:16:29 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:30 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:31 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:32 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:33 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:33 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:34 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:35 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:36 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:37 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:38 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:38] INFO:     127.0.0.1:47914 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:16:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:16:38 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:16:39 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:16:40 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:16:41 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:16:42 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:16:43 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:16:43 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:16:44 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:16:45 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:46 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:47 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:48 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:48 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:49 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:50 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:51 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:52 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:52 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:53 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:16:54 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:16:55] INFO:     127.0.0.1:53104 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:16:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:16:55 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:16:56 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:16:57 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:16:57 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:16:58 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:16:59 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:00 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:01 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:17:02 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:02 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:17:03 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:17:04 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:05 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:06 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:06 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:07 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:08 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:09 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:10 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:11 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:11] INFO:     127.0.0.1:60704 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:17:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:17:11 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:17:12 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:17:13 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:17:14 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:17:15 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:16 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:17:16 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:17:17 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:18 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:17:19 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:20 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:20 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:21 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:22 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:23 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:24 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:25 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:25 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:26 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:27 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:17:28] INFO:     127.0.0.1:34690 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:17:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:17:28 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:17:29 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:17:30 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:30 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:31 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:32 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:33 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:34 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:34 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:17:35 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:36 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:37 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:17:38 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:39 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:39 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:17:40 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:41 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:42 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:17:43 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:17:44 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:17:44] INFO:     127.0.0.1:60972 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:17:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:17:44 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 04:17:45 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:46 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:17:47 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:17:48 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:17:49 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:49 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:17:50 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:51 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:17:52 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:53 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:53 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:17:54 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:55 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:56 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:57 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:17:58 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:17:58 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:17:59 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:00 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:01] INFO:     127.0.0.1:33948 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:18:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:18:01 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:18:02 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:03 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:18:03 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:18:04 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:05 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:06 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:07 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:07 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:08 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:09 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:10 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:11 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:12 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:12 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:13 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:14 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:15 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:16 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:16 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:17] INFO:     127.0.0.1:57384 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:18:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:18:17 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:18:18 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:18:19 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:18:20 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:18:21 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:21 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:22 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:23 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:24 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:25 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:26 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:26 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:27 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:28 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:29 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:30 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:30 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:31 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:32 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:33 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:33] INFO:     127.0.0.1:51480 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:18:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:18:34 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:18:35 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:35 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:18:36 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:37 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:38 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:18:39 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:40 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:40 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:41 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:42 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:43 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:44 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:45 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:45 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:18:46 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:47 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:48 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:18:49 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:49 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:18:50] INFO:     127.0.0.1:38242 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:18:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:18:50 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:18:51 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:18:52 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:18:53 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:54 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:54 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:18:55 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:56 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:18:57 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:58 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:18:59 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:18:59 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:00 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:01 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:02 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:03 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:03 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:04 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:05 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:06 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:06] INFO:     127.0.0.1:48328 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:19:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:19:07 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:19:08 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:08 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:19:09 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:10 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:11 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:12 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:13 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:13 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:14 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:15 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:16 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:17 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:17 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:18 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:19 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:20 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:21 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:22 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:22 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:23] INFO:     127.0.0.1:48856 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:19:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:19:23 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:19:24 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:19:25 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:19:26 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:19:27 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:27 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:28 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:29 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:30 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:31 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:31 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:32 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:33 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:34 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:35 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:36 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:36 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:37 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:38 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:39 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:39] INFO:     127.0.0.1:49200 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:19:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:19:40 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:19:41 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:19:41 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:42 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:43 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:44 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:19:45 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:46 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:46 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:47 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:48 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:19:49 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:50 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:50 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:51 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:52 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:19:53 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:19:54 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:55 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:19:55 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:19:56] INFO:     127.0.0.1:59160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:19:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:19:56 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:19:57 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:19:58 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:19:59 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:00 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:20:00 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:01 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:02 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:03 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:04 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:04 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:05 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:06 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:07 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:08 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:09 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:09 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:10 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:11 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:12 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:12] INFO:     127.0.0.1:56870 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:20:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:20:13 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:20:14 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:20:14 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:15 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:16 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:17 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:18 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:18 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:20:19 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:20 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:21 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:22 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:23 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:23 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:20:24 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:20:25 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:26 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:20:27 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:20:28 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:28 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:20:29] INFO:     127.0.0.1:47160 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:20:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:20:29 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:20:30 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:20:31 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:20:32 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:33 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:33 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:20:34 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:35 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:36 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:37 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:37 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:38 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:39 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:40 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:41 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:42 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:42 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:43 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:44 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:45 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:45] INFO:     127.0.0.1:33878 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:20:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:20:46 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:20:47 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:20:47 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:20:48 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:20:49 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:20:50 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:51 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:51 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:20:52 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:53 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:54 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:55 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:56 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:56 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:20:57 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:20:58 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:20:59 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:00 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:00 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:01 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:02] INFO:     127.0.0.1:49508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:21:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:21:02 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:21:03 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:04 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:21:05 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:05 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:06 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:21:07 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:21:08 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:21:09 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:21:10 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:10 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:21:11 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:21:12 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:13 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:21:14 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:14 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:15 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:21:16 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:17 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:18 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:21:18] INFO:     127.0.0.1:35960 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:21:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:21:19 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:21:20 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:21:20 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:21:21 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:21:22 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:21:23 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:24 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:24 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:21:25 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:26 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:21:27 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:28 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:29 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:21:29 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:30 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:31 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:32 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:33 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:21:33 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:34 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:35] INFO:     127.0.0.1:56608 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:21:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:21:35 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.35, #queue-req: 0, 
[2025-10-18 04:21:36 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:21:37 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:38 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:38 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:39 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:40 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:41 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:42 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:43 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:43 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:44 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:45 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:46 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:47 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:47 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:48 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:49 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:21:50 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:21:51 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:51] INFO:     127.0.0.1:58980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:21:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:21:52 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:21:52 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:21:53 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:21:54 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:21:55 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:56 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:21:57 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:21:57 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:21:58 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:21:59 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:00 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:01 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:01 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:02 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:03 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:04 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:05 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:06 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:06 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:07 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:08] INFO:     127.0.0.1:34788 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:22:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:22:08 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.34, #queue-req: 0, 
[2025-10-18 04:22:09 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:22:10 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:22:11 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:22:11 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:12 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:13 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:14 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:15 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:15 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:16 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:17 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:18 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:19 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:20 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:20 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:21 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:22 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:23 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:24 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:22:24] INFO:     127.0.0.1:49596 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:22:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:22:25 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.17, #queue-req: 0, 
[2025-10-18 04:22:25 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:22:26 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:22:27 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:28 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:22:29 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:30 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:30 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:31 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:32 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:33 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:22:34 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:34 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:35 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:36 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:22:37 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:38 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:39 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:39 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:40 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:41] INFO:     127.0.0.1:42594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:22:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:22:41 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:22:42 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:43 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:22:44 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:44 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:22:45 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:46 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:47 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:22:48 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:22:48 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:49 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:50 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:22:51 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:52 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:53 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:22:53 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:54 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:22:55 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:22:56 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:22:57 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:22:57] INFO:     127.0.0.1:48258 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:22:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:22:58 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.26, #queue-req: 0, 
[2025-10-18 04:22:58 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:22:59 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:23:00 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:01 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:23:02 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:23:02 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:23:03 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:04 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:05 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:06 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:07 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:07 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:08 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:09 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:10 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:11 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:12 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:12 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:13 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:14] INFO:     127.0.0.1:56106 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:23:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:23:14 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:23:15 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:16 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:17 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:23:17 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:23:18 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:19 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:20 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:21 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:21 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:22 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:23 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:24 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:25 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:26 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:26 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:27 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:28 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:29 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:23:30 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:30] INFO:     127.0.0.1:53594 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:23:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:23:31 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:23:31 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:23:32 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:23:33 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:34 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:23:35 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:23:35 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:23:36 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:37 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:38 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:39 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:40 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:40 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:41 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:42 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:43 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:23:44 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:44 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:45 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:46 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:23:47] INFO:     127.0.0.1:35904 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:23:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:23:47 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:23:48 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:49 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:23:49 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:23:50 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:23:51 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:23:52 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:23:53 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:54 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:54 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:55 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:56 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:23:57 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:58 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:58 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:23:59 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:00 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:01 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:02 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:03 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:03] INFO:     127.0.0.1:38230 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:24:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:24:03 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:24:04 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:05 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:06 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:07 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:08 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:08 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:09 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:10 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:11 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:12 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:13 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:13 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:24:14 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:24:15 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:24:16 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:17 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:24:17 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:24:18 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:24:19 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:24:20] INFO:     127.0.0.1:54624 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:24:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:24:20 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:24:21 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:22 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:24:22 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:23 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:24 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:25 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:26 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:27 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:27 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:28 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:29 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:30 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:31 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:31 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:32 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:33 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:34 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:35 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:36 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:36] INFO:     127.0.0.1:38078 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:24:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:24:36 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:24:37 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:38 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:39 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:40 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:41 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:41 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:24:42 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:43 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:44 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:24:45 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:45 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:46 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:24:47 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:48 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:49 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:50 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:50 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:51 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:24:52 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:24:53] INFO:     127.0.0.1:48846 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:24:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:24:53 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:24:54 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:55 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:24:55 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:56 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:57 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:58 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:24:59 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:00 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:00 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:01 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:02 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:03 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:04 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:04 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:05 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:06 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:07 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:08 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:09 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:09] INFO:     127.0.0.1:40616 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:25:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:25:09 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:25:10 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:25:11 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:12 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:25:13 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:14 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:14 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:15 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:16 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:17 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:18 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:18 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:19 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:20 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:21 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:22 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:23 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:23 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:24 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:25 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:26] INFO:     127.0.0.1:34494 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:25:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:25:26 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:25:27 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:25:28 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:25:28 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:25:29 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:25:30 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:31 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:32 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:32 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:33 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:34 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:35 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:36 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:37 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:37 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:38 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:39 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:40 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:41 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:41 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:42] INFO:     127.0.0.1:39702 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:25:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:25:42 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:25:43 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:25:44 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:25:45 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:25:46 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:46 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:47 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:25:48 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:49 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:50 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:25:51 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:51 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:52 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:53 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:54 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:55 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:25:56 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:56 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:25:57 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:25:58 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:25:58] INFO:     127.0.0.1:51438 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:25:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:25:59 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:26:00 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:26:01 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:01 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:02 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:03 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:04 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:05 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:05 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:06 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:07 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:08 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:09 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:10 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:10 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:11 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:12 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:13 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:14 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:14 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:26:15] INFO:     127.0.0.1:52028 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:26:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:26:15 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:26:16 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:17 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:18 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:19 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:19 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:20 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:21 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:22 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:23 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:24 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:24 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:25 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:26 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:27 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:28 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:28 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:26:29 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:30 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:26:31 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:26:31] INFO:     127.0.0.1:53760 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:26:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:26:32 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:26:33 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:26:33 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:26:34 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:26:35 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:26:36 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:37 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:38 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:38 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:39 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:40 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:41 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:42 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:42 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:43 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:44 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:45 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:46 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:47 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:26:47 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:26:48] INFO:     127.0.0.1:56980 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:26:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:26:48 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:26:49 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:26:50 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:26:51 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:52 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:52 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:53 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:54 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:26:55 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:56 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:56 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:26:57 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:26:58 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:26:59 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:00 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:01 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:01 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:02 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:03 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:04 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:04] INFO:     127.0.0.1:36694 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:27:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:27:05 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:27:06 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:27:06 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:07 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:08 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:09 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:10 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:27:11 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:11 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:27:12 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:27:13 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:27:14 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:27:15 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:27:15 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.73, #queue-req: 0, 
[2025-10-18 04:27:16 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:27:17 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:27:18 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:27:19 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:27:20 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.71, #queue-req: 0, 
[2025-10-18 04:27:20 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.72, #queue-req: 0, 
[2025-10-18 04:27:21] INFO:     127.0.0.1:42084 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:27:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:27:21 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.22, #queue-req: 0, 
[2025-10-18 04:27:22 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:27:23 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:27:24 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:27:25 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:27:25 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:26 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:27:27 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:28 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:29 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:29 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:30 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:31 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:32 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:33 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:34 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:34 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:35 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:36 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:37 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:27:37] INFO:     127.0.0.1:37050 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:27:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:27:38 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:27:39 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:27:39 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:27:40 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:27:41 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:27:42 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:27:43 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:44 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:44 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:45 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:46 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:47 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:48 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:48 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:49 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:50 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:27:51 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:52 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:53 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:27:53 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:27:54] INFO:     127.0.0.1:56144 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:27:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:27:54 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.25, #queue-req: 0, 
[2025-10-18 04:27:55 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:27:56 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:27:57 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:27:58 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:27:58 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:27:59 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:00 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:01 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:02 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:02 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:03 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:04 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:05 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:06 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:07 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:07 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:08 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:09 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:10 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:10] INFO:     127.0.0.1:55504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:28:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:28:11 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:28:12 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:28:12 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:28:13 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:28:14 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:28:15 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:28:16 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:28:16 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:17 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:18 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:19 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:20 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:21 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:21 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:22 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:23 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:24 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:25 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:25 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:26 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:27] INFO:     127.0.0.1:46626 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:28:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:28:27 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:28:28 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:29 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:30 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:30 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:31 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:32 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:33 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:34 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:35 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:28:35 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:36 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:37 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:28:38 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:28:39 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:40 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:40 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:28:41 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:28:42 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:28:43 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:28:43] INFO:     127.0.0.1:56580 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:28:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:28:44 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:28:45 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:28:45 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:46 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:28:47 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:48 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:49 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:28:49 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:50 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:51 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:28:52 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:53 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:54 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:54 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:55 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:56 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:28:57 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:28:58 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:28:58 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:28:59 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:00] INFO:     127.0.0.1:49326 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:29:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:29:00 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:29:01 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:02 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:29:03 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:29:03 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:04 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:05 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:06 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:29:07 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:08 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:08 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:09 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:10 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:11 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:12 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:29:12 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:13 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:14 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:15 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:29:16 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:16] INFO:     127.0.0.1:60916 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:29:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:29:17 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:29:17 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:18 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:29:19 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:29:20 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:29:21 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:22 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:22 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:23 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:24 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:25 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:26 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:26 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:27 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:28 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:29 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:30 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:31 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:31 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:32 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:33] INFO:     127.0.0.1:60670 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:29:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:29:33 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:29:34 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:29:35 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:36 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:36 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:37 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:38 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:39 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:40 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:41 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:41 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:42 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:43 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:44 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:45 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:45 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:46 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:47 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:48 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:29:49 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:29:49] INFO:     127.0.0.1:51778 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:29:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:29:50 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:29:50 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:29:51 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:29:52 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:29:53 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:54 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:29:55 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:29:55 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:56 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:57 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:58 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:29:59 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:29:59 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:00 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:01 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:02 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:03 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:04 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:04 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:30:05 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:30:06] INFO:     127.0.0.1:50832 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:30:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:30:06 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:30:07 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:30:08 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:30:09 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:30:09 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:30:10 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:11 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:12 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:13 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:30:13 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:14 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:15 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:16 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:17 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:18 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:18 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:19 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:20 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:21 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:22 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:22] INFO:     127.0.0.1:47718 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:30:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:30:23 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.33, #queue-req: 0, 
[2025-10-18 04:30:23 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:30:24 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:30:25 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:26 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:30:27 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:27 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:30:28 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:29 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:30 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:31 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:32 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:32 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:33 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:34 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:35 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:30:36 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:37 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:37 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:30:38 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:30:39] INFO:     127.0.0.1:45900 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:30:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:30:39 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:30:40 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:41 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:30:42 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:42 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:43 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:44 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:30:45 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:46 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:46 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:30:47 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:48 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:49 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:50 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:51 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:51 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:52 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:30:53 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:30:54 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:30:55 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:30:55] INFO:     127.0.0.1:36698 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:30:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:30:56 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.97, #queue-req: 0, 
[2025-10-18 04:30:56 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:57 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:30:58 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:30:59 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:31:00 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:00 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:01 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:02 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:03 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:04 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:05 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:05 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:06 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:07 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:08 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:09 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:09 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:10 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:11 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:31:12] INFO:     127.0.0.1:45508 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:31:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:31:12 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:31:13 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:14 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:14 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:15 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:16 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:17 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:18 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:19 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:19 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:31:20 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:31:21 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:22 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:23 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:31:24 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:24 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:31:25 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:26 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:31:27 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:28 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.74, #queue-req: 0, 
[2025-10-18 04:31:28] INFO:     127.0.0.1:51228 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:31:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:31:29 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:31:29 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:31:30 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:31:31 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:31:32 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:31:33 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:31:33 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:31:34 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:35 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:36 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:37 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:38 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:38 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:39 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:40 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:41 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:42 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:42 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:43 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:44 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:31:45] INFO:     127.0.0.1:54110 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:31:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:31:45 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 43.79, #queue-req: 0, 
[2025-10-18 04:31:46 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:31:47 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:31:47 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:31:48 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:49 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:50 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:31:51 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:52 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:52 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:53 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:54 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:55 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:56 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:56 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:31:57 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:31:58 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:31:59 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:00 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:32:01 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:01] INFO:     127.0.0.1:44818 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:32:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:32:01 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:32:02 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:32:03 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:32:04 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:05 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:06 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:32:06 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:07 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:08 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:09 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:10 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:11 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:11 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:12 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:13 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:14 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:15 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:15 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:16 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:17 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:18] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:32:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:32:18 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.29, #queue-req: 0, 
[2025-10-18 04:32:19 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:20 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:20 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:21 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:22 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:23 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:24 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:25 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:25 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:26 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:27 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:28 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:29 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:29 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:30 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:31 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:32 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:33 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:34 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:34] INFO:     127.0.0.1:34278 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:32:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:32:34 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:32:35 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:32:36 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:32:37 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:38 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:32:39 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:32:39 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:40 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:41 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:42 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:32:43 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:43 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:44 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:45 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:32:46 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:47 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:48 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:48 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:49 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:50 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:32:51] INFO:     127.0.0.1:51782 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:32:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:32:51 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.26, #queue-req: 0, 
[2025-10-18 04:32:52 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:53 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:53 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:54 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:55 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:32:56 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:57 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:57 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:32:58 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:32:59 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:00 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:01 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:02 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:33:02 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:33:03 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:04 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:05 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:06 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:07 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:33:07] INFO:     127.0.0.1:58102 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:33:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:33:07 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.32, #queue-req: 0, 
[2025-10-18 04:33:08 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:33:09 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:33:10 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:33:11 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:33:12 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:33:12 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:33:13 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:33:14 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:15 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:16 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:16 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:17 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:18 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:19 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:20 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:21 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:21 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:22 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:23 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:24] INFO:     127.0.0.1:46446 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:33:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:33:24 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:33:25 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:33:26 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:33:26 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.85, #queue-req: 0, 
[2025-10-18 04:33:27 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:33:28 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:33:29 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:33:30 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:33:30 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:33:31 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:33:32 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:33 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:34 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:35 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:35 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:36 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:37 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:38 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:39 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:39 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:40] INFO:     127.0.0.1:60710 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:33:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:33:40 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:33:41 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:33:42 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:33:43 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:44 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:33:44 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:45 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:46 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:47 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:48 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:49 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:33:49 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:50 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:51 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:52 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:33:53 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:53 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:54 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:55 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:33:56 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:33:56] INFO:     127.0.0.1:42748 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:33:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:33:57 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:33:58 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:33:58 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.86, #queue-req: 0, 
[2025-10-18 04:33:59 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:34:00 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:34:01 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:34:02 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:03 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:03 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:04 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:05 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:06 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:34:07 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:08 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:08 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:09 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:10 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:11 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:12 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:12 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:13] INFO:     127.0.0.1:37708 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:34:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:34:13 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.31, #queue-req: 0, 
[2025-10-18 04:34:14 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:34:15 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:34:16 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:34:17 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:17 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:18 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:34:19 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:20 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:21 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:34:22 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:22 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:23 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:24 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:25 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:26 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:26 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:27 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:28 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:29 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:29] INFO:     127.0.0.1:54504 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:34:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:34:30 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.27, #queue-req: 0, 
[2025-10-18 04:34:31 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.83, #queue-req: 0, 
[2025-10-18 04:34:31 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.84, #queue-req: 0, 
[2025-10-18 04:34:32 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:33 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:34 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:35 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:34:36 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:36 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:37 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:38 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:39 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:40 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:40 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:41 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:34:42 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:34:43 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:44 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:45 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:45 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:46] INFO:     127.0.0.1:55288 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:34:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:34:46 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.30, #queue-req: 0, 
[2025-10-18 04:34:47 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:34:48 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:49 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:50 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:34:50 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:51 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:34:52 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:53 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:54 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:54 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:55 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:56 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:34:57 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:34:58 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:59 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:34:59 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:00 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:01 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:02 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.76, #queue-req: 0, 
[2025-10-18 04:35:02] INFO:     127.0.0.1:45422 - "POST /generate HTTP/1.1" 200 OK
[2025-10-18 04:35:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 3200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-10-18 04:35:03 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 44.28, #queue-req: 0, 
[2025-10-18 04:35:04 TP0] Decode batch. #running-req: 1, #token: 3255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.81, #queue-req: 0, 
[2025-10-18 04:35:04 TP0] Decode batch. #running-req: 1, #token: 3295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:35:05 TP0] Decode batch. #running-req: 1, #token: 3335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.82, #queue-req: 0, 
[2025-10-18 04:35:06 TP0] Decode batch. #running-req: 1, #token: 3375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:35:07 TP0] Decode batch. #running-req: 1, #token: 3415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.80, #queue-req: 0, 
[2025-10-18 04:35:08 TP0] Decode batch. #running-req: 1, #token: 3455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:35:09 TP0] Decode batch. #running-req: 1, #token: 3495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:35:09 TP0] Decode batch. #running-req: 1, #token: 3535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:35:10 TP0] Decode batch. #running-req: 1, #token: 3575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.79, #queue-req: 0, 
[2025-10-18 04:35:11 TP0] Decode batch. #running-req: 1, #token: 3615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:35:12 TP0] Decode batch. #running-req: 1, #token: 3655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
[2025-10-18 04:35:13 TP0] Decode batch. #running-req: 1, #token: 3695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:13 TP0] Decode batch. #running-req: 1, #token: 3735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:14 TP0] Decode batch. #running-req: 1, #token: 3775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
[2025-10-18 04:35:15 TP0] Decode batch. #running-req: 1, #token: 3815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:16 TP0] Decode batch. #running-req: 1, #token: 3855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:17 TP0] Decode batch. #running-req: 1, #token: 3895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:18 TP0] Decode batch. #running-req: 1, #token: 3935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:18 TP0] Decode batch. #running-req: 1, #token: 3975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.77, #queue-req: 0, 
[2025-10-18 04:35:19] INFO:     127.0.0.1:54432 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-10-18 04:35:26] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
[2025-10-18 04:35:28] Gracefully exiting... Remaining number of requests 0. Remaining requests remaining_rids=[].
