INFO 11-06 11:30:44 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:30:44] WARNING model_config.py:715: quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:30:44] WARNING server_args.py:1165: Attention backend not explicitly specified. Use aiter backend by default.
[2025-11-06 11:30:44] WARNING server_args.py:1354: DP attention is enabled. The chunked prefill size is adjusted to 16384 to avoid MoE kernel issues. 
[2025-11-06 11:30:44] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:30:44] server_args=ServerArgs(model_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.68, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=16384, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=8, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=991442200, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', api_key=None, served_model_name='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=8, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='aiter', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_amx_weight_path=None, kt_amx_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=16, cuda_graph_bs=[1, 2, 4, 8, 12, 16], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=True, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, decrypted_config_file=None, decrypted_draft_config_file=None)
[2025-11-06 11:30:44] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:30:44] Using default HuggingFace chat template with detected content format: string
INFO 11-06 11:30:52 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:30:52 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:30:52] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:30:52] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
INFO 11-06 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
INFO 11-06 11:31:01 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:31:01 DP1 TP1] Process 510 gpu_id 1 is running on CPUs: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
[2025-11-06 11:31:01 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:31:01 DP5 TP5] Process 514 gpu_id 5 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:31:01 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:31:01 DP4 TP4] Process 513 gpu_id 4 is running on CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:31:01 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP0 TP0] Process 509 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[2025-11-06 11:31:01 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:31:01 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP1 TP1] Init torch distributed begin.
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-06 11:31:01 DP6 TP6] Process 515 gpu_id 6 is running on CPUs: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
[2025-11-06 11:31:01 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP3 TP3] Process 512 gpu_id 3 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-11-06 11:31:01 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP5 TP5] Init torch distributed begin.
[2025-11-06 11:31:01 DP7 TP7] Process 516 gpu_id 7 is running on CPUs: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
[2025-11-06 11:31:01 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP2 TP2] Process 511 gpu_id 2 is running on CPUs: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]
[2025-11-06 11:31:01 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP4 TP4] Init torch distributed begin.
[2025-11-06 11:31:01 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP0 TP0] Init torch distributed begin.
[2025-11-06 11:31:01 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP6 TP6] Init torch distributed begin.
[2025-11-06 11:31:01 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP3 TP3] Init torch distributed begin.
[2025-11-06 11:31:01 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP7 TP7] Init torch distributed begin.
[2025-11-06 11:31:01 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-06 11:31:01 DP2 TP2] Init torch distributed begin.
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-11-06 11:31:02 DP0 TP0] sglang is using nccl==2.26.6
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-11-06 11:31:09 DP7 TP7] Init torch distributed ends. mem usage=3.10 GB
[2025-11-06 11:31:09 DP6 TP6] Init torch distributed ends. mem usage=3.11 GB
[2025-11-06 11:31:09 DP5 TP5] Init torch distributed ends. mem usage=3.17 GB
[2025-11-06 11:31:09 DP4 TP4] Init torch distributed ends. mem usage=3.10 GB
[2025-11-06 11:31:09 DP0 TP0] Init torch distributed ends. mem usage=3.22 GB
[2025-11-06 11:31:09 DP1 TP1] Init torch distributed ends. mem usage=2.82 GB
[2025-11-06 11:31:09 DP3 TP3] Init torch distributed ends. mem usage=3.24 GB
[2025-11-06 11:31:09 DP2 TP2] Init torch distributed ends. mem usage=3.24 GB
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[2025-11-06 11:31:10 DP4 TP4] Load weight begin. avail mem=284.40 GB
[2025-11-06 11:31:10 DP5 TP5] Load weight begin. avail mem=284.33 GB
[2025-11-06 11:31:10 DP7 TP7] Load weight begin. avail mem=284.40 GB
[2025-11-06 11:31:10 DP1 TP1] Load weight begin. avail mem=284.68 GB
[2025-11-06 11:31:10 DP3 TP3] Load weight begin. avail mem=284.26 GB
[2025-11-06 11:31:10 DP0 TP0] Load weight begin. avail mem=284.28 GB
[2025-11-06 11:31:10 DP0 TP0] Only Deepseek V3/R1 on NV-platform with capability >= 80 can use shared experts fusion optimization. Shared experts fusion optimization is disabled.
[2025-11-06 11:31:10 DP2 TP2] Load weight begin. avail mem=284.26 GB
[2025-11-06 11:31:10 DP6 TP6] Load weight begin. avail mem=284.39 GB
Loading safetensors checkpoint shards:   0% Completed | 0/73 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   1% Completed | 1/73 [00:00<00:14,  4.87it/s]
Loading safetensors checkpoint shards:   3% Completed | 2/73 [00:00<00:18,  3.80it/s]
Loading safetensors checkpoint shards:   4% Completed | 3/73 [00:00<00:21,  3.22it/s]
Loading safetensors checkpoint shards:   5% Completed | 4/73 [00:01<00:23,  2.97it/s]
Loading safetensors checkpoint shards:   7% Completed | 5/73 [00:01<00:25,  2.69it/s]
Loading safetensors checkpoint shards:   8% Completed | 6/73 [00:02<00:24,  2.79it/s]
Loading safetensors checkpoint shards:  10% Completed | 7/73 [00:02<00:26,  2.54it/s]
Loading safetensors checkpoint shards:  11% Completed | 8/73 [00:02<00:24,  2.65it/s]
Loading safetensors checkpoint shards:  12% Completed | 9/73 [00:03<00:23,  2.78it/s]
Loading safetensors checkpoint shards:  14% Completed | 10/73 [00:03<00:22,  2.84it/s]
Loading safetensors checkpoint shards:  15% Completed | 11/73 [00:03<00:22,  2.78it/s]
Loading safetensors checkpoint shards:  16% Completed | 12/73 [00:04<00:22,  2.68it/s]
Loading safetensors checkpoint shards:  18% Completed | 13/73 [00:04<00:19,  3.09it/s]
Loading safetensors checkpoint shards:  19% Completed | 14/73 [00:04<00:19,  2.96it/s]
Loading safetensors checkpoint shards:  21% Completed | 15/73 [00:05<00:30,  1.89it/s]
Loading safetensors checkpoint shards:  22% Completed | 16/73 [00:06<00:25,  2.23it/s]
Loading safetensors checkpoint shards:  23% Completed | 17/73 [00:06<00:22,  2.45it/s]
Loading safetensors checkpoint shards:  25% Completed | 18/73 [00:06<00:22,  2.42it/s]
Loading safetensors checkpoint shards:  26% Completed | 19/73 [00:07<00:22,  2.43it/s]
Loading safetensors checkpoint shards:  27% Completed | 20/73 [00:07<00:20,  2.53it/s]
Loading safetensors checkpoint shards:  29% Completed | 21/73 [00:07<00:19,  2.65it/s]
Loading safetensors checkpoint shards:  30% Completed | 22/73 [00:08<00:17,  2.87it/s]
Loading safetensors checkpoint shards:  32% Completed | 23/73 [00:08<00:16,  3.10it/s]
Loading safetensors checkpoint shards:  33% Completed | 24/73 [00:08<00:16,  3.00it/s]
Loading safetensors checkpoint shards:  34% Completed | 25/73 [00:09<00:16,  2.98it/s]
Loading safetensors checkpoint shards:  36% Completed | 26/73 [00:09<00:15,  3.00it/s]
Loading safetensors checkpoint shards:  37% Completed | 27/73 [00:09<00:15,  3.05it/s]
Loading safetensors checkpoint shards:  38% Completed | 28/73 [00:10<00:13,  3.21it/s]
Loading safetensors checkpoint shards:  40% Completed | 29/73 [00:10<00:13,  3.17it/s]
Loading safetensors checkpoint shards:  41% Completed | 30/73 [00:10<00:14,  3.04it/s]
Loading safetensors checkpoint shards:  42% Completed | 31/73 [00:11<00:13,  3.07it/s]
Loading safetensors checkpoint shards:  45% Completed | 33/73 [00:11<00:10,  3.91it/s]
Loading safetensors checkpoint shards:  47% Completed | 34/73 [00:11<00:10,  3.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 35/73 [00:12<00:10,  3.49it/s]
Loading safetensors checkpoint shards:  49% Completed | 36/73 [00:12<00:16,  2.31it/s]
Loading safetensors checkpoint shards:  51% Completed | 37/73 [00:13<00:14,  2.45it/s]
Loading safetensors checkpoint shards:  52% Completed | 38/73 [00:13<00:13,  2.63it/s]
Loading safetensors checkpoint shards:  53% Completed | 39/73 [00:13<00:12,  2.73it/s]
Loading safetensors checkpoint shards:  55% Completed | 40/73 [00:14<00:10,  3.07it/s]
Loading safetensors checkpoint shards:  56% Completed | 41/73 [00:14<00:08,  3.63it/s]
Loading safetensors checkpoint shards:  58% Completed | 42/73 [00:14<00:07,  3.97it/s]
Loading safetensors checkpoint shards:  59% Completed | 43/73 [00:14<00:06,  4.33it/s]
Loading safetensors checkpoint shards:  60% Completed | 44/73 [00:14<00:05,  5.16it/s]
Loading safetensors checkpoint shards:  63% Completed | 46/73 [00:14<00:03,  7.13it/s]
Loading safetensors checkpoint shards:  66% Completed | 48/73 [00:15<00:02,  9.40it/s]
Loading safetensors checkpoint shards:  68% Completed | 50/73 [00:15<00:04,  5.70it/s]
Loading safetensors checkpoint shards:  70% Completed | 51/73 [00:16<00:06,  3.49it/s]
Loading safetensors checkpoint shards:  71% Completed | 52/73 [00:17<00:08,  2.49it/s]
Loading safetensors checkpoint shards:  73% Completed | 53/73 [00:17<00:09,  2.18it/s]
Loading safetensors checkpoint shards:  74% Completed | 54/73 [00:19<00:12,  1.47it/s]
Loading safetensors checkpoint shards:  75% Completed | 55/73 [00:19<00:12,  1.47it/s]
Loading safetensors checkpoint shards:  77% Completed | 56/73 [00:20<00:11,  1.47it/s]
Loading safetensors checkpoint shards:  78% Completed | 57/73 [00:20<00:09,  1.71it/s]
Loading safetensors checkpoint shards:  79% Completed | 58/73 [00:21<00:07,  1.89it/s]
Loading safetensors checkpoint shards:  81% Completed | 59/73 [00:21<00:06,  2.02it/s]
Loading safetensors checkpoint shards:  82% Completed | 60/73 [00:22<00:06,  2.09it/s]
Loading safetensors checkpoint shards:  84% Completed | 61/73 [00:22<00:05,  2.12it/s]
Loading safetensors checkpoint shards:  85% Completed | 62/73 [00:22<00:04,  2.40it/s]
Loading safetensors checkpoint shards:  86% Completed | 63/73 [00:23<00:03,  2.58it/s]
Loading safetensors checkpoint shards:  88% Completed | 64/73 [00:23<00:03,  2.53it/s]
Loading safetensors checkpoint shards:  89% Completed | 65/73 [00:23<00:02,  2.76it/s]
Loading safetensors checkpoint shards:  90% Completed | 66/73 [00:24<00:02,  2.71it/s]
Loading safetensors checkpoint shards:  92% Completed | 67/73 [00:24<00:02,  2.60it/s]
Loading safetensors checkpoint shards:  93% Completed | 68/73 [00:24<00:01,  2.55it/s]
Loading safetensors checkpoint shards:  95% Completed | 69/73 [00:25<00:01,  2.57it/s]
Loading safetensors checkpoint shards:  96% Completed | 70/73 [00:25<00:01,  2.83it/s]
Loading safetensors checkpoint shards:  97% Completed | 71/73 [00:25<00:00,  2.87it/s]
Loading safetensors checkpoint shards:  99% Completed | 72/73 [00:26<00:00,  3.57it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:26<00:00,  2.43it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:26<00:00,  2.72it/s]

[2025-11-06 11:31:39 DP1 TP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.50 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP2 TP2] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.09 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP7 TP7] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.22 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP4 TP4] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.23 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP5 TP5] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.15 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP3 TP3] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.08 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP6 TP6] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.21 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.11 GB, mem usage=49.18 GB.
[2025-11-06 11:31:39 DP0 TP0] Using KV cache dtype: torch.bfloat16
[2025-11-06 11:31:39 DP0 TP0] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP0 TP0] Memory pool end. avail mem=88.43 GB
[2025-11-06 11:31:39 DP3 TP3] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP1 TP1] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP3 TP3] Memory pool end. avail mem=88.40 GB
[2025-11-06 11:31:39 DP1 TP1] Memory pool end. avail mem=88.82 GB
[2025-11-06 11:31:39 DP5 TP5] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP5 TP5] Memory pool end. avail mem=88.47 GB
[2025-11-06 11:31:39 DP4 TP4] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP4 TP4] Memory pool end. avail mem=88.55 GB
[2025-11-06 11:31:39 DP7 TP7] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP7 TP7] Memory pool end. avail mem=88.54 GB
[2025-11-06 11:31:39 DP2 TP2] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP2 TP2] Memory pool end. avail mem=88.41 GB
[2025-11-06 11:31:39 DP6 TP6] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-06 11:31:39 DP6 TP6] Memory pool end. avail mem=88.53 GB
[2025-11-06 11:31:40 DP1 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=88.70 GB
[2025-11-06 11:31:40 DP4 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
[2025-11-06 11:31:40 DP7 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
[2025-11-06 11:31:40 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=88.30 GB
[2025-11-06 11:31:40 DP0 TP0] Capture cuda graph bs [1, 2, 4, 8, 12, 16]
[2025-11-06 11:31:40 DP5 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=88.34 GB
[2025-11-06 11:31:40 DP6 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=88.40 GB
[2025-11-06 11:31:40 DP3 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=88.27 GB
[2025-11-06 11:31:40 DP2 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=88.28 GB
  0%|          | 0/6 [00:00<?, ?it/s]Capturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
ler_DP7_TP7: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 7, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank7]:E1106 11:31:41.925000 516 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP5_TP5: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 5, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank5]:E1106 11:31:41.936000 514 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP6_TP6: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    ler_DP4_TP4: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = #0blocked :  = i#32ttg}. blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>:
 #tensor<blocked321x = i#32ttg, .#blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>ttg
.#slice<{dim = 0, parent = #blocked6}>blocked>2  = -># ttgtensor<.1blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>x
32#xblockedi332 = , ##ttgblocked.6blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>

#      blocked%447 =  = #tt.splatttg .%blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>arg10
 #:blocked i532 =  #->ttg .tensor<blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>1
x#32xblockedi632 = , ##ttgblocked.6blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>>

#      blocked%748 =  = #ttgarith.muli. %blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>46
,# blocked%847 =  #ttg:. blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>tensor<
1#xblocked329x = i#32ttg, .#blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
blocked#6linear> = 
      %#49ttg = .arith.extsilinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}> 
%#48linear 1: =  tensor<#1ttgx.32linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>x
i#32linear, 2# = blocked#6ttg> .tolinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}> 
tensor<#1sharedx = 32#xttgi.64swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>, 
##blockedsmem6 = >#
ttg      .%shared_memory50
 = modulett.broadcast attributes  {%"45t t:g .tensor<num-ctas" = 1 : i6432x, 1"xtit64g, .#nblockedu6>m -->w artensor<p64sx"32 = x4i : 64i, 32#, blockedttg.target6 = >"
h      i%p51: = gtt.broadcastf %x499 5:0 "tensor<, 1"xt32txg.ith64r, e#ablockedd6s>-p e->r -tensor<w64axr32px"i = 6464,  : #iblocked326}> 
{      
%  52tt.func =  arith.addipublic  %@50_batched_gemm_afp4_wfp4_pre_quant_kernel,( %%arg051:  !:tt .tensor<ptr<bf16>64 {xtt.divisibility32 = x16i : 64i32, }#, blocked%6arg1>: 
!      tt%.53ptr<i8> =  {tt.addptrtt.divisibility  = %16arg1 : ,i 32%}42,  %:arg2 : !!tttt..ptr<i8>ptr<bf16>, { tt.divisibilityi = 6416
 :       i%3254} = , arith.extsi% arg3%: arg14! tt:.ptr<i8>  {itt.divisibility32 =  16to :  ii3264}
,       %%arg455:  = iarith.muli32  {%tt.divisibility7 = ,16  : %i5432 }:,  %iarg564: 
i      32% {56 = tt.divisibilitytt.addptr =  16% : arg3i32,} , %%55arg6 : :i 32! {tttt.divisibility. = ptr<i8>16, :  ii3264}
,       %%arg757:  = itt.expand_dims32  {%tt.divisibility41 =  {16axis :  = i132 : }i, 32%}arg8 : :i 32tensor< {32tt.divisibilityx = i1632 : , i#32ttg}., slice<{dim = 1, parent = #linear1}>%>arg9 : ->i 32tensor< {32tt.divisibilityx = 116x : ii3232, }#, linear%1arg10>: 
i      32% {58tt.divisibility =  = tt.splat16  : %iarg1532 }:,  %iarg1132:  i->32  {tensor<tt.divisibility32 = x161 : xii3232}, , #%lineararg121: >i
32       {%tt.divisibility59 =  = 16arith.muli :  i%3257},,  %%arg1358:  i:32  {tensor<tt.divisibility32 = x161 : xii3232}, , #%lineararg141: >i32
 {      tt.divisibility% = 6016 =  : arith.extsii 32%}59,  %:arg15 : tensor<i3232x)1 attributesx {inoinline32 = , false#}linear 1{>
     to% csttensor< = 32arith.constantx 1dense<x127i>64 : , tensor<#4linearx14>x
      1%x61i = 8tt.make_range,  {#endblocked = >4
 :     i%32cst_0,  = startarith.constant =  0dense< : 0x7FC0i>32 : }tensor< 4:x 128tensor<x4xbf16i, 32#, blocked#ttg1.>slice<{dim = 0, parent = #linear1}>
>    %
cst_1       = %arith.constant62  = dense<tt.broadcast2097152 >% : 60tensor< 4:x 4tensor<x321xx1ix32i, 64#, blocked#>linear
1    >% cst_2->  = tensor<arith.constant32 xdense<44x>i : 64tensor<, 4#xlinear41x>16
x      i%863,  = #tt.expand_dimsblocked 2%>61
 {    axis% = c31_i320 =  : arith.constanti 3231} :  i:32 
tensor<    4%xcst_3i = 32arith.constant,  #dense<ttg0.000000e+00.>slice<{dim = 0, parent = #linear1}> : >tensor< 4->x32 xtensor<f321, x4#xblockedi332>, 
#    linear%1c32_i32> = 
arith.constant      % 6432 =  : tt.broadcasti32 
    %%63c4_i32  = :arith.constant  tensor<41 : xi432x
i    32%, true# = lineararith.constant1 >true 
->     %tensor<c0_i3232 = xarith.constant4 x0i : 32i, 32#
linear    1%>cst_4
 =       arith.constant% 65dense< = -8388608arith.extsi>  : %tensor<644x 4:x 1xtensor<i32x324, x#iblocked32>, 
#    linear%1cst_5> =  arith.constantto  dense<tensor<322.000000e+00x>4 : xtensor<i464x, 4#xlinear11x>f32
,       #%66blocked = >arith.addi
     %%65cst_6, =  arith.constant% 62dense< 0.000000e+00:> :  tensor<tensor<432xx44xx1ix64f32, , ##linearblocked1>>

          %%67cst_7 =  = tt.splatarith.constant  %dense<56-2147483648 >: :  tensor<!4ttx.4ptr<i8>x 32->x itensor<3232, x#4blockedx>!tt
.    ptr<i8>%, cst_8# = lineararith.constant1 >dense<
23      >% : 68tensor< = 4tt.addptrx 4%x6732,x i%3266,  #:blocked >tensor<
32    x%4cst_9x = !arith.constanttt .dense<ptr<i8>255, > : #tensor<linear41x>4,x 32tensor<x32ix324, x#iblocked64>, 
#    linear%1cst_10 = >arith.constant
       dense<%838860769> =  : tt.loadtensor< 4%x684x 32:x itensor<3232, x#4xblocked!>tt
.    ptr<i8>%, cst_11# = lineararith.constant1 >dense<
1      >% : 70tensor< = 4tt.transx 4%x6932 {xorderi = 32array<, i#32blocked: >1
,     0%>cst_12} =  arith.constant:  dense<tensor<12732x>4 : xtensor<i48x, 4#xlinear32x1i>32 , -># blockedtensor<>4
x    32%xcst_13i = 8arith.constant,  #dense<ttg4194304.>slice<{dim = 2, parent = #blocked4}> : >tensor<
4      x%471x = 32tt.splatx i%3229,  #:blocked >!
tt    .%ptr<bf16>cst_14  = ->arith.constant  tensor<dense<4126x>128 : xtensor<!4ttx.4ptr<bf16>x, 32#xblockedi132>, 
#      blocked%>72
 =     tt.addptr% cst_15% = 71arith.constant,  %dense<282 >: :  tensor<tensor<44xx4128xx32!xtti.32ptr<bf16>, , ##blockedblocked>1
>    ,% cst_16tensor< = 4arith.constantx 128dense<x21i>64 : , tensor<#4blockedx14>x
32      x%i7332,  = #tt.loadblocked >%72
     :% cst_17tensor< = 4arith.constantx 128dense<x28!>tt : .tensor<ptr<bf16>4, x#4blockedx132>x
      i%3274,  = #tt.splatblocked >%
53     %:cst_18  = !arith.constanttt .dense<ptr<i8>-1.270000e+02 >-> :  tensor<tensor<464xx432xx1!xttf32., ptr<i8>#, blocked#>blocked
6    >%
cst_19      % = 75arith.constant =  tt.addptrdense< 7%>74 : ,tensor< 4%x5232 x:i 16tensor<, 64#xttg32.slice<{dim = 2, parent = #blocked4}>x>!
tt    .%ptr<i8>cst_20,  = #arith.constantblocked 6dense<>-1,>  : tensor<tensor<644xx3232xxii64, 8, ##blockedttg6.>slice<{dim = 2, parent = #blocked4}>>

          %%76cst_21 =  = tt.loadarith.constant  %dense<750x7FC0 >cacheModifier :  tensor<=128 xcg32 x:bf16 , tensor<#64blockedx532>x
!    tt%.cst_22ptr<i8> = , arith.constant# blockeddense<67>>
 :       tensor<%477x = 4ttg.convert_layoutx32 x%i7632 , :# blockedtensor<>64
x    32%xcst_23i = 8arith.constant,  #dense<blocked1.270000e+026>> :  tensor<4->x 4tensor<x641xx32f32x, i#8blocked, #>blocked
3    >%
cst_24       = %arith.constant78  = dense<tt.reshape1.270000e+02 >% : 73tensor< 4:x 4tensor<x41xx128f32x, bf16#, linear>#
    blocked%1>cst_25  = ->arith.constant  tensor<dense<4-1.270000e+02x>4 : xtensor<324xxbf164, x#1blockedx>f32
,       #%linear79> = 
math.absf     %%cst_2678 =  arith.constant:  dense<tensor<2.000000e+004>x : 4tensor<x432xx4bf16x, 1#xblockedf32>, 
#      linear%>80
 =     arith.extf% cst_27% = 79arith.constant  :dense< -8388608>tensor< : 4tensor<x44xx432xx1bf16x, i#32blocked, ># linearto> 
tensor<    4%cst_28x = 4arith.constantx 32dense<x2097152f32>,  : #tensor<blocked4>x
4      x%181x = i"32t, t#.linearr>e
d    u%cst_29c = earith.constant" (dense<%12780>) :  <tensor<{4axisx = 42x : 1ix32}i>8 (, {#
linear      >^bb0
(    %%arg16cst_30:  = f32arith.constant,  %dense<arg177: >f32 : )tensor<:4
x        4%xi20916 = , arith.maxnumf# ttg%.arg16slice<{dim = 2, parent = #blocked}>,>
     %%arg17cst_31  = :arith.constant  f32dense<
-1        >tt.reduce.return :  tensor<%4209x 4:x i8f32, 
#      ttg}.)slice<{dim = 2, parent = #blocked}>> : 
(    tensor<4llvm.intr.assumex 4%xtrue32 x:f32 , i#1blocked
>    ) -> llvm.intr.assumetensor< 4%xtrue4 x:f32 , i#1ttg
.    slice<{dim = 2, parent = #blocked}>llvm.intr.assume> 
%      true% :82  = ttg.convert_layouti 1%
81     llvm.intr.assume:  %tensor<true4 x:4x f32, i#1ttg
.    slice<{dim = 2, parent = #blocked}>llvm.intr.assume>  %->true  tensor<:4 xi41x
f32    , llvm.intr.assume# ttg%.slice<{dim = 2, parent = #linear}>true> 
:       i%183
 =     tt.expand_dimsllvm.intr.assume  %%82true { axis: =  2i : 1i
32    } llvm.intr.assume:  tensor<%4truex 4:x f32i, 1#
ttg    .llvm.intr.assumeslice<{dim = 2, parent = #linear}> >% true->  :tensor< 4ix14
x    1llvm.intr.assumex f32%, true# linear:> 
i      1%
84     = llvm.intr.assumett.expand_dims  %%81true { axis: =  2i : 1i
32    }llvm.intr.assume  %:true  tensor<:4 xi41x
f32    , %#0ttg = .tt.get_program_idslice<{dim = 2, parent = #blocked}> > x->  :tensor< 4ix324
x    1%x1f32 = , tt.get_program_id# blockedy> 
:       i%3285
 =     tt.bitcast% 2% = 83arith.addi  :% arg5tensor<,4 x%4c31_i32x1 xf32:,  #ilinear32>
     ->% 3tensor< = 4arith.divsix 4%x21,x i%32, c32_i32# linear:> 
i      32%
86     = %tt.bitcast4  = %arith.extsi84  %:arg7  tensor<:4 xi432x 1tox f32i, 64#
blocked    >% 5-> =  arith.extsitensor< 4%arg9x 4:x 1ix32i 32to,  #iblocked64>

          %%876 =  = arith.addiarith.extsi  %%85arg11,  :% cst_28i 32:  totensor< 4ix644
x    1%x7i32 = , arith.extsi# linear%>0
       :% 88i = 32arith.addi  to% 86i,64 
%    cst_1% 8: =  arith.divsitensor< 4%x14,x 1%x3i 32:,  #iblocked32>

          %%989 =  = arith.remsitt.bitcast  %%187,  :% 3tensor< 4:x 4ix321
x    illvm.intr.assume32 , %#truelinear >:  ->i 1tensor<
4x    llvm.intr.assume4 x%1truex i:32 , i#1linear
>    
llvm.intr.assume       %%90true =  tt.bitcast:  %i881 
:     %tensor<104 = xarith.cmpi4 xsgt1,x i%32arg6, ,# blocked%>c0_i32  ->:  tensor<i432x
4    xscf.if1 x%i1032 , {#
blocked      >%
11       = %arith.muli91  = %arith.andi8 ,% 89%,c4_i32  %:cst_27  i:32 
tensor<      4%x124 = xtt.make_range1 {xendi = 324,  : #ilinear32>, 
start =       0% : 92i = 32arith.andi}  %:90 ,tensor< 4%xcst_4i 32:,  #tensor<ttg4.xslice<{dim = 1, parent = #blocked1}>4>
x      %113x = itt.make_range32 {, end# = blocked4> : 
i      32%, 93start =  = tt.bitcast0  : %i91 32: }tensor< 4:x 4tensor<x41xxii3232, , ##linearttg>. slice<{dim = 1, parent = #blocked3}>->> 
tensor<      4%x144 = xtt.splat1 x%f3211,  #:linear >i
32       %94-> =  tt.bitcasttensor< 4%92x i:32 , tensor<#4ttgx.4slice<{dim = 1, parent = #blocked1}>x>1
xi      32%, 15# = blockedarith.addi>  %->14 ,tensor< 4%x124 x:1 xtensor<f324, x#iblocked32>, 
#      ttg%.slice<{dim = 1, parent = #blocked1}>95> = 
math.log2       %%1693 =  tt.splat:  %arg4tensor< 4:x 4ix321 x->f32 , tensor<#4linearx>i
      32%, 96# = ttgmath.log2. slice<{dim = 1, parent = #blocked1}>>%
94       %:17  = tensor<arith.remsi 4%x154,x 1%x16 f32:,  #tensor<blocked4>xi
32      , %#97ttg = .math.floorslice<{dim = 1, parent = #blocked1}> >%
95       %:18  = tensor<arith.muli4 x%47x,1x f32%, 4# linear:> 
i64      
%      98% = 19math.floor =  tt.expand_dims% 96% 17: { axistensor< = 41x : i432x}1 x:f32 , tensor<#4blockedx>i
32      , %#99ttg = .arith.subfslice<{dim = 1, parent = #blocked1}> >% 97->,  tensor<%4cst_26x 1:x itensor<324, x#4blocked1x>1
x      f32%20,  = #tt.splatlinear >%
arg8       %: 100i = 32arith.subf  ->% 98tensor<,4 x%1cst_5x i:32 , tensor<#4blockedx14>x
      1%x21f32 = , arith.muli# blocked%>19
,       %%10120 =  tt.clampf:  %tensor<994,x1 x%icst_2532, , %#cst_24blocked,1 >propagateNan
       =% 22none =  arith.extsi:  %tensor<214x 4:x 1tensor<x4f32x, 1#linearx>i
32      , %#blocked1021 = >tt.clampf  to% 100tensor<,4 x%1cst_18x,i 64%, cst_23#,blocked 1propagateNan> 
=       %none23  = :tt.make_range  {tensor<end4 = x1284 : xi132x, f32start,  = #0blocked : >i
32      }% 103: =  arith.fptouitensor< 128%x101i 32:,  #tensor<ttg4.xslice<{dim = 0, parent = #blocked1}>4>x
      1%x24f32 = , tt.expand_dims# linear%>23  {toaxis  = tensor<04 : xi432x}1 x:i 8tensor<, 128#xlineari>32
,       #%ttg104. = slice<{dim = 0, parent = #blocked1}>arith.fptoui>  %->102  tensor<:1 xtensor<1284xxi432x, 1x#f32blocked, 1#>blocked
>       %to25  = tensor<arith.extsi4 x%424x 1:x itensor<81, x#128blockedx>i
32      , %#105blocked = 1arith.addi>  %to103 ,tensor< 1%xcst_29128 x:i 64tensor<, 4#xblocked41x>1
x      i8%, 26# = lineartt.broadcast> %
22       %:106  = tensor<arith.addi4 x1%x104i,64 , %#cstblocked 1:>  tensor<->4 xtensor<44xx1128xxii864, , ##blockedblocked>1
      >%
107       = %arith.subf27  = %tt.broadcastcst_6 ,% 25% 102:  :tensor< 1tensor<x4128xx4ix641, x#f32blocked, 1#>blocked >->
       tensor<%4108x = 128math.exp2x i%64107,  #:blocked 1tensor<>4
x      4%x281 = xarith.addif32 , %#26blocked,> 
%      27% 109: =  tensor<arith.extf4 x%12878x i:64 , tensor<#4blockedx14>x
32      x%bf16, 29#blocked = >tt.addptr  to% arg0tensor<,4 x%418x 32:x f32!, tt#.blockedptr<bf16>>,
       i%64110
 =       tt.broadcast% 30% = 108arith.muli  :% 9tensor<,4 x%4c32_i32x 1:x f32i, 32#
blocked      >% ->31  = tensor<tt.make_range4 {xend4 = x3232 : xif3232, , #startblocked = >0
 :       i%32111} =  arith.mulf:  %tensor<10932,x i%32110,  #:ttg .tensor<slice<{dim = 0, parent = #blocked6}>>4
x      4%x3232 = xtt.make_rangef32 {, end# = blocked32> : 
i      32%, 112start =  = tt.bitcast0  : %i11132 }:  :tensor< 4tensor<x324xxi3232x, f32#, #ttgblocked.>slice<{dim = 0, parent = #blocked3}> >->
       tensor<%433x = 4tt.make_rangex {32endx = i3232 : , i#32blocked, >start
 =       0% : 113i = 32arith.andi}  %:112 ,tensor< 32%xcst_7i 32:,  #tensor<ttg.4slice<{dim = 1, parent = #linear1}>x>4
x      32%x34i = 32tt.splat,  #%blocked30> 
:       i%32114  = ->arith.shrui  tensor<%32112x,i 32%, cst_8# ttg:. slice<{dim = 0, parent = #blocked6}>tensor<>4
x      4%x3532 = xtt.splati 32%, 30#blocked >:
       i%32115  = ->arith.andi  tensor<%32114x,i %32cst_9 , :# ttgtensor<.4slice<{dim = 1, parent = #linear1}>x>4
x      32%x36i = 32arith.addi,  #%blocked34>,
       %%31116  = :arith.andi  tensor<%32112x,i 32%, cst_10# ttg:. slice<{dim = 0, parent = #blocked6}>tensor<>4
x      4%x3732 = xarith.addii 32%35, ,# blocked%>33
       :% 117tensor< = 32arith.addix i%11532,,  #%ttgcst_11. slice<{dim = 1, parent = #linear1}>:>
       tensor<4%x384 = xtt.splat32 x%iarg532 , :# blockedi>32
       ->% 118tensor< = 32arith.subix i%32cst_12, ,# ttg%.117slice<{dim = 0, parent = #blocked6}> >:
       tensor<4%x39 = 4tt.splatx 32%xarg5i 32:,  #iblocked32> 
->       %tensor<11932x = iarith.cmpi32 , ult#,ttg .%slice<{dim = 1, parent = #linear1}>115>,
       %%cst_1240  = :arith.remsi  tensor<%436x, 4%x3832 x:i 32tensor<, 32#xblockedi>32
,       #%ttg120. = slice<{dim = 0, parent = #blocked6}>arith.shrui> 
%      116%,41  = %arith.remsicst_11  %:37 ,tensor< 4%x394 x:32 xtensor<i3232x, i#32blocked, >#
ttg      .%slice<{dim = 1, parent = #linear1}>121> = 
arith.ori       %%42120 = ,arith.muli  %%cst_137 ,:  %tensor<54 x:4 xi3264x
i      32%, 43# = blockedtt.make_range> {
end       = %64122 :  = iarith.shrui32 , %start121 = ,0  : %i11832 :}  tensor<:4 xtensor<464xxi3232x, i#32ttg, .#slice<{dim = 1, parent = #blocked6}>blocked>>

      %      44% = 123tt.expand_dims =  arith.select% 43% {119axis,  = %1122 : , i%32116} :  tensor<:4 xtensor<464xx32ix32i, 1#, ttg#.blockedslice<{dim = 1, parent = #blocked6}>>>,  tensor<->4 xtensor<464xx321xxii3232, , ##blockedblocked>6
>      
%      124% = 45arith.maxui =  arith.extsi% 115%,44  %cst_14:  :tensor< 64tensor<x41xx4ix3232, x#iblocked326>,  to# blockedtensor<>64
x1      x%i12564 = , #arith.subiblocked 6%>124
      ,% 46% = cst_14tt.expand_dims  :% 40tensor< {4axisx = 40x : 32xii3232},  #:blocked >tensor<
32      x%i12632 = , arith.shli# ttg%.125slice<{dim = 0, parent = #blocked6}>,>  %cst_15 : tensor<4x4x->32 xtensor<i132x, 32#xblockedi>32
,       #%blocked1276 = >arith.shrui
       %%12347, =  tt.splat% cst_16% arg10:  :tensor< 4ix324 x->32 xtensor<i132x, 32#xblockedi>32
,       #%blocked1286 = >arith.ori
       %%12648, =  arith.muli% 127% 46:,  tensor<%447x 4:x 32tensor<x1ix3232, x#iblocked32>
,       #%blocked1296 = >arith.addi
       %%12849, =  arith.extsi% cst_11% 48:  :tensor< 4tensor<x14xx3232xxii3232, , ##blockedblocked6>>
       to% 130tensor< = 1arith.shruix 32%x129i,64 , %#cst_11blocked 6:> 
tensor<      4%x504 = xtt.broadcast32 x%i4532,  #:blocked >tensor<
64x      1x%i13164 = , arith.minui#blocked 6%>130 ,->  %tensor<cst_2264 x:32 xtensor<i464x, 4#xblocked326x>i32
,       #%blocked51 = >tt.broadcast
       %%49132  = :arith.shrui  tensor<%1113x,32 x%icst_1764 , :# blockedtensor<64>x 4->x 32tensor<x64ix3232, x#iblocked64>, 
#      blocked%6133> = 
arith.ori       %%52132 = ,arith.addi  %%13150 :, tensor< 4%x514 x:32 xtensor<i6432x, 32#xblockedi>64
,       #%blocked1346 = >arith.trunci
       %%13353  = :tt.addptr  tensor<%4arg1x,4 x%3242x i:32 , !#ttblocked.>ptr<i8> ,to  itensor<644
      x%4x5432 = xarith.extsii 8%, arg14# blocked:> 
i      32% 135to =  tt.reshapei 64%
134       %:55  = tensor<arith.muli4 x%47x,32 x%i548 , :# blockedi>64 
->       %tensor<564 = xtt.addptr4 x%16arg3x,2 x%i558 , :# blocked!7tt>.
ptr<i8>      ,% outLHSi, 64%
outRHS       = %tt.split57  = %tt.expand_dims135  %:41  {tensor<axis4 = x14 : xi3216}x 2:x itensor<832, x#iblocked732>,  #->ttg .tensor<slice<{dim = 1, parent = #linear1}>>4 x->4 xtensor<1632xxi18x, i#32blocked, 2#>linear
1      >%
136       = %arith.shli58  = %tt.splatoutRHS ,% arg15% cst_2:  :i 32tensor< 4->x 4tensor<x3216xx1ix8i, 32#, blocked#2linear>1
>      
%      137% = 59arith.ori =  arith.muli% outLHS%,57 ,% 136% 58:  :tensor< 4tensor<x324xx116xxii328, , ##linear1blocked>2
>      
%      60% = 138arith.extsi =  tt.reshape% 59% 137:  :tensor< 32tensor<x41xx4ix3216, x#ilinear81, ># blockedto2 >tensor< 32->x 1tensor<x4ix6464, x#lineari18>, 
#      blocked%861> = 
tt.make_range       {%end139 =  = 4tt.reshape :  %i10532 , :start  = tensor<04 : xi432x}1 x:i 8tensor<, 4#xlineari>32 , -># ttgtensor<.4slice<{dim = 0, parent = #linear1}>x>4
      x%i628 = , tt.broadcast# ttg%.60slice<{dim = 2, parent = #blocked}> >:
       tensor<%32x1401 = xtt.reshapei 64%, 106# linear:1 >tensor< ->4 xtensor<432xx14xxii864, , ##blockedlinear>1 >->
       tensor<%463x = 4tt.expand_dimsx i%861,  {#axislinear = 20> : 
i      32%}141  = :ttg.convert_layout  tensor<%4140x i:32 , tensor<4#xttg4.xslice<{dim = 0, parent = #linear1}>i>8 , -># lineartensor<21>x 4->x itensor<324, x#4linearx1i>8
,       #%ttg64. = slice<{dim = 2, parent = #blocked}>tt.broadcast> 
%      63% :142  = tensor<arith.extui1 x%4141x i:32 , tensor<#4linearx14> x->i 8tensor<, 32#xttg4.xslice<{dim = 2, parent = #blocked}>i>32 to,  #tensor<linear41x4>x
i      16%, 65# = ttgarith.extsi. slice<{dim = 2, parent = #blocked}>%>64
       :% 143tensor< = 32arith.shlix 4%x142i,32 , %#cst_30linear 1:>  tensor<to4 xtensor<432xxi416x, i#64ttg, .#slice<{dim = 2, parent = #blocked}>linear>1
>      
%      144% = 66tt.bitcast =  arith.addi% 143% 65:,  tensor<%462x 4:x itensor<1632, x#4ttgx.slice<{dim = 2, parent = #blocked}>i>64 , -># lineartensor<14>x
4      x%bf1667,  = #tt.splatttg .%slice<{dim = 2, parent = #blocked}>56> 
:       %!145tt = .tt.expand_dimsptr<i8>  %->144  {tensor<axis32 = x24 : xi!32tt}. ptr<i8>:,  #tensor<linear41x>4
x      bf16%, 68# = ttgtt.addptr. slice<{dim = 2, parent = #blocked}>%>67 ,->  tensor<%466x :4 xtensor<132xxbf164, x#!blockedtt>.
ptr<i8>      , %#146linear = 1tt.broadcast> ,% 145tensor<32 x:4 xtensor<i464x, 4#xlinear11x>bf16
,       #%blocked69> =  tt.load->  %tensor<684x 4:x 32tensor<x32bf16x, 4#xblocked>!
tt      .%ptr<i8>147 = , tt.reshape# linear%1146> 
:       %tensor<704 = xtt.trans4 x%6932 {xorderbf16 = , array<#iblocked32>:  1->,  0tensor<>4}x 128:x bf16tensor<, 32#xblocked41x>i
8      , %#148linear = 1amdgpu.scaled_upcast_fp4>  %->138  scaletensor< 4%x14732 {xaxisi = 81,  : #ittg32.}slice<{dim = 2, parent = #blocked4}> >:
       tensor<%471x = 64tt.splatx i%298 , :# blocked!8>tt, .tensor<ptr<bf16>4 x->128 xtensor<bf164, x#128blockedx1!>tt .->ptr<bf16> , tensor<#blocked41>x
128      x%bf1672,  = #tt.addptrblocked 1%>71
,       %%14928 =  arith.cmpi:  eq, %139,tensor< 4%xcst_31128 x:! tttensor<.4ptr<bf16>x, 4#xblockedi18>, ,# ttgtensor<.4slice<{dim = 2, parent = #blocked}>x>128
x      i%64150,  = #tt.expand_dimsblocked 1%>149
 {      axis% = 732 =  : tt.loadi 32%}72  : :tensor< 4tensor<x44xx128ix1!, tt#.ttgptr<bf16>., slice<{dim = 2, parent = #blocked}>#> blocked->1 >tensor<
4      x%474 = xtt.splat1 x%i531 , :# blocked!>tt
.      ptr<i8>% 151-> =  tt.broadcasttensor< 64%x15032 x:! tttensor<.4ptr<i8>x, 4#xblocked16x>i
1      , %#75blocked = >tt.addptr  ->% 74tensor<,4 x%452x 32x:i 1tensor<, 64#xblocked32>x
!      tt%.152ptr<i8> = , tt.reshape# blocked%6151>,  :tensor< 64tensor<x324xx4ix6432, x#iblocked16, >#
blocked      >% 76-> =  tt.loadtensor< 4%x75128 xcacheModifieri 1=,  #cgblocked 1:> 
tensor<      64%x15332 = xarith.select! tt%.ptr<i8>152, , #%blockedcst_06, >%
148       : %77tensor< = 4ttg.convert_layoutx 128%x76i 1:,  #tensor<blocked641x>32, xtensor<i48x, 128#xblockedbf166, ># blocked->1> 
tensor<      64%x15432 = xttg.local_alloci 8%, 153# blocked:3 >(
tensor<      4%x78128 = xtt.reshapebf16 , %#73blocked 1:> )tensor< -> 4!xttg128.xmemdesc<4x128xbf16, #shared, #smem>bf16
,       %#155blocked = 1ttg.local_load >% 154->  :tensor< 4!ttgx.4memdesc<4x128xbf16, #shared, #smem>x 32->x bf16tensor<, 4#xblocked128x>bf16
,       #%ttg79. = dot_op<{opIdx = 0, parent = #blocked3}>math.absf> 
%      78%156  = :arith.extui  tensor<%470x :4 xtensor<324xxbf1632, x#iblocked8>, 
#      ttg%.80slice<{dim = 2, parent = #blocked4}> = >arith.extf  to% 79tensor< 4:x 32tensor<x4ix164, x#32ttgx.bf16slice<{dim = 2, parent = #blocked4}>, >#
blocked      >% 157to =  arith.shlitensor<4 x%4156x,32 x%f32cst_19,  #:blocked >tensor<
4      x%3281x = i"16t, t#.ttgr.eslice<{dim = 2, parent = #blocked4}>d>u
c      e%"158( = %tt.bitcast80 )% <157{ axis: =  2tensor< : 4ix3232}x>i (16{, 
#ttg      .^bb0slice<{dim = 2, parent = #blocked4}>(>%arg16 : ->f32 , tensor<%4arg17x: 32f32x)bf16:, 
#        ttg%.209slice<{dim = 2, parent = #blocked4}> = >arith.maxnumf
       %%159arg16 = ,tt.expand_dims  %%arg17158  {axis: = 2  : f32
i        32tt.reduce.return}  %:209  tensor<:4 xf3232
x      bf16}, )# : ttg(.tensor<slice<{dim = 2, parent = #blocked4}>4>x 4-> xtensor<324xxf3232, x#1blockedx>bf16) -> , tensor<#4xblocked44x>f32
,       #%ttg160. = slice<{dim = 2, parent = #blocked}>tt.broadcast> 
%      %15982  = :ttg.convert_layout  tensor<%481x 32:x 1tensor<x4bf16x, 4#xblockedf324, ># ttg->. slice<{dim = 2, parent = #blocked}>tensor<>4 x->32 xtensor<324xxbf164, x#f32blocked, 4#>ttg
.      slice<{dim = 2, parent = #linear}>%>161
 =       tt.trans% 83% = 160tt.expand_dims { order% = 82array< {iaxis32:  = 02,  : 2i, 321}> }:  :tensor< 4tensor<x44xx32f32x, 32#xttgbf16.slice<{dim = 2, parent = #linear}>, ># blocked->4 >tensor< 4->x 4tensor<x41xx32f32x, 32#xlinearbf16>, 
#      blocked%984> = 
tt.expand_dims       %%16281 =  {tt.reshapeaxis  = %2161 :  i:32 }tensor< 4: xtensor<32x432xx4bf16, x#f32blocked, 9#>ttg .->slice<{dim = 2, parent = #blocked}> >tensor< 128-> xtensor<324xxbf164, x#1blockedx5f32>, 
#      blocked%>163
 =       amdgpu.scaled_upcast_fp4% 85% = 77tt.bitcast  scale% 83 %:162  {tensor<axis4 = x04 : xi132x}f32 , :# lineartensor<>64 x->32 xtensor<i48x, 4#xblocked13x>i,32 , tensor<#128linearx>32
x      bf16%, 86# = blockedtt.bitcast5 >% 84->  :tensor< 128tensor<x432xx4xbf161, x#f32blocked, 5#>blocked
>       %->164  = tensor<arith.cmpi4 xeq4,x 1%x70i, 32%, cst_20# blocked:> 
tensor<      4%x8732 = xarith.addii 8%85, ,# ttg%.cst_28slice<{dim = 2, parent = #blocked4}>> 
:       %tensor<1654 = xtt.expand_dims4 x%1164x {iaxis32 = , 2# : lineari>32
}       %:88 tensor< = 4arith.addix 32%x86i,1 , %#cst_1ttg .:slice<{dim = 2, parent = #blocked4}> >tensor< 4->x 4tensor<x41xxi3232x, 1#xblockedi>1
,       #%blocked894 = >tt.bitcast
       %%87166  = :tt.broadcast  tensor<%4165x 4:x 1tensor<x4ix3232, x#linear1>x i->1 , tensor<#4blockedx44>x 1->x itensor<324, x#32linearx>32
x      i%190,  = #tt.bitcastblocked 4%>88
       :% 167tensor< = 4tt.transx 4%x1661 {xorderi = 32array<, i#blocked32>:  0->,  2tensor<, 41x>4}x 1:x itensor<324, x#32blockedx>32
x      i%191,  = #arith.andiblocked 4%>89 ,->  %tensor<cst_274 x:32x 32tensor<x4ix14, x#1blockedx9i>32
,       #%linear168> = 
tt.reshape       %%92167 =  arith.andi:  %tensor<904,x 32%xcst_4 32:x itensor<14, x#4blockedx91>x i->32 , tensor<#128blockedx>32
x      i%193,  = #tt.bitcastblocked 5>%
91       %:169  = tensor<arith.select4 x%4168x, 1%xcst_21i, 32%, 163# : lineartensor<>128 x32->x itensor<14, x#4blockedx51>x, f32tensor<, 128#xlinear32>x
      bf16%, 94# = blockedtt.bitcast5 >%
92       %:170  = tensor<ttg.local_alloc4 x%4169x1 x:i 32(, tensor<#128blockedx>32 x->bf16 , tensor<#4blockedx54x>1) -> x!f32, ttg#.memdesc<128x32xbf16, #shared, #smem>blocked
>      
%      171% = 95ttg.local_load =  math.log2% %17093 :  :! ttgtensor<.4memdesc<128x32xbf16, #shared, #smem>x 4->x 1tensor<xf32128, x#32linearx>
bf16      , %#96ttg = .math.log2dot_op<{opIdx = 1, parent = #blocked3}> >%94
       :% 172tensor< = 4tt.dotx 4%155x, 1%x171f32,,  #%blockedcst_3>
       :% 97tensor< = 4math.floorx 128%95x bf16: , tensor<#4ttgx4.xdot_op<{opIdx = 0, parent = #blocked3}>ler_DP1_TP1: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
1>x f32*,  #tensor<linear128>x
32      x%bf1698,  = #math.floorttg .dot_op<{opIdx = 1, parent = #blocked3}>%>96  ->:  tensor<tensor<44x32xx4f32x, 1#xblockedf323, >#
blocked      >%
173       = %arith.addf99  = %arith.subf172 ,% 97%,cst_3  %:cst_26  tensor<:4 xtensor<324xxf324, x#1blocked3x>f32
,       #%linear174> = 
arith.truncf       %%100173 =  arith.subf:  %tensor<984,x 32%xcst_5f32 , :# blockedtensor<34>x 4tox 1xtensor<f324, x#32blockedx>bf16
,       #%blocked1013 = >tt.clampf
       %%17599 = ,arith.extsi  %%cst_2513,  :% cst_24tensor<, 4propagateNanx i=32,  #nonettg .:slice<{dim = 1, parent = #blocked3}> >tensor< 4tox 4tensor<x41xxif32, 64#, linear#>ttg
.      slice<{dim = 1, parent = #blocked3}>%>102
 =       tt.clampf% 176% = 100arith.extsi,  %%11cst_18 ,:  #%iblockedcst_2332  = ,to#  ttgpropagateNani. 64blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>= 

none      #blocked %1:177 =   = #tensor<tt.splatttg4 .blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>x%
4176#blockedx 21: = x #f32ittg, 64.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}># 
#blocked->blocked> 3 = 
      tensor<#%4ttg103x.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> = i64
arith.fptoui, # #ttgblocked%.4101slice<{dim = 1, parent = #blocked3}>> =  
      #ttg:%.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}> 178
#tensor< = blocked4arith.addi5x  = 4%177#x,ttg.1 blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>x%
#f32175blocked,  6 = #:#ttglinear .blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>>tensor<
 4x#toiblocked7 64ler_DP0_TP0: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
 = tensor<, #4#ttgxttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>4.
xslice<{dim = 1, parent = #blocked3}>#blocked1>8 = x
      #ttgi%179.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>8 = 
, arith.extsi#blocked# 9 = linear%#>32ttg
 .      :blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>% 
#104tensor<linear = 32 = arith.fptouix#ttg i.%32linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>102, 
# #linear1:ttg =  .#tensor<slice<{dim = 0, parent = #blocked3}>ttg4>.x tolinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>4 
#xtensor<linear1322xx = f32i#, 64, ttg##.blockedttglinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>>.slice<{dim = 0, parent = #blocked3}>
# >sharedto
 =        #ttgtensor<%180.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>4 = 
#xarith.extsismem4  = x%#ttg130.shared_memoryx 
i: module8i attributes, 32 {# "blockedtot> tg
i.n      %#64um105blocked
      - =  = %carith.addi#181 = tas ttgtt.splat"%103.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>  = ,
%1801 %#  : cst_29blocked:i :1 =  32 #i64, tensor<ttg ->"t4. tx4blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>tensor<g.x
32n1#xuxblockedi64m-i2, w8,  = #a##ttgrplinear>ttg.s
.slice<{dim = 0, parent = #blocked3}>>" =       blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
4%
       : 106#%182i32 = blocked = , arith.addi 3arith.addi ttg.target = %104 = %", #181,h%ttg icst.%179p blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> :: 
: gftensor<4#tensor<x9xblocked43254 = x0x1#i64"xittg, , 8, .#ttg"#blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>.slice<{dim = 0, parent = #blocked3}>ttblocked
>
g.>
#      t      %blocked%h1075183r =  =  = eaarith.subf #arith.muli ds%ttg%-cst_6.7pe,blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>, r- 
%w%102#6ar :blocked p tensor<6:"4 =   = x#i644ttg64 : ix.
321xblocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>      }f32
% , ##184 = {blockedblocked7tt.addptr 
> = %arg2,  
# tt.func      ttg% %108.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>183public = 
#  math.exp2blocked8: @  = !_batched_gemm_afp4_wfp4_pre_quant_kernel%107#ttgtt( ..ptr<bf16>%:blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>,arg0 
 : tensor<4#blockedi64!ttx49 = 
.x1#ttg      ptr<bf16>xf32.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>%185 {, 
 = tt.divisibility##tt.expand_dims = blockedlinear 16> = % : i
      #ttg17832%. {}109linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>axis = ,  = 
1%arith.extf# : iarg1:  linear32}!%1 :tt.78 =  ptr<i8> #tensor< {: ttg4xtt.divisibility = tensor<4.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>i6416x
,  : 4##ix32linearttg.32xbf162 = slice<{dim = 1, parent = #blocked3}>}, ##ttg>, blocked. %> linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>->arg2to 
# tensor<: tensor<shared4x!tt4x = 1x.ptr<bf16>4#i {xttg64tt.divisibility32.,  = xswizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>#16f32, 
#blocked3 : #smem>
i32blocked =       }>
#ttg%186,       . = %%110shared_memoryarith.extsi arg3:  = 
%!tt.broadcastmodulearg13tt  attributes :.ptr<i8>% {  {108 "i32tt.divisibility = :t to16 t  : tensor<g.i64i4xn
      32}4u%, x1m-187%xf32ct = arg4, #att.expand_dims : blocked>s%i " = 17532-> 1 {axis {tensor< :  = tt.divisibility4xi1 :  = 4x32i1632, 32 : xf32"t} i32, t: }, #gtensor<4%blocked.nxarg5>umi: 
      -w64, i%a#32111rttg. { = psslice<{dim = 1, parent = #blocked3}>tt.divisibilityarith.mulf " = > = %4 ->16109 :   : ,itensor<i32 %324x}, 110, 1% ttg.targetxarg6: = i64:  ", i32tensor<h#blocked {4xip3tt.divisibility4:> = x32gf
16xx       : f329%188i, 5 = 32}#0arith.muli , blocked>"%186%
      , ,arg7%" : 112t%i = tg17632tt.bitcast.t : { h tt.divisibility%rei64 = 111 ad
16: s-       : itensor<4pe%32}x4r-189, xw = %32att.splat arg8: xf32rp%i, "186 32 {#blocked = :tt.divisibility> 64 i = -> : 6416 tensor<i32 -> : 4x} i4 tensor<432}x32{x1, x
xi%i  64arg932tt.func, : ,  #blockedi#blockedpublic332>
 >
 {      @      tt.divisibility%113_batched_gemm_afp4_wfp4_pre_quant_kernel%190 =  = ( = 16arith.andi%arith.muli  :  arg0%189i32%112: ,}, !tt , %.%187%cst_7ptr<bf16> arg10:  : {: i32 tensor<tt.divisibility = tensor< {4x164xtt.divisibility = 4x : 1x1632xi32i : i32}64, i, #, #blocked32}blocked>%arg13, 
      : >%%!
      arg11: 114 = tt.%191iarith.shruiptr<i8> = 32  {tt.addptr  {%112tt.divisibility = %tt.divisibility,16184, =   : i 16%cst_832% :  }188i:,  32 %:}tensor<4arg2:  , x!!tt%4tt.arg12: x32.ptr<bf16>ptr<bf16>,ix { 32itt.divisibilityi64 {32 = 
      tt.divisibility = , 16%19216#blocked : i =  : >32}tt.expand_dimsi
      ,  32}%115%%,  = arg3182%arith.andi:  {axisarg13 %!tt = : 114,.ptr<i8>0i % { : i32cst_9tt.divisibility32 {  = } tt.divisibility:16:  =   : itensor<16tensor<3232x : 4}iix4, 64, 32}x32%arg4#, x: ttg.%iislice<{dim = 0, parent = #blocked3}>arg14: 32, 32 {> i32#tt.divisibility-> {blocked> =  tt.divisibility = 
16tensor<16 :        : 1xi%i3232116 = 32}x}arith.andi, i64,  %, #%%arg5: blocked3arg15: 112i>
i,32      32  {%)%tt.divisibility193 =  attributes {cst_10  = tt.broadcastnoinline:16  =  tensor< : %190false4i }x32: 4x} {
32x, tensor<    i%4%32arg6xcst, : 1 = #blockedi32xiarith.constant> {64,  
      tt.divisibility = #blockeddense<%163>127117 =  : i >arith.addi 32-> : %} tensor<115,, tensor<4 %4x%arg7x324xcst_11: xi1 :i3264x  {, #itensor<4tt.divisibility = blocked8x4163>, x : 
      #blocked32xi32%194>i} = 
32, , tt.expand_dims     #%%%blocked>arg8: 179cst_0
i { =       32axis = arith.constant%118 {0 :   = tt.divisibilityidense<arith.subi = 32} 0x7FC0 16: >% : tensor<32 : tensor<cst_12ix4,32i64x }, 128%, #x117%arg9ttgbf16 : .slice<{dim = 0, parent = #blocked3}>, :i32>#  { ->blockedtensor<tt.divisibility 1>4 = tensor<1
    x16x%cst_14x : i32 = 32x32}xiarith.constanti, 64,  32, %#blockeddense<#blockedarg103>2097152>
: 
>      i       : tensor<%32%1954x119 =  { = 4xarith.cmpitt.divisibilitytt.broadcast1  =  xult16%i, : 19432,  i32 #%}, : blocked115%tensor<1>, arg11: x32
    %ix%cst_1232i64cst_2 =  : {, arith.constant tensor<tt.divisibility = # 4x16blockeddense<4 : 34x32i32> >x}-> : i,  tensor<32%tensor<4, #arg12: 4xx4blockedi32x>32xi16
 {64x      tt.divisibility, i% = #blocked8, 120163# =  : i>
blockedarith.shrui 32}      2>%, %196
116,%arg13 =      %: tt.addptr%cst_11i c31_i32 32% = :  {191arith.constanttensor<4tt.divisibility = , x416 31x : %180 : 32i :ixi32} 3232, !
, %tt    #arg14.%blocked>: ptr<bf16>cst_3
      %121 = arith.ori %120, % = i,cst_13arith.constant32    {i64:dense<tt.divisibility
       0.000000e+00 = %tensor<>161974 :  : i = xtensor<32arith.addi44} xx, %3232%arg15195xx: i, i32f3232%, #, )193blocked# attributes >blocked {:
      3noinline =  %>falsetensor<122
}4 =      xarith.shrui%{
32 c32_i32    x% = %csti121arith.constant = 64, ,  arith.constant#%32 blocked118 : dense<3 :i127> 32>
tensor<
     :       4%tensor<%x4c4_i324198x = x = 32arith.constant4xarith.extsix 1 i4x%arg432 : i , #i8:blocked32,  i>
#blocked32
    >       %
to%true     i123 = %cst_064 = arith.constant = 
arith.select arith.constant       true %%
dense<199119    0x7FC0 = , %>tt.splat%c0_i32 :  122 = tensor<%, arith.constant4198 %116 x: : 0128 tensor< : xi4ibf16, 64x432#blocked ->x
1> 32x    
    tensor<i1%%cst_14, cst_4 = x# = arith.constant1blockedarith.constant x> dense<i, dense<209715264tensor<-8388608>, 4> : #blockedx : tensor<34tensor<4>x4x4
      32xxx1%i4x20032xi = , 132arith.cmpi #x, #sltblockediblocked,>32> 
, 
%      #    185,%blocked% 124>cst_2 = % = 
arith.constant199arith.maxui      : %dense< tensor<%cst_54>4115 =  : tensor<x1,arith.constant4xxi % 4x64cst_14dense<16,  2.000000e+00x#:>iblocked  : 83tensor<tensor<, #>
4x4blocked2      4x>%x4
201 = 32x    %arith.extsi xi1c31_i32 = %32xarith.constantarg5 , f32 : #, 31i32blocked# :  to>blockedi 
>32i      %

64
125               = %%%arith.subi cst_6cst_3 = 202% = arith.constant = 124,arith.constant tt.splat  dense< %dense<0.000000e+00%cst_140.000000e+00>201 > :  : : tensor<4: tensor<x itensor<43264 4xxx->4x4f32,  32x#tensor<1xi1blocked3x32x>32, f32
    xi#blocked, %c32_i3264># = , #
blockedarith.constantblocked      > 3>%
32
      126     : % = %i203 = arith.shlicst_732
arith.cmpi  =      slt%arith.constant%c4_i32, 125  = %,dense<arith.constant192 -2147483648 ,%>4 cst_15 :  : i% tensor<32
202:4     : x% tensor<tensor<4true14x = xx32arith.constant324x xx32itrue
ix32    %64i, c0_i32, 32# = #, blockedarith.constantblocked3#> >blocked
0
      >     : %
%i32204 =       cst_8
tt.broadcast% =      127arith.constant%% =  cst_4200arith.shruidense< =   23arith.constant:%>  123 : dense<tensor<,tensor<-8388608>4 %4 : xcst_16xtensor<1 44x:xx4i1 32x1, tensor<xx#4iiblockedx3232, 34, #blocked>x#> 32blocked
-> xi>    tensor<32
%4,     cst_5 = x#blocked%arith.constant32>cst_9 x
 = dense<i      arith.constant2.000000e+001% >, 128dense< : # = 255tensor<blocked3arith.ori>4>  : x
%tensor<4      %1264x1205,xx =  4f32tt.broadcast%127x, #  :32blocked% x>203tensor<4i
 :x32     4, %cst_6tensor<x# = 1x32blockedarith.constant32x> xi32
dense<i,     0.000000e+00>1, #% : #blockedblocked>cst_10tensor<3
 = 4x>      arith.constant4x % 1->129dense<x  = 8388607f32tensor<arith.addi>, 4x  : #32x%tensor<blockedi1284>1,x
,  4    %#%xcst_7blocked3cst_1132 = >
 xarith.constant      :i % tensor<32dense<206 = 4, -2147483648>arith.andi x4# : %204xblockedtensor<,32>4 x
x%205i32    4 , %x32: #cst_11xtensor<blocked = i324>arith.constant, x32
       #blockedx%dense<>ler_DP3_TP3: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
i1301
    1 = >%cst_8, #arith.shrui :  = blocked tensor<arith.constant3%4 >129xdense<
      , 423>%207%cst_11x :  =  32tensor<4tt.splat:xx  tensor<i4x%1964x3232x :4, i x32#32, !ttxiblocked#blocked.32>>ptr<bf16> , 

->#         blocked%%tensor<>cst_12cst_94
 =  = x32      arith.constantarith.constantx%131  ! = dense<dense<tt.arith.minui127255>ptr<bf16> > : , #% : tensor<blocked130tensor<4x3>,44
 xx32      %cst_224x% xi32208:32, # =  xblockedtt.addptrtensor<i> 432
%x,     2074#%,xblockedcst_10 32> = %x
arith.constant197i      :32%#dense< , #cst_13blocked8388607>tensor<blocked =  =  : 4x>arith.constant#tensor<32
 ttg4xx      dense<.4x!tt%1324194304blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>32. = >
xptr<bf16>arith.shrui  : #i32, #%tensor<blocked, blocked11341#3>,x = blocked, 4#> %xttg
    tensor<4cst_1732.%x32 xblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>cst_11x:i
 = i64 32#arith.constant, tensor<, blocked #4#2dense<blockedxblocked = 134>#>>x
ttg : tensor<
32    .4x      x%blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>4xtt.storei32cst_14
32 ,  = #x%#arith.constantblockedi32208blocked 3, ,>
dense< = #       %126#blocked%174133>ttg>, =  : .
     arith.ori tensor<blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>%%206%4
cst_12 132x# = :,4blockedarith.constant  x4 tensor<%32 = dense<4131 x#127x:ittg>32 32. : xtensor<, blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>tensor<!4#
4xttxblocked#4.4>blockedxptr<bf16>x32
532, x     = x#i%#i32blocked32cst_15ttg, #3,  = .blocked>>#blockedarith.constantblocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>

> 
        
dense<#%}      %2blockedcst_13
134>6 =      =  :  = arith.constanttt.returnarith.truncitensor<# 
 4ttgdense<  }%133x.4194304>
 4blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}> : }:x
tensor<
 32#blocked4x
tensor<4x74x{-#x4i = 32
x3232#x  x, ttgi32externali32#., _resources: {
, blockedblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>#blocked    #blocked>
>mlir_reproducer: {>
#

     blocked          to%8%pipeline cst_16 = cst_14: tensor< = # = "4arith.constantttgarith.constantbux4 . ilxdense<blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>dense<t3221
126>ix># : n.i : blockedtensor<m8tensor<94xo, 4 = 4d#x#x32ublocked4ttgxle>x.i(
32blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>32op      x
, t%i##im13532linearblocked>i = ,  = 
ztt.reshape##    %e blockedttgcst_15-%>. = a134
linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>arith.constantm     
 d-: %#dense<ltensor<cst_17linear2d4 = 1>sxarith.constant =  : -4 #tensor<uxdense<ttg4s32x28.xai>linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>4xge8,  : 
32{l#tensor<#xdblocked4linearis>x232- 4 = , l->x##i 32ttgblockedmtensor<x.>i4ilinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
tx32
    =4, #%0 x#sharedcst_16 = ta16blocked = arith.constantrx># g2
ttgdense<ex    .21t-i8%swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>>a, #cst_18
 : rblocked = #tensor<ch7>arith.constantsmem4=
        = xgf%dense<#4xoutLHS-1.270000e+02ttgx9, >.3250% : shared_memoryxi},outRHS = tensor<
32 tt.split4module, #tr x attributesblocked>it%4 {
on135x"    - 1t%sc:xtcst_17f f32g = -tensor<4, .arith.constanttx#n o4blockedudense<-x>m28cf16x
->,2    c :  xi%ttensor<c8cst_19a4on, # = sxveblocked7arith.constant"4rt>   = x-->dense<132in 7 : xdtensor<>iiex4 : 3232-xtensor<, , t44"#oxxtblocked-1632t>lxxg
lii.    v816n%m, , ucst_18{##m = iblocked2ttg-arith.constantn>
.w d      slice<{dim = 2, parent = #blocked4}>adense<e%>r-1.270000e+02x-136
p>bi =     s : tarith.shli%"tensor<4wi cst_20 = xdt% = 44houtRHSarith.constant : x=,  i10%cst_2dense<32x}, -1, f32,  a:>ttg.target#blockedl  :  = >ltensor<tensor<"
    o44h%cax4xicst_19tx1632p = e-xix:arith.constanta8ig m, 8fdense<d#, x7gpblocked#9>u-2ttg5 : sh>.0tensor<a
slice<{dim = 2, parent = #blocked4}>"4re      %>, xd137
"32- =     txmarith.ori%tie cst_21g16mo% = ., routLHSarith.constantt#ttgy,,  h. %dense<rslice<{dim = 2, parent = #blocked4}>c1360x7FC0e>o :>a
n  : d    vtensor<4tensor<s%erx128-cst_20t4xp = -x1632earith.constanttxxr riibf16-dense<t8, w-1on, #a>-#blockedr : amblocked25ptensor<d>>"4xg

 = 32p          64xu%% : i-138cst_22i8, t =  = 32#ott.reshapearith.constant}ttg-   .l%dense<{slice<{dim = 2, parent = #blocked4}>l1377
>v :>  m  : 
tt.func{atensor<4tensor<     rx44%publicchxxcst_21 =g164 = @fxxarith.constant_batched_gemm_afp4_wfp4_pre_quant_kernelxi832 (9, xdense<%5#i0x7FC0arg00 blocked32>: f2,  : !t>#tensor<ttz= ->blocked128.t >xptr<bf16>rtensor<
32 {u4x    xtt.divisibilitye64%bf16 = },xicst_23, 16 8 = # : ic, #arith.constantblocked32anblocked8 5}on>dense<>, i
1.270000e+02
%ca      >    arg1l% : %: iz139tensor<cst_22!tte{ = 4 = .  tt.reshapexarith.constantptr<i8>ma 4  {x%xdense<tt.divisibility = -i1051716t x> : ier:f32 : 32a , tensor<}titensor<#4, o4blockedx%arg2nsx>4: =14x
x!tt0 1x    32.mi%xptr<bf16> {a8cst_24itt.divisibility = x,  = 3216-#arith.constant,  : nulinear #im->dense<blocked32r 1.270000e+02>}e->>
, w  :     %ritensor<tensor<%arg3t44cst_23: exx = !s44arith.constanttt=xx .-i1dense<ptr<i8>18x1.270000e+02 { r, f32>tt.divisibilitye#,  :  = gttg#tensor<16i.slice<{dim = 2, parent = #blocked}>linear4 : io>
>x32n-      
4}si%    x, m140 = %1%pltt.reshapecst_25xarg4i % = f32: f106arith.constant, iy  #32 {=n: dense<blockedtt.divisibilityotensor<-1.270000e+02> = rm4x>
16al4x :      :  1xtensor<%itei84cst_2432s, #x = }tblocked>4arith.constant, - x %co-> 1dense<arg5nvtensor<4x1.270000e+02: ex4f32>irxi,  : 32ge8, #tensor< {nc#linear4tt.divisibilitye=linear>x = f2
416a>    x : ils
      %132e%cst_26x},  141 = f32%to = arith.constant, arg6pttg.convert_layout  #: -%140dense<linearid 2.000000e+00>32o:>
 {w  :     tt.divisibilityntensor<tensor<% = =t44cst_2516rx4x =  : uex4arith.constanti}ix 32,81dense<},  , x-1.270000e+02%c#linearf32>arg7s2,  : : ie>#tensor<32 {,  ->linear4tt.divisibilityco tensor<>x = n4
416vx4    x : ex%1irticst_27x32}-c8 = f32, f, arith.constant, %-# #arg8: tttgdense<lineario.-8388608>32 {-slice<{dim = 2, parent = #blocked}>>
tt.divisibility = l> :     16l
tensor<% : ivm      4cst_2632}{%x = , in1424arith.constant%d = x arg9: exarith.extui1dense<i32-b x2.000000e+00 {i%141i>tt.divisibilityt 32 :  = wi:, tensor<16d #4 : ithtensor<linearx32}=04>4, }x4
x%,x    1arg10 ci8%x: o, cst_28f32inv# = , 32 {ettgarith.constant#tt.divisibility = rt. linear16-slice<{dim = 2, parent = #blocked}>dense<> : iar>2097152
32}i >    , thto : %%- tensor<cst_27arg11totensor<4 = : i-l4xxarith.constant32 {l44 tt.divisibilityvxxdense< = mi1-838860816 : {16x>ii, i : 32n#32tensor<}dettg, 4, x.#x%-bslice<{dim = 2, parent = #blocked}>linear4arg12: i>>xitw
      
132 {id%    xtt.divisibilityt143 = %i = harith.shli cst_293216=% = ,  : 0}142arith.constant#i32,, linear},   dense<>%arg13c%127
: acst_30>    in : : %32o tensor<cst_28 {ntensor<4 = tt.divisibilityic4xxarith.constant = a4x4 16lixdense< : ii161209715232ze, x>}{ #i : , % ttg8tensor<arg14ma.slice<{dim = 2, parent = #blocked}>, 4: x->#xi32i
linear4 {t      >xtt.divisibility = e%
116r144    x : iat = %i32itt.bitcastcst_3032}, o % = , %n143arith.constant#arg15s=  linear: 1:dense<>i0 7
32 tensor<>    )m4 : % attributesaxtensor<cst_29 {x44 = noinline-xxarith.constant = ni4 falseu16, xdense<}m#ttgi127 -.16>{rslice<{dim = 2, parent = #blocked}>,  : 
e>#tensor<    w ttg4%r->.xcstit slice<{dim = 2, parent = #blocked}>4 = estensor<>xarith.constant=4
1 -1x4    xdense< x%i127rbf16, cst_318>eg# = ,  : ittgarith.constant#tensor<o.slice<{dim = 2, parent = #blocked}> linear4n>dense<>x-
-1
4s      >    xim% : %1pl145tensor<cst_30xif = 4 = iytt.expand_dimsxarith.constant8= 4 , n%xdense<#blockedor144i7>m {8>
aaxis,  :     l = #tensor<% t2ttg4cst_0es : .x = t-i32slice<{dim = 2, parent = #blocked}>4arith.constantco} >x nv: 
idense<etensor<    160x7FC0r4llvm.intr.assume, >gex # : n4%ttgtensor<cextrue.4=bf16 slice<{dim = 2, parent = #blocked}>xf, :>128a# 
xlsttgi    bf16e .1%, toslice<{dim = 2, parent = #blocked}>>
cst_31#p      = blocked1-d-> llvm.intr.assumearith.constant>otensor<4  
wnx4%dense<    =x1true-1%tx >cst_1rbf16: :  = u,  tensor<arith.constante}#i4 ,blocked1xdense< >
42097152>c
    x : se      %llvm.intr.assumeitensor<, 146 =  84sytt.broadcast%, xmb true#4xol%145 ttg1- :.xd: slice<{dim = 2, parent = #blocked}>i32c i>, #etensor<1
blocked,4
    > ex4    llvm.intr.assume
nxllvm.intr.assume     a1 %%cst_2bx%true = lebf16, true arith.constant-# : lblocked: dense<i>  i4ne-> i1>-tensor<1
 : i4
    tensor<nx4    llvm.intr.assume4fxllvm.intr.assume x4o32 %x,x%true16 bf16true xc, # :ioblocked>: 8n
 i, ve      i1#rt%1
blocked2-b147 = 
    >utt.reshape    llvm.intr.assume
il llvm.intr.assume     t% %%c31_i32i146%true = n true arith.constant-f: : un : 31ctensor<4 i : -x4i1itx1
32o32
    
-x    llvm.intr.assume    lbf16llvm.intr.assume %l,  %cst_3vm#%true = {blocked>true arith.constantf  : t->: dense<z  i0.000000e+00=tensor<i1> : tr4x1
tensor<u128x
    4ebf16    llvm.intr.assumex}), #llvm.intr.assume 32"blocked1 %x,>%truef32

true ,              :#disable_threading%: blocked: 148 =  i3falseamdgpu.scaled_upcast_fp4i1>, 1


%
              138     llvm.intr.assume%verify_each: scalellvm.intr.assume c32_i32true  % = 
%%truearith.constant    }147true  
  } { :32
axis:  : #-}
 = 1 ii32 : i1
i1
    %32}
/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0    c4_i32 =      : llvm.intr.assumearith.constant:llvm.intr.assumeerror:     Failures have been detected while processing an MLIR pass pipeline%4tensor<%
true : 4true/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0:  ix64 :note: :32
x Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`     ii
i%811true = , 

arith.constant#blocked         8llvm.intr.assumellvm.intr.assumetrue
>      , %%%tensor<4truetruec0_i32x128   = x::arith.constantbf16   , #ii0blocked111 : i> 

32->        
 llvm.intr.assumellvm.intr.assume    tensor<  %4x%%cst_4128xtruetrue = bf16,   arith.constant#:: blocked  dense<1ii-8388608>
11>      

 : %149        tensor< = %llvm.intr.assume4arith.cmpi0 x  = %4eq,tt.get_program_idtruex   1%x:x139,  i %:i32, cst_31 1# :i
blocked tensor<32    >4x
llvm.intr.assume
4x         i8%%%, 1truecst_5# =   = ttg.[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 6, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank6]:E1106 11:31:41.994000 515 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
tt.get_program_id:arith.constantslice<{dim = 2, parent = #blocked}>>   
      yidense<% 12.000000e+00150 = :
>tt.expand_dims      :  %illvm.intr.assumetensor<14932 4 {axis
%x =     true4x2 : % 1i322:x}  =  f32, :arith.addii# tensor< 1blocked4x%
>4xarg5    
i1,%    ,  0%cst_6#ttg% =  = .c31_i32tt.get_program_idarith.constantslice<{dim = 2, parent = #blocked}> :  > xdense< i 0.000000e+00-> 32:>tensor<
  : 4x4    itensor<x%3241x3
xi =     41, arith.divsi%x#blocked 11>% = x
2tt.get_program_idf32      , , %151 y# = % blockedtt.broadcast c32_i32:>%150  
 :i    : 32% i
cst_7tensor<432     = x4
%arith.constantx    2 1% = dense<xi4arith.addi-21474836481,  =  >#blockedarith.extsi% : tensor<>  arg54-> %,xtensor<arg7 4x4x %324x:c31_i32x32  i32xii:, 1, 32 ##blocked iblocked>
to32>       

%152i         = 64%%tt.reshape 
3cst_8%151     =  =  :%arith.divsiarith.constant 5  tensor<4 = %dense<xarith.extsi223>4x , : 32% tensor<xiarg9%41,  c32_i32x#blocked: 4>  :x-> i 32xtensor<432iix128 3232xito
, 1,      ##blockedi%blocked>644 = 1>

arith.extsi
               %153%%% = cst_96arg7arith.select  =  =  %arith.constantarith.extsi:152,    %dense<%icst_0, 255arg1132%148>   :  : :totensor<4tensor<  x4ii128x3264x4 
i1xto    , #32 %blocked1xi5>i64 = , 32
arith.extsitensor<4,      x128#%%xbf16blocked7arg9, #> =  blocked1
arith.extsi:>      
      %%i%cst_10032154 =   to = arith.constant: ttg.local_alloc  i dense<i64%153838860732
 >     %: : to6 =  tensor< arith.extsi (4i%tensor<x64arg114x4
 128xx    :bf16, 32% #blockedx8i1i = 32 >32arith.divsito ),  i -> #%64!ttgblocked1
.memdesc<4x128xbf16, #shared, #smem>>,    

 %          %7%%3 = 155 = cst_11 arith.extsittg.local_load = :  arith.constant %%154 i0 dense<32 :1
: >     !ttg : %i.memdesc<4x128xbf16, #shared, #smem>tensor<932 4 =  -> xarith.remsito tensor<44 ix128x%64x321
bf16x,    , i %#32%8ttg, 3 = .# arith.divsidot_op<{opIdx = 0, parent = #blocked3}>>blocked: 
> %1      %
i,156 =     32 arith.extui%
%3 cst_12     %70 = llvm.intr.assume: arith.constant  :  %itensor<4dense<true32x127 
    32>:%9xi :   = 8tensor<iarith.remsi, 41 #x
%ttg4    1.slice<{dim = 2, parent = #blocked4}>xllvm.intr.assume,> 32  to x%%tensor<4itrue3x3232  x, ::i16#  , blockedii#>132ttg.


slice<{dim = 2, parent = #blocked4}>            >
%llvm.intr.assumellvm.intr.assume      cst_13  % = %%157 = arith.constanttruetruearith.shli    :%156dense<: , 4194304 i1%>i
cst_19 : 1     tensor<
llvm.intr.assume :4    % tensor<x%true4x410 :32xx =  i32arith.cmpii16, x 1#ttgisgt
.32,    slice<{dim = 2, parent = #blocked4}>>,  llvm.intr.assume
#%       %blockedarg6%158 = >,truett.bitcast
   %    %:157 %c0_i32 : cst_14 itensor< = :14xarith.constant 
    32 i%xdense<3210i16126
 = , >    arith.cmpi#ttg : scf.if .slice<{dim = 2, parent = #blocked4}>tensor< sgt>4%, ->x10  4 %tensor<x{arg6432
,x32x       xi%%bf16, 3211c0_i32#,  =  ttg.#arith.muli:slice<{dim = 2, parent = #blocked4}>blocked  >>%i
      
832%159    ,
 = %     tt.expand_dims cst_15%scf.if%158 = c4_i32  {axisarith.constant % =  :102 : dense<  i322i{
}>32       : : 
% tensor<      11tensor<4% = 4x12arith.mulix4 =  32xtt.make_range%x32 {8bf16xend,, i =  #324%ttg.,  : c4_i32slice<{dim = 2, parent = #blocked4}>#i >blocked32: >,  -> 
startitensor<     = 324%0
xcst_16 :       32x = i%1xarith.constant3212bf16 } = , #dense< tt.make_rangeblocked21: {4>> end
       : tensor< = %tensor<441604x :  = xiitt.broadcast 43232%159x, ,  :32#start tensor<xttg = 4xi.03232slice<{dim = 1, parent = #blocked1}> : x, >i1#
32xbf16blocked      }, >% #
13:blocked4     =  >%tt.make_rangetensor< cst_17 {4->  = endxtensor<arith.constant = i4x 43232dense< : , x3228i#ttgxbf16>32.,  : , slice<{dim = 1, parent = #blocked1}>#tensor<start>blocked4 = 
      4x0%>4 : 13
      xi = %1613232tt.make_range = x} {tt.transi end 32: = %,  4160#tensor< :  {blocked4iorder = >x32array<
i, i32    32start: %,  = 0, cst_18#02 = ttg : i, 1arith.constant.32>} slice<{dim = 1, parent = #blocked3}>} :dense<> : tensor<-1.270000e+02
 4x>      tensor<32 : %4xtensor<14x32x4 = ibf16xtt.splat32, , 4 ##blockedx%ttg4111.> x slice<{dim = 1, parent = #blocked3}>-> f32:>tensor<,  
      4#i%x32blocked3214x>  = 32x
->tt.splatbf16      , %tensor<%#cst_19411blocked9 = x >arith.constanti:
       32 %162dense<, i = 7#32tt.reshape >ttg %161 : .-> :tensor<slice<{dim = 1, parent = #blocked1}>  4>tensor<tensor<4x
4x3232      xxx%i32xi1532bf1616 = , , #, arith.addi#ttgblocked9# .> ttg%slice<{dim = 1, parent = #blocked1}>-> .14>tensor<slice<{dim = 2, parent = #blocked4}>,
128>       x32
%%xbf16    1215, #%  = blockedcst_20:arith.addi5 =   >arith.constanttensor<%14
 4,      %dense<x 163 = -1i%amdgpu.scaled_upcast_fp4>3212  : ,  %77tensor<#: scale4ttg  %x.tensor<16232slice<{dim = 1, parent = #blocked1}>4x {x>iaxis = i
3208      ,  : i, %#32#16ttg}ttg = .slice<{dim = 1, parent = #blocked1}> :.tt.splat> slice<{dim = 2, parent = #blocked4}> 
      tensor<64>%%x
arg41632x      = i%:tt.splat8cst_21  , # = i%blockedarith.constant32arg43>   ,dense<->: 0x7FC0  tensor<128>tensor<ix : 432 32xtensor<x->bf16, 128i #x32tensor<blocked532, 4> x#x-> bf16ttgitensor<128, .32x#slice<{dim = 1, parent = #blocked1}>, 32xblocked>#bf16, 5
ttg#blocked>      .5>
%slice<{dim = 1, parent = #blocked1}>
    17>      %% = 
164 = cst_22arith.remsi      arith.cmpi =  % eqarith.constant%17, 15 =  dense<,arith.remsi%707  , >%%% : 1615,cst_20tensor<   :4:% x 16tensor<44tensor< x32x4:x32x i8xitensor<, i324#ttg32, x.slice<{dim = 2, parent = #blocked4}>, #i>#ttg32
      blocked., %165>slice<{dim = 1, parent = #blocked1}># = 
>ttgtt.expand_dims     
.%164%      slice<{dim = 1, parent = #blocked1}> {axiscst_23%> =  = 18
2 : arith.constant =       i32 arith.muli%}dense< 18 :1.270000e+02% =  tensor<>7arith.muli4 : , x32tensor< %x4%7i1x4,, 4  %#x:4ttg.1  slice<{dim = 2, parent = #blocked4}>>xi: f3264 ->, 
i tensor<#      644blocked%
      x32>19%x1
 = 19x    tt.expand_dims = i1% tt.expand_dims, cst_24% #blocked = 17%174>arith.constant { {
       axisaxis%166dense< =  =  = 1.270000e+0211tt.broadcast > :  : %165 : ii tensor<3232:4}} x  tensor<4::4xx  32x1tensor<tensor<1x44xf32xxi1, ii, #3232#blockedlinear, , 4>##> 
ttgttg.->     .slice<{dim = 1, parent = #blocked1}>tensor<4%slice<{dim = 1, parent = #blocked1}>>xcst_25> 32x =  ->32xarith.constant-> i  tensor<1, dense<tensor<4#-1.270000e+024xblocked4>x1>
 : 1x      %tensor<xi167 = 4i32tt.transx32,  4, #blocked%166x#1 {1blocked>orderx1
 = f32>      array<i, 
%32: #      200, linear% = 2, >20tt.splat1
 =  >}    tt.splat% % arg8:cst_26%  tensor< = arg8: 4arith.constant i32x : ->32xdense<  32x2.000000e+00itensor<i1>324, # :  xblocked4tensor<->1> 4 x-> xtensor<itensor<44432xxx, 32x11#32xxblockedxif32i11, 32>, ##, 
blocked9linear#      >>blocked%
      
121%168    > =  = %
arith.mulitt.reshapecst_27        % = %%167arith.constant2119 :  = , dense<arith.muli tensor<4-8388608 %x>%2032x : 19 :32xtensor<, i4 tensor<1x%4, #420xblockedx 1x9>1:i ->x 32 itensor<, tensor<128324#blockedx32, x1>x#1
i1linearx      , >i%#
3222 = blocked    , arith.extsi 5>%#%
cst_28blocked21       % = 1:169 = arith.constant> arith.select  
tensor<%168dense<      4, 2097152%x%>221xcst_21 :  = i, %tensor<arith.extsi32163 : 4 , tensor<128x%#blockedx421132x >xi1: 1, x to#itensor< blocked5324tensor<>, x4, #1xtensor<128linearx1x32>ixxbf16
32i,     , 64#blocked%#, #5>cst_29blockedblocked1
 = 1>
      %arith.constant>      170 =   %ttg.local_alloc dense<to23%169127  =  >tensor<tt.make_range: : 4 { (tensor<xendtensor<41 = 128xxx12832x4i : bf16, x64i#1, 32blocked5x#, >iblockedstart = )810 -> , > : !ttg#
i.memdesc<128x32xbf16, #shared, #smem>linear      32
>%}      
23 %171     = : = %tt.make_range ttg.local_loadcst_30 {tensor< % = end128170arith.constant = x  128i: dense< : 32!ttg7i, .>32#memdesc<128x32xbf16, #shared, #smem>  : , ttg->tensor<start.slice<{dim = 0, parent = #blocked1}> 4 = >
tensor<128x0      x324 : %xxi24bf16i32 = , 16}tt.expand_dims#,   %ttg.#:23dot_op<{opIdx = 1, parent = #blocked3}>>ttg  {
.tensor<axis      %slice<{dim = 2, parent = #blocked}>128 = 172 = >x0tt.dot
i :      32i32%155%, } , cst_31#:%171 = ttg ,arith.constant.tensor<  slice<{dim = 0, parent = #blocked1}>128%cst_3dense<>x -1
i: >      32tensor<4 : %, xtensor<24#ttg1284 = .slice<{dim = 0, parent = #blocked1}>xbf16xtt.expand_dims>, 4  #x%-> ttgi23tensor<.dot_op<{opIdx = 0, parent = #blocked3}>8 {1>, axisx *# = 128 ttg0xtensor<128. : ixslice<{dim = 2, parent = #blocked}>i3232>32, #xbf16
}blocked,      1#ttgllvm.intr.assume:>.  
dot_op<{opIdx = 1, parent = #blocked3}>>%tensor<       true128%-> x25 =  :iarith.extsitensor<4 32 x32i, %x1#24f32, 
ttg #blocked    .:3>llvm.intr.assumeslice<{dim = 0, parent = #blocked1}> 
 >tensor<      % 1%true->x173 =   128arith.addf:tensor<1x  xi%172i12832,1x,  
i#blocked%cst_3    321> llvm.intr.assume,  to: #  %blockedtensor<tensor<true114x >x32x:
128f32       x, #i%iblocked125643
 = , #>
    arith.extsiblocked      %llvm.intr.assume 1174 =  %>arith.truncf%24
 true       %173 :% : 26: tensor< =  i1tt.broadcasttensor<41x x
128%32x    x22f32, llvm.intr.assumei # 32:blocked%,  3>true#tensor<  blocked4to:1x  >1tensor<i x4x1toi32
 64, xbf16    tensor<#, #llvm.intr.assume1blockedblocked3 x1>>%128 
      truex->% i 175:64tensor< =  , 4arith.extsii#x 1blocked128x%
1i6413    >,  :llvm.intr.assume
# tensor<       blocked4x%%1itrue26>32,   = 
#:tt.broadcast      ttg  %.slice<{dim = 1, parent = #blocked3}>i%27 = > 122tt.broadcastto 
  tensor<    :%4xllvm.intr.assume 25i64 tensor< , %4:#truex ttg. 1tensor<slice<{dim = 1, parent = #blocked3}>:x1> ix
i64128      %1, x176 = 
#iarith.extsi     blocked64%11llvm.intr.assume1, # : >blocked % 1i32true->>    to:tensor<->  4 i64ixtensor<
      11284%
xx177 =     i128tt.splatllvm.intr.assume64x  , i%176%#64 :trueblocked, #  1blockedi:>164  
>
-> i            tensor<41%%x
2728i64     =  = , llvm.intr.assumett.broadcastarith.addi#   ttg%%%.slice<{dim = 1, parent = #blocked3}>true2526>  ,
      :: %178  %27 = itensor< arith.addi 11:%177
x ,     128tensor<%175llvm.intr.assumex4 : ix %64128tensor<4true, xx #ii64:blocked64,  1, #ttgi>#.slice<{dim = 1, parent = #blocked3}>1 blocked1>
->>
           
%179%tensor<       = 04%arith.extsi  = x29%32tt.get_program_id128 =   xtt.addptr: xi tensor<32 64%x:, arg0i32 #,, iblocked #321%ttg
>18.slice<{dim = 0, parent = #blocked3}>    
 >%      : to1%  tensor< = 28!32tt.get_program_id = ttx arith.addi.i64y ptr<bf16>,  %,#:26 ttg. ,islice<{dim = 0, parent = #blocked3}>i 64>32%

      
27      %     %180%:30 = 2  = arith.extsi  = tensor<arith.muli%30arith.addi4  : x% %1289i32arg5x, to,i  i 64%64
%, c32_i32      c31_i32# % blocked: 181 = :1itt.splat  >32%i

180 32            : 
%%i    293164% =  =  ->3tt.addptrtt.make_range  =   {tensor<32arith.divsi%end = xi arg03264%, : , 2 i#ttg,%32. 18, slice<{dim = 0, parent = #blocked3}>>% start
c32_i32: =       %  0182:! :  =  ttiarith.addi i.32%18132ptr<bf16>}, 
, %179     :  :%itensor< 46432xtensor<32 = 
ixiarith.extsi      3264,  %, #ttg%30#.arg7 = ttg.slice<{dim = 0, parent = #blocked3}> arith.mulislice<{dim = 0, parent = #blocked6}>>: >
       %
%183i9       = 32,%arith.muli   32%7to% = ,  c32_i32tt.make_range%i  {664:end =  :
 32     i : ii64%3232
      5
, % =       start184arith.extsi% =  =  310tt.addptr % =  : %arg9tt.make_rangeiarg2,  {32 %:end}183  =  : :i32  32 : tensor<!tt i32x.to32iptr<bf16> , 32, istart, i6464 = #
      
0ttg.%185     : slice<{dim = 0, parent = #blocked3}> = %i>tt.expand_dims632
 % = }      178arith.extsi % {axis :33 =  = % tt.make_range1arg11tensor< { :  32end = i:x3232} i :  :i32i 32, 32tensor<4 #, xitottgstart64 . = , islice<{dim = 0, parent = #blocked6}>0#ttg64> : .slice<{dim = 1, parent = #blocked3}>

i>          32 %%}-> 732 tensor< =  = :4arith.extsitt.make_range x  {tensor<1%end32xxi0 = i64 3232, #: : , blocked3 i#>i32ttg
      32, .%186 startslice<{dim = 1, parent = #linear1}> = to = >arith.extsi  0
%arg13i :        :64i%34 
32 = i32    }tt.splat to%   i8:%64 =  30
      arith.divsitensor< %187 32: = %x tt.expand_dims1ii ,3232%175 ,  -> {axis%#  = 3ttgtensor<1 .32 : :slice<{dim = 0, parent = #blocked3}>xi32 >i} i
32:32      ,  
%#ttgtensor<    33.4x% = slice<{dim = 0, parent = #blocked6}>i9tt.make_range>
64,  =  {      %#ttgarith.remsiend35 = .slice<{dim = 1, parent = #blocked3}>  = tt.splat> %32 -> 1 : %tensor<4,i30x 32 :1x%,  i643starti, #  = 32blocked:0 ->3>  :  
      iitensor<32%1883232x = 
}iarith.muli      32%186llvm.intr.assume:, ,   #%176%tensor<ttg :true32.  xslice<{dim = 1, parent = #linear1}>i64:i>
 32
      %i,       1891#% = 
ttg36 = tt.splat     .arith.addi%186llvm.intr.assumeslice<{dim = 1, parent = #linear1}>   >%: %
34itrue      , 64  %%->:3431   =  :tensor<4itt.splat x1 tensor<1
%32xi    30x64, llvm.intr.assume i#blocked :323>% , 
      truei#% 32ttg190 = : .arith.muli  ->slice<{dim = 0, parent = #blocked6}>%i >189,1tensor<
 %
32      187    x%37 :%i =  1032arith.addi tensor<4 = , %xarith.cmpi#351 ttg, xisgt.%64, ,slice<{dim = 0, parent = #blocked6}>33# > :blocked3%
 >
arg6      tensor<      %,%32191 =  35xtt.addptr % = i%184c0_i32tt.splat32, ,   #%188:%ttg : 30. i slice<{dim = 1, parent = #linear1}>!32:>tt.
 
ptr<bf16>    i      , scf.if32%38i   = 64
%->tt.splat      10  %192 tensor<% = {32arg5tt.expand_dims 
x :%182      i  {axis%32i = 11, 32 0 = #-> : arith.mulittg i .tensor<32}%slice<{dim = 1, parent = #linear1}>32 :8>x tensor<,
i32x       32i64%%, , c4_i3236##  = ttgttg.:arith.addi.slice<{dim = 0, parent = #blocked6}>slice<{dim = 0, parent = #blocked3}>>  > ->i%
 tensor<3234      1x
,%32       39x%% = i641231tt.splat,  =   #tt.make_range:%blocked3 { arg5>
endtensor<        = 32:%1934x  =  : iitt.broadcasti3232  32, ->%, # 190startttgtensor<  = .32:0slice<{dim = 0, parent = #blocked6}>x  : >itensor<4i
32x132      , x}%#i64 37ttg, #: = .blocked3 arith.addislice<{dim = 1, parent = #linear1}>> tensor< >->4%
       tensor<x35%4i,40x3232  = xi, %arith.remsi64#33 , #ttg %blocked.:363>slice<{dim = 1, parent = #blocked1}> ,
>tensor<       %
32%38194 =       x tt.expand_dims %i:%1791332  {axis = , tensor< = tt.make_range#320 :  {ttgxi32end.i}  = slice<{dim = 1, parent = #linear1}>32: 4>, tensor< : 
#32xi      ttgi6432%.slice<{dim = 0, parent = #blocked6}>, , 38>
#ttgstart =       . = tt.splat%slice<{dim = 0, parent = #blocked3}>0 41> : % =  ->iarg5arith.remsi 32  tensor<}:%1x  3732x:i, i64 32%, tensor< 39 #blocked4->:3>x  
      itensor<tensor<%323232x195, xi = #i32tt.broadcast ttg32, %194., # :slice<{dim = 1, parent = #blocked3}>#ttg >ttg.slice<{dim = 1, parent = #linear1}>tensor<1
.>x32      slice<{dim = 0, parent = #blocked6}>
xi%>      6414
%, # =       42blocked3tt.splat% = > 39arith.muli ->% =   11tt.splat%tensor<  7,4x:% 32x arg5%i64i 5, 32: #blocked  :3>->i 
       32i%tensor< 64196 = 4->
tt.addptr x       %itensor<%191,323243 %, x = 180 #itt.make_range:ttg32 { ., end!ttslice<{dim = 1, parent = #blocked1}># = .>ttg64ptr<bf16>,
. :  i      slice<{dim = 1, parent = #linear1}>i64
%>32      %15
, 197 =  =       startarith.addi arith.addi% = % 400195,% =  :  14arith.remsii%193, 32} : %  tensor<%36:412, x32  tensor<xi:%6464 38x, #tensor< iblocked4:323>x , 
      itensor<#ttg%1983232. = , xslice<{dim = 1, parent = #blocked6}>arith.extsi#i>
 ttg32      %arg4., % slice<{dim = 1, parent = #blocked1}>#44: >ttg = i
.tt.expand_dims32       slice<{dim = 0, parent = #blocked6}> to %>%i16
4364 =        {
      tt.splat%axis%199 41 =  = % = 1tt.splatarg4arith.remsi :    i%198:%32  37}: i, i32 :64 %  ->39tensor<->  64 tensor<:xtensor<4 i4xxtensor<321xi32, i32x#ttg64, , i.##32slice<{dim = 1, parent = #blocked6}>blocked3ttg, >>.# ->
slice<{dim = 1, parent = #blocked1}>ttg       >.tensor<%200
slice<{dim = 1, parent = #linear1}>64 =       >xarith.cmpi %
1slt17      x, = %i %arith.remsi4232185,  = ,  %%arith.muli#19915 blocked ,%6:  7>tensor<4%,
x116       x %%i64:545, #   = blocked3tensor<:arith.extsi>
4        xi%%201i6444 = 32
 arith.extsi ,       :%#% arg5 ttg43tensor<: . = 64i32slice<{dim = 1, parent = #blocked1}>tt.make_rangex > {1to
endx        = ii64%6432, 
      18 : #% = iblocked202 = arith.muli326>tt.splat  ,  %201%startto :7 =   ,0tensor<i64  : 64 ->%ix 4321tensor<1 }xx: i32x :64, ii #blocked64, 64tensor<6#blocked
64>3>      x
      
      %i%%203193246 =  = ,  = arith.cmpi tt.expand_dims#tt.expand_dimsslt ttg ,%.% %17slice<{dim = 1, parent = #blocked6}>40192 {> {,axis
axis  =        = %1%0202 : 44 :  i = i: 32tt.expand_dims32tensor<1} }x32 % xi:43:64,   { #tensor<axistensor<blocked34 = 32>
x1x      i : i%32i32204 = , 32, tt.broadcast #}#%200ttg ttg. :.:slice<{dim = 0, parent = #blocked6}> tensor<slice<{dim = 1, parent = #blocked1}> >4>tensor< ->x1 64 x->xtensor<i1 i1, #tensor<32xblocked34, 32x> x#i-> 1ttg32tensor<4x., xislice<{dim = 1, parent = #blocked6}>#3232>blockedx,  6>i1#->
, blocked       #1tensor<%blocked3>6447>

x =       %      1tt.splat205 = %xi tt.broadcast2032%  = , arg10%tt.splat# 203 blocked:  :%6i arg8>32tensor< 
 1x:      ->32 % xii45tensor<1, 32 = 1#blocked arith.extsix3>-> 32  %xi-> tensor<4432tensor<44 , #x32x:blockedx1 6i1xtensor<>, i64
#blocked32x      3, 1%>#x48 = 
blockediarith.muli      %132 206>, % = 
#46arith.andi      blocked, %6 %20421>%,  =  47%205arith.mulito  :  : %tensor< tensor<41964tensor<x,x132x 1xi1%x32, #20ixblocked 64i3>:, 32
 #,       tensor<blocked#blocked%207466 = x>>tt.splat 1

      %x      %196i%49 =  3246arith.extsi :,  = % #tt.expand_dims48!ttblocked  .ptr<bf16>1%: ->>40  
 {tensor<tensor<      axis14x% = x32x22032!tt =  : x.ptr<bf16>arith.extsiii,  3232, #blocked%}#blocked3>21 6
       :>%:  208 =  tensor<tott.addptr tensor<32 %4xtensor<207xi1, 132x%197x, 32 i#x:32ttgi , .64tensor<4#slice<{dim = 0, parent = #blocked6}>, x32blocked>#x1 blocked6!>->>
tt        .ptr<bf16>totensor<%, # 150blocked3tensor<x = >432tt.broadcast, xx tensor<1i%454x32 x32i, :x64# i64, blockedtensor<, ##664blocked3blocked>x>1
1
      >      xtt.store
%i       4764, %208% = #, 23tt.splatblocked6%174 =  >, tt.make_range% ->%206 {arg10  end tensor<: = :64 128 xtensor<4 : i32x32i32xx32 i!tt, ->64.ptr<bf16>start , , # = tensor<#blocked301blocked6> : x>
i32
          }32x%
}i51     32 = tt.return:, tt.broadcast
 #   }tensor<blocked%49
1286 }x>:
i
 
32      tensor<{-#, %1
#48x  externalttg = 32x_resources: {
.arith.mulii    mlir_reproducerslice<{dim = 0, parent = #blocked1}> 64: {
>%,       
46#pipeline:       ,blocked"% 6bu24%>i = 47 lttt.expand_dims ->in : .% tensor<mo23tensor<64d {1xulaxisx32e = 32x(o0xip : i64ti32, im32, #i}#blockedze blocked6-a:6>m >
d-tensor<
      ld128      %s-x%52usi49 = a32 = arith.addi g, arith.extsi%e{# 50,ldttg% s-.48%lislice<{dim = 0, parent = #blocked1}> 51m>: it  :=->tensor< 0 1tensor< ttensor<x64ar132xgexx32t-128ixarx32ichi, 64=32#, gf, blocked#x#6blocked9blocked>6501 >},>to
 t
       r      tensor<%it%153o25x = n- = 32tt.addptrscarith.extsix f- i%t%64arg1o-24, ,c # f,:blocked% c 642 ontensor<>:v1
 erx      !ttt-128%.ix50ptr<i8>ndi = ,ex32tt.broadcast -,  ito#%64-blocked45
      ll1 %vm>:54{   = intotensor<arith.extside 64 xtensor<x%-11arg14bixx tw128i: idx64iti, 32h=64# to0}, blocked , #6ialblocked>64l1 
      oc>->%a
 55te      tensor< = -%64arith.muliam26x d = 32%gtt.broadcastx7pu i,-s%64 ha22, %54r # :e:blocked d- 6imtensor<>64e4

mx            o1%%56rx51 = y,i = tt.addptr  c64tt.broadcast%o,  arg3,n#% vblocked49%55er1  t>::-t   ri->tensor<!to 1ttntensor<x.ptr<i8>-a432,mdxx gp128iiu-x6464toi, 
-64#      ll, blocked%v#657 = m{blocked>tt.expand_dimsar1  c>->%h
 41=      tensor< {g%64axis = f27x1x = 32 : 95tt.broadcastxi0 i32 f%64}tz25,  =t #:r:blocked ue 6tensor<},tensor<>32x c1
ianx      32on128%, ix52#cai = ttgli64arith.addi.ze,  slice<{dim = 1, parent = #linear1}>{ #%> mblocked50 ax1,->->  it %tensor<er->5132at  xiotensor<:1ns4 x=1xtensor<i0 1286432mxx, axi32#-64xlinearn, i1um#64>-rblocked, 
      ew1#%ri>blocked58 = te
6tt.splats      > =%
%-128      arg15 r = % :egarith.addi53 i  = ion%tt.addptr32-26  s,%-> i arg1tensor<mp%,32li27 xfy %1=n:42xor  imatensor<:32l4 ,  tx!#es128ttlineart-x.1coiptr<i8>>nv64,
      e,  %rg#i59enblocked64 = ce1
arith.muli =f>      %57al
%,se      54  t% = %op29arith.extsi58- =   dtt.addptr%:ow arg14 n=% tensor<trarg0:32ue, x} i1,%32x 18 ics to32e: , #,  ilinearc!641>ontt

ve.            rtptr<bf16>%%-c,5560f  =  = -tiarith.muliarith.extsio64  -l
%%lv      759m{%, in30 :de = % xarith.muli54tensor<-  32bi%:xt9 1xwi,iid 6432t%
, #h=c32_i32      linear0 %1>},:56  c  = toonitt.addptr v32 tensor<e
%32r      arg3xt%,1-31 xar = %iittt.make_range5564h { , -tend:#o- =  linearll32!1>vm : tt
      {ii.%nd32ptr<i8>61 = ex, ,tt.make_range-start  {bi = iend = tw0644id : 
 : thi      i=032%32},}57,  c  = startan:tt.expand_dims = o  0ntensor<% : ic3241iax {32liiaxis}ze32 =  { , 1: # :  mattgitensor<x.324-islice<{dim = 0, parent = #blocked6}>}xte> ir
:32a       , ti%tensor<#o3232ttg.ns = xslice<{dim = 0, parent = #linear1}>=1tt.make_rangei>0  {32
maend,       x- = #%62nu32ttg = m- : .tt.broadcastreislice<{dim = 1, parent = #linear1}> w32>%60ri,   testart->:s= =   -10tensor<tensor<  : 3232reixxgi3211o}xxn ii-:3264, si , #mptensor<#linearli32linear1fyx1>=ni> or32
->ma,        l #%tensor<tettg5832s. = xtslice<{dim = 0, parent = #blocked3}>tt.splat4-> xco
%in      arg1564v% , e33:#rg =  linear1entt.make_rangei>ce {32
=end       fa = ->%ls32 63 = e  : tensor<tt.expand_dims toi32%p-32x61d, 1 {owstartxaxis = n= = i0tr032 : ue : , i32}i#}, 32linear :c}1 se >tensor<,:
4 s       xymtensor<%ib325932olx = , -diarith.muli#ttgce32 .slice<{dim = 0, parent = #linear1}>, , %>en#57 attg,-> bl. tensor<eslice<{dim = 1, parent = #linear1}>%1-l>58xi
 4ne      :x-i% inf34tensor<32o = 32, , tt.splatx#co 1linearnv%x1er30i>t- 32
b:,       ui #%ltilinear64i321 = n- >tt.broadcastfu->
 n       %ctensor<%63-t3260 ox = :-iarith.extsi ll32 tensor<v, %1m{#59xfttg 4xtz.:i=tslice<{dim = 0, parent = #blocked6}> 32ru>tensor<, e}
32#)      xlinear"%11,35x>
 = i       tt.splat32->disable_threading:  ,  false%#tensor<,
30linear32       1xverify_each: :>4true  x
itoi    }32 32, 
  } tensor<#linear
#-}->321>
 x
tensor<1      32x%xi65i64 = /tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:032, arith.extsi: , # error: #linear%Failures have been detected while processing an MLIR pass pipelinettg164 
.>:/tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:0slice<{dim = 1, parent = #linear1}>
 : >      tensor<note: 
%32Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
      61x% = 436tt.make_rangex =  {iarith.addiend32  = , %4#34 : linear,i1 32>%,  31startto  =  :0tensor<  : 32tensor<ix32324x}xi i32:64,  , #tensor<#ttg4linear.x1slice<{dim = 0, parent = #blocked6}>i>>32

,             #%%ttg6637. =  = slice<{dim = 0, parent = #linear1}>arith.addiarith.addi>  
%%      6535%,,62   = %%tt.broadcast6233   %::60   tensor<tensor<:3232 xxtensor<4i32x32xi, 164#x, ttgi#.64linearslice<{dim = 1, parent = #linear1}>, 1>#>
linear
      1      %>%38 67 = -> = tt.splat tt.splat tensor< %32%arg5x56 4 :x: i [rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 4, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank4]:E1106 11:31:42.022000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
i64!32, tt #.->linearptr<i8> 1 tensor<>->32
 x      tensor<i%323263x,  = 4#tt.expand_dimsxttg !.%ttslice<{dim = 0, parent = #blocked6}>61.> {ptr<i8>
axis,        = #%0linear39 : 1 = i>tt.splat32
 }      % %arg5:68   = :tensor<tt.addptr 4 ix%32i67 32,->,   #%tensor<ttg6632. xslice<{dim = 0, parent = #linear1}>:i> 32 tensor<, ->32# xttgtensor<4.1xslice<{dim = 1, parent = #linear1}>x!>4tt
x.      iptr<i8>%32, 40, # = #lineararith.remsilinear1 1>%>,36
 ,      tensor< %32%64x38 = 4 tt.broadcastx: i %64tensor<63, 32 #x:lineari 132tensor<>, 1
#x      ttg4%.x69slice<{dim = 0, parent = #blocked6}>i = >32tt.load
,        #%%linear68411  = >:arith.remsi   ->tensor<% 3237tensor<x,324 xx%4!39xtt i.:32ptr<i8> , , tensor<##32linearlinearx11i>>32

,             #%%ttg6570. =  = slice<{dim = 1, parent = #linear1}>arith.extsitt.trans>  
%%      6469%  {42:order =   = arith.mulitensor<array< 32i%x3274: ,x1 i, %3205, > #}:linear  1:i> 64 tensor<
to32       x%tensor<44332x = xitt.make_range48 {x, endi# = 64linear64, 1 : #>ilinear 321->, > start
tensor< =       40%x : 6632i = x32arith.addii} 8 %, :65# ,ttgtensor< .64%slice<{dim = 2, parent = #blocked4}>x62>i 
32:      ,  %#tensor<71ttg32 = .xtt.splatslice<{dim = 1, parent = #blocked6}>4 >x%
i29      64 %, :44#  = linear!tt.expand_dims1tt >.%
ptr<bf16>43        {%->axis67  =  = tensor<1tt.splat4 :  xi%1283256x} ! :tt: . !ptr<bf16>tensor<tt, 64.#xptr<i8>blockedi 132->>,  
#tensor<      ttg32%.x72slice<{dim = 1, parent = #blocked6}>4 = >xtt.addptr ! ->tt% .71tensor<ptr<i8>,64,  x#%1linear28x1 i>:32
 ,       tensor<#%4blocked68x6 = 128>tt.addptrx
 !      %tt%67.45,ptr<bf16> =  , arith.extsi%# 66blocked% 144:>  ,:tensor<  32tensor<tensor<x4644xxx1281!xxttii.6432ptr<i8>, , , ###blockedblockedlinear161>>>
 ,      to % tensor<73tensor<32 = 64xtt.loadx4 1x%xi72i64 64, :, # #lineartensor<blocked146>x>
128
      x      %!%69tt46 = . = tt.loadptr<bf16>tt.expand_dims ,  %#%68blocked40 1 {:>axis 
 = tensor<      032% : x74i4 = 32xtt.splat}!  tt%:.53 ptr<i8> tensor<, :32# xlinear!i1tt32>., 
ptr<i8>#       ttg%->.70 slice<{dim = 0, parent = #blocked6}> = tensor<>tt.trans64  x->%32 69xtensor< {!1orderttx = .32array<ptr<i8>xi, i32#32: blocked, 16#, >blocked0
6>      >}%
 75      : = % tt.addptr47tensor<  = 32%tt.splatx74 4,%x arg10i% 852:,   #:ilinear 321tensor< >64-> x ->32tensor< x1tensor<!x4tt32x.x32ptr<i8>ix, 32i#, 8blocked#, 6blocked#>6ttg,>. 
slice<{dim = 2, parent = #blocked4}>tensor<      >64%
x48      32 = %xarith.muli71i  = 64%tt.splat, 46 #,%blocked 296% >47:
        :!% tt76tensor<. = 1ptr<bf16>tt.loadx  32->%x 75itensor< 324cacheModifier, x #128=blockedx 6!cg>tt 
.:      ptr<bf16> %, tensor<49#64 = blockedxarith.extsi132 >x%
!48      tt %.:72ptr<i8>  = , tensor<tt.addptr#1 blockedx%63271>x,
i       32%%, 2877#  = blocked:ttg.convert_layout6  >tensor<% 476tox  128:tensor<x 1!tensor<xtt6432.xxptr<bf16>32i, x64#i, blocked8#1, blocked>#6,blocked> 6
tensor<>      4 %x->50128  = xtensor<tt.broadcasti64 64x%, 3245#x blockedi:18 >, tensor<
#64      blockedx%3173>x = 
itt.load      64 %, %78#72 = blocked tt.reshape6: > % tensor<73->4  x:tensor<128 64xtensor<x!432ttxx.128iptr<bf16>x64, bf16, #, #blocked#blocked1blocked6>1>
>
             %->%74 51 = tensor< = tt.splat4tt.broadcast x %4%53x49 32 :x: bf16 !, tensor<tt#1.blockedxptr<i8>>32 
x->      i %64tensor<79, 64 = #xmath.absfblocked32 6x%>!78 tt ->.: ptr<i8> tensor<, tensor<64#4xblockedx3264x>xi
3264      x, %bf16#75, blocked = #6tt.addptrblocked> >
%
      74      %,%52 80 = % = arith.addi52arith.extf   %:%50 79,tensor<  64:%x 5132tensor< x4:!x tt4tensor<.x64ptr<i8>32x, x32#bf16xblocked, i6#64>blocked, ,>#  blockedtensor<to664 >xtensor<
324      xx%i45364x = , 32tt.addptr#x blockedf32%6, arg1>#,
blocked       >%%
4276        = %:tt.load81   = !%"tt75t. tptr<i8>cacheModifier., r =ei d64cgu
 c      :e% "54tensor<( = 64%arith.extsix80 32)%x <arg14!{ ttaxis:. =  ptr<i8>2i,  : 32#i blocked32to6} >>i
 (64      {
%
      77      % = ^bb055ttg.convert_layout( =  %arith.muli%arg16 76: % f327:, , % tensor<arg17%64: 54xf32 32):x: i
i8        64, %
#209      blocked = %6arith.maxnumf56>  =  %tt.addptr->arg16  ,%tensor< arg364%,xarg17 32 %x:55i  8f32:, 
 #        !blockedtt.reduce.returntt3 .>%ptr<i8>
209,        %:i78 64 = f32
tt.reshape
             %%}5773) =   : tt.expand_dims:(  tensor<%tensor<4414x {x4axis128x = x321bf16x : , f32i#, 32blocked#}1blocked >>: ) ->  ->tensor<tensor< 432tensor<xx44ixx324f32, x, #32#ttgxttg.bf16.slice<{dim = 1, parent = #linear1}>, slice<{dim = 2, parent = #blocked}>>#> blocked
->>       
%tensor<      8232% = x79ttg.convert_layout1 =  xmath.absf%i 8132% , 78:#  linear:tensor<1 4>tensor<x
44      xx%4f3258x,  = 32#tt.splatxttg bf16.%, slice<{dim = 2, parent = #blocked}>arg15#> blocked :>-> 
 i      tensor<32%4 80x-> = 4 arith.extfxtensor< f3232%, x79#1 ttgx:.i slice<{dim = 2, parent = #linear}>32tensor<>, 4
#x      linear4%1x83>32 = 
xtt.expand_dims      bf16 %, %59#82 = blocked {arith.muli>axis   = %to257  : ,tensor<i 432%x}584  x::32  xtensor<tensor<f32432, xx#41blockedxx>f32i
, 32      #, %ttg#81.linear = slice<{dim = 2, parent = #linear}>1">>t 
t->      . %rtensor<60e4 = dxarith.extsiu4 cx%e159"x (f32:%,  80#tensor<)linear32 <>x{
1axis      x = %i28432 :  = , itt.expand_dims#32 linear}%1>81> ( { {axisto
 =        2tensor<^bb0 : 32(ix%321arg16}x:  if32:64,  , %tensor<#arg174linear: x1f324>)x
:f32      
, %        #61%ttg = 209.tt.make_range = slice<{dim = 2, parent = #blocked}> {arith.maxnumf>end   = %->4arg16  : ,tensor<i 432%x, arg174start x = :10 x : f32f32i
, 32        #}tt.reduce.returnblocked  >:%
 209      tensor< %4:85x  = if32tt.bitcast32
 ,       %#}83ttg) . : :slice<{dim = 0, parent = #linear1}>( >tensor<tensor<
44      xx%4462xx = 321tt.broadcastxx f32f32%, , 60## blockedlinear:>> ) ->  tensor<tensor<->324 xxtensor<144xixx64f324, , x##1linearttgx1.i>slice<{dim = 2, parent = #blocked}>32 >, ->
#       lineartensor<%>3282
x =       4ttg.convert_layout%86x  = i%tt.bitcast6481 ,  %#:84linear  1tensor<:>4 
xtensor<      44%xx63f324 = , xtt.expand_dims#1x ttgf32%., 61slice<{dim = 2, parent = #blocked}># {>blockedaxis > = -> 0 -> : tensor< i4tensor<32x4}4x x4:f32x , 1tensor<4#xxttgii.3232slice<{dim = 2, parent = #linear}>, , >##
blockedttg      >.%
slice<{dim = 0, parent = #linear1}>83      > = % tt.expand_dims87->  =  %arith.additensor<82 1 {%xaxis854 = ,x2 i : %32icst_28, 32 #}:linear  1:tensor<> 4
tensor<x      44%xx6441 = xxtt.broadcastf32i , 32%#, 63ttg# .linear:slice<{dim = 2, parent = #linear}>> >
tensor<       1->%x 884tensor< = x4arith.addiix 324%, x86#1,linearx 1f32%>, cst_1 # ->linear: > tensor<
tensor<32      4x%x4844xx = 1itt.expand_dimsx32 i, %32#81, linear {#1axisblocked> = >
2
       :       %i%653289 = } = arith.extsi tt.bitcast : % %64tensor<87 4 :x: 4 tensor<xtensor<32f324x, x4#4xttgxi.132slice<{dim = 2, parent = #blocked}>x, >i# 32linear->, 1 #>tensor<linear 4>tox  4->tensor<x 321tensor<xx44f32xx, 4i#x64blocked1, >x#
ilinear      321%, >85#
 = linear>      tt.bitcast
%       66%% = 8390arith.addi  =  :tt.bitcast%  65tensor<%,488 x %4:62x  1tensor<:x4 f32xtensor<, 432#xxlinear14>xx ii->3264 , , tensor<##4blockedlinearx>14 >x->
1       xtensor<%i46732x = , 4tt.splat#x linear1%>x56
i       32:%,  86#! = blockedtttt.bitcast>. 
ptr<i8>%       84%-> 91 : = tensor< arith.andi32tensor< x4%4xx89!4,ttx .1%ptr<i8>xcst_27, f32 #, :linear# 1blockedtensor<>>4
 x      ->4% x68 = tensor<1tt.addptr4x xi%43267x, ,1# xlinear%i>6632
       , %:#92 blocked = tensor<>arith.andi32
 x      %4%90x87,! =  ttarith.addi%. cst_4ptr<i8>% , 85:#, linear tensor<1%4>cst_28x, 4 : xtensor<tensor<1324xxxi4432xx, i1#64xblocked, i>#32
linear,       1>#%
linear93      > = %69
tt.bitcast =        tt.load%% 8891% =  68arith.addi: :   %tensor<tensor<86432,xx 44%xxcst_11! xtt:i. 32ptr<i8>tensor<, , 4##xlinearlinear4>1x >1->
x       itensor<%32470, x = tt.trans#4 blockedx%>169
x {      f32order%,  = 89#array< = linearitt.bitcast>32 
: %      187%,  940: = > tt.bitcast}tensor<  4%:x92 4 :tensor<x 321tensor<xx44ixx324i, x8#1, linearx#>ilinear 321->, > # tensor<blocked->4> x tensor<4->4x x1tensor<32x4xixi3248, x, #1#linearxttg>f32.
, slice<{dim = 2, parent = #blocked4}>      #>%blocked
90>       = 
%tt.bitcast      71 % = %95tt.splat88 =   math.log2%: 29 % tensor<93:4  x:!4 ttxtensor<.14ptr<bf16>xx i4->32x , 1tensor<#x4blockedf32x>, 128 #x->linear! >tttensor<
.4      ptr<bf16>x%, 496#x = blocked1math.log21x >i%
3294      ,  %#:72blocked  = >tensor<tt.addptr
4       x%%47191x, = 1 arith.andix% f3228%,  89#:,blocked  >tensor<%
4cst_27      x %128:97x  = !tensor<math.floortt4 .x%ptr<bf16>495, x #1:blockedx 1itensor<>324,, x #4tensor<linearx4>1x
x128      f32x%, i92#64 = linear, arith.andi># 
blocked%      190%>,98
  =       %math.floor%cst_4 73 % = :96tt.load   tensor<:%4 72xtensor< 44:xx 14tensor<xx4i1x32x128, f32x#, !blocked#tt.>blockedptr<bf16>
>,       
#%      blocked193%> = 99
tt.bitcast =        arith.subf%% 7491% =  97tt.splat:,   %tensor<%534cst_26 x :4: x !1tensor<ttx4.ixptr<i8>324 , x->#1 linearxtensor<>f3264 , x->#32 linearxtensor<>!4
ttx      .4%ptr<i8>x100, 1 = #xarith.subfblockedf32 6, %>#98
linear,      > %
%75      cst_5 = % tt.addptr94:  =  %tt.bitcasttensor<74 4,%x 924% x52:1  x:tensor<f32 tensor<4, 64x#x4blocked32x>x1
!x      tti%.32101ptr<i8>,  = , #tt.clampf#blocked blocked>%6 99>->,,   tensor<%tensor<4cst_2564x,x4 32x%x1cst_24ix,64f32 , , propagateNan## blockedblocked=6> >
none
             %:%95 76 = tensor< = math.log24tt.load x %4%93x75 1 :xcacheModifier f32 tensor<, =4# xlinearcg4> x
:1       x%tensor<f3210264,  = x#tt.clampf32linear x>%!
100tt      ,.% ptr<i8>96%,  = cst_18#math.log2,blocked  6%%>94cst_23
 ,      : %77 propagateNan = tensor< ttg.convert_layout4= x %4none76x  1::x  f32tensor<tensor<, 464#xxblocked432>xx
1i      x8%f32, 97, # = #blockedmath.floorblocked6 >>%
 95      -> % :103tensor<  = 64tensor<arith.fptouix4 32x%x4101ix 81:, x #f32tensor<blocked, 43#x>linear4
>x      
1%      x78%f32 = 98, #tt.reshape = linear math.floor>%  73%to 96 : tensor< :4tensor< x4tensor<4x4x128x1x4xbf16xi, 18#x, blockedf32#1, linear>#> blocked
->>       
%tensor<      1044% = x99arith.fptoui4 =  xarith.subf%32 102x% bf1697:, , # tensor<blocked%4>cst_26x
 4      :x% 179tensor<x = 4f32math.absfx,  4#%xblocked781> x :f32to ,  tensor<#tensor<4linear4x>x4
4x      x32%1x100xbf16 = i, arith.subf8# , blocked%#>98blocked
,>       
%%      80cst_5% =  105arith.extf: =   arith.addi%tensor< 794x% 4103:x, 1 tensor<x%4f32cst_29x,  4#:xblocked 32>tensor<x
4bf16      x, %4#101xblocked = 1>tt.clampfx  ito%8 99, tensor<,#4 linearx%>4cst_25
x,      32 %x%106f32cst_24 = , ,arith.addi#  blockedpropagateNan%> 104
=,        %none%81 cst = : " :ttensor< t4tensor<.x4r4xex4d1xux1cf32xe, i"#8(linear, %>#80
blocked)      > <%
{102      axis = % = tt.clampf1072  =  : %arith.subfi100 32,%} cst_6>%, (cst_18 {,%
 102      % ^bb0cst_23:(, % tensor<arg16propagateNan4:  xf32=4,  x%none1arg17 x: :f32f32 , )tensor<#:4blocked
x>        4
%x      2091% = x108arith.maxnumff32 =  , math.exp2%# arg16blocked%,>107 
 %      :arg17%  103tensor<: = 4 arith.fptouixf32 4
%x        1011tt.reduce.return x :f32% , 209tensor<# 4blocked:x> 4
f32x      
1%      x109}f32 = ), arith.extf : # (linear%tensor<>784  xto:4  xtensor<tensor<3244xxxf3244, xx#132blockedxx>ibf16) -> 8, tensor<, #4#blockedxlinear>4> x
tof32       , %tensor<#1044ttg = x.arith.fptoui4slice<{dim = 2, parent = #blocked}> x>%32
102x       f32%:, 82 # = tensor<blockedttg.convert_layout4> x
%4      81x% 1110:x =  f32tt.broadcasttensor<,  4#%xblocked1084> x :f32to ,  tensor<#tensor<4ttg4x.x4slice<{dim = 2, parent = #blocked}>4x>x1 1x->xf32 i, tensor<8#4, blockedx#>4blocked x>->f32
 ,       tensor<#%4ttg105x. = 4slice<{dim = 2, parent = #linear}>arith.addix> 32
%x      103f32%,, 83 # = %blockedtt.expand_dimscst_29>  
%:      82 % {tensor<111axis4 =  = xarith.mulf24  : x%i110932x,}i  8%:, 110 # tensor<linear:4> x
tensor<4      4x%xf321064,  = x#arith.addi32ttg x.%f32slice<{dim = 2, parent = #linear}>104, >,#  blocked->%> cst
tensor<       4:%x 1124tensor< = x4tt.bitcast1x x4%f32x111, 1 #x:lineari >8tensor<
, 4      #x%blocked484>x = 
32tt.expand_dims      x %f32%107, 81 = # {arith.subfblockedaxis > = % 2cst_6-> : , i tensor<32%4}102x  4::x  32tensor<tensor<x44ixx3244, xx#f321blocked, x>#f32
ttg,       .#%slice<{dim = 2, parent = #blocked}>blocked113>> =  
arith.andi->        %%tensor<1081124 = ,xmath.exp2 4 %x%cst_71107 x :f32: ,  tensor<#tensor<4blocked4x>x4
4x      x32%1x85 = xitt.bitcast f3232%, , 83## blockedblocked>:>
 
      tensor<      %4%114x109 = 4 = arith.shruixarith.extf 1 %x%112f3278,,   #:%linear cst_8>tensor<  4:->x  4tensor<tensor<x4432xxx44bf16xx, 321#xxblockedii>3232 , , to## blockedlineartensor<>>4

x            4%%x1158632 =  = xarith.anditt.bitcastf32  , %%#11484blocked, :>  
%tensor<      cst_94% x110:4 =  xtt.broadcasttensor<1 4x%xf321084,  x#:32blocked x>tensor<i 432->x,  4#tensor<xblocked41>xx
4f32      x, %1#116xblocked = i>arith.andi32  , ->%# 112blockedtensor<,>4 
x%      4cst_10%x 8732: = x arith.addif32tensor< , 4%#x85blocked4,>x 
32%      xcst_28%i 11132: = ,  arith.mulf#tensor< blocked4%>x109
4,      x %1%117x110 = i arith.addi32: ,  %#tensor<115linear4,>x 
      4%%xcst_118832  = x:arith.addif32  , tensor<%#486blockedx,>4 
x%      32cst_1%x 112i: = 32 tt.bitcast, tensor< #4%blockedx111>4 
x:      1 %xtensor<118i4 = 32xarith.subi, 4 #x%blocked32cst_12>x,
f32       ler_DP2_TP2: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
, %%#11789blocked  = >:tt.bitcast   ->tensor<% 487tensor<x 44:xx 432tensor<xx432ixx324i, x32#1, blockedx#>iblocked
32>      , 
%#      119linear% = >113arith.cmpi  =  ->arith.andiult,   tensor<%%4112115x,,4  x%%1cst_7cst_12x  i::32  , tensor<tensor<#44linearxx>44
xx      3232%xx90ii = 3232tt.bitcast, ,  ##%blockedblocked88>> 

:             %%tensor<1141204 =  = x4arith.shruiarith.shruix  1%%x112116i,,32  , %%#cst_8cst_11blocked  >#:: blocked  -> = tensor<tensor< #44tensor<ttgxx4.44xblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>xx4
3232x#xx1blockediix13232i = , , 32###, ttgblockedblocked#.>>blockedblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>

>
            
#%%      blocked115121%2 =  = 91 = arith.andiarith.ori = #  arith.andittg%% .114120%blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>,,89
  ,#%% blockedcst_9cst_13%3  cst_27 = :: #  :ttgtensor<tensor< .44tensor<blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>xx4
44x#xx4blocked3232x4xx1 = iix#3232ittg, , 32.##, blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>blockedblocked#
>>linear#

>blocked            
5%%       = 116122%# =  = 92ttgarith.andiarith.shrui = .  arith.andiblocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>%% 
112121%#,,90blocked  ,6%%  = cst_10118%#  cst_4ttg:: .  :blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>tensor<tensor< 
44tensor<#xx4blocked44x7xx4 = 3232x#xx1ttgiix.3232iblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>, , 32
##, #blockedblocked#blocked>>blocked8

> =             
#%%      ttg117123%. =  = 93blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>arith.addiarith.select = 
  tt.bitcast#%% blocked115119%9 = ,, 91# % ttg%122:.cst_11,  blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}> %tensor<
:1164#  : xlineartensor<tensor<4 = 4x4x#4x1ttgx4x.32xilinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
x3232#ix, linear32i#1, 1linear = #, >#blocked# ttg>blocked->.
> linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>      , tensor<
%tensor<4#1184xlinear = x42arith.subi4x =  x1#%32xttgcst_12xf32.,i, linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}> 32#
%, linear#117#>shared blocked
 = :>      # 
%ttgtensor<      94.4% = swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>x124tt.bitcast
4 =  #xarith.maxui%smem32 92 = x% #i115:ttg32, .,  tensor<shared_memory#%4
blockedcst_14xmodule> 4 attributes
:x {       1"%tensor<xt1194it = x32garith.cmpi4, . x#nult32blockedu,x>m i -%32->c115,  ta,#tensor<s blocked>4"%
x = cst_12      41 %x : :1251i  = x32tensor<arith.subif32, 4 , "x%#tt4124blockedgx,>.32 
nx%      uicst_14%m32 95-, : = w# math.log2ablockedtensor< r>4%p
x93s      4 "%x: = 12032 4 = xtensor< : arith.shruii4i 32x32%, 4, ttg.target116#x = ,blocked1" >xh%
f32icst_11      , p %#::126linearg  = >fxtensor<arith.shli
94       5x%%0412596"x, = , 32 math.log2"x% ticst_15%t32 94g, : .# :tblockedtensor< h>4tensor<r
x4e      4xa%x4d12132xs = x1-arith.oriixp 32f32e%, , r120##-,blockedblockedw >>a%

rcst_13            p %%":12797 =   =  = 64tensor<arith.shruimath.floor : 4  ix%%32412395}x,  32 :{x% 
icst_16tensor<  32 4tt.func, :x # 4publicblockedtensor<x >41@
xx_batched_gemm_afp4_wfp4_pre_quant_kernel      4f32(%x32, %122x#arg0 = ilinear: arith.shrui32, >! #
tt%blocked      .121>%ptr<bf16>,
98 {        = tt.divisibility%%math.floor = 16118128  :   = %i:arith.ori9632}   , %tensor<%:arg14126 : x,tensor<!4 4ttx%x.321274ptr<i8>x x {i:1tt.divisibility32 x = , tensor<f3216#4,  : blockedx#i>4blocked>32
x
}      32      , %x%%123i99arg2 = 32 = : arith.select, arith.subf! # tt%blocked%.119>97ptr<bf16>, 
, {%       tt.divisibility122%% = , 129cst_2616% =   : 116arith.addi:i :   32tensor<%tensor<}41284, x,x%4 4arg3x%x: 32cst_111!x xtti:f32.1 , ptr<i8>, tensor<# {#4lineartt.divisibilityblockedx> = >4
16, x       : tensor<32%i4x10032xi = }432arith.subf, x,  %32#%arg4xblocked98: ii>,3232
  {,       %tt.divisibility#%cst_5 = blocked130 16> = : : 
arith.shrui i32       tensor<}%%4, 124129x% = ,4arg5arith.maxui x:  %1i%cst_11x32115 f32 {,:, tt.divisibility  # = %tensor<blocked16cst_144> :  x
i:4      32 x%}tensor<432101, xx = %4itt.clampfarg6x32 : 32, %ix#9932iblocked, {32> tt.divisibility, 
% = #      cst_2516blocked%, : >131 i
 = %32      arith.minuicst_24}% ,, 125% % = 130propagateNanarg7arith.subi, :   =i%% 32124cst_22none {,  tt.divisibility :: = %  16cst_14tensor<tensor< :  44i:xx32 44}tensor<xx, 4321%xxxarg84if32: x32, i32, #32x#linear {iblocked>tt.divisibility32>
 = , 
      16#      % : blocked%102i>132 = 32
 = tt.clampf}      arith.shrui , % %%126%100arg9 = 113,: arith.shli, i  %32%%cst_18 {125cst_17,tt.divisibility,   =  :%16% cst_23 : cst_15tensor<,i 4 32:xpropagateNan} 4 , tensor<x=%432 arg10xxnone: 4i ix32:3232,   {x#tensor<tt.divisibilityiblocked4 = 32>x16, 
4 : #      xiblocked%132>133x}
 = f32,       arith.ori, %% #arg11127%blocked:  = 132>iarith.shrui,
32         {%%%tt.divisibility123131103 = ,  = 16 :arith.fptoui : %  icst_16tensor<%32 4101}:x ,  4:%tensor<x arg12432tensor<: xx4i4ix32x324 {32, xtt.divisibilityx#1 = iblockedx1632>f32 : , 
, i32#      #}blocked%linear, >134>%
 =  arg13      arith.trunci to: %% i128133tensor<32 =  4 {arith.ori:xtt.divisibility  4 = %tensor<x1612641 : ,xxi 4i32%x8}12732, ,  x#%:ilineararg14 32>: tensor<, 
i4#      32xblocked% {4>104tt.divisibilityx  =  = 32toarith.fptoui16x   : itensor<%i32410232, x }#4:, blockedx %>32tensor<arg15
x4:       ixi%8432129, x) = arith.addi#1 attributes blockedx {%>f32noinline128
,  = ,      #false %blocked}%135> cst_11 =  { tt.reshapeto
:       %tensor<%tensor<1344cst4 :x = x 4arith.constant4tensor<x x41dense<32xx127x4i>ix8 : 3232, tensor<, x#4#iblockedxblocked8>4>, 
x
#      1      blocked%x%>105i130  = 8 = ->arith.addi, arith.shrui  # tensor<%blocked%4103>129x,
,4      x%%%16cst_29cst_0cst_11x  =  2:arith.constant:x   itensor<dense<tensor<840x7FC04, x>x#4 : 4blockedxtensor<x71432>xxx
i128i      8x32%, bf16, outLHS#, #, linear#blocked%>blocked>outRHS
1
 =       >      tt.split%
% 106    131% = % = 135arith.addicst_1 = arith.minui  arith.constant :% % 104dense<130tensor<,2097152,4 > x% : %4csttensor<cst_22x 4 16:x:x 4 2tensor<xtensor<x414ixxx84i4, x32x#1, 32blockedx#x7iblockedi>8>32 , 
, ->#    # blocked%cst_2blockedtensor<> = >4
arith.constant
x             4%dense<%x107413216 = > = xarith.subf : arith.shruii tensor< 8%4%, cst_6x113#,4,blocked x 2%16%>102xcst_17
 i       :8:% ,  136tensor<#tensor< = 4blocked4arith.shlix2x 4>4%x
xoutRHS1    32,x%x f32c31_i32i%,  = 32cst_2#arith.constant,  blocked #:>31blocked 
 : >tensor<      i
4%32      x108
%4 =     133xmath.exp2% = 16 cst_3arith.orix%107 : tensor<4x4x1xf32,  =  i#arith.constant%8blocked 132, >dense<,#
0.000000e+00 blocked      >%2% : 131>109tensor< 
 = 4:      arith.extfx % 32tensor<137%x4 = 78f32xarith.ori , 4 :#x% blocked32outLHStensor<3x,4>i x
32%4    , 136x%# 32c32_i32blocked:x = > bf16arith.constant
tensor<,        4#32%xblocked : 1344>i = x 32arith.trunci16to
 x     %itensor<%13384c4_i32 , x = :#4arith.constant blockedx tensor<23244>x : x
f32i4      , 32x%#
32138blocked    x = >%itt.reshape
true32        = , %%arith.constant#137110 blocked  = true>:tt.broadcast
       totensor<%% 4108c0_i32tensor<x  = 44:arith.constantxx  416tensor<0xx4 : 32ixix8432i, x
8#1    , blockedx%#2f32cst_4blocked>,  = > #arith.constant
->blocked        >dense<%tensor< -83886081354->> = x  : tt.reshape64tensor<tensor< x44%ixx134844 , xx:#321 blockedxxtensor<8f32i4>, 32x
#, 4      blocked#x%>blocked32139
>x =       
itt.reshape%    8 111%, % = cst_5#105arith.mulf = blocked  arith.constant>:%   109dense<->tensor<,2.000000e+00 4 >tensor<x% : 44110tensor<xx 441:xxx 416itensor<xx8412, xxx#4f32ilinearx, 8>32#,  xblocked#->f32>blocked , 
7tensor<#    >4blocked%
x>cst_6      4
 = %x      arith.constantoutLHSi% , 8112dense<%,  = 0.000000e+00outRHS#tt.bitcast> = ttg  : tt.split.%tensor< slice<{dim = 2, parent = #blocked}>1114%> x135
:4        x:%tensor<1 1404xtensor< = xf324tt.reshape4, x x#4%32blockedx106x>16 f32
x:,     2 #%xtensor<blockedcst_7i4> = 8x arith.constant, 4-> #x dense<blocked1tensor<-21474836487x4>>ix :  84tensor<->, x4 #32xtensor<blockedx44>ixx 32324->, xx #i16tensor<blocked32x4>, ix
#84      blocked, x%>#i113
blocked8 =     2, arith.andi%># cst_8
linear% =       2112arith.constant%>, 136
 dense< =       %23arith.shli%cst_7> 141  : % = :tensor<outRHSttg.convert_layout 4, tensor<x %44%140xxcst_2 432 :xx: 32i tensor<x32tensor<4i, 4x32#x4, blocked4x#>xiblocked
168>    x, 
%i#      cst_98linear% = , 2114arith.constant#> =  blocked arith.shruidense<2-> 255> %>
tensor<112 :       4,tensor<%x 41374%x = xcst_84arith.orii x 8:32%,  xoutLHS#tensor<i,ttg432 .x, %slice<{dim = 2, parent = #blocked}>4#136>xblocked 
32>:      x
 %i    tensor<14232%4 = , cst_10xarith.extui# = 4 blockedarith.constantx%> 16141
dense<x       8388607i:%>8 115 : , tensor< = tensor<#4arith.andi4blockedx x24%4>x114x
i,32      8 x%, %i138#cst_932 = ttg , tt.reshape.:# slice<{dim = 2, parent = #blocked}> blocked%>tensor<>137 4
 tox    : 4% tensor<xcst_11tensor<432 = 4xxarith.constantx4i 4x32dense<xi, 11616#>x, blocked : i#>tensor<8ttg
4, .      x#slice<{dim = 2, parent = #blocked}>%4blocked>116x2
 = 32>      arith.andix % i->143%32  = 112, tensor<arith.shli,#4  blockedx%%>64142cst_10
x,     i :%8% cst_12, cst_30tensor< = # 4arith.constantblocked:x 8 4dense<>tensor<x127
432>      xx : %4itensor<139x324 = i, xtt.reshape16#4 , blockedx%#>32105ttg
x .      i:slice<{dim = 2, parent = #blocked}>%32 >117, tensor<
 = #4      arith.addiblockedx% >4144%
x = 115    1tt.bitcast,%x  cst_13i%% = 8143cst_11arith.constant,    #::dense<linear  4194304>tensor<tensor<> 44 : ->xxtensor< 444tensor<xxx4i324x16xx4, i32x#32xittg, i8.#32, slice<{dim = 2, parent = #blocked}>blocked, #>>#ttg 
blocked.->      >slice<{dim = 2, parent = #blocked}> %
>tensor<118    
4 = %      xarith.subicst_14%4  = 140x%arith.constant = bf16cst_12 tt.reshape, ,dense< # 126%ttg%>106.117 :  slice<{dim = 2, parent = #blocked}> tensor<: tensor<4x4x1xi8, #blocked>>
       :->% 4 145tensor<xtensor< = 444tt.expand_dimsxxx 4324%xxx14432ii {x328axisi, ,  = 32##2, blockedlinear : #>2iblocked
>32>    
}
%             cst_15%:% = 141 119arith.constant = tensor< =  ttg.convert_layout4arith.cmpidense< x 2%4ult>140x, :  bf16 tensor<:, %4 #115xtensor<ttg,44. xxslice<{dim = 2, parent = #blocked}>%324>cst_12xx  ii->:328  , , tensor<tensor<##44blockedlinearxx>244
>xx     132%->xxcst_16 bf16i = tensor<, 32arith.constant4#,  xblocked#dense<4>blocked21x
>>i      
 : 8%      tensor<, 146%4# = 120xttgtt.broadcast = 4. arith.shruixslice<{dim = 2, parent = #blocked}>% 32>145%x
 116i      :,32%  , 142tensor<%# = 4cst_11blockedarith.extuix > 4:
%x     1411tensor<% x4cst_17:bf16x =  , 4arith.constanttensor<#x 4blocked32dense<x>x284 i>x->32 : i , tensor<8tensor<#4, 4blockedx#x>4ttg4
x.x      32slice<{dim = 2, parent = #blocked}>32%x>x121i bf16 = 32to, arith.ori,  # #tensor<blocked%blocked4>120>x
,
4           x%%%i147cst_13cst_1816 =   = , tt.reshape:arith.constant#   ttg%tensor<dense<.1464-1.270000e+02slice<{dim = 2, parent = #blocked}> x>>:4 : 
 xtensor<      tensor<324%4xx143xi4 = 432xarith.shlix, 1 32#x%xblockedf32142bf16>, ,, 
# #      blocked%blocked%>cst_30> 122
 : =     -> arith.shrui% tensor< cst_19tensor<4% = 4x121arith.constantx4, 128x dense<xi%7bf1616118>, ,   : #blocked1#:tensor<>ttg. 4
      slice<{dim = 2, parent = #blocked}>tensor<x%>432148
xx =       4iamdgpu.scaled_upcast_fp4%144x16  = 32, %tt.bitcastx#138 ittg %32.scale143, slice<{dim = 2, parent = #blocked4}>  #>%:blocked
147 >     {tensor<
%axis4      cst_20 = x% = 14123arith.constant : x =  iiarith.selectdense<3216 -1}, %> #119 : :ttg, tensor< .%4tensor<slice<{dim = 2, parent = #blocked}>122x4>, 32x %x64->116ix  : 8itensor<tensor<, 844#, #blockedxxttg844.>xxslice<{dim = 2, parent = #blocked4}>,bf16, 32> #x
tensor<ttgi    4x.1%128slice<{dim = 2, parent = #blocked}>, cst_21xbf16># = , 
blockedarith.constant#      > blocked%, dense<1145tensor<0x7FC0>  = 4>->tt.expand_dimsx :   4tensor<tensor<%x128414432xx {x32128axisixx = 32bf16bf162, , ,  : ###iblockedblockedblocked32>51}
>>       

:%           124%%tensor< = cst_221494arith.maxui =  = x arith.constantarith.cmpi4%  x115dense<eqbf16,7,,  > #% : %ttgcst_14tensor<139. 4,slice<{dim = 2, parent = #blocked}>:x > 4% tensor<xcst_31->432  xx:tensor<4i 4x32tensor<x32, 4x4x#4xiblockedx132>ix, 
8bf16#    , , blocked%##>cst_23ttgblocked
 = .>      arith.constantslice<{dim = 2, parent = #blocked}>
% >      125dense<
% = 1.270000e+02      146arith.subi>% =   : 150tt.broadcast %tensor< = %1244tt.expand_dims145,x   4%:%x149 cst_141 {tensor< xaxis4:f32 = x , 24tensor<# : x4blockedi1x>32x4
}bf16x     , 32%: #xcst_24tensor<blockedi = 4>32arith.constantx ,  4->#dense<x blocked1.270000e+02itensor<>>14
 : , x      tensor<#4%4ttgx126x.32x = 4slice<{dim = 2, parent = #blocked}>bf16arith.shlix>, # 1 blocked%x->>125f32 
,, tensor<       #4%%linearx147cst_15>4 =  
xtt.reshape:    1  %x%tensor<cst_25i1464 = 1 xarith.constant, :4 #blocked xdense<>tensor<32-1.270000e+02
4xx>      4i : %x32tensor<15132, 4 = x#xtt.broadcastbf16blocked4 , >x%#
1150blocked      x >%f32: 127,  -> = #tensor< arith.shruilinear4tensor< >x4%
4x123    x128,%1x cst_26xbf16% = i, cst_16arith.constant1#  , blocked:dense<#1 2.000000e+00blocked>
tensor<>>      4 :  %xtensor<->14844  = xxtensor<amdgpu.scaled_upcast_fp43244 xxx4x%i132x13832xi , f321scale#, ,  blocked##%>linearblocked147
>> {      

axis%           = 128%%1 = cst_27152 : arith.ori = arith.constant = i  tt.reshape32%dense< }126-8388608% ,>151:  :   %tensor<:tensor<1274 tensor<4 x4x:4x64 x4xtensor<1xi4x328xix, 432i#x, 1blocked32#, 8xlinear#>i>blocked,32
> ,      tensor<#%->4blockedcst_28 x> = tensor<128
arith.constant4x       xbf16%dense<128, 1292097152x# = >iblockedarith.addi : 11 tensor<, >%4# 128xblocked->,41  x>tensor<%1
4cst_11x      x i%128:32153x ,  = bf16tensor<#arith.select, 4linear #x>%blocked4
1521x    , >
32%%      xcst_29cst_0%i = , 14932arith.constant% = ,  148arith.cmpi#dense< :  blocked127tensor<eq>>4,
 : x       tensor<128%%4x139130xi, = 41 arith.shruix, % 1#cst_31%xblocked 129i1:,8>  , , tensor<%#tensor<4cst_11linear4x >x4:
128x     xitensor<%bf1684cst_30, , x = ##4arith.constantblockedttgx 1.32dense<>slice<{dim = 2, parent = #blocked}>x7
>i>      
32 : %      , tensor<154%#4 = 150blockedxttg.local_alloc = >4 tt.expand_dims
x%       i153%%16 149131, : { = # axisarith.minuittg( =  .tensor<2%slice<{dim = 2, parent = #blocked}>4 : 130>xi,
12832     x}%%bf16 cst_22cst_31, :  = # :arith.constantblockedtensor<  14tensor<dense<>x4-1)4x> -> x4 : !ixtensor<ttg1324., xxmemdesc<4x128xbf16, #shared, #smem>#i4
ttg32x      ., i%slice<{dim = 2, parent = #blocked}>#8155>blocked,  =  >#ttg.local_load->
ttg        .%tensor<%slice<{dim = 2, parent = #blocked}>1544132> x = 
:4arith.shrui     x llvm.intr.assume!1% ttgx113%.i,truememdesc<4x128xbf16, #shared, #smem>1   , #%:->blockedcst_17  > itensor<
:14       
x%tensor<    1281514llvm.intr.assumex = x bf16tt.broadcast4%,  xtrue#%32 ttg150x:. i dot_op<{opIdx = 0, parent = #blocked3}>:32i> , 1
tensor<#
      4blocked    %x>llvm.intr.assume1564
  = x      %arith.extui1%true x133 %i = :701arith.ori  ,  i:#%1 blocked>132
tensor< ,    4-> llvm.intr.assumex % 32tensor<131%x4 trueix: 84 :, xtensor< #324ittgxx1.i4
slice<{dim = 2, parent = #blocked4}>1x    >, 32llvm.intr.assume #x toblockedi% >32truetensor<
,  4      #:x%blocked 32152>ix = 
1itt.reshape      
16 %    , %134llvm.intr.assume#151 =  ttg arith.trunci%.: trueslice<{dim = 2, parent = #blocked4}> % >tensor<133:
4        %x:i1574 1 = xtensor<
arith.shli324     xxllvm.intr.assume%i4 1561x%,, 32true #x %blockedi:cst_19> 32  :-> , i tensor<#1tensor<4blocked
4x>    x128 llvm.intr.assume32xto xi %i1tensor<true16, 4 , #x:#blocked4 ttg1>xi.
      321slice<{dim = 2, parent = #blocked4}>%x
>153i    
 = 8llvm.intr.assume      arith.select,  % #%158%blockedtrue = 152> tt.bitcast, 
: %       %cst_0%i157, 1351 % = 
:148tt.reshape      :  llvm.intr.assumetensor<4tensor<% x324134%xx truei128: 16x :, itensor< #14ittg., x1slice<{dim = 2, parent = #blocked4}>#4
>blockedx     132llvm.intr.assume-> >x tensor<, i%4tensor<8truex4,  32x#:x128blocked bf16x>i, bf16 1#, ->
ttg#     .blockedtensor<llvm.intr.assumeslice<{dim = 2, parent = #blocked4}>>14 
      >x%%
4true159      x  = %16:tt.expand_dims154x   = 2i%ttg.local_allocx1158 i
 {%8    axis153, % =  #02:blocked =  :  7tt.get_program_idi(> 32tensor<
x}4        x%:: 128outLHS tensor<x, i4bf16%32x, outRHS
32# =     xblockedtt.split%bf161 1, >% = #)135tt.get_program_idttg ->   .!:yslice<{dim = 2, parent = #blocked4}>ttg  >.tensor<: memdesc<4x128xbf16, #shared, #smem>4 ->
xi       432tensor<%x
415516    x = x%32ttg.local_load22x x = 1%iarith.addix1548 bf16 , %, :#arg5# blocked,blocked!7 4ttg>%>. c31_i32
memdesc<4x128xbf16, #shared, #smem>->         :%->tensor< 160 4i = tensor<x32tt.broadcast44
 xx    %12816%159xx3 bf16i = :, 8arith.divsi #,  tensor<ttg#%4.blocked2xdot_op<{opIdx = 0, parent = #blocked3}>2,32>> x

%1            c32_i32x%% bf16156136:,  =  =  #arith.extuiarith.shliiblocked  324%%
>70outRHS      ,%->: 4  % = arith.extsicst_2tensor<tensor<  44%:xxarg7 3232 tensor<xx:432i xx8i4bf16, 32x, # 16#ttgtoxblocked4. i>slice<{dim = 2, parent = #blocked4}>i8
>64,        
#%to    blocked161 %2 = tensor<5>tt.trans4 = arith.extsi
 x       %32%%160xarg9137 {i  = order16:arith.ori = ,   array<#i%ittg32outLHS32. ,: slice<{dim = 2, parent = #blocked4}>to 0> %, 
i1362      64 , %
:1157     > = %tensor<}arith.shli64   = x:%arith.extsi4 156 xtensor<,%164 arg11xx% i32cst_19:8x  , 32:i#x 32blockedbf16tensor< 2, 4to>#x 
blocked32i      4x64%>i
138 16     = ->, %tt.reshape #7 tensor<ttg = %4.arith.extsi137xslice<{dim = 2, parent = #blocked4}>  32>%:x
0 32       tensor<x%:4bf16158 x,  = i4#tt.bitcast32xblocked  169%tox>157 i
 i8      :64, % 
#162tensor<    blocked = 4%2tt.reshapex8> 32 =  %xarith.divsi->161i   16%tensor<:, 14 #,xtensor<ttg 644.%xxslice<{dim = 2, parent = #blocked4}>3i32> 8x :, 32-> #x iblockedbf16tensor<328, 4
>#x    
blocked32%      9x9%>bf16 = 139 , arith.remsi = -># tt.reshape ttg% tensor<.1%128slice<{dim = 2, parent = #blocked4}>,105x>  32
%:x      3 bf16% tensor<, 159:4# =  xblockedtt.expand_dimsi45 32x>%
1
158    x       {llvm.intr.assumei%axis 8163 = %,  = 2true#amdgpu.scaled_upcast_fp4 :  linear i:>%32  77}i->  1 scale:
tensor<      4%tensor<llvm.intr.assumex1624 4 {x%xaxis32truei = x 80bf16:,  : ,  #i#ittg32ttg1.}.
slice<{dim = 2, parent = #blocked}> slice<{dim = 2, parent = #blocked4}>    >:>llvm.intr.assume
         tensor<->%%64 true140xtensor<  = 324:tt.reshapexx  i32i%8x1106, 1
 #x    :blockedbf16% 3, 10tensor<># = 4,blockedarith.cmpix 4 4tensor<>sgtx128
,1x       x32%%ix160arg68bf16 = ,, , tt.broadcast ## %blockedblocked%c0_i32>5159  > :-> :  -> itensor< tensor<324tensor<4
x128x    4x32scf.ifx32x ix1%8bf16x10, , bf16 ##, {linearblocked#
25blocked      >>4%

>11              = %%->arith.muli141164   =  = tensor<%ttg.convert_layoutarith.cmpi48  x,%eq32 140,x%  32c4_i32:%x  70bf16:tensor<,,  4 #ix%blocked324cst_204
x >      i:
%8       12 = , tensor<%tt.make_range#4161 {linearx = end232tt.trans = >x 4 i% : ->8160i ,  {32tensor<#order, 4ttg = startx.array< = 4slice<{dim = 2, parent = #blocked4}>i0x>32 : i
: i8      032, %, }#1652 ttg = , :.tt.expand_dims1 slice<{dim = 2, parent = #blocked}> >tensor<>%}4
164 x       {:i%axis 32142 = tensor<,  = 24#arith.extui : xttg i32.%32xslice<{dim = 1, parent = #blocked1}>141}32>  x
:: bf16       tensor<, %tensor<4#134xblocked = x324tt.make_range4x> {xi endi1-> = 8,  4, #tensor< : #ttg4ittg.x32.slice<{dim = 2, parent = #blocked4}>32, slice<{dim = 2, parent = #blocked}>>xstart> 32 =  ->x0to bf16 :  tensor<, itensor<4#324xblocked}x329 4x>:x1
 ix      tensor<16i%4, 1162x#,  = ittg#tt.reshape32.blocked , slice<{dim = 2, parent = #blocked}>4%#>>161ttg

 .            :slice<{dim = 1, parent = #blocked3}>%% >143166tensor<
 =  = 4      arith.shlitt.broadcastx%  3214%%x = 14216532tt.splat, x  :bf16%% , 11cst_30tensor<#  4blocked::x9  32>itensor<x 3241-> xx ->4itensor< x1128tensor<i, x416#32x, blockedxi#4bf1632ttg>, , . ##slice<{dim = 2, parent = #blocked}>->blockedttg> 5.
tensor<>slice<{dim = 1, parent = #blocked1}>      4
>%x      
14432%       = x163%tt.bitcast32 = 15 xamdgpu.scaled_upcast_fp4 = %i arith.addi1431%  , 77%:# 14 blockedscale,tensor<4  4>%%x
162124       { x%axis:i167 =  16 = 0tensor<, tt.trans : 4# ixttg%32i.166}32slice<{dim = 2, parent = #blocked}> { , >order:#  =  ttg->array<tensor<. i64slice<{dim = 1, parent = #blocked1}>tensor<32x>4: 32
x0x      4, i%x2816bf16, ,  = , 1#tt.splat#>blocked ttg}3%. >arg4slice<{dim = 2, parent = #blocked}>:, >  :
tensor<tensor<       4128i%xx321453232  = xx->tt.expand_dims32bf16  x, tensor<%i#41441blockedx {, 5iaxis#>32 = blocked , 24-># : > ttgi tensor<.32->128slice<{dim = 1, parent = #blocked1}>} x> tensor<32
:4x       xbf16%tensor<32, 174x# = x32blockedarith.remsi4x5 xi>%bf161
15, ,       ,##% ttgblocked164%.9 = 16slice<{dim = 2, parent = #blocked}>>arith.cmpi >
 :       eq ->%,tensor< 168 4tensor< = %x4tt.reshape70ix ,324% , x167%#1 cst_20ttgx: .bf16 :slice<{dim = 1, parent = #blocked1}>, tensor< >#4tensor<
blockedx4      >32x%
x3218      32x = %xiarith.muli146i8  = 1, %tt.broadcast, #7 #ttg,%blocked. 1459slice<{dim = 2, parent = #blocked4}>% >>4: 
  ->      :tensor< % 4tensor<165ix128 = 644xtt.expand_dims
x32       1x%%xi16419bf161 { = , , axistt.expand_dims## =  blockedblocked2%>5 : 17 >i {->
32axis       } = tensor<% 14169: : x =  i4arith.selecttensor<32x 4}32%x x16832:bf16, x , #%itensor<blockedcst_2114>, , x
%#i      163ttg32% : ., 147tensor<slice<{dim = 2, parent = #blocked4}># = 128>ttgtt.reshapex . 32->slice<{dim = 1, parent = #blocked1}>%x >146itensor<  14->:, x  #32tensor<tensor<blockedx4451xx>x14, ixxtensor<1i32128, 32xx#, bf1632blocked#, x4blocked#bf16>1blocked, 
>>#      
 blocked%      ->5166% > = 20tensor<
tt.broadcast = 4       tt.splatx%% 128170165%x =  arg8bf16ttg.local_alloc: ,   :#%tensor< blocked1694i1 x32>:32 
 x->      (1 %tensor<xtensor<148128i4 = x1xamdgpu.scaled_upcast_fp432, 1 x#x%bf16blockedi138, 432 #>, scaleblocked # 5->blocked%> 1147)tensor<> { -> 4
axis!x       = ttg32%1.x21 : memdesc<128x32xbf16, #shared, #smem>32 = i
xarith.muli32      i }%1% 171, 19: = #, ttg.local_loadblocked tensor< 4%4%>20x170
 64       :x:% i 167tensor<8! = 4, ttgtt.transx#. 1blockedmemdesc<128x32xbf16, #shared, #smem>%x8 166i>-> {32, order,  tensor< = #tensor<128array<blocked4xi1x3232>128x: 
xbf160      bf16, , %, #ttg222#.,  = blockeddot_op<{opIdx = 1, parent = #blocked3}>1arith.extsi1>> >
}%        21->%:  172 :tensor< = tensor< 4tt.dot4tensor<x x4128%32xx155x1bf16,32x,  xi#%i32blocked1711, 1,, #> #blocked
%blocked1      cst_34 >%>: 149  to = ->tensor< arith.cmpi 4tensor< tensor<x4eq4128x,xx1 32bf16x%x, i13932#64,xttg,  i.#%1dot_op<{opIdx = 0, parent = #blocked3}>blockedcst_31, >1 # >:blocked*
 9       tensor<>tensor<%4
12823x      x = 4%32tt.make_rangex168x {i = bf16end8tt.reshape,  = ,  #128#%ttg : ttg167.i. dot_op<{opIdx = 1, parent = #blocked3}>32slice<{dim = 2, parent = #blocked}>:>, >  start
tensor<-> =       4 0%xtensor< : 150324i = xx32tt.expand_dims3232} xx %if32:1491,   {, #blockedtensor<axis#3128 = blocked>x29
i : >      32i %, 32->173#}  = ttg tensor<arith.addf.:128 slice<{dim = 0, parent = #blocked1}> x%>tensor<32172
4x,      xi %41%24x, cst_3 = i# tt.expand_dims1blocked: , 5 %#>tensor<23ttg
4 {.      xaxisslice<{dim = 2, parent = #blocked}>%32 = >169x0  = f32 : ->arith.select, i  #32tensor<%blocked}41683 x, >:4%
 xcst_21      tensor<1, %128x%174xi163 = i1 : arith.truncf32, tensor< , #128%#blockedx173ttg>32 .
x:slice<{dim = 0, parent = #blocked1}>      i >%1tensor< 151, 4-> = #x tt.broadcastblocked32tensor< 5x1%>f32x150, , 128 tensor<#x:128blockedi x332tensor<32>, 4x #xbf16toblocked4,  1x#tensor<>1blocked4
x5x      i>32%1
x25,       bf16 = #%, arith.extsiblocked170# > = blocked% ttg.local_alloc324-> >  %
:tensor<169       4 %tensor<x:17514  = xx(arith.extsi12832tensor< xx128%iix1332132 , , x:##bf16 blockedblocked, tensor<1>#4>
blockedx       5ito%>32 152), tensor< =  -> #1tt.reshape!ttgx ttg.128%.slice<{dim = 1, parent = #blocked3}>x151memdesc<128x32xbf16, #shared, #smem>>i 
 64:      to,  % #tensor<171tensor<blocked4 = 41xttg.local_loadx>4 i
x%64      32170, %x #26i:ttg = 1 .tt.broadcast, !slice<{dim = 1, parent = #blocked3}> #ttg>%blocked.
22>memdesc<128x32xbf16, #shared, #smem>         %:->->176    = tensor<tensor<tensor<arith.extsi44128 xxx%11283211xxx iibf16:641,  , , #i##ttg32blockedblocked. 11dot_op<{opIdx = 1, parent = #blocked3}>to>>>  

i->            64 %%
tensor<153172      4 =  = %xarith.selecttt.dot177128   = x%%tt.splati152155 64, ,%, % 176#cst_0% blocked, 171:1%, i>148 64
 : %       tensor<cst_3->%4  27x:tensor< = 128 4xtt.broadcastxtensor<i i464%1x, 25, 128# #xttg:blockedbf16. 1, slice<{dim = 1, parent = #blocked3}>tensor<>#>1, ttg
xtensor<.      1284dot_op<{opIdx = 0, parent = #blocked3}>%xx>178i128  = 64x*arith.addi, bf16  #, tensor<%blocked#1281771blockedx,>132  >x%->
bf16175       ,  tensor<%#:4154ttg x = .tensor<128ttg.local_allocdot_op<{opIdx = 1, parent = #blocked3}>4x >xi% i64153->64,   , #:tensor<#blocked 4ttg1(x.>tensor<32slice<{dim = 1, parent = #blocked3}>
4x>      xf32
%128,       28x#% = bf16blocked179arith.addi, 3 =  #>arith.extsi%blocked
 261      %,>%32 )173 % ->  = :27!arith.addf  ttg tensor<:.%32 memdesc<4x128xbf16, #shared, #smem>172xtensor<
,i4       32x%%, 128155cst_3#x =  ttgittg.local_load:.64  slice<{dim = 0, parent = #blocked3}>, %tensor<>#1544 blocked xto1:32 > xtensor<
!f3232      ttg, x%.#i29memdesc<4x128xbf16, #shared, #smem>blocked64 =  3, tt.addptr->>#  
ttg%tensor<      .arg04%slice<{dim = 0, parent = #blocked3}>,x174> 128 = 
%xarith.truncf      18bf16 % , %180:#173 =  ttg arith.extsi!.: ttdot_op<{opIdx = 0, parent = #blocked3}> %.>tensor<30ptr<bf16>
4 ,      x: %32 i156xi64 = f3232
arith.extui,         #to%%blocked 30703i =  >64arith.muli: 
  to      %tensor< %94tensor<181,x4 =  32xtt.splat%x32 c32_i32ix% 8bf16180:, ,   ##:ittgblocked 32.3i
slice<{dim = 2, parent = #blocked4}>>64      >
 %       ->31to%  =  175tensor<tt.make_rangetensor< = 32 {4arith.extsixendx i = 32%64, 32x13# : i ttgi16:.32,  slice<{dim = 0, parent = #blocked3}>, #tensor<>startttg4
 = .x      0slice<{dim = 2, parent = #blocked4}>i% : >32182 = i
, arith.addi32      # }%ttg% 157.181: = slice<{dim = 1, parent = #blocked3}>, arith.shli> tensor<  %32%to179x156  i,tensor<:32 4 , %xtensor<#cst_19i32ttg 64x.:, islice<{dim = 0, parent = #blocked6}> #64>tensor<ttg, 
4.#      xslice<{dim = 1, parent = #blocked3}>ttg%32>.32x
slice<{dim = 0, parent = #blocked3}> = i      >tt.make_range16%
 {, 176      end# = % = ttgarith.extsi18332.  =  : slice<{dim = 2, parent = #blocked4}>%arith.mulii>11 32
 %,       :7start% , = 158i 0 = 32% : tt.bitcast 6i to 32% :}157i   64i::
64        
tensor<tensor<%      324177%xx = 184i32tt.splat = 32x tt.addptr, i% #16176%ttg,  arg2.#:,slice<{dim = 0, parent = #blocked3}>ttg  >.i%
slice<{dim = 2, parent = #blocked4}>64183      >  % ->:33->   =  tensor<!tt.make_rangetensor<4tt {4x.endxiptr<bf16> = 3264,32x,   : bf16#ii, ttg6432#.
, ttgslice<{dim = 1, parent = #blocked3}>      start.>% = slice<{dim = 2, parent = #blocked4}>
1850>       =  : 
%tt.expand_dimsi      178 32% = %}159arith.addi178  =   {:tt.expand_dims%axis =   1771tensor<%, : 32158 ix {%32iaxis175}32 =   , 2::# :   ttgitensor<tensor<.3244slice<{dim = 1, parent = #linear1}>}xx> ii
:6464       , , %tensor<##344ttgttg = x..tt.splat32slice<{dim = 1, parent = #blocked3}>slice<{dim = 1, parent = #blocked3}> x>>%bf16
 ->30,         #%tensor<:ttg1794 . = xislice<{dim = 2, parent = #blocked4}>arith.extsi132> x  %i->->3264   , tensor<tensor<:#324 blockedxxtensor<3i3232>32xx
, 1i      #x32%ttgbf16, 186., # = slice<{dim = 0, parent = #blocked6}>#ttgarith.extsi>blocked. 
4slice<{dim = 0, parent = #blocked3}>%      >>arg13%
  35      to: = %  tt.splat160tensor<i  = 3232%tt.broadcastx 30 ito %64 :159, i  #64i:ttg
32 .       tensor<slice<{dim = 0, parent = #blocked3}>%->4>187 x
 = tensor<32      tt.expand_dims32x% x1180%ix = 17532bf16arith.extsi {, ,  axis##% = ttgblocked301.4  : slice<{dim = 1, parent = #linear1}>>:i>  32
->i}       32 %tensor< :364to  = x tensor<arith.addi32i4 x64x%32
i34x      64,bf16%,  , 181#%# = ttg31blockedtt.splat. 4 slice<{dim = 1, parent = #blocked3}>:>%> 
180 tensor<       ->32%: x161 tensor<i = i432tt.trans64x,   1#%->xttg160 i. {tensor<64slice<{dim = 0, parent = #blocked6}>order32, > = x#
array<iblocked      i643%32, >37: #
 = 0ttg      arith.addi, .% 2slice<{dim = 0, parent = #blocked3}>188%, > = 351
arith.muli,>        }%%% 18218633: = ,  arith.addi :tensor< % 4%176tensor<x181 3232,:xx  i32%i32x17964
, bf16       #, :%ttg# 189 = .blockedtensor<tt.splatslice<{dim = 1, parent = #linear1}>432 >>x%
 i186      ->64 :% ,  i38tensor<#64 = 4ttg tt.splatx.-> 32slice<{dim = 0, parent = #blocked3}> %x>tensor<arg532
4 x      x:bf16%1 , 183xi# = i32blockedarith.muli64 9 , ->>%# 
7blockedtensor<      ,332% >x162%
i = 6      32tt.reshape %,  :190#%  = ttg161iarith.muli. 64 slice<{dim = 0, parent = #blocked6}>:
%>       189
tensor<%,      4184 %x = %3932tt.addptr187 = x  tt.splat32%: xarg2 %bf16,tensor<arg5,  4 #%x:blocked1831 9 xi>:i32  64 ->!, -> tt# tensor<.blockedtensor<128ptr<bf16>332x,>x32 
ixi      32bf1664%, , 
191##       = ttgblocked%tt.addptr.5185 slice<{dim = 1, parent = #linear1}>> = %>
tt.expand_dims184
       ,      %% %163178%40 =  {188 = amdgpu.scaled_upcast_fp4axis arith.remsi  = : %1 %77 : !36 itt,scale32.  }ptr<bf16>%% ,38162:   { i:axistensor<64  = 4
tensor<0x      32 : i%xi64192i32,  = 32}#tt.expand_dims,  ttg #:.%ttg slice<{dim = 1, parent = #blocked3}>182.tensor<> {slice<{dim = 0, parent = #blocked6}>64 axis>x-> = 
32 0      xtensor< : %i4i418x32 = , 1}arith.remsi#x  blocked3i:%>64 37,, tensor<, #32 tensor<blockedx%1283i39x>64 32
, :x      # bf16%ttgtensor<, 186.32# = slice<{dim = 0, parent = #blocked3}>xblockedarith.extsi>i5  32>%->,  arg13 #-> tensor<ttg :1.tensor< xslice<{dim = 1, parent = #linear1}>128i32>x32x
32 i      xto64%bf16 , 42, i# = #64blockedarith.muliblocked
3 5      >%>%
7
187      ,       = % %tt.expand_dims193%164  = 5 = %tt.broadcast arith.cmpi175 :  {% eqaxis190i, =  64 1:
% :        70itensor<%,32443 }x = % 1tt.make_rangecst_20:x {  iend:tensor<64 =  4, 64tensor<x# : 4iblockedix6433232, >, x# startittg-> = 8. 0, slice<{dim = 1, parent = #blocked3}>tensor< : #>4ittg x32.->32}slice<{dim = 2, parent = #blocked4}> x >tensor<i:
464       x, tensor<%1#64165xblockedx = i3itt.expand_dims64>32 , 
, %#      #164blocked%ttg {3194.axis> = slice<{dim = 1, parent = #blocked6}> = 
tt.expand_dims>2       
 : %%      i188179%32 =  {44}arith.muliaxis =    = tt.expand_dims:%0  186 : %tensor<,i434 32 {x%}axis32176  = x :1i:  : 1 tensor<i, i3232#64x}ttg
i .      64:slice<{dim = 2, parent = #blocked4}>%,  >189#tensor<  = ttg64->tt.splat.x  slice<{dim = 0, parent = #blocked3}>itensor<%>324186 , x ->#32: ttgx tensor<.1i1slice<{dim = 1, parent = #blocked6}>x64x>i 32 1->x->,  i #tensor<64tensor<blocked4, 644x#x>1blocked1
x3x      i>i%64
32166,       ,  = #%#tt.broadcastblocked195blocked 3 = 6%>tt.broadcast>165
 
       %      :%194% 190 45tensor< = : = 4arith.muli arith.extsix tensor< 32%1%x189x441,32 x x:i%i 118764tensor<,  , 64#:#xblocked blocked14tensor<3x>4>i x 32->1->,  x #tensor<itensor<blocked46446x, x>32#32 xblockedxto323i x>64tensor<i
, 641      #x, %blocked1#1913xblocked = >i4tt.addptr
64>       , 
%%#      184196blocked%, = 6167 tt.addptr> = % 
tt.trans188%        191%%:,46166   =  {!%tt.expand_dimsordertt180  = . %array<ptr<bf16>:40i,  {32 !axis: itt = 064.0, 
ptr<bf16> : 2      ,i, % 321192i}> = 64 }tt.expand_dims
:         :%%tensor< 18219732tensor< { = x4axisarith.addiix =  32320%, x : 195#32i,ttgx32 .i}%slice<{dim = 0, parent = #blocked6}>1 193>, :  # :->blockedtensor<  432tensor<tensor<>x41 ixx->643232 , xxtensor<#ii4ttg6432x., , 32slice<{dim = 0, parent = #blocked3}>##x>blockedblocked32 36x->>>i 

1tensor<            , 1%%#x19847blocked32 =  = 9xarith.extsitt.splat>i  
64%%      , arg4arg10%#  168blocked:: = 3  tt.reshape>ii 
3232%        167%to-> 193  : = itensor< tt.broadcast641tensor< 
x4%      32x190%x32 199ix: = 3232 tt.splat, xtensor< #i4%blocked1x1986, 1 >#x:
blockedi       964i%>, 6448 #  = ->blocked->arith.muli 3  tensor<>tensor<%128 446x->x,32 1 xtensor<x%i4i471x64 , 32, :#x# blockediblockedtensor<56431>, >x
#
32      blocked      x%3%i169>20032 = 
 = , arith.select      arith.cmpi# % blocked%194slt6168 = ,>, tt.expand_dims 
% %      cst_21%185%, 179,49% {  = 163axis%arith.extsi :  = 199 tensor<0 %128 : :48xi  3232tensor<:x}4 i xtensor<1:11,  xx#tensor<i32blocked3264x5x, i>i#32, 64blocked, tensor<, 3#128#>blockedxttg
632.      >xslice<{dim = 0, parent = #blocked3}>% bf16>201to,   =  #->arith.extsitensor<blocked  15tensor<%x>1arg532
x x      32:i%x 64170ii,  = 6432#ttg.local_alloc,  blocked #to 6%blockedi>169364
 >
      :
      %       %50(%202 = tensor<195 = tt.broadcast128 = tt.splat xtt.broadcast %32 %45x%201 bf16194 :,  : #: tensor<blocked i645tensor<64x>1 1)x->x -> 32 i!xtensor<64ttgi1, .64x#memdesc<128x32xbf16, #shared, #smem>, 32blocked
#x6      blockedi>%364 171>, -> =  # ttg.local_load->blockedtensor<  364%tensor<>x1704
32 x      x:32%i x20364!i = , ttg64arith.cmpi#.,  blockedmemdesc<128x32xbf16, #shared, #smem>#slt,6 blocked >->3%
 >192      tensor<
, %128      %51x%202 = 32196 tt.broadcastx = : bf16tt.addptr %,  tensor<49#%1 ttg191x:.,32 dot_op<{opIdx = 1, parent = #blocked3}> xtensor<>%i1
18064x       , 32%:#x172 blockedi = !364tt.dottt>,  .
#%ptr<bf16>      blocked155,%6, 204> i =  %64tt.broadcast->171
  ,      %tensor< %20064%197 xcst_3 = :32 arith.addi x: tensor<i %464tensor<195x, 4,1#x xblocked128%i6x1931>bf16 , 
, :#      # blocked%ttgtensor<352.4> = dot_op<{opIdx = 0, parent = #blocked3}>x arith.addi>32->  x %*itensor<50 644,tensor<, x 128#32%xblockedx51323i x>1:bf16
,  ,       #tensor<#%blocked64ttg1983x. = >32dot_op<{opIdx = 1, parent = #blocked3}>arith.extsi
x>       i %%64->arg4205,    = #tensor<:tt.broadcastblocked4  6xi%>3232203
x        f32to:%,   53#itensor< = blocked641tt.addptr3
x >      32%
%xarg1      199i,% = 1 173tt.splat, % =  #42arith.addf%blocked  1983:% > 172: !, ->tt i .%64tensor<ptr<i8>cst_3 4, ->x : 32i tensor<x64tensor<4i
4x1      x1, %32x#54xiblocked = f32643arith.extsi, , > ##
%blockedblocked      arg1433% >>206:

 =              arith.andii%% 32174200%  =  = 204toarith.truncfarith.cmpi,    i%slt%64173,205
         :%:% 185 55tensor<,tensor< = 4 4arith.mulix%x 3219932%x x7f32:i,,  1,  #tensor<#%blocked4blocked543x3 >1>: x
 toi      i 64%64tensor<, 207
4# =       xblockedtt.splat%323 56x>
% = bf16      196tt.addptr, %  #201:%blocked =  arg33arith.extsi!,> tt 
%.%      arg5ptr<bf16>55%   175:->: =    arith.extsiitensor<! 324tt% x.13to32ptr<i8>  x,:i!  64ttitensor<
.644      ptr<bf16>, 
x%#      i202blocked%32 = 357, tt.splat>
 = #       tt.expand_dimsttg%% .201208%slice<{dim = 1, parent = #blocked3}>  = 41>:tt.addptr {   axistoi% =  642071tensor< , : 4-> ix %32itensor<197}641  , x::#32  ttgxtensor<tensor<.i432slice<{dim = 1, parent = #blocked3}>64xx>, 32i
#x32      blocked!, %3tt#176>.ttg = 
ptr<bf16>.arith.extsi      , slice<{dim = 1, parent = #linear1}> %#>%203blocked 11 = 3-> arith.cmpi> : ,tensor< slt 32i,tensor<x32 4x1 %32xto192xi ,i32i 64, 64%, #
202#linear       blocked1%:3>177 >
 = tensor<
      tt.splat1      % xtt.store58%32  = 176x%tt.splat i208 :64,% ,  arg15i#% 64blocked174: 3, ->> i 
%32tensor<      206 4% ->x204: i =  tensor<64tt.broadcasttensor<32,  4x#%x1ttg20032x. xislice<{dim = 1, parent = #blocked3}>:!32> tt, 
tensor<.#      4ptr<bf16>linear%x, 11781#> = xblocked
arith.addii3       1>%%, 
59177#     = ,blocked}arith.muli 3
 %>    %175 tt.return57 ->
,:     tensor<}%tensor<4
584x} x32
:ix
 64i{-#tensor<, 1
32#,   xttg#external1.blocked_resources: {xslice<{dim = 1, parent = #blocked3}>3
i>>    32

mlir_reproducer,             : {#%%
linear179205      1 =  = pipeline>arith.extsitt.broadcast: 
  "      %%b%32203u60  i = ::larith.extsi  t tensor<tensor<i%321n59xx. i32m:32xo , idtensor<#1u32ttg, lx.#e1slice<{dim = 0, parent = #blocked3}>blocked(x>3oi >p32to t,  ->i#tensor< mlinear32tensor<i1x4ze>ix- 6432ato, xm #idtensor<ttg1-l32., dxslice<{dim = 0, parent = #blocked3}>#s1>blocked-x
3ui      >s64%
a, 180      ge# = %{lineararith.extsi206l1  = d>%arith.andis
30 -       %l%:204i61 ,m = i itt.make_range32%t { 205=endto 0 =  : 4i t : 64tensor<ai
4r32      xg, %32estart181xt =  = i-0tt.splat1a :  , ri%#c32180blockedh} 3= :>g: 
f i      xtensor<64%94 2075x-> = 0i tt.splat}32tensor< ,, 32% t#x196rttgi i.64:tslice<{dim = 0, parent = #linear1}>,  o>#!n
ttgtt-      ..s%slice<{dim = 0, parent = #blocked3}>ptr<bf16>c62> f = 
->-tt.broadcast       t %tensor<o%1824-60 = xc arith.addi32f: x, %! tensor<181ttc32,.ox ptr<bf16>n1%, vx179#ei blockedr64:3t,  >-#tensor<
ilinear32      n1x%d>i208e 64 = x->, tt.addptr- # ttensor<ttg%o32.207-xslice<{dim = 0, parent = #blocked3}>,l4> lx
%vi      197m64% {, 183:i# =  nlineararith.mulitensor<d1 4e>%xx
732-      ,xb% !i63%ttt = 6.witt.expand_dims ptr<bf16>d :, t% #h61iblocked= {6430}axis
>, =       , 0% a : 184tensor<li = 4l32tt.addptrxo} 32c %xa:arg2it ,64etensor< , -4%#ax183blockedmi 3d32:>g,  
p#!      u-ttgtttt.stores.. hslice<{dim = 0, parent = #linear1}>ptr<bf16>%a>,208r  ,e->i d 64%-tensor<
174m1      ,ex% mo4185%rx = 206yitt.expand_dims ,32 : , % c#178tensor<olinear {4n1axisxv> = 32e
1xr       : !t%itt-6432.t = }ptr<bf16>rtt.broadcast , i :#t% blockedo63tensor<3n 4>-:x
a i    mtensor<64}d1, 
gx#    p4ttgtt.returnux.
-islice<{dim = 1, parent = #blocked3}>  t32>}o,  
-#->}llinear 
l1tensor<
v>4{-#m x
{->1  a xexternalrtensor<i_resources: {c3264
hx,     =4#mlir_reproducergxblocked: {fi3
x32>      9, 
pipeline5#      : 0linear%" 1186bf> = ut
arith.extsiiz       l=%%tt65arg13iru =  nearith.extsi:.}  m,%io 6432dc  ua:toln  eotensor<i(n3264oix
pc4      tax%ili187mi32 = iz, tt.expand_dimsze# e{linear%- 1175a > {mm axisdato = -x 1l-tensor< : di32istx32-e4}urx sai:at64 gi, tensor<eo#4{nlinearxls1id=>64s1
, -0      #l %ttgim66.ma = slice<{dim = 1, parent = #blocked3}>ixarith.addi>t-  =n%->0u65  m,tensor<t- 4ar%xre621gw xer:iti 64-ttensor<, ae32#rsxblockedc=43h-x>=1i
g 64      fr, %xe#1889glinear = 5io1arith.muli0n> }-
%,s      186 i%,tm67 rp = %iltt.splat176ti  of%:ny=56 -n iso:64cr 
fm!      -att%tl.189o ptr<i8> = -t tt.splatce-> fs %,ttensor<186 -32 ccx:oo4 nnxivv!64eett rr.->tgptr<i8> -e, tensor<in#4nclinearxde11e=>xxf
i-a      64tl%, os68#-e = blockedl ttt.addptr3lo >vp%
m-67      {d,%io 190nw% = dn66arith.mulie=  xtr:%-u 189betensor<,i}32 t,x%w 4187icx ds!:tett h,.tensor<= ptr<i8>40c, x}on#1,vlinearx e1iar>64lt,, l- #octensor<blockedcf323a-x>tt4
eox      --i%al64191ml,  = dv#tt.addptrgmlinear p{1%ui>184-n
,sd       he%%ax69188r- =  ebtt.load:di  -t%!mw68ttei .md:ptr<bf16>ot ,rhtensor< y=32i,0x64 }4
c,x      o !%nctt192vo. = enptr<i8>tt.expand_dimsrv,  te#%-rlinear182trt1 {i->axista
 = or      0ni% : -t70iah = 32m-tt.trans}dt  go%:p-69 ul {tensor<-lorder32tv = xomarray<i-{i64li32, ln: #vd1ttgme, .{x0slice<{dim = 0, parent = #blocked3}>a->>rb} ci ->ht: =w tensor<gitensor<1fd32xxtx329h4x5=xi00i64 }8, f,, #t #blockedzclinear3=a1>tn>
ro       un->%ei 193}ctensor< = ,a4tt.broadcast lx ci32%azx190nei o{8:n ,  i #tensor<cmttg4aa.xlxslice<{dim = 2, parent = #blocked4}>1i->xzi
iet      64{e%,  r71# a = blockedmttt.splat3ai >xo% -n29->is  t=:tensor<e1 4r0 !xamtt32tax-.xinptr<bf16>iou 64nm-->, sr #=etensor<blocked1w430rx> i128
mtx      ae!%xstt194-=. = n-ptr<bf16>tt.expand_dimsu1,  m #%-rblocked179re1 {eg>axiswi
 = ro      0in% : t-s72iei = 32smtt.addptr}=p  -l%:1i71  f,tensor<ry 32e=%xgn28iio 64or:, nm #-atensor<ttgsl4.i xslice<{dim = 0, parent = #blocked3}>mt128>pex ls!->ittt f-.tensor<ycptr<bf16>1=o, xnon#32rvblockedxme1iar>64lg,,  e #tntensor<blockedec43sex>t=128
-fx      cai%ol64195ns,  = ve#tt.broadcaste blocked rt1%go>194ep
 n-      :cd% eo73tensor<=w = 1fntt.loadxa= 32lt%xsr72ieu 64 e:, t} #o,tensor<blockedp 43-cx>ds128 oex->w,! n tttensor<=s.4typtr<bf16>xrm, 32ub#xeoblockedi}l164,->,  d
#cc      blockedse%3e,74>,  = 
 ett.splat      cn %oa%196nb53 = vl tt.addptree: r- %tl!191-itt,cn. feptr<i8>%-- 180ti-> on :-ftensor< lo64!l,xttv 32.mcxptr<bf16>{o!,intt nv.ideptr<i8>64er, 
xt#      --blocked%bb6197iu> = ti
arith.addiwl       it%%di75195,tn =  h-tt.addptr%=f 1930u% }n74:,c,  - tensor<ct%4oo52xn- 32vl:xel irvtensor<64tm64, -{x#af32blockedrtx3iz!>t=tt
ht.      -ruptr<i8>%te, 198o}# = -)"blockedarith.extsil,6 l
>%v      ,arg4mdisable_threading  {: falsetensor<:i,64 n
xid      3232everify_eachx x: ito-true64 b
, ii    }#64t
blocked
w  }6      i
>%d#-}
199t
       = h%tt.splat=76 0 = %}tt.load198,   %/tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0:c75:  a error: incacheModifierFailures have been detected while processing an MLIR pass pipeline64o 
 /tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0n=->: i  note: ccgtensor<Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`a 4
l:xi 1ztensor<xe64i{x64 32,  x#m!blockedatt3x.>-ptr<i8>
i,       t#%eblocked200r6 = a>arith.cmpit
 i      slto%,n77 s = %=ttg.convert_layout1851 ,0%  76%m 199a: x :-tensor< n64tensor<ux4m32x-x1rixe8iw, 64r#, iblocked#t6blockede>3s >=->
-       1tensor<% 64201rx = e32arith.extsigx ii%o8arg5n,  -#:sblocked i3im>32p
 l      toi% f78iy = 64=tt.reshape
n       o%%r73202m  = a:tt.splatl   tensor<%t4201ex s128[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 0, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank0]:E1106 11:31:42.089000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
:tx -bf16ic, 64o# nblocked->v1 e>tensor<r 1g->xe 32ntensor<xc4iex64=4, fx#a32blockedlx3sbf16>e, 
 #      tblocked%o>203p
 = -      arith.cmpid% o79sltw = ,nmath.absf = %t%192r78,u  e:%} 202,tensor<  4:cx s4tensor<ex1,32x x32sbf16xy, im#64bblocked, o>#l
blocked-      3d%>c80
e =       ,arith.extf%  204e% = n79tt.broadcasta  b:%l 200etensor< -4:lx i4tensor<nx4e32x-x1ibf16xn, if#1oblocked, ,>#  blockedcto3o >ntensor< v4->ex r4tensor<tx4-32xbx32uf32xi, il#1tblocked, i>#n
blocked-      3f%>u81
n =       c"%-t205tt = o.tt.broadcast-r le%ld203vu mc:{e f"tensor<t(1z%x=8032t)xr <iu{1eaxis, } = #)2blocked" : 3,i>
32       }->disable_threading> :  (tensor<false{4,
x
      32      ^bb0xverify_each(i: %1truearg16, 
: #    }f32blocked
, 3  }%>
arg17
#-}:       
f32%)206: = 
arith.andi         %%209204 = ,arith.maxnumf  %%205arg16, /tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0 :: % error: arg17tensor<Failures have been detected while processing an MLIR pass pipeline 4
:/tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0x : 32f32note: x
Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`i        
1tt.reduce.return,  #%blocked2093 >:
       f32%
207       = }tt.splat)  : %(196tensor< 4:x 4!xtt32.xptr<bf16>f32 , -># blockedtensor<>4) -> xtensor<324xx!4ttx.f32ptr<bf16>, , ##ttgblocked.3slice<{dim = 2, parent = #blocked}>>>

            %%20882 =  = tt.addptrttg.convert_layout  %%20781,  :% 197tensor< 4:x 4tensor<x4f32x, 32#xttg!.ttslice<{dim = 2, parent = #blocked}>.>ptr<bf16> , -># blockedtensor<34>x,4 xtensor<f324, x#32ttgx.islice<{dim = 2, parent = #linear}>64>, 
#      blocked%383> = 
tt.expand_dims       tt.store% 82% {208axis, =  2% : 174i,32 }% 206:  :tensor< 4tensor<x44xx32f32x, !#ttttg..ptr<bf16>slice<{dim = 2, parent = #linear}>, ># blocked->3 >tensor<
4    x}4
x    1tt.returnx
f32  , }#
linear}>


      {-#%
84  [rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 1, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank1]:E1106 11:31:42.091000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
 = externaltt.expand_dims_resources: { 
%    81mlir_reproducer {: {axis
 =       2pipeline : : i"32b}u i:l ttensor<i4nx.4mxof32d, u#lttge.(slice<{dim = 2, parent = #blocked}>o>p t->i mtensor<i4zxe4-xa1mxdf32-, l#dblockeds>-
u      s%a85g = ett.bitcast{ l%d83s -:l itensor<m4ixt4=x01 xtf32a, r#glineare>t -->a rtensor<c4hx=4gxf1xx9i5320, }#,linear >t
r      i%t86o = ntt.bitcast- s%c84f -:t otensor<-4cxf4,x 1cxof32n, v#eblockedr>t -->i ntensor<d4exx4-xt1ox-il32l, v#mblocked{>i
n      d%e87x = -arith.addib i%t85w,i d%tcst_28h =:0 }tensor<,4 xa4lxl1oxcia32t, e#-lineara>m
d      g%p88u = -arith.addis h%a86r,e d%-cst_1m e:m otensor<r4yx,4 xc1oxniv32e, r#tblocked->t
r      i%t89o = ntt.bitcast- a%m87d g:p utensor<-4txo4-xl1lxvim32{, a#rlinearc>h =->g ftensor<x49x540x 1fxtiz32=, t#rlinearu>e
}      ,% 90c = att.bitcastn o%n88i c:a ltensor<i4zxe4{x 1 xmia32x, -#iblockedt>e r->a ttensor<i4oxn4sx=11x0i 32m, a#xblocked->n
u      m%-91r = earith.andiw r%i89t,e s%=cst_27- 1:  rtensor<e4gxi4oxn1-xsii32m, p#llineari>f
y      =%n92o = rarith.andim a%l90 ,t e%scst_4t -:c otensor<n4vxe4rxg1exnic32e, =#fblockeda>l
s      e% 93t = ott.bitcastp -%d91o w:n =tensor<t4rxu4ex}1,x ic32s, e#,linear >c o->n vtensor<e4rxt4-xc1fx-f32t, o#-linearl>l
v      m%{94i = ntt.bitcastd e%x92- b:i ttensor<w4ixd4txh1=x0i}32,,  #cblockedo>n v->e rtensor<t4-xa4rxi1txhf32-, t#oblocked->l
l      v%m95{ = imath.log2n d%e93x -:b itensor<t4wxi4dxt1hx=f320, }#,linear >c
a      n%o96n = imath.log2c a%l94i z:e {tensor< 4 xm4axx1-xif32t, e#rblockeda>t
i      o%n97s = =math.floor1 0% 95m a:x -tensor<n4uxm4-xr1exwf32r, i#tlineare>s
=      -%198  = rmath.floore g%i96o n:- stensor<i4mxp4lxi1fxyf32=, n#oblockedr>m
a      l% 99t = earith.subfs t%-97c,o n%vcst_26e r:g etensor<n4cxe4=xf1axlf32s, e# lineart>o
p      -%d100o = warith.subfn =%t98r,u e%}cst_5,  :c stensor<e4,x 4sxy1mxbf32o, l#-blockedd>c
e      ,% 101e = ntt.clampfa b%l99e,- l%icst_25n,e -%icst_24n,f opropagateNan,  =c ononen v:e rtensor<t4-xb4uxi1lxtf32i, n#-linearf>u
nCapturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:01<?, ?it/s]      
c%-102t = ott.clampf- l%l100v,m {%fcst_18t,z =%tcst_23r,u epropagateNan} )=" ,none
       :disable_threading : tensor<false4,x
4      xverify_each1: xtruef32
,     }#
blocked  }>

#-}      
%103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst :/tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:0 : tensor<error: 4Failures have been detected while processing an MLIR pass pipelinex
4x/tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:01: xnote: iPipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`8
, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> [rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 3, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank3]:E1106 11:31:42.095000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
-> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 2, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank2]:E1106 11:31:42.097000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
[2025-11-06 11:31:42 DP0 TP0] Registering 0 cuda graph addresses
[2025-11-06 11:31:42 DP4 TP4] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/kb/ckbholskekd5monmzoob5oljoxgfz4xlzonoap6m2ll232d6zm3s.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP3 TP3] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/fp/cfplyp6avjs7k66evomdrkblvk3x7vmq4xbwl45377k5xadqi4oz.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP0 TP0] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/qg/cqgsnoaf7qv573naauflw76hoe7lt2j53i52yzx23qgjtfr4l44p.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP6 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/pj/cpjly2vl4nqwtzgee66y5vt32vu6dgbpxnwply3m77qu7msp2omg.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP2 TP2] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/xv/cxvgv42f65hkiltj6b5iwoiz2l5sndhmjhvwbjdojjhantp37qny.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP1 TP1] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/u4/cu4fnpc62wbtrsq3q6m4vrhrnsfq72pxqfvfwbdlgyuapc53vmbi.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP5 TP5] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/tm/ctmceenu2imu4zi3rrqe5pil7qagahbhgnw5fnxnwfpfmryd77bb.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-06 11:31:42 DP7 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/ak/cakbedn2f7cj4eqs3al5ygu2rdzforicyweesoc6i3q2nhz66hnv.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2791, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 319, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 322, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 479, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1995, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[rank0]:[W1106 11:31:43.439576760 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:[W1106 11:31:43.530010545 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[W1106 11:31:43.540100098 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1106 11:31:43.550628771 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[W1106 11:31:43.560512307 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank5]:[W1106 11:31:43.570158828 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1106 11:31:43.570886454 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1106 11:31:43.580342278 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
