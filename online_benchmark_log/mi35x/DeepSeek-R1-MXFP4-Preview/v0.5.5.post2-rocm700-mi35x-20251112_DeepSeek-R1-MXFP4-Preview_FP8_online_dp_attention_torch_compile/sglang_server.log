merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:32 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:33] WARNING model_config.py:723: quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:33] WARNING server_args.py:1197: Attention backend not explicitly specified. Use aiter backend by default.
[2025-11-12 18:12:33] WARNING server_args.py:1370: DP attention is enabled. The chunked prefill size is adjusted to 16384 to avoid MoE kernel issues. 
[2025-11-12 18:12:33] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:33] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:33] server_args=ServerArgs(model_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.51, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=16384, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=8, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=469446387, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', api_key=None, served_model_name='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=8, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='aiter', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=[1, 2, 4, 8], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=True, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, decrypted_config_file=None, decrypted_draft_config_file=None)
[2025-11-12 18:12:33] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:33] Using default HuggingFace chat template with detected content format: string
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:40 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:40 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:40] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:40] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:40] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:40] WARNING memory_pool_host.py:36: Current platform not support pin_memory
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:48 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-12 18:12:48] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:48] WARNING memory_pool_host.py:36: Current platform not support pin_memory
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:48 DP5 TP5] Process 511 gpu_id 5 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]
[2025-11-12 18:12:48 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:49 DP2 TP2] Process 508 gpu_id 2 is running on CPUs: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]
[2025-11-12 18:12:49 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP6 TP6] Process 512 gpu_id 6 is running on CPUs: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
[2025-11-12 18:12:49 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-12 18:12:49 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP5 TP5] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:49 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP2 TP2] Init torch distributed begin.
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:49 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP6 TP6] Init torch distributed begin.
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:49 DP1 TP1] Process 507 gpu_id 1 is running on CPUs: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
[2025-11-12 18:12:49 DP0 TP0] Process 506 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_tuned_gemm_ds_v3.csv
merge tuned file under model_configs/ and configs/  /sgl-workspace/aiter/aiter/configs/a8w8_blockscale_bpreshuffle_tuned_gemm.csv:/sgl-workspace/aiter/aiter/configs/model_configs/a8w8_blockscale_bpreshuffle_tuned_gemm_dsv3.csv
INFO 11-12 18:12:49 [__init__.py:241] Automatically detected platform rocm.
[2025-11-12 18:12:49 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:49 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:49 DP3 TP3] Process 509 gpu_id 3 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-11-12 18:12:49 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP4 TP4] Process 510 gpu_id 4 is running on CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]
[2025-11-12 18:12:49 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP1 TP1] Init torch distributed begin.
[2025-11-12 18:12:49 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP0 TP0] Init torch distributed begin.
[2025-11-12 18:12:49 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP3 TP3] Init torch distributed begin.
[2025-11-12 18:12:49 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP4 TP4] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-12 18:12:49] INFO trace.py:69: opentelemetry package is not installed, tracing disabled
[2025-11-12 18:12:49] WARNING memory_pool_host.py:36: Current platform not support pin_memory
[2025-11-12 18:12:49 DP7 TP7] Process 513 gpu_id 7 is running on CPUs: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
[2025-11-12 18:12:49 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-12 18:12:49 DP7 TP7] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-11-12 18:12:50 DP0 TP0] sglang is using nccl==2.26.6
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-11-12 18:12:56 DP7 TP7] Init torch distributed ends. mem usage=3.10 GB
[2025-11-12 18:12:56 DP0 TP0] Init torch distributed ends. mem usage=3.22 GB
[2025-11-12 18:12:56 DP6 TP6] Init torch distributed ends. mem usage=3.11 GB
[2025-11-12 18:12:56 DP5 TP5] Init torch distributed ends. mem usage=3.17 GB
[2025-11-12 18:12:56 DP4 TP4] Init torch distributed ends. mem usage=3.10 GB
[2025-11-12 18:12:56 DP3 TP3] Init torch distributed ends. mem usage=3.24 GB
[2025-11-12 18:12:56 DP2 TP2] Init torch distributed ends. mem usage=3.24 GB
[2025-11-12 18:12:56 DP1 TP1] Init torch distributed ends. mem usage=2.82 GB
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[2025-11-12 18:12:57 DP5 TP5] Load weight begin. avail mem=284.33 GB
[2025-11-12 18:12:57 DP4 TP4] Load weight begin. avail mem=284.40 GB
[2025-11-12 18:12:57 DP2 TP2] Load weight begin. avail mem=284.26 GB
[2025-11-12 18:12:58 DP7 TP7] Load weight begin. avail mem=284.40 GB
[2025-11-12 18:12:58 DP3 TP3] Load weight begin. avail mem=284.26 GB
[2025-11-12 18:12:58 DP0 TP0] Load weight begin. avail mem=284.28 GB
[2025-11-12 18:12:58 DP1 TP1] Load weight begin. avail mem=284.68 GB
[2025-11-12 18:12:58 DP0 TP0] Only Deepseek V3/R1 on NV-platform with capability >= 80 can use shared experts fusion optimization. Shared experts fusion optimization is disabled.
Loading safetensors checkpoint shards:   0% Completed | 0/73 [00:00<?, ?it/s]
[2025-11-12 18:12:58 DP6 TP6] Load weight begin. avail mem=284.39 GB
Loading safetensors checkpoint shards:   1% Completed | 1/73 [00:00<00:13,  5.45it/s]
Loading safetensors checkpoint shards:   3% Completed | 2/73 [00:00<00:19,  3.60it/s]
Loading safetensors checkpoint shards:   4% Completed | 3/73 [00:00<00:20,  3.40it/s]
Loading safetensors checkpoint shards:   5% Completed | 4/73 [00:01<00:22,  3.07it/s]
Loading safetensors checkpoint shards:   7% Completed | 5/73 [00:01<00:25,  2.67it/s]
Loading safetensors checkpoint shards:   8% Completed | 6/73 [00:01<00:22,  2.99it/s]
Loading safetensors checkpoint shards:  10% Completed | 7/73 [00:02<00:23,  2.84it/s]
Loading safetensors checkpoint shards:  11% Completed | 8/73 [00:02<00:22,  2.94it/s]
Loading safetensors checkpoint shards:  12% Completed | 9/73 [00:03<00:22,  2.79it/s]
Loading safetensors checkpoint shards:  14% Completed | 10/73 [00:03<00:22,  2.78it/s]
Loading safetensors checkpoint shards:  15% Completed | 11/73 [00:03<00:22,  2.72it/s]
Loading safetensors checkpoint shards:  16% Completed | 12/73 [00:04<00:22,  2.69it/s]
Loading safetensors checkpoint shards:  18% Completed | 13/73 [00:04<00:20,  2.91it/s]
Loading safetensors checkpoint shards:  19% Completed | 14/73 [00:05<00:30,  1.96it/s]
Loading safetensors checkpoint shards:  21% Completed | 15/73 [00:05<00:28,  2.07it/s]
Loading safetensors checkpoint shards:  22% Completed | 16/73 [00:06<00:25,  2.21it/s]
Loading safetensors checkpoint shards:  23% Completed | 17/73 [00:06<00:22,  2.53it/s]
Loading safetensors checkpoint shards:  25% Completed | 18/73 [00:06<00:19,  2.75it/s]
Loading safetensors checkpoint shards:  26% Completed | 19/73 [00:07<00:19,  2.78it/s]
Loading safetensors checkpoint shards:  27% Completed | 20/73 [00:07<00:18,  2.81it/s]
Loading safetensors checkpoint shards:  29% Completed | 21/73 [00:07<00:17,  2.98it/s]
Loading safetensors checkpoint shards:  30% Completed | 22/73 [00:08<00:17,  2.94it/s]
Loading safetensors checkpoint shards:  32% Completed | 23/73 [00:08<00:17,  2.80it/s]
Loading safetensors checkpoint shards:  33% Completed | 24/73 [00:08<00:18,  2.64it/s]
Loading safetensors checkpoint shards:  34% Completed | 25/73 [00:09<00:16,  2.84it/s]
Loading safetensors checkpoint shards:  36% Completed | 26/73 [00:09<00:16,  2.86it/s]
Loading safetensors checkpoint shards:  37% Completed | 27/73 [00:09<00:15,  2.98it/s]
Loading safetensors checkpoint shards:  38% Completed | 28/73 [00:10<00:15,  2.93it/s]
Loading safetensors checkpoint shards:  40% Completed | 29/73 [00:10<00:14,  3.12it/s]
Loading safetensors checkpoint shards:  41% Completed | 30/73 [00:10<00:13,  3.09it/s]
Loading safetensors checkpoint shards:  42% Completed | 31/73 [00:11<00:14,  2.95it/s]
Loading safetensors checkpoint shards:  45% Completed | 33/73 [00:11<00:15,  2.65it/s]
Loading safetensors checkpoint shards:  47% Completed | 34/73 [00:12<00:15,  2.51it/s]
Loading safetensors checkpoint shards:  48% Completed | 35/73 [00:12<00:15,  2.46it/s]
Loading safetensors checkpoint shards:  49% Completed | 36/73 [00:13<00:15,  2.45it/s]
Loading safetensors checkpoint shards:  51% Completed | 37/73 [00:13<00:14,  2.54it/s]
Loading safetensors checkpoint shards:  52% Completed | 38/73 [00:13<00:13,  2.67it/s]
Loading safetensors checkpoint shards:  53% Completed | 39/73 [00:14<00:12,  2.83it/s]
Loading safetensors checkpoint shards:  55% Completed | 40/73 [00:14<00:10,  3.16it/s]
Loading safetensors checkpoint shards:  58% Completed | 42/73 [00:14<00:06,  4.95it/s]
Loading safetensors checkpoint shards:  60% Completed | 44/73 [00:14<00:04,  6.74it/s]
Loading safetensors checkpoint shards:  63% Completed | 46/73 [00:14<00:03,  7.70it/s]
Loading safetensors checkpoint shards:  66% Completed | 48/73 [00:15<00:02,  8.74it/s]
Loading safetensors checkpoint shards:  68% Completed | 50/73 [00:16<00:07,  3.12it/s]
Loading safetensors checkpoint shards:  70% Completed | 51/73 [00:17<00:08,  2.46it/s]
Loading safetensors checkpoint shards:  71% Completed | 52/73 [00:19<00:14,  1.48it/s]
Loading safetensors checkpoint shards:  73% Completed | 53/73 [00:19<00:13,  1.48it/s]
Loading safetensors checkpoint shards:  74% Completed | 54/73 [00:20<00:12,  1.58it/s]
Loading safetensors checkpoint shards:  75% Completed | 55/73 [00:20<00:10,  1.78it/s]
Loading safetensors checkpoint shards:  77% Completed | 56/73 [00:20<00:08,  1.95it/s]
Loading safetensors checkpoint shards:  78% Completed | 57/73 [00:21<00:07,  2.03it/s]
Loading safetensors checkpoint shards:  79% Completed | 58/73 [00:21<00:06,  2.19it/s]
Loading safetensors checkpoint shards:  81% Completed | 59/73 [00:22<00:06,  2.28it/s]
Loading safetensors checkpoint shards:  82% Completed | 60/73 [00:22<00:05,  2.33it/s]
Loading safetensors checkpoint shards:  84% Completed | 61/73 [00:22<00:04,  2.50it/s]
Loading safetensors checkpoint shards:  85% Completed | 62/73 [00:23<00:03,  2.96it/s]
Loading safetensors checkpoint shards:  86% Completed | 63/73 [00:23<00:03,  2.88it/s]
Loading safetensors checkpoint shards:  88% Completed | 64/73 [00:23<00:03,  2.78it/s]
Loading safetensors checkpoint shards:  89% Completed | 65/73 [00:24<00:02,  2.69it/s]
Loading safetensors checkpoint shards:  90% Completed | 66/73 [00:24<00:02,  2.75it/s]
Loading safetensors checkpoint shards:  92% Completed | 67/73 [00:24<00:02,  2.69it/s]
Loading safetensors checkpoint shards:  93% Completed | 68/73 [00:25<00:01,  2.67it/s]
Loading safetensors checkpoint shards:  95% Completed | 69/73 [00:25<00:01,  2.72it/s]
Loading safetensors checkpoint shards:  96% Completed | 70/73 [00:26<00:01,  2.63it/s]
Loading safetensors checkpoint shards:  97% Completed | 71/73 [00:26<00:00,  2.47it/s]
[2025-11-12 18:13:25 DP7 TP7] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.22 GB, mem usage=49.18 GB.
[2025-11-12 18:13:25 DP5 TP5] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.15 GB, mem usage=49.18 GB.
[2025-11-12 18:13:25 DP4 TP4] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.23 GB, mem usage=49.18 GB.
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:27<00:00,  2.75it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:27<00:00,  2.68it/s]

[2025-11-12 18:13:26 DP2 TP2] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.09 GB, mem usage=49.18 GB.
[2025-11-12 18:13:26 DP6 TP6] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.21 GB, mem usage=49.18 GB.
[2025-11-12 18:13:26 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.11 GB, mem usage=49.18 GB.
[2025-11-12 18:13:26 DP3 TP3] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.08 GB, mem usage=49.18 GB.
[2025-11-12 18:13:27 DP1 TP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.50 GB, mem usage=49.18 GB.
[2025-11-12 18:13:27 DP0 TP0] Using KV cache dtype: torch.bfloat16
[2025-11-12 18:13:27 DP0 TP0] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP0 TP0] Memory pool end. avail mem=136.81 GB
[2025-11-12 18:13:27 DP3 TP3] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP2 TP2] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP3 TP3] Memory pool end. avail mem=136.79 GB
[2025-11-12 18:13:27 DP2 TP2] Memory pool end. avail mem=136.80 GB
[2025-11-12 18:13:27 DP5 TP5] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP5 TP5] Memory pool end. avail mem=136.86 GB
[2025-11-12 18:13:27 DP4 TP4] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP7 TP7] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP4 TP4] Memory pool end. avail mem=136.94 GB
[2025-11-12 18:13:27 DP7 TP7] Memory pool end. avail mem=136.93 GB
[2025-11-12 18:13:27 DP1 TP1] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP1 TP1] Memory pool end. avail mem=137.21 GB
[2025-11-12 18:13:27 DP6 TP6] KV Cache is allocated. #tokens: 1463402, KV size: 95.77 GB
[2025-11-12 18:13:27 DP6 TP6] Memory pool end. avail mem=136.92 GB
[2025-11-12 18:13:27 DP5 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=136.73 GB
[2025-11-12 18:13:27 DP4 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=136.81 GB
[2025-11-12 18:13:27 DP2 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=136.67 GB
[2025-11-12 18:13:27 DP6 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=136.79 GB
[2025-11-12 18:13:27 DP1 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=137.08 GB
[2025-11-12 18:13:27 DP7 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=136.80 GB
[2025-11-12 18:13:27 DP3 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=136.66 GB
[2025-11-12 18:13:27 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=136.69 GB
[2025-11-12 18:13:27 DP0 TP0] Capture cuda graph bs [1, 2, 4, 8]
  0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=136.68 GB):   0%|          | 0/4 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
ler_DP4_TP4: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/cd/ccdbibxj7d5hxa66wvzz7fgnlag4usj6w3qhp5ehenipbgcleyiv.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/cd/ccdbibxj7d5hxa66wvzz7fgnlag4usj6w3qhp5ehenipbgcleyiv.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 4, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank4]:E1112 18:13:30.897000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP0_TP0: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
ler_DP2_TP2: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = #blockedarith.muli =  #%ttg9.,blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> 
%#c32_i32blocked 1: =  #ittg32.
blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>      
%#31blocked = 2tt.make_range =  {#endttg = .32blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> : 
i#32blocked, 3start =  = #0ttg : .iblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>32
}# blocked:4  = tensor<#32ttgx.iblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>32
, ##blockedttg5. = slice<{dim = 0, parent = #blocked6}>#>ttg
.      blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>%
32# = blockedtt.make_range6 { = end# = ttg32. : blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>i
32#, blockedstart7 =  = 0# : ttgi.32blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>}
 #:blocked 8tensor< = 32#xttgi.32blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>, 
##ttgblocked.9slice<{dim = 0, parent = #blocked3}> = >#
ttg      .%blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>33
 = #tt.make_rangelinear { = end# = ttg32. : linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>i
32#, linearstart1 =  = 0# : ttgi.32linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>}
 #:linear 2tensor< = 32#xttgi.32linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>, 
##ttgshared. = slice<{dim = 1, parent = #linear1}>#>ttg
.      swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>%
34# = smemtt.splat =  #%ttg30. shared_memory:
 modulei attributes32 { "->t ttensor<g32.xniu32m, -#cttgt.aslice<{dim = 0, parent = #blocked6}>s>"
 =       1% : 35i = 32tt.splat,  "%t30t g:. niu32m -->w atensor<r32pxsi"32 = , 4# : ttgi.32slice<{dim = 1, parent = #linear1}>, >ttg.target
 =       "%h36i = parith.addi: g%f34x,9 5%031" , :" ttensor<t32gx.it32h, r#ettga.dslice<{dim = 0, parent = #blocked6}>s>-
p      e%r37- = warith.addia r%p35", =  64% : 33i 32:}  tensor<{32
x  itt.func32 , public# ttg@._batched_gemm_afp4_wfp4_pre_quant_kernelslice<{dim = 1, parent = #linear1}>(>%
arg0      : %!38tt = .tt.splatptr<bf16>  {%tt.divisibilityarg5 =  16: :  ii3232} , ->% arg1tensor<: 32!xtti.32ptr<i8>,  {#tt.divisibilityttg = .16slice<{dim = 0, parent = #blocked6}> : >i
32      }%, 39% = arg2tt.splat:  !%ttarg5. ptr<bf16>: { tt.divisibilityi = 3216  : ->i 32tensor<}32, x%iarg332: , !#ttttg..ptr<i8>slice<{dim = 1, parent = #linear1}> {>tt.divisibility
 =       16% : 40i = 32arith.remsi} , %%36arg4,:  i%3238,  %:arg5 : tensor<i3232x {itt.divisibility32 = , 16# : ttgi.32slice<{dim = 0, parent = #blocked6}>}>, 
%      arg6%: 41i = 32arith.remsi { tt.divisibility% = 3716, :  i%3239} , :% arg7tensor<: 32ix32i {32tt.divisibility,  = #16ttg : .islice<{dim = 1, parent = #linear1}>32>}
,       %%arg842:  = iarith.muli32  {%tt.divisibility7 = ,16  : %i532 }:,  %iarg964: 
i      32% {43tt.divisibility =  = tt.make_range16 { : endi = 3264} : , i%32arg10, : starti = 320 { : tt.divisibilityi = 3216} :  i:32 }tensor<, 64%xarg11i: 32i, 32# {ttgtt.divisibility. = slice<{dim = 1, parent = #blocked6}>16> : 
i      32%}44,  = %tt.expand_dimsarg12 : %i4332 { {axistt.divisibility =  = 116 :  : ii3232}} , :% arg13tensor<: 64ix32i {32tt.divisibility,  = #16ttg : .islice<{dim = 1, parent = #blocked6}>32>} , ->% arg14tensor<: 64ix321 {xtt.divisibilityi = 3216,  : #iblocked326}>, 
%      arg15%: 45i = 32arith.extsi)  attributes% {44noinline  = :false }tensor< 64{x
1    x%icst32 = , arith.constant# blockeddense<6127>>  : totensor< 4tensor<x644xx11xxii648, , ##blockedblocked6>>

          %%cst_046 =  = arith.constanttt.expand_dims  dense<%0x7FC040> { : axistensor< = 40x : 128ix32bf16},  #:blocked 1tensor<>32
x    i%32cst_1,  = #arith.constantttg .dense<slice<{dim = 0, parent = #blocked6}>2097152>>  : ->tensor< 4tensor<x14xx321xxii3232, , ##blockedblocked6>>

          %%cst_247 =  = arith.constanttt.splat  dense<%4arg10>  : :tensor< 4ix324 x->16 xtensor<i18x, 32#xblockedi232>, 
#    blocked%6c31_i32> = 
arith.constant       %3148 :  = iarith.muli32 
%    46%,cst_3  = %arith.constant47  dense<:0.000000e+00 >tensor< : 1tensor<x432xx32ix32f32, , ##blockedblocked63>>

          %%49c32_i32 =  = arith.extsiarith.constant  %3248 :  i:32 
tensor<    1%xc4_i3232 = xarith.constanti 324,  : #iblocked326
>     %totrue  = tensor<arith.constant1 xtrue32
x    i%64c0_i32,  = #arith.constantblocked 60> : 
i      32%
50     = %tt.broadcastcst_4  = %arith.constant45  dense<:-8388608 >tensor< : 64tensor<x41xx4ix641, x#iblocked326, ># blocked->> 
tensor<    64%xcst_532 = xarith.constanti 64dense<, 2.000000e+00#>blocked : 6tensor<>4
x      4%x511 = xtt.broadcastf32 , %#49blocked >:
     tensor<%1cst_6x = 32arith.constantx idense<640.000000e+00, ># : blockedtensor<64>x 4->x 1tensor<x64f32x, 32#xblockedi>64
,     #%blockedcst_76 = >arith.constant
       dense<%-214748364852> =  : arith.additensor< 4%x504,x 32%x51i 32:,  #tensor<blocked64>x
32    x%icst_864 = , arith.constant# blockeddense<623>>
 :       tensor<%453x = 4tt.addptrx 32%xarg1i,32 , %#42blocked >:
     !%ttcst_9. = ptr<i8>arith.constant,  dense<i25564>
 :       tensor<%454x = 4arith.extsix 32%xarg14i 32:,  #iblocked32> 
to     %icst_1064 = 
arith.constant       %dense<558388607 = >arith.muli :  tensor<%47x,4 x%3254x i:32 , i#64blocked
>      
%    56% = cst_11tt.addptr =  arith.constant% arg3dense<,1 >% : 55tensor< 4:x 4!xtt32.xptr<i8>i,32 , i#64blocked
>      
%    57% = cst_12tt.expand_dims =  arith.constant% 41dense< {127axis> =  : 1tensor< : 4ix324}x 32:x itensor<3232, x#iblocked32>, 
#    ttg%.cst_13slice<{dim = 1, parent = #linear1}> = >arith.constant  ->dense< 4194304tensor<>32 : xtensor<14xxi432x, 32#xlineari132>, 
#      blocked%>58
 =     tt.splat% cst_14% = arg15arith.constant  :dense< 126i>32 :  tensor<->4 xtensor<432xx321xxii3232, , ##blockedlinear>1
>    
%      cst_15% = 59arith.constant =  arith.mulidense< 2%>57 : ,tensor< 4%x584 x:32 xtensor<i3232x, 1#xblockedi>32
,     #%linearcst_161 = >arith.constant
       dense<%2160> =  : arith.extsitensor< 4%x594 x:32 xtensor<i3232x, 1#xblockedi>32
,     #%linearcst_171 = >arith.constant  todense< 28tensor<>32 : xtensor<14xxi464x, 32#xlineari132>, 
#      blocked%>61
 =     tt.make_range% {cst_18end =  = arith.constant4  : dense<i-1.270000e+0232>,  : starttensor< = 40x : 4ix321}x f32:,  #tensor<blocked4>x
i    32%, cst_19# = ttgarith.constant. slice<{dim = 0, parent = #linear1}>dense<>7
>       : %tensor<624 = xtt.broadcast32 x%i6016 , :# ttgtensor<.32slice<{dim = 2, parent = #blocked4}>x>1
x    i%64cst_20,  = #arith.constantlinear 1dense<>-1 >-> :  tensor<tensor<432xx324xxii864, , ##ttglinear.1slice<{dim = 2, parent = #blocked4}>>>

          %%63cst_21 =  = tt.expand_dimsarith.constant  %dense<610x7FC0 {>axis :  = tensor<0128 : xi3232x}bf16 , :# blockedtensor<54>x
i    32%, cst_22# = ttgarith.constant. slice<{dim = 0, parent = #linear1}>dense<>7 >-> :  tensor<tensor<41xx44xx32ix32i, 32#, linear#1blocked>>

          %%64cst_23 =  = tt.broadcastarith.constant  %dense<631.270000e+02 >: :  tensor<tensor<41xx44xx1ix32f32, , ##linearblocked1>>
     ->% cst_24tensor< = 32arith.constantx 4dense<x1.270000e+02i>32 : , tensor<#4linearx14>x
1      x%f3265,  = #arith.extsilinear >%
64     %:cst_25  = tensor<arith.constant32 xdense<4-1.270000e+02x>i : 32tensor<, 4#xlinear41x>1 xtof32 , tensor<#linear>
    %cst_26 = arith.constant32 xdense<42.000000e+00x>i : 64tensor<, 4#xlinear41x>1
x      f32%, 66# = lineararith.addi> 
%    65%,cst_27  = %arith.constant62  dense<:-8388608 >tensor< : 32tensor<x44xx4ix641, x#ilinear321, >#
linear      >%
67     = %tt.splatcst_28  = %arith.constant56  dense<:2097152 >! : tttensor<.4ptr<i8>x 4->x 1tensor<x32ix324, x#!lineartt>.
ptr<i8>    , %#cst_29linear = 1arith.constant> 
dense<      127%>68 :  = tensor<tt.addptr4 x%467x,1 x%i668 , :# lineartensor<>32
x    4%xcst_30! = ttarith.constant. ptr<i8>dense<, 7#>linear : 1tensor<>4,x 4tensor<x32ix164, x#ittg64., slice<{dim = 2, parent = #blocked}>#>linear
1    >%
cst_31       = %arith.constant69  = dense<tt.load-1 >% : 68tensor< 4:x 4tensor<x32ix84, x#!ttgtt..slice<{dim = 2, parent = #blocked}>ptr<i8>>, 
#    linearllvm.intr.assume1 >%
true       %:70  = itt.trans1 
%    69llvm.intr.assume { order% = truearray< i:32 : i11, 
0    >llvm.intr.assume}  %:true  tensor<:32 xi41x
i    8llvm.intr.assume,  #%lineartrue1 >:  ->i 1tensor<
4    xllvm.intr.assume32 x%itrue8 , :# ttgi.1slice<{dim = 2, parent = #blocked4}>
>    
llvm.intr.assume       %%71true =  tt.splat:  %i291 
:     llvm.intr.assume! tt%.trueptr<bf16>  :->  itensor<14
x    128llvm.intr.assumex !%tttrue. ptr<bf16>:,  #iblocked11
>    
llvm.intr.assume       %%72true =  tt.addptr:  %i711,
     %llvm.intr.assume28  %:true  tensor<:4 xi1281x
!    ttllvm.intr.assume. ptr<bf16>%, true# blocked:1 >i,1 
tensor<    4llvm.intr.assumex 128%xtruei 64:,  #iblocked11
>    
%      0% = 73tt.get_program_id =  tt.loadx  %:72  i:32 
tensor<    4%x1128 = xtt.get_program_id! tty. ptr<bf16>:,  #iblocked321
>    
%      2% = 74arith.addi =  tt.splat% arg5%,53  %:c31_i32  !:tt .iptr<i8>32 
->     %tensor<364 = xarith.divsi32 x%!2tt,. ptr<i8>%, c32_i32# blocked:6 >i
32      
%    75% = 4tt.addptr =  arith.extsi% 74%,arg7  %:52  i:32  tensor<to64 xi3264x
!    tt%.5ptr<i8> = , arith.extsi# blocked%6arg9> ,:  tensor<i6432x 32tox ii6464, 
#    blocked%66> = 
arith.extsi       %%76arg11 =  tt.load:  %i7532  cacheModifierto  =i 64cg
     :% 7tensor< = 64arith.extsix 32%x0! tt:. ptr<i8>i, 32# blockedto6 >i
64      
%    77% = 8ttg.convert_layout =  arith.divsi% 76% 1:,  tensor<%643x 32:x ii832, 
#    blocked%69> =  arith.remsi->  %tensor<164,x 32%x3i 8:,  #iblocked323
>    
llvm.intr.assume       %%78true =  tt.reshape:  %i731 
:     llvm.intr.assumetensor< 4%xtrue128 x:bf16 , i#1blocked
1    >llvm.intr.assume  ->% truetensor< 4:x 4ix132
x    bf16%, 10# = blockedarith.cmpi> 
sgt      ,% 79% = arg6math.absf,  %%78c0_i32  ::  tensor<i432x
4    xscf.if32 x%bf1610,  #{blocked
>      
%      11% = 80arith.muli =  arith.extf% 8%,79  %:c4_i32  tensor<:4 xi432x
32      x%bf1612,  = #tt.make_rangeblocked {>end  = to4  : tensor<i432x, 4startx = 320x : f32i, 32#}blocked>
      %81 = " t:t .tensor<r4exdiu32c, e#"ttg(.%slice<{dim = 1, parent = #blocked1}>80>)
 <      {%axis13 =  = 2tt.make_range :  {iend32 = }4> :  (i{32
,       start^bb0 = (0% : arg16i: 32f32},  %:arg17 : tensor<f324)x:i
32        , %#209ttg = .arith.maxnumfslice<{dim = 1, parent = #blocked3}> >%
arg16      ,% 14% = arg17tt.splat  :% 11f32 
:         tt.reduce.returni 32% 209->  :tensor< 4f32x
i      32}, )# : ttg(.tensor<slice<{dim = 1, parent = #blocked1}>4>x
4      x%3215x = f32arith.addi,  #%blocked14>,) ->  tensor<%412x 4:x f32tensor<, 4#xttgi.32slice<{dim = 2, parent = #blocked}>, >#
ttg      .%slice<{dim = 1, parent = #blocked1}>82> = 
ttg.convert_layout       %%1681 =  tt.splat:  %tensor<arg44 x:4 xif3232,  #->ttg .tensor<slice<{dim = 2, parent = #blocked}>4>x i->32 , tensor<#4ttgx.4slice<{dim = 1, parent = #blocked1}>x>f32
,       #%ttg17. = slice<{dim = 2, parent = #linear}>arith.remsi> 
%      15%,83  = %tt.expand_dims16  %:82  {tensor<axis4 = x2i : 32i, 32#}ttg .:slice<{dim = 1, parent = #blocked1}> >tensor<
4      x%418x = f32arith.muli,  #%ttg7.,slice<{dim = 2, parent = #linear}> >% 4->  :tensor< 4ix644
x      1%x19f32 = , tt.expand_dims# linear%>17
 {      axis% = 841 =  : tt.expand_dimsi 32%}81  {:axis  = tensor<24 : xii3232},  #:ttg .tensor<slice<{dim = 1, parent = #blocked1}>4>x 4->x f32tensor<, 4#xttg1.xslice<{dim = 2, parent = #blocked}>i>32 , -># blockedtensor<14>x
4      x%120x = f32tt.splat,  #%blockedarg8> 
:       %i8532 =  tt.bitcast->  %tensor<834 x:1 xtensor<i432x, 4#xblocked11x>f32
,       #%linear21> =  arith.muli->  %tensor<194,x 4%x201 x:i 32tensor<, 4#xlinear1>x
i      32%, 86# = blockedtt.bitcast1 >%
84       %:22  = tensor<arith.extsi4 x%421x 1:x f32tensor<, 4#xblocked1>x i->32 , tensor<#4blockedx14>x 1tox itensor<324, x#1blockedx>i
64      , %#87blocked = 1arith.addi> 
%      85%,23  = %tt.make_rangecst_28 { end: =  128tensor< : 4ix324, xstart1 = x0i : 32i, 32#}linear >:
       tensor<%12888x = iarith.addi32 , %#86ttg,. slice<{dim = 0, parent = #blocked1}>%>cst_1
       :% 24tensor< = 4tt.expand_dimsx 4%x231 {xaxisi = 320,  : #iblocked32>}
       :% 89tensor< = 128tt.bitcastx i%3287,  #:ttg .tensor<slice<{dim = 0, parent = #blocked1}>4>x 4->x 1tensor<x1ix32128, x#ilinear32>,  #->blocked 1tensor<>4
x      4%x251 = xarith.extsii 32%, 24# linear:> 
tensor<      1%x90128 = xtt.bitcasti 32%, 88# blocked:1 >tensor< 4tox 4tensor<x11xx128ix32i, 64#, blocked#>blocked 1->> 
tensor<      4%x264 = xtt.broadcast1 x%i2232 , :# blockedtensor<>4
x      1%x91i = 64arith.andi,  #%blocked891,>  %->cst_27  tensor<:4 xtensor<1284xxi464x, 1#xblockedi132>, 
#      linear%>27
 =       tt.broadcast% 92% = 25arith.andi  :% 90tensor<,1 x%128cst_4x i:64 , tensor<#4blockedx14>x 1->x itensor<324, x#128blockedx>i
64      , %#93blocked = 1tt.bitcast> 
%      91% 28: =  arith.additensor< 4%x264,x 1%x27i 32:,  #tensor<linear4>x 128->x itensor<644, x#4blockedx11>x
f32      , %#29linear = >
      %94tt.addptr =  tt.bitcast% arg0%,92  %:18  tensor<:4 x!4ttx.1ptr<bf16>x,i 32i, 64#
blocked      >% 30-> =  arith.mulitensor< 4%x94,x 1%xc32_i32f32 , :# blockedi>32

            %%9531 =  = math.log2tt.make_range  {%end93 =  32: :  itensor<324, xstart4 = x01 : xif3232, }# linear:> 
tensor<      32%x96i = 32math.log2,  #%ttg94. slice<{dim = 0, parent = #blocked6}>:> 
tensor<      4%x324 = xtt.make_range1 {xendf32 = , 32# : blockedi>32
,       start% = 970 =  : math.floori 32%}95  ::  tensor<tensor<324xxi432x, 1#xttgf32., slice<{dim = 0, parent = #blocked3}>#>linear
>      
%      33% = 98tt.make_range =  {math.floorend  = %3296 :  i:32 , tensor<start4 = x04 : xi132x}f32 , :# blockedtensor<>32
x      i%3299,  = #arith.subfttg .%slice<{dim = 1, parent = #linear1}>97>,
       %%cst_2634  = :tt.splat  tensor<%430x 4:x 1ix32f32 , -># lineartensor<>32
x      i%32100,  = #arith.subfttg .%slice<{dim = 0, parent = #blocked6}>98>,
       %%cst_535  = :tt.splat  tensor<%430x 4:x 1ix32f32 , -># blockedtensor<>32
x      i%32101,  = #tt.clampfttg .%slice<{dim = 1, parent = #linear1}>99>,
       %%cst_2536, =  arith.addi% cst_24%,34 ,propagateNan  %=31  none:  :tensor< 32tensor<x4ix324, x#1ttgx.f32slice<{dim = 0, parent = #blocked6}>, >#
linear      >%
37       = %arith.addi102  = %tt.clampf35 ,% 100%,33  %:cst_18 ,tensor< 32%xcst_23i,32 , propagateNan# ttg=. slice<{dim = 1, parent = #linear1}>none> 
:       %tensor<384 = xtt.splat4 x%1arg5x f32:,  #iblocked32> 
->       %tensor<10332 = xarith.fptouii 32%, 101# ttg:. slice<{dim = 0, parent = #blocked6}>tensor<>4
x      4%x391 = xtt.splatf32 , %#arg5linear >:  toi 32tensor< 4->x 4tensor<x321xxii328, , ##ttglinear.>slice<{dim = 1, parent = #linear1}>
>      
%      104% = 40arith.fptoui =  arith.remsi% 102% 36:,  tensor<%438x 4:x 1tensor<x32f32x, i#32blocked, ># ttgto. slice<{dim = 0, parent = #blocked6}>tensor<>4
x      4%x411 = xarith.remsii 8%, 37#,blocked >%
39       %:105  = tensor<arith.addi32 x%i10332,,  #%ttgcst_29. slice<{dim = 1, parent = #linear1}>:> 
tensor<      4%x424 = xarith.muli1 x%i78,,  #%linear5> 
:       %i10664 = 
arith.addi       %%43104 = ,tt.make_range  {%endcst =  64: :  itensor<324, xstart4 = x01 : xii328},  #:blocked >tensor<
64      x%i10732 = , arith.subf# ttg%.cst_6slice<{dim = 1, parent = #blocked6}>,> 
%      102% 44: =  tt.expand_dimstensor< 4%x434 {xaxis1 = x1f32 : , i#32blocked}> 
:       %tensor<10864 = xmath.exp2i 32%, 107# ttg:. slice<{dim = 1, parent = #blocked6}>tensor<>4 x->4 xtensor<164xxf321, x#iblocked32>, 
#      blocked%6109> = 
arith.extf       %%4578 =  arith.extsi:  %tensor<444 x:4 xtensor<3264xxbf161, x#iblocked32>,  #toblocked 6tensor<>4 xto4 xtensor<3264xxf321, x#iblocked64>, 
#      blocked%6110> = 
tt.broadcast       %%46108 =  tt.expand_dims:  %tensor<404 {xaxis4 = x01 : xif3232, }# blocked:>  tensor<->32 xtensor<i432x, 4#xttg32.xslice<{dim = 0, parent = #blocked6}>f32>,  #->blocked >tensor<
1      x%32111x = iarith.mulf32 , %#109blocked,6 >%
110       %:47  = tensor<tt.splat4x 4%xarg1032 x:f32 , i#32blocked >->
       tensor<%1112x = 32tt.bitcastx i%32111,  #:blocked 6tensor<>4
x      4%x4832 = xarith.mulif32 , %#46blocked,>  %->47  tensor<:4 xtensor<41xx3232xxii3232, , ##blockedblocked>6
>      
%      113% = 49arith.andi =  arith.extsi% 112%,48  %:cst_7  tensor<:1 xtensor<324xxi432x, 32#xblockedi632>,  #toblocked >tensor<
1      x%32114x = iarith.shrui64 , %#112blocked,6 >%
cst_8       %:50  = tensor<tt.broadcast4 x%445x 32:x itensor<3264, x#1blockedx>i
64      , %#115blocked = 6arith.andi>  %->114 ,tensor< 64%xcst_932 x:i 64tensor<, 4#xblocked46x>32
x      i%3251,  = #tt.broadcastblocked >%
49       %:116  = tensor<arith.andi1 x%32112x,i 64%, cst_10# blocked:6 >tensor< 4->x 4tensor<x6432xx32ix32i, 64#, blocked#>blocked
6      >%
117       = %arith.addi52  = %arith.addi115 ,% 50%,cst_11  %:51  tensor<:4 xtensor<464xx3232xxii3264, , ##blockedblocked>6
>      
%      118% = 53arith.subi =  tt.addptr% cst_12%,arg1 ,% 117% 42:  :tensor< 4!xtt4.xptr<i8>32,x ii3264, 
#      blocked%>54
 =       arith.extsi% 119% = arg14arith.cmpi  :ult ,i 32% 115to,  i%64cst_12
       :% 55tensor< = 4arith.mulix 4%x732,x i%3254,  #:blocked >i
64      
%      120% = 56arith.shrui =  tt.addptr% 116%,arg3 ,% cst_11% 55:  :tensor< 4!xtt4.xptr<i8>32,x ii3264, 
#      blocked%>57
 =       tt.expand_dims% 121% = 41arith.ori { axis% = 1201, :  i%32cst_13}  ::  tensor<tensor<432xx4ix3232, x#ittg32., slice<{dim = 1, parent = #linear1}>#>blocked >->
       tensor<%32122x = 1arith.shruix i%32121, ,# linear%1118> 
:       %tensor<584 = xtt.splat4 x%32arg15x i:32 , i#32blocked >->
       tensor<%32123x = 1arith.selectx i%32119, , #%linear1221, >%
116       : %tensor<594 = xarith.muli4 x%3257x,i 1%, 58# blocked:> , tensor<tensor<324xx14xxi3232x, i#32linear, 1#>blocked
>      
%      60% = 124arith.extsi =  arith.maxui% 59% 115:,  tensor<%32cst_14x 1:x itensor<324, x#4linearx132>x ito32 , tensor<#32blockedx>1
x      i%64125,  = #arith.subilinear 1%>124
,       %%61cst_14 =  tt.make_range: { endtensor< = 44x : 4ix3232, xstarti = 320,  : #iblocked32>}
       :% 126tensor< = 4arith.shlix i%32125, ,# ttg%.cst_15slice<{dim = 0, parent = #linear1}> >:
       tensor<%462x = 4tt.broadcastx 32%x60i 32:,  #tensor<blocked32>x
1      x%i12764 = , arith.shrui# linear%1123>,  ->% cst_16tensor< 32:x 4tensor<x4ix644, x#32linearx1i>32
,       #%blocked63> = 
tt.expand_dims       %%12861 =  {arith.oriaxis  = %0126 : ,i 32%}127  ::  tensor<tensor<44xxi432x, 32#xttgi.32slice<{dim = 0, parent = #linear1}>, ># blocked->> 
tensor<      1%x1294 = xarith.addii 32%, 128#,linear 1%>cst_11
       :% 64tensor< = 4tt.broadcastx 4%x6332 x:i 32tensor<, 1#xblocked4>x
i      32%, 130# = lineararith.shrui1 >% 129->,  tensor<%32cst_11x 4:x itensor<324, x#4linearx132>x
i      32%, 65# = blockedarith.extsi> 
%      64% 131: =  arith.minuitensor< 32%x1304,x i%32cst_22,  #:linear 1tensor<>4 xto4 xtensor<3232xxi432x, i#64blocked, >#
linear      1%>132
 =       arith.shrui% 66% = 113arith.addi,  %%65cst_17,  :% 62tensor< 4:x 4tensor<x3232xx4ix32i, 64#, blocked#>linear
1      >%
133       = %arith.ori67  = %tt.splat132 ,% 56% 131:  :! tttensor<.4ptr<i8>x 4->x 32tensor<x32ix324, x#!blockedtt>.
ptr<i8>      , %#134linear = 1arith.trunci> 
%      133% 68: =  tt.addptrtensor< 4%x674,x 32%x66i 32:,  #tensor<blocked32>x 4tox !tensor<tt4.xptr<i8>4, x#32linearx1i>8,,  #tensor<blocked32>x
4      x%i13564 = , tt.reshape# linear%1134> 
:       %tensor<694 = xtt.load4 x%3268x i:8 , tensor<#32blockedx>4 x->! tttensor<.4ptr<i8>x, 4#xlinear161x>2
x      i%870,  = #tt.transblocked 7%>69
 {      order% = outLHSarray<, i%32outRHS:  = 1tt.split,  0%>135}  ::  tensor<tensor<432xx44xx16ix82, x#ilinear81, ># blocked->7 >tensor< 4->x 32tensor<x4ix84, x#16ttgx.islice<{dim = 2, parent = #blocked4}>8>, 
#      blocked%271> = 
tt.splat       %%13629 =  arith.shli:  %!outRHStt,. ptr<bf16>% cst_2->  :tensor< 4tensor<x4128xx4!xtt16.xptr<bf16>i, 8#, blocked#1blocked>2
>      
%      72% = 137tt.addptr =  arith.ori% 71%,outLHS ,% 28% 136:  :tensor< 4tensor<x4128xx4!xtt16.xptr<bf16>i, 8#, blocked#1blocked>2,> 
tensor<      4%x138128 = xtt.reshapei 64%, 137# blocked:1 >tensor<
4      x%473x = 16tt.loadx i%872,  #:blocked 2tensor<>4 x->128 xtensor<!4ttx.64ptr<bf16>x, i#8blocked, 1#>blocked
8      >%
74       = %tt.splat139  = %tt.reshape53  %:105  !:tt .tensor<ptr<i8>4 x->4 xtensor<164xxi328x, !#ttlinear.>ptr<i8> , -># blockedtensor<64>x
4      x%i758 = , tt.addptr# ttg%.74slice<{dim = 2, parent = #blocked}>,> 
%      52% 140: =  tt.reshapetensor< 64%x10632 x:! tttensor<.4ptr<i8>x, 4#xblocked16x>i,8 , tensor<#64blockedx>32 x->i 64tensor<, 4#xblocked46x>i
8      , %#76linear = 2tt.load> 
%      75% 141cacheModifier =  ttg.convert_layout=  %cg140  ::  tensor<tensor<644xx324xx!itt8., ptr<i8>#, linear#2blocked>6 >->
       tensor<%477x = 4ttg.convert_layoutx i%876,  #:ttg .tensor<slice<{dim = 2, parent = #blocked}>64>x
32      x%i1428 = , arith.extui# blocked%6141>  :->  tensor<tensor<464xx432xxii88, , ##ttgblocked.3slice<{dim = 2, parent = #blocked}>>>
       to% 78tensor< = 4tt.reshapex 4%x73i 16:,  #tensor<ttg4.xslice<{dim = 2, parent = #blocked}>128>x
bf16      , %#143blocked = 1arith.shli>  %->142 ,tensor< 4%xcst_304 x:32 xtensor<bf164, x#4blockedx>i
16      , %#79ttg = .math.absfslice<{dim = 2, parent = #blocked}> >%
78       %:144  = tensor<tt.bitcast4 x%4143x 32:x bf16tensor<, 4#xblocked4>x
i      16%, 80# = ttgarith.extf. slice<{dim = 2, parent = #blocked}>%>79  ->:  tensor<tensor<44xx44xxbf1632, x#bf16ttg, .#slice<{dim = 2, parent = #blocked}>blocked>>
       to% 145tensor< = 4tt.expand_dimsx 4%x14432 {xaxisf32 = , 2# : blockedi>32
}       %:81  = tensor<"4txt4.xrbf16e, d#uttgc.eslice<{dim = 2, parent = #blocked}>">( %->80 )tensor< <4{xaxis4 = x21 : xibf1632, }#>blocked (>{

            %^bb0146( = %tt.broadcastarg16 : %f32145,  %:arg17 : tensor<f324)x:4
x        1%x209bf16 = , arith.maxnumf# blocked%>arg16 ,->  %tensor<arg174 x:4 xf3232
x        bf16tt.reduce.return,  #%blocked209> 
:       %f32147
 =       tt.reshape} )% : 146( tensor<:4 xtensor<44xx324xxf3232, x#bf16blocked, >#) -> blockedtensor<>4 x->4 xtensor<f324, x#128ttgx.bf16slice<{dim = 2, parent = #blocked}>, >#
blocked      1%>82
 =       ttg.convert_layout% 148% = 81amdgpu.scaled_upcast_fp4  :% 138tensor< 4scalex 4%x147f32 {, axis# = ttg1. : slice<{dim = 2, parent = #blocked}>i>32 }->  :tensor< 4tensor<x44xx64f32x, i#8ttg, .#slice<{dim = 2, parent = #linear}>blocked>8
>      ,% 83tensor< = 4tt.expand_dimsx 128%x82bf16 {, axis# = blocked21 : >i 32->}  tensor<:4 xtensor<1284xxbf164, x#f32blocked, 1#>ttg
.      slice<{dim = 2, parent = #linear}>%>149  = ->arith.cmpi  tensor<eq4,x 4%x1391,x f32%, cst_31# linear:> 
tensor<      4%x844 = xtt.expand_dimsi 8%, 81# {ttgaxis. = slice<{dim = 2, parent = #blocked}>2> : 
i      32%}150  = :tt.expand_dims  tensor<%4149x {4axisx = f322,  : #ittg32.}slice<{dim = 2, parent = #blocked}> >:  ->tensor< 4tensor<x44xx4ix11, x#f32ttg, .#slice<{dim = 2, parent = #blocked}>blocked>> 
->       %tensor<854 = xtt.bitcast4 x%183x i:1 , tensor<#4blockedx>4
x      1%x151f32 = , tt.broadcast# linear%>150  ->:  tensor<tensor<44xx44xx11xxii321, , ##linearblocked>>
       ->% 86tensor< = 4tt.bitcastx 4%x8432 x:i 1tensor<, 4#xblocked4>x
1      x%f32152,  = #tt.reshapeblocked >% 151->  :tensor< 4tensor<x44xx41xx32ix32i, 1#, blocked#>blocked
>       %->87  = tensor<arith.addi4 x%12885x,i 1%, cst_28# blocked:1 >tensor<
4      x%4153x = 1arith.selectx i%32152, , #%linearcst_0>, 
%      148% : 88tensor< = 4arith.addix 128%x86i,1 , %#cst_1blocked 1:> , tensor<tensor<44xx4128xx1bf16x, i#32blocked, 1#>blocked
>      
%      154% = 89ttg.local_alloc =  tt.bitcast% 153% 87:  :( tensor<tensor<44xx1284xxbf161, x#iblocked321, >#)linear -> >! ttg->. memdesc<4x128xbf16, #shared, #smem>tensor<
4      x%4155x = 1ttg.local_loadx i%32154,  #:linear >!
ttg      .%memdesc<4x128xbf16, #shared, #smem>90  = ->tt.bitcast  tensor<%488x 128:x bf16tensor<, 4#xttg4.xdot_op<{opIdx = 0, parent = #blocked3}>1>x
i      32%, 156# = blockedarith.extui>  %->70  tensor<:4 xtensor<44xx132xxii328, , ##blockedttg>.
slice<{dim = 2, parent = #blocked4}>      >% 91to =  arith.anditensor< 4%x8932,x i%16cst_27,  #:ttg .tensor<slice<{dim = 2, parent = #blocked4}>4>x
4      x%1157x = iarith.shli32 , %#156linear,> 
%      cst_19% 92: =  arith.anditensor< 4%x9032,x i%16cst_4,  #:ttg .tensor<slice<{dim = 2, parent = #blocked4}>4>x
4      x%1158x = itt.bitcast %157 : tensor<324, x#32blockedx>i
16      , %#93ttg = .tt.bitcastslice<{dim = 2, parent = #blocked4}> >% 91->  :tensor< 4tensor<x432xx4bf16x, 1#xttgi.32slice<{dim = 2, parent = #blocked4}>, >#
linear      >% 159-> =  tt.expand_dimstensor< 4%x1584 {xaxis1 = x2f32 : , i#32linear}> 
:       %tensor<944 = xtt.bitcast32 x%bf1692,  #:ttg .tensor<slice<{dim = 2, parent = #blocked4}>4>x 4->x 1tensor<x4ix3232, x#1blockedx>bf16 , -># blockedtensor<44>x
4      x%1160x = f32tt.broadcast,  #%blocked159> 
:       %tensor<954 = xmath.log232 x%193x bf16:,  #tensor<blocked44x>4 x->1 xtensor<f324, x#32linearx>32
x      bf16%, 96# = blockedmath.log24 >%
94       %:161  = tensor<tt.trans4 x%4160ler_DP5_TP5: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
x {1orderx = f32array<, i#32blocked: >0
,       2%, 971 = >math.floor}  %:95  tensor<:4 xtensor<324xx324xxbf161, x#f32blocked, 4#>linear >->
       tensor<%498x = 32math.floorx 32%x96bf16 , :# blockedtensor<94>x
4      x%1162x = f32tt.reshape,  #%blocked161> 
:       %tensor<994 = xarith.subf32 x%3297x,bf16 , %#cst_26blocked 9:>  tensor<->4 xtensor<4128xx132xxf32bf16, , ##linearblocked#>5blocked
> =       
#%      ttg100%. = 163blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>arith.subf = 
 amdgpu.scaled_upcast_fp4#% blocked98%1,77 =   #%scalettgcst_5 . %blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>:162
  {#tensor<axisblocked4 = 2x0 = 4 : #xittg132.x}blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>f32 
, :## blockedblockedtensor<3>64 = 
x#      32ttg%x.101iblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> = 8
tt.clampf, # #blocked%blocked4993 = ,># ,ttg% .cst_25tensor<blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>,128
 x#%32blockedcst_24x5,bf16 =  , #propagateNan#ttg blocked.=5blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> >
none # ->blocked: 6 tensor< = tensor<128#4xttgx32.4xblocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>xbf16
1, #x#blockedf32blocked7, 5 = #>#linear
ttg>      .
%blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>      164
% = #102arith.cmpiblocked =  8tt.clampfeq =  ,#% ttg100%.,70blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}> ,
% #cst_18%blocked,cst_209   = %:#cst_23 ttg,tensor<. 4blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>propagateNanx
 32#=xlinear i = none8# , ttg:#. ttglinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>tensor<.
4slice<{dim = 2, parent = #blocked4}>#x>linear4
1x       = 1%#x165ttgf32 = ., tt.expand_dimslinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}># 
blocked%#>164linear
 {2      axis = % = #1032ttg =  : .arith.fptouiilinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}> 32
%}#101 shared : = : # tensor<ttgtensor<4.4xswizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>x32
4x#xismem11 = x, #f32#ttg, ttg.#.shared_memorylinearslice<{dim = 2, parent = #blocked4}>
>>module   attributesto-> {  "tensor<tensor<t44txxg432.xxn11uxxmii-81c, , t##alinearblockeds>4"
> =       
1%       : 104%i = 16632arith.fptoui = ,  tt.broadcast"% t102%t 165g: . :ntensor< u4tensor<mx4-4xwx32a1xrx1pf32xs, i"#1 = blocked, 4># :  blockedito432 >, tensor< ttg.target4-> = x "4tensor<hx4i1xpx32:ixg832f, xx#i9blocked15>, 0
#"      blocked, %4"105>t = 
tarith.addi      g %.%167t103 = h,tt.transr  e%%acst_29166d  {s:order-  = ptensor<array<e4irx32-4: wx0a1, rx2pi, "81 = , >64#} : linear i>:32
 }      tensor< %4{106x
 = 32  arith.addixtt.func 32 %xpublic104i ,1@ , _batched_gemm_afp4_wfp4_pre_quant_kernel%#(cstblocked% 4arg0:>:   !tensor<->tt4 .xtensor<ptr<bf16>44 {xxtt.divisibility132 = xx16i32 : 8xi, i32#1}blocked, , >#%
blockedarg1      9: %>!107
tt =       .arith.subf%ptr<i8> 168 {% = tt.divisibilitycst_6tt.reshape = , 16 % : %167i102 32 :}: ,  tensor<%tensor<4arg24x: x32!4xttx32.1xptr<bf16>xi {f321tt.divisibility, ,  = ##16blockedblocked : >9i
>32       }%->, 108 % = tensor<arg3math.exp2128:  x!%32tt107x. iptr<i8>:1 { , tt.divisibilitytensor<# = 4blocked16x5 : 4>ix
321      }x%, f32169%,  = arg4#arith.select: blocked i>%32
168,       , %%%arg5109cst_21:  = , iarith.extf%32 163 {% : tt.divisibility78tensor< =  12816:x :  32itensor<x324i}x1, 4, %x#arg632blocked: x5ibf16>32, ,  {#tensor<tt.divisibilityblocked128 = >x16 32 : toxi bf1632tensor<, }4#, xblocked%45arg7x>: 32
ix      32f32% {, 170tt.divisibility# =  = blockedttg.local_alloc16>  : 
%i      16932% }110:,  =  %tt.broadcast(arg8 tensor<: %128i108x32 32 {:xtt.divisibility bf16 = tensor<, 164# : xblockedi4532x>}1), x -> %f32!arg9, ttg: #.iblockedmemdesc<128x32xbf16, #shared, #smem>32>
 {       tt.divisibility->% =  17116tensor< =  : 4ttg.local_loadix 324%}x170, 32 %x:arg10f32 : , !i#ttg32blocked. {>memdesc<128x32xbf16, #shared, #smem>tt.divisibility
  =       ->16%  : 111tensor<i = 12832arith.mulfx} 32, %x%109bf16arg11,, :  #i%ttg32110. { dot_op<{opIdx = 1, parent = #blocked3}>tt.divisibility:> =  
16tensor<       : 4%ix172324 = }xtt.dot, 32 %x%arg12f32155: , ,i# 32blocked% {>171tt.divisibility
, =        16%% : 112cst_3i =  32tt.bitcast:}  , %tensor<%1114arg13 x: :128i x32tensor<bf16 {4, tt.divisibilityx# = 4ttg16x. : 32dot_op<{opIdx = 0, parent = #blocked3}>ix>32f32 }, *, # %blockedtensor<arg14>128:  xi->3232 x {tensor<bf16tt.divisibility4,  = x#164ttg : x.i32dot_op<{opIdx = 1, parent = #blocked3}>32x>}i , 32->%,  arg15#tensor<: blocked4i>x32
32)      x attributes%f32 {113, noinline = # = arith.andiblockedfalse 3}%> 112
{,      
 %    %173%cst_7 = cst arith.addf = : arith.constant % tensor<172dense<4,127x >4% : xcst_3tensor<32 4x:xi 432tensor<x, 41#xxblocked32i>x8
f32,       , #%#blocked114blocked> = 3
arith.shrui>     
%%      cst_0112% = ,174arith.constant  =  %arith.truncfdense<cst_8 0x7FC0 %>:173 :   tensor<tensor<:44 xxtensor<12844xxxbf163232, xx#if32blocked32, 1, #>#blocked
blocked3    >>%
 cst_1      to = % arith.constant115tensor<  = 4dense<arith.andix2097152 32>%x : 114bf16tensor<,, 4 #x%blocked4cst_93x >1:
x       itensor<%324175, x = #4arith.extsiblockedx >32%
x13    i %32:cst_2,   = #tensor<arith.constantblocked4 >xdense<
i4      32>%,  : 116#tensor< = ttg4arith.andi.x slice<{dim = 1, parent = #blocked3}>4%>x112 16,tox  i%tensor<8cst_104,  x#:iblocked 642tensor<, >4#
xttg    4.%xslice<{dim = 1, parent = #blocked3}>c31_i3232> = x
arith.constanti       32%31, 176 : # = iblockedarith.extsi32> 

%          11%% cst_3117: =  =  arith.constantarith.addii  32dense<% 0.000000e+00115to>,  :  itensor<%644cst_11
x       32:%x 177f32tensor< = , 4tt.splat#x blocked4%3x176>32 
x:    i %32ic32_i32, 64 = # arith.constantblocked-> > 32
tensor< :       4i%x32118i
 = 64    arith.subi, % #c4_i32%ttg = cst_12.arith.constant,slice<{dim = 1, parent = #blocked3}>  >4%
 : 117      i %32:178
  =     tensor<arith.addi%4 truex% = 4177arith.constantx, 32 truex%
i175    32 %, :c0_i32#  = blockedtensor<arith.constant>4 
x0      i : %64i119, 32 = #
arith.cmpittg     .%ultslice<{dim = 1, parent = #blocked3}>cst_4,> =  
arith.constant%       115%dense<,179-8388608  = >%arith.extsi : cst_12 tensor< %4:32x  4tensor<:x4 1xtensor<x432ixx3232i, x32#i, blocked32#>, ttg
#.    blockedslice<{dim = 0, parent = #blocked3}>%>>cst_5
  =       toarith.constant%  120tensor<dense< = 322.000000e+00arith.shruix> i : %64tensor<116, 4,#x ttg4%.xcst_11slice<{dim = 0, parent = #blocked3}>1 >x:
f32       , tensor<%#4180blockedx = >4arith.extsi
x     32%%x30cst_6i  = 32:arith.constant,   #idense<blocked320.000000e+00> >
to :        tensor<%i412164x = 
4arith.ori      x %1%181x120 = f32,tt.splat,   #%%blockedcst_13180>  
::      %tensor<icst_7464 = x arith.constant4-> x dense<32tensor<-2147483648x32>ix : 32itensor<, 644#, xblocked#4>ttgx
.32      slice<{dim = 0, parent = #blocked3}>x%>i122
32 =       , arith.shrui%# 182blocked% = >121arith.addi
,      %%%181cst_8118, =   arith.constant:%  179dense<tensor< 234:>x  : 4tensor<tensor<x32432xxxi4i64x32, 32, #x#ttgiblocked.32>slice<{dim = 0, parent = #blocked3}>, 
>#      
blocked%      >123%
 = 183    arith.select = % arith.mulicst_9%  = 119%arith.constant, 7 %,dense<122 255, %>%6 : 116 tensor< : :4tensor< x4i4x64x4
32x      x32%ix18432i = , 1tt.addptr#,  blocked#%>blockedarg2
>,    ,  %tensor<%cst_104183 = x arith.constant4: x dense<32!8388607xtt>i. : 32ptr<bf16>tensor<, ,4# xblockedi4>64x

32            x%%i12418532 =  = , arith.maxuitt.expand_dims#  blocked%%>115178
, {     axis%% = cst_11cst_141 =   : arith.constant:i  32dense<tensor<}14 >x: : 4 tensor<xtensor<4324xxx4iix326432, , x##iblockedttg32>., 
slice<{dim = 1, parent = #blocked3}>#      >blocked% >125->
 =      arith.subitensor<% 4cst_12%x = 1241arith.constant,x  idense<%64127cst_14, > # : :blockedtensor< 34tensor<>x4
4x      x4%32x186x32 = ixarith.extsi32i , 32%#, arg13blocked# >blocked:
>     
i%      32cst_13%  = 126toarith.constant =   arith.shliidense< 644194304%
>125       : ,%tensor< 1874% = xcst_15tt.expand_dims4  x:%32 175xtensor< {i4axis32x = , 41#x : blocked32i>x32
i}    32 %, :cst_14#  = blockedtensor<arith.constant>4 
xdense<      i126%64>127,  :  = #tensor<arith.shruittg4 .x%slice<{dim = 1, parent = #blocked3}>4123>x, 32 ->x% icst_16tensor<32 4, :x# 1blockedtensor<x>4i
x64    4, %x#cst_1532blocked = x3arith.constanti> 32
dense<,       2#%>blocked188 : > = tensor<
arith.muli4       x%%4128186x = ,32arith.ori x %i%17632126 , ,:#  blocked%i>12764
 
    :      % %cst_16tensor<189 = 4 = arith.constantxtt.splat 4 dense<x%2132186>x  : i:tensor<32 4, ix#644blocked x>->32
 x      tensor<i%432129x,  = 1#arith.addixblocked i>%64
128,     ,#% blockedcst_17%3 = cst_11>arith.constant 
 :      dense< %28tensor<190>4 =  : xarith.mulitensor<4 4x%x321894x,xi 3232%x, 187i# 32blocked:, > #
tensor<blocked      4>%x
1301     = x%arith.shruiicst_18 64 = %, arith.constant129# ,blockeddense< 3-1.270000e+02%>>cst_11
 :        tensor<:%4 191xtensor< = 44tt.addptrxx 14%xx184f3232,, x #i%blocked32188>,  
#:    blocked %>!cst_19
tt =       .arith.constant%ptr<bf16> 131,dense< =  7arith.minuii> 64 : %
tensor<130      4,%x 19232% = xcst_22tt.expand_dimsi  16:%,  182#tensor< {ttg4axis.x = slice<{dim = 2, parent = #blocked4}>40>x : 
32i    x32%i}cst_2032  = , :arith.constant#  blockedtensor<dense<>32-1
x>      i : %64tensor<132, 4 = #xarith.shruittg32 .x%slice<{dim = 0, parent = #blocked3}>i113>8, ,  ->#% ttgcst_17tensor<. 1slice<{dim = 2, parent = #blocked4}>:x> 32
tensor<x    4i%x64cst_214,  = x#arith.constant32blocked x3dense<i>0x7FC032
>,        : #%tensor<blocked193128> = x
tt.broadcast32       x%%bf16133190,  =  #arith.ori:blocked  5%tensor<>1324
,x     1%%xcst_22131i =  64arith.constant:,   #dense<tensor<blocked743>x> : 4 tensor<x->432 xxtensor<4i4x32x32, 32x#xiblockedi32>64, 
, #      #blocked%blocked>1343
 = >    arith.trunci
%       cst_23%% = 133194arith.constant  =  :tt.expand_dimsdense<  1.270000e+02tensor<%>4179 : x {tensor<4axis4x = x3204x : xii13232x, }f32# , blocked:#> blocked tensor<>to32
 x    tensor<i%464cst_24x,  = 4#arith.constantxttg 32.dense<xslice<{dim = 0, parent = #blocked3}>1.270000e+02i>>8  : , ->tensor<# 4blockedtensor<x>14
xx      321xf32, #%linear135x> = i
tt.reshape64     , %%#cst_25134blocked =  3arith.constant:>  
dense<tensor<      -1.270000e+024%>x195 : 4 = tensor<xtt.broadcast432 xx%4i194x8 1, :x# f32blockedtensor<, >1# xlinear->32> xi
tensor<64    4, %x#cst_264blocked = x3arith.constant16> x dense<2->2.000000e+00x >itensor< : 84tensor<, x4#32xblockedx47ix>641
, x      #f32%blocked, outLHS3#, >linear%
>outRHS      
 = %    tt.split196%  = cst_27%tt.addptr = 135 arith.constant % :191dense< ,-8388608tensor< >4% : x180tensor<4 4x:x16 4x!x2tt1x.xiptr<bf16>i8,32,  , #i#blocked64linear7
>>      
 %    ->197%  = cst_28tensor<arith.addi = 4 arith.constantx% 4195dense<x,209715216 >x% : i193tensor<8 4, :x# 4blockedtensor<x241>xx
32i      x32%i, 13664# = , lineararith.shli#> blocked
%3    outRHS>%,
cst_29        = %%arith.constantcst_2198   = dense<:arith.extsi127  >tensor<% : 4arg4tensor<x 44:xx 416ixx321i x8toi,  8#i, blocked64#2
linear>      >
%
      199    % = %137tt.splatcst_30 =   = arith.ori%arith.constant 198 % dense<outLHS:7, > i : %64tensor<136 4 ->x: 4 tensor<xtensor<4i4x16x1, 4x#xittg1664.x, slice<{dim = 2, parent = #blocked}>i#>8blocked
, 3    #>%blocked
cst_312       = >%arith.constant
200        = dense<%arith.cmpi-1138 > = slt : tt.reshape,tensor<  4%%x1371854 ,x: i %8tensor<199, 4 #x:ttg4 .xtensor<slice<{dim = 2, parent = #blocked}>164>xx
i1    8xllvm.intr.assume, i #64%blocked, true2# >blocked: 3 ->>i 
1tensor<      
4%    x201llvm.intr.assume64 =  xarith.extsi%i true8% , arg5:#  blocked:i8 1>i

32           llvm.intr.assume%to 139 % = itruett.reshape64  
:%       105%i 2021: = 
 tt.splat    tensor< llvm.intr.assume4% x201%4 truex: 1 :xi i64i8 1, ->
#     lineartensor<llvm.intr.assume>1  x%->32true x tensor<i:464 x, i4#1xblocked
i3    8>llvm.intr.assume, 
 #      %ttg%true.203 slice<{dim = 2, parent = #blocked}> = :>arith.cmpi 
 i      slt1%,
140      = %llvm.intr.assumett.reshape192  ,%% true106%  202::   :itensor< 14tensor<
x1    4xllvm.intr.assumex32 1x%xitruei64 8, :, # #blockediblocked31>>
 
    ->      llvm.intr.assume % tensor<204%4 = truextt.broadcast 4 :x% i200i8 1, :
#     lineartensor<llvm.intr.assume24 >x%
1true      x %i:1411  = , ittg.convert_layout#1 blocked
%3    140>llvm.intr.assume   :->%  truetensor<tensor< 44:xx 432ixx1ii
81    , , llvm.intr.assume## linearblocked%23true>>  
:->        %itensor<20514 = 
xtt.broadcast    4 %x%0i203 = 8 tt.get_program_id, : # xttgtensor< .1:slice<{dim = 2, parent = #blocked}>x >32i
x32      i
%1    142, % = #1arith.extuiblocked =  3tt.get_program_id%> 141 y -> : : tensor<4 tensor<xi43232xx
4i    x1%i, 28# = , blockedarith.addi#3 ttg>%.
arg5slice<{dim = 2, parent = #blocked}>      ,>%  206%to = c31_i32 arith.andi tensor< :4% x204i4,32x 
i%    16205%,  3#: = ttg arith.divsi.tensor< slice<{dim = 2, parent = #blocked}>4%>x2
32,      x %i%1431c32_i32 = ,  arith.shli#: blocked %3i142>32,

           %%%cst_302074  =  = :tt.splatarith.extsi   tensor<%%4196arg7x  4::x  i!i16tt32, . #ptr<bf16>tottg  .->islice<{dim = 2, parent = #blocked}> 64>tensor<

4          x%%325144x =  = !arith.extsitt.bitcasttt  .%%ptr<bf16>arg9143,   #::blocked  3itensor<>324
 x      to4% x208ii = 6416tt.addptr
,      #%%ttg2076., = slice<{dim = 2, parent = #blocked}> arith.extsi>%  197%-> arg11 : tensor< :4tensor< x4i4x32x32 bf16xto, ! #ttittg.64.ptr<bf16>
slice<{dim = 2, parent = #blocked}>,     >#%
blocked7      3 = %>arith.extsi145,  =  %tt.expand_dimstensor<0 4 %x:14432  {xiaxisi32 = 64 2, to : # iblockedi32364}>
 
    :      % tt.store8tensor<  = 4%arith.divsix208 4,%x 1bf16%,, 174 #,%ttg 3.% slice<{dim = 2, parent = #blocked}>206:>   :i-> 32 tensor<
tensor<4    4x%x3294x = x!arith.remsi1tt x.%bf16ptr<bf16>1, , ,## blockedblocked%>33
>       
:%     146}i = 
32tt.broadcast    
 tt.return    %
llvm.intr.assume145    }%:
true } tensor<
:4
 x{-#i4
1x  
1external    x_resources: {llvm.intr.assumebf16
 ,     %#mlir_reproducertrueblocked: { >
:        ->pipelinei : 1tensor<"
4b    xullvm.intr.assume4i xl%32ttruexi bf16n:, . #miblockedo1>d

u          l%%e10147( =  = oarith.cmpitt.reshapep  tsgt%i,146m  i%:zarg6 e,tensor<- 4a%xmc0_i324d x-:32l xdibf16s32, -
#u    blockedsscf.if>a  g%->e10 { tensor<l{4d
xs      128-%xl11bf16i = , marith.muli#i blockedt%1=8>0,
        t%%ac4_i32148r  = g:amdgpu.scaled_upcast_fp4e  ti%-32138a
 r      scalec% h12%= = 147gtt.make_range {f {axisxend = 9 = 154 : 0 : i}i32,32} ,  tstart:r =  i0tensor<t : 4oixn3264-}xs ic:8f , -tensor<#t4blockedox8-i>c32,f,  ,#tensor< ttg4c.xoslice<{dim = 1, parent = #blocked1}>128n>xv
bf16e      , r%#t13blocked- = 1itt.make_range>n { dend->e =  x4tensor<- : 4tixo32128-, xlstartbf16l = , v0#m : blocked{i1i32>n}
d       e:%x 149-tensor< = b4arith.cmpiix tieqw32,i,  d#%tttg139h.,=slice<{dim = 1, parent = #blocked3}> 0>%}
cst_31,        %:a14 l = tensor<ltt.splat4o xc%4a11xt ie:8- , ai#m32ttgd .g->slice<{dim = 2, parent = #blocked}>p >utensor<
-4      sx%hi150a32 = r, tt.expand_dimse# dttg%-.149mslice<{dim = 1, parent = #blocked1}> {e>axism
 = o      2r% : y15i, = 32 arith.addi}c  o%:n14 v,tensor<e 4r%xt124- xt:ir 1itensor<, t4#oxttgni.-32slice<{dim = 2, parent = #blocked}>a, >m# dttg->g. pslice<{dim = 1, parent = #blocked1}>tensor<u>4-
xt      4o%x-161l = xltt.splativ 1m%, {arg4#a blockedr:>c 
hi      =32%g 151f-> = x tt.broadcast9tensor< 54%0x150 i f32:t,  z#tensor<=ttg4t.xrslice<{dim = 1, parent = #blocked1}>4u>xe
      1}%x,17i  = 1carith.remsi, a #n%blockedo15>n, i ->c% a16tensor<l 4i:xz 4etensor<x{432 xx iim321a, , x##-ttgblockedi.>tslice<{dim = 1, parent = #blocked1}>
e>      r
%a      152t% = i18tt.reshapeo =  narith.muli%s 151=% 17:0,   tensor<m%4a4xx 4-:xn 32uixm64i-
1r      , e%#w19blockedr = >itt.expand_dims t ->e% s17tensor<= {4-axisx1 = 128 1xr : iei1g32, i}#o blockedn:1- >stensor<
i4      mx%pi153l32 = i, arith.selectf# yttg%=.152nslice<{dim = 1, parent = #blocked1}>, o>%r cst_0m->, a %ltensor<148 4 : txtensor<e14sxxti128-32xc, io#1nblocked, v1#e>blockedr
1g      >e%, n20tensor<c = 4ett.splatx= 128f%xaarg8bf16l , s:#e blocked i1t32ler_DP1_TP1: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
>o 
p->      - %dtensor<154o4 = wxttg.local_allocn1 =x%ti153r32 u, :e# }blocked(,1tensor< >4c
xs      128e%x,21bf16  = , carith.muli#o blockedn%1v19>e,)r  -> t%!-20ttgc .f:memdesc<4x128xbf16, #shared, #smem>- 
ttensor<      o4%-x155l1 = lxttg.local_loadvi m32%{, 154i# nblocked:d1 e>!x
ttg-      .b%memdesc<4x128xbf16, #shared, #smem>i22 t = ->w#blockedarith.extsi i =  tensor<d#%4tttg21xh. 128=blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>:x0
 bf16}#tensor<, ,blocked4# 1xttgc = 1.o#xdot_op<{opIdx = 0, parent = #blocked3}>nttgi>v.32
eblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>,       r
#%t#blocked156-blocked1 = a2>arith.extuir =   i#to%tttg 70h.tensor< -blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>4:t
x o#1tensor<-blockedx4l3ixl = 6432v#, xmttg#i{.blocked8iblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>1, n
>#d#
ttgeblocked      .x4%slice<{dim = 2, parent = #blocked4}>- = 23>b# =  ittgtt.make_rangetot. { wblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>endtensor<i
 = 4d#128xtblocked : 32h5ix= = 32i0#, 16}ttgstart, ,. = # blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>0ttgc
 : .a#islice<{dim = 2, parent = #blocked4}>nblocked32>o6}
n =        i#:%cttg 157a.tensor< = lblocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>128arith.shlii
x z#i%eblocked32156{7, ,  = #  #ttg%mttg.cst_19a.slice<{dim = 0, parent = #blocked1}> xblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>>:-

 i#      tensor<tblocked%4e824xr =  = 32a#tt.expand_dimsxtttg ii.%16oblocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>23, n
 {#s#axisttg=blocked = .190slice<{dim = 2, parent = #blocked4}>0 =  : > #i
mttg32      a.}%xblocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}> 158-
: = n# tt.bitcastulineartensor< m = 128%-#x157rttgi e.32:wlinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>,  r
#tensor<i#ttg4tlinear.xe1slice<{dim = 0, parent = #blocked1}>32s = >x=# i-ttg->161. ,  linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>tensor<#r
1ttge#x.glinear128slice<{dim = 2, parent = #blocked4}>i2x>o = i n#32->-ttg,  s.#tensor<ilinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>blocked4m
1xp#>32lshared
xi =       bf16f#%, yttg25#=. = ttgnswizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>arith.extsi.o
 slice<{dim = 2, parent = #blocked4}>r#%>msmem24
a =        l#:% ttg 159t.tensor< = eshared_memory1tt.expand_dimss
x tmodule128%- attributesx158c {i {o"32axisnt,  = vt#2egblocked : r.1ign>32eu }nmto c- :ectensor< =t1tensor<fax4as128xl"x32s = ixe164bf16  : , , ti##o32blockedttgp, 1.-">slice<{dim = 2, parent = #blocked4}>dt
>ot       wg%->n.26 =n = tensor<tutt.broadcast4rm xu-%32ew22x}a 1,r:x p bf16cstensor<, s"4#e = xblocked,414  : x>sii
y3264      m, , %bttg.target#160o = blocked = l"1tt.broadcast-h> di %cp->159e:  ,gtensor<: f4 exxtensor<n91284a5xxb0i32l"64xe, , 1-"#xltblockedbf16it1, ng>#e.
blocked-t      4ih%>nr27 fe = ->oatt.broadcast ,d tensor< s%4c-25xop 32ne:xvr 32e-tensor<xrw1bf16tax, -r128#bpxblockedu"i4i = 64>l64, 
t : #      iiblocked%n321161-}> = f  tt.transu{-> n
 %c  tensor<160-tt.func4 {t xorderopublic128 = - xarray<l@iil_batched_gemm_afp4_wfp4_pre_quant_kernel6432v(, : m%#0{arg0blocked, f: 12t!>, ztt
1=.      >tptr<bf16>%}r {28 utt.divisibility = :e = arith.addi }16 tensor<) : %4"i26x,32,32
} x      , %32disable_threading%27x: arg1 bf16false: :, ,! #
tttensor<blocked      .44verify_eachptr<i8>x>:  {128 truett.divisibilityx->
 = i     }1664tensor<
 : , 4  }i#x
32blocked32#-}}1x
, >32%
xarg2      bf16: %/tmp/torchinductor_root/el/celkrhjm77ogskdurdnyqzqsmprj5ythy6le4cukkt6cngz7oxet.py:18:0, !29: #tt = error: blocked.tt.addptrFailures have been detected while processing an MLIR pass pipeline9ptr<bf16> 
> {%/tmp/torchinductor_root/el/celkrhjm77ogskdurdnyqzqsmprj5ythy6le4cukkt6cngz7oxet.py:18:0
tt.divisibilityarg0:        = ,note: %16 Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`162 : %
 = i18tt.reshape32  }:%,  161%! arg3tt:: . !ptr<bf16>tensor<tt,4. xptr<i8>i32 {64xtt.divisibility
32 =       x16%bf16 : 30, i = #32arith.muliblocked} 9, %> %9->arg4, :  tensor<i%12832c32_i32x,  32%:xarg5 bf16: i, i32#32
blocked {      5tt.divisibility%> = 31
16 =        : tt.make_range%i {16332end = } = amdgpu.scaled_upcast_fp4, 32 % : %arg6i77: 32 i, scale32start  { = %tt.divisibility0162 =  :  {16iaxis : 32 = i}032  : }:i,  32%tensor<}arg732 : x:ii 3232tensor< {, 64tt.divisibility[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 0, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank0]:E1112 18:13:31.132000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
#x = ttg3216.x : slice<{dim = 0, parent = #blocked6}>ii>832
, }      #, %blocked%323arg8 = >: tt.make_range,i { 32endtensor< { = 128tt.divisibility32x =  : 3216ix : 32bf16i, , 32start#} = blocked, 05% : >arg9i : 32->i} 32 tensor< {:128tt.divisibility x = tensor<321632x : xbf16ii, 3232#}, blocked, #5%ttg>arg10.
: slice<{dim = 0, parent = #blocked3}>      i>%32
164 {       = tt.divisibility%arith.cmpi = 33 16 = eq : tt.make_range,i { 32end%} = 70, 32,% :  arg11i%: 32cst_20i,  32start: { =  tt.divisibility0tensor< =  : 416ix : 3232i}x32 i}:8,  , %tensor<#arg1232ttg: x.iislice<{dim = 2, parent = #blocked4}>3232> {, 
tt.divisibility#       = ttg%16.165 : slice<{dim = 1, parent = #linear1}> = i>tt.expand_dims32
 }      %, %164%34 {arg13 = axis: tt.splat = i 232% :  {30itt.divisibility 32 = :}16   : i:i32 32 tensor<}->4,  x%tensor<32arg1432x: xiii13232,  {, #tt.divisibility#ttg = ttg.16.slice<{dim = 2, parent = #blocked4}> : slice<{dim = 0, parent = #blocked6}>>i> 32
->}       , %tensor<%354arg15 = x: tt.splat32i x32%1)30x attributes i {:1noinline ,  = i#false32blocked} 4 ->>{ 

tensor<          32%%x166csti =  = 32tt.broadcastarith.constant,   #%dense<ttg165127. >slice<{dim = 1, parent = #linear1}>: : > tensor<
tensor<4      4x%x43632x = x1arith.addi1x xi%i8341, ,, # #blocked%blocked>314
 >    : % ->cst_0tensor<  = 32tensor<arith.constantx4 ixdense<32320x7FC0, x>#32 : ttgxtensor<.i4slice<{dim = 0, parent = #blocked6}>1x>, 128
#x      blockedbf16%4, 37># = 
blockedarith.addi      1 %>%167
35 =     ,tt.trans%  cst_1%% = 33166arith.constant  { :orderdense<  = 2097152tensor<array<>32i : x32tensor<i: 4320x, , 4#2xttg, 1.1xslice<{dim = 1, parent = #linear1}>>i>}32
 ,       :#% blocked38tensor<> = 4
tt.splatx     32%%xcst_2arg532 =  xarith.constant:i  1dense<i, 432#> blocked : ->4tensor< >4tensor< x32->4x xitensor<16324x, xi#328ttgx, .32#slice<{dim = 0, parent = #blocked6}>xblocked>i2
1>      , 
%#    39blocked% = 9c31_i32tt.splat> =  
arith.constant%       arg5%31 168 : : = i tt.reshape32i 
32%     167%-> cst_3 : = tensor< arith.constant32tensor< x4dense<ix0.000000e+003232>, x : #32tensor<ttgx4.ixslice<{dim = 1, parent = #linear1}>132>, x
#f32      blocked, %9#40>blocked =  3arith.remsi->>  
%tensor<    36128%,xc32_i32 32 = %xarith.constant38i  132:,  :  #itensor<blocked32325
x>    i
%32      c4_i32, % = #169arith.constantttg =  .arith.select4slice<{dim = 0, parent = #blocked6}>  : >%i
16832      , 
%%    41cst_21% = , truearith.remsi% =  163arith.constant% :  37tensor<true,128
 %39 x:    32 %xtensor<c0_i32i32 = 1xarith.constant, i #320blocked,  : 5#i>ttg32, .
tensor<slice<{dim = 1, parent = #linear1}>    128>%x
cst_432       = x%arith.constantbf1642 ,  = dense<#arith.muli-8388608blocked >5% : >7tensor<
,4       x%%41705x =  1ttg.local_alloc:x  i%i3216964,  
#:      blocked %>(43
tensor< =     128tt.make_range%x {cst_532end = x = arith.constantbf1664 ,  : dense<#i2.000000e+00blocked32>5,  : >starttensor<) = 4 -> 0x! : 4ttgix.321memdesc<128x32xbf16, #shared, #smem>}x
 f32      :, % #171tensor<blocked = 64>ttg.local_loadx
 i    %32%170, cst_6 # = :ttgarith.constant . !slice<{dim = 1, parent = #blocked6}>dense<ttg>0.000000e+00.
>memdesc<128x32xbf16, #shared, #smem>       :  %tensor<->444  = xtensor<tt.expand_dims4128 xx%13243xx {f32bf16axis, ,  = ##1blockedttg : >.i
dot_op<{opIdx = 1, parent = #blocked3}>32    >}%
 cst_7      : = % arith.constant172tensor<  = 64dense<tt.dotx-2147483648 i>%32 : 155, tensor<,#4 ttgx%.4171slice<{dim = 1, parent = #blocked6}>x,>32  x%->icst_3 32 tensor<, :64# xblockedtensor<1>4x
xi    12832%x, cst_8bf16# = , blockedarith.constant#6 ttg>dense<.
23dot_op<{opIdx = 0, parent = #blocked3}>      >>% :  45tensor<* = 4 arith.extsixtensor< 4128%xx443232 xx:ibf16 32, tensor<, #64#ttgxblocked.1>dot_op<{opIdx = 1, parent = #blocked3}>x
>i     32Capturing batches (bs=8 avail_mem=136.68 GB):   0%|          | 0/4 [00:03<?, ?it/s]%->, 
cst_9 # = tensor<blockedarith.constant46 x>dense<32 255xto>f32  : , tensor<tensor<#644blockedxx314>xx
i32      64x%, i173#32 = blocked, arith.addf6# >blocked%
>172      
,%     46%% = cst_10cst_3tt.expand_dims =   arith.constant:%  40dense<tensor< {83886074axis>x =  : 320tensor<x : 4f32ix, 324#}xblocked 323:x> i
tensor<32      32, %x#174iblocked = 32>arith.truncf, 
 #    %ttg%173.cst_11 slice<{dim = 0, parent = #blocked6}> = :>arith.constant   tensor<->dense<4 1xtensor<>321 : xxtensor<f32324, xx#i4blocked32x3, 32>#x blockedito632 >, tensor<
#4      blockedx%>3247
x =     bf16tt.splat%,  cst_12#% = blockedarg10arith.constant3  >:dense<
 127      i>%32 : 175 tensor< = ->4arith.extsi x tensor<4%1x13x32 32x:xi i32tensor<32, 4, #x#blockediblocked>326
, >    #
%ttg      cst_13.% = slice<{dim = 1, parent = #blocked3}>48arith.constant> =   arith.mulidense<to 4194304 %>tensor<46 : 4,tensor<x 4i%x64474,  x#:32ttg x.tensor<islice<{dim = 1, parent = #blocked3}>132>x, 
32#      xblocked%i>17632
 = ,     arith.extsi#% blockedcst_14%6 = 11>arith.constant 
 :      dense< %126i49>32 =  :  arith.extsitensor<to 4 %xi48464 x
:32       x%tensor<i177132 = x, tt.splat32# xblocked%i>17632
 ,     :#% blockedcst_15i6 = 64>arith.constant   ->todense<  2tensor<tensor<>41 : xxtensor<i32464xx, i4#64xttg, 32.#xslice<{dim = 1, parent = #blocked3}>blockedi>632
>,       
#%      blocked178%> = 50
arith.addi =      tt.broadcast%% cst_16177% = ,45arith.constant   %:dense<175 21 tensor<>:64 :  xtensor<tensor<144xxxi4i64x64, 32, #x#blockedittg632.>, slice<{dim = 1, parent = #blocked3}> #>->blocked
 >      tensor<
%64    179x% = 32cst_17arith.extsix =  iarith.constant%64 32, dense< #28:blocked> 6 : tensor<>tensor<32
4x      xi%43251x,  = 32#tt.broadcastxttg i.%32slice<{dim = 0, parent = #blocked3}>49, > # :blockedto > tensor<
tensor<1    32x%x32cst_18ix = 64iarith.constant, 64 #, dense<ttg#-1.270000e+02.blocked>slice<{dim = 0, parent = #blocked3}>6 : >>tensor<
 4      ->x% 4180tensor<x = 641arith.extsixx 32f32%x, 30i# 64blocked:, > #
iblocked    326% >cst_19to
 =        arith.constanti% 6452dense<
 = 7      arith.addi>%  : 181%tensor< = 504tt.splat,x  32%%x18051i  16::,   #itensor<ttg6464. xslice<{dim = 2, parent = #blocked4}>->32> x
tensor<i    3264%x, cst_20i# = 64blockedarith.constant, 6 #>dense<ttg
-1.      >slice<{dim = 0, parent = #blocked3}>% : >53tensor<
 = 4      tt.addptrx% 32182%x = arg1iarith.addi,8  , %%#18142ttg, . :slice<{dim = 2, parent = #blocked4}>% >179!
 tt    :.% ptr<i8>cst_21tensor<, = 32 arith.constantxi i64dense<64
0x7FC0,       >#% : ttg54tensor<. = 128slice<{dim = 0, parent = #blocked3}>arith.extsix> 32
%x      arg14bf16% , 183:# =  blockedarith.mulii5 32>% 
7to    , % icst_22%64 = 6
arith.constant        :%dense< 557i = >64arith.muli : 
 tensor<      %4%7x184,4 =  xtt.addptr%32 54x% iarg2:32, ,  i#%64blocked183
>       
:%     56%! = cst_23tttt.addptr = . arith.constantptr<bf16>% ,arg3dense< ,1.270000e+02i >64% : 
55tensor<       4%:x185 4 = !xtt.expand_dimstt1 .x%ptr<i8>f32178,,  { #axisiblocked = 64>1

 :           i%%3257cst_24} =  =  tt.expand_dimsarith.constant:   %dense<tensor<411.270000e+024 {>xaxis : i = tensor<6414,  : x#i4ttg32x.}1slice<{dim = 1, parent = #blocked3}> x>:f32  , ->tensor<# 32lineartensor<x>4i
x32    1, %x#cst_25ittg = 64.arith.constant, slice<{dim = 1, parent = #linear1}>ler_DP7_TP7: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
 #>dense<blocked -1.270000e+023->>>  : 
tensor<tensor<      324%xx18614 = xxarith.extsii1 32x%, f32arg13#,  linear#:1linear >>i

32           %%to58cst_26  =  = itt.splatarith.constant64  
%dense<      arg152.000000e+00% >187: :  =  tensor<tt.expand_dimsi4 32x% 4175->x { 1axistensor<x = 32f321x,  : 1#ixlinear32i>}32
 ,     :#% linearcst_27tensor<1 = 4>arith.constantx
 i      dense<64%-8388608, 59># =  : ttg#arith.mulitensor<.blocked 4slice<{dim = 1, parent = #blocked3}> = %x>#574 ttg,x->. 1 blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>%xtensor<
58i4# 32xblocked:, 11 #x = tensor<lineari#32>64ttgx
, .1    #blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>x%blocked
icst_283#32 = >blocked, arith.constant
2#        = lineardense<%#12097152188ttg>> = .
 : arith.muliblocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>      tensor< 
%4%#60x186blocked = 4,3arith.extsix  =  1%#%x176ttg59i . 32:blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>:,  
 #i#tensor<linear64blocked32>
4x
       = 1    %#x%189ttgicst_29 = .32 = tt.splatblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>, arith.constant 
# %#lineardense<186blocked1127 5>>: =   :  #totensor<ittg 464.tensor<x blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>324->
xx #11tensor<blockedxx46iix = 6481#, , xttg##i.linearlinear64blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>1>, 
>
##
    blockedblocked      %37%cst_30> = 61 = 
# = arith.constant      ttgtt.make_range %. {dense<190blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>end7 = 
 = >arith.muli#4 :  blocked : tensor<%8i4189 = 32x,#, 4 ttgstartx%. = i187blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>016 
 : , :#i# blocked32ttgtensor<9}.4 =  slice<{dim = 2, parent = #blocked}>x#:>1ttg 
x.tensor<    iblocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>4%64
xcst_31, #i = #linear32arith.constantblocked = ,  3##dense<>ttgttg-1
..>      linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>slice<{dim = 0, parent = #linear1}> : %
>tensor<191#
4 = linear      xtt.addptr1%4  = 62x%# = i184ttgtt.broadcast8,. ,  linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>%#%
60ttg188# . linear:slice<{dim = 2, parent = #blocked}>:2 >  = tensor<
!#32    ttttgxllvm.intr.assume..1 ptr<bf16>linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>x%,
itrue #64 ishared, :64 = # 
#lineari      ttg11%.>
192swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>      = 
->llvm.intr.assumett.expand_dims#   smemtensor<%% = 32true182#x  {ttg4:axis.x  = shared_memoryii0
641 : module, 
i attributes#    32 {linearllvm.intr.assume}"1  t>%:t
true g       tensor<.%:32n63 xu = iimtt.expand_dims164- 
, c%    #t61llvm.intr.assumettga { .saxis%slice<{dim = 0, parent = #blocked3}>" = true> = 0  1 : :-> : i  i32itensor<32}11,  
x":    32t llvm.intr.assumexttensor< ig4%64.xtrue, ni #u32:blockedm,  3-#i>wttg1
a.
      rslice<{dim = 0, parent = #linear1}>    %p>llvm.intr.assume193s   = "->%tt.broadcast =  true 4tensor< % : 1:190ix  324i:, x1 ttg.targeti
tensor< = 32    4", llvm.intr.assumexh# 1ilinear%xp1truei:> 64g
:, f       #x%iblocked964135 = 
>0tt.broadcast     " llvm.intr.assume->, %  "63%tensor<t true4t: xg :32.tensor< xt1iihx164r4
, ex    #aillvm.intr.assumeblockedd32 3s, %>-#true
plinear       e1:%r> 194- i = w->1tt.expand_dimsa 
 rtensor<    %p32llvm.intr.assume179"x  { = 4%axis64xtrue =  : i 0i32: : 32,  i}#i32 linear1}{1
 
>    :  
llvm.intr.assume tt.func       tensor< %%32public65truex  =  i@arith.extsi:64_batched_gemm_afp4_wfp4_pre_quant_kernel  , (%i#%641ttgarg0 
.: :    slice<{dim = 0, parent = #blocked3}>! llvm.intr.assume>tttensor<  .32%->ptr<bf16>xtrue  {4 tensor<tt.divisibilityx:1 = i x1632i32 : , 1xi#
i32linear    64}1%, , >0#%  = blockedarg1tott.get_program_id3:   >!tensor<x
tt32       .x:%ptr<i8>4 195 {xi = tt.divisibilityi32tt.broadcast = 64
 16,     % : #%194ilinear1 321 = :}>tt.get_program_id , 
 tensor<%      y1arg2% x: 66:32! =  xttarith.addiii. 3264ptr<bf16>%
,  {65    #tt.divisibility,%blocked =  2316% = > : 62arith.addi i  ->32:% } arg5tensor<, tensor<,4%32 xarg3x%32: 4c31_i32x!x itti:64.64 , ptr<i8>, i# {#32blockedtt.divisibilitylinear
3 = 1    >16>%
 : 
3      i       = %32%arith.divsi196}67  = ,  = %tt.addptr%tt.splat2 arg4 ,%: % 191i56%,32 c32_i32 , : %% :180arg5!  : tti:i.32 32ptr<i8>
! {     tttt.divisibility->%. =  4ptr<bf16>16tensor< = , : 32arith.extsi ix i324%64}xarg7
, !       %tt:%arg6. 197: ptr<i8>i = i, 32arith.addi32#   {linearto%tt.divisibility1 195 = >i,16
64  :       
%i%    1933268% } = 5:, tt.addptr =  % arith.extsitensor<arg7% 4: 67%xi,arg93232  x {%:itt.divisibility66 64 =  i, 16:32# :   blockeditensor<to33232 >}xi
, 464      %x
%arg8!    198: tt% = i.6arith.extsi32ptr<i8> =   {, arith.extsi%tt.divisibility# arg4 = linear% 161arg11: : >  i,:i32  32}tensor<i , 3232to%x  arg94toi: x 64iii
326464       {, 
%tt.divisibility#    199 = linear% = 1617tt.splat : > =  i
arith.extsi%32       198}%% , 690:% =   arg10tt.load:i:   64i%i 326832-> {   tt.divisibility:totensor< =   416tensor<ix : 32641ix
x324    i}x%64, !8, %tt = #arg11.arith.divsiblocked: ptr<i8> 3i, %>32#1
 {linear,      tt.divisibility1 % = >%20016
3 =  :        arith.cmpii%: 3270 slt} = i,, tt.trans32 % 
%arg12%    185: 69%,i {9 32order = % { = arith.remsi199tt.divisibilityarray<   = i%:16321  : : ,tensor<i1 432, %x}031, > x%}:iarg13  64: :i, i 32#32tensor<
blocked {32    3tt.divisibilityxllvm.intr.assume> = 4 
16x%       : itrue%i8 20132, : = }# arith.extsi, lineari %11%arg14>
arg5:       i->llvm.intr.assume:32    {tensor<%itt.divisibility4true32 = x  1632:to : x  iiii328164}, 

, #          %ttgllvm.intr.assume%arg15. 202: slice<{dim = 2, parent = #blocked4}>% = i>truett.splat32
  )      :% attributes% 201 {71i noinline = 1: = tt.splat
 false     i}%%64 2910 {  = ->
:arith.cmpi       tensor<%!sgt1csttt,x = . 32arith.constantptr<bf16>%x  arg6idense<->,64127  , >tensor<%# : 4c0_i32blockedtensor<x 34128:>xx 
4!i      xtt32%1.
203xptr<bf16>     = i, scf.ifarith.cmpi8#  , blocked%slt#110,blocked>  >
{%
      
192    %      ,%72% cst_0 = 11% = tt.addptr = 202arith.constant arith.muli  % :dense<71% 0x7FC0,8tensor<> ,1 : % xtensor<28%324 c4_i32xx: i128 :64xtensor< , bf164i#, x32blocked#128
3blockedx      >1!%
>tt12      
. = %    ptr<bf16>tt.make_range204%,  { = cst_1#endtt.broadcast = blocked =  arith.constant14% > : 200dense<,i 2097152 32:>tensor<,   : 4starttensor<tensor<x = 441280xxx : 14iixx6432i1, }1x# , iblocked:#321 blocked, >tensor<3#
4>blocked      x >%i->
7332      = , tensor<%tt.load#4cst_2 ttgx = %.32arith.constant72slice<{dim = 1, parent = #blocked1}>x  >idense<:
14       , >tensor<%# : 413blockedtensor<x = 34128tt.make_range>xx {
4!end      xtt = %16.4205xptr<bf16> :  = i, itt.broadcast8#32 , blocked, %#1start203blocked> =  2
0:>       :  
%itensor<    74321% = }xc31_i32tt.splat 32 =  :xarith.constant% i 53tensor<131 4,  : :x#i iblocked32!323
tt, >    .# %ptr<i8>ttg->cst_3 .  = ->slice<{dim = 1, parent = #blocked3}>tensor<arith.constant >4 tensor<
xdense<64      320.000000e+00x%x>3214i : x = 1tensor<!tt.splat, 4tt #x.%blocked32ptr<i8>113x,  >f32#:
, blocked       #6i%blocked>322063
  = >      ->arith.andi
%      75tensor<%% = 4204c32_i32tt.addptrx, =  i arith.constant%32% 74, 20532,#  :  ttg:i%. 3252slice<{dim = 1, parent = #blocked1}>tensor<
 >4    :
x%       32c4_i32tensor<%x = 6415iarith.constantx = 1 32arith.addi, 4x # : !%blockeditt14332.,>
ptr<i8> 
    , %      %#12%trueblocked 207 = 6: = arith.constant> tt.splat ,tensor< true 4%
tensor<x196    64i %x32:c0_i3232,   = x#!arith.constantittgtt 64..0, slice<{dim = 1, parent = #blocked1}>ptr<bf16> : #> iblocked
->326       
>%tensor<    
164%       = xcst_4%tt.splat32 = 76 xarith.constant = %! tt.loadarg4ttdense<  .-8388608%:ptr<bf16>>75 ,  :  i#tensor<cacheModifier32blocked4  3x=->>4  
xcgtensor<      1 4%x:x208i i = 32tensor<32tt.addptr, 64,  #x#%blocked32ttg207>x.,
!slice<{dim = 1, parent = #blocked1}>     tt>%%.
197cst_5ptr<i8>        = , %:arith.constant#17  blocked = tensor<dense<6arith.remsi42.000000e+00> x>
%32 :       15xtensor<%,!477 ttx = %.4ttg.convert_layout16ptr<bf16>x  , 1%:#x76 blockedf32 tensor<3, :4># x,blockedtensor<i >6432tensor<
x, 4    32#x%xttg32cst_6i.x = 8slice<{dim = 1, parent = #blocked1}>iarith.constant, >64 #
, dense<blocked      #0.000000e+006%blocked>>183 :   = >tensor<->arith.muli
4        xtensor<%tt.store4647 xx,%132 208xx%,f32i4 , 8 %#, :174blocked# ,>blockedi 
364%    >
206%
       cst_7      %: = %19 arith.constant78 = tensor<  = tt.expand_dims4dense<tt.reshape x-2147483648 %32>%17x : 73 {!tensor< axistt4: = .x 1ptr<bf16>4tensor< : , x4i#32x32blockedx128}3ix >32bf16:
, ,      ##tensor<}blockedblocked4
>1x    
>itt.return     32
%->,   cst_8 #} = tensor<ttg
arith.constant4.} xslice<{dim = 1, parent = #blocked1}>
dense<4>
23x {-#>32->
 : x   tensor<bf16tensor<external4, 4_resources: {x#x
4blocked1    x>xmlir_reproducer32
i: {x      32
i%,       3279#pipeline,  = blocked: #math.absf1"blocked >b>%
u
78      i     %l%:20tcst_9  = i = tensor<tt.splatnarith.constant4 . x%mdense<4arg8o255x d>32:u : x ltensor<bf16ie4, 32(x# o4blocked->px> t32
tensor<ix      4mi%xi32801z,  = xe#arith.extfi-blocked 32a>%, m
79#d     blocked-%:1lcst_10 >d = tensor<
sarith.constant4      - x%udense<421s8388607x = a>32arith.mulig : x etensor<bf16%{4, 19lx#,d4blocked sx>%-32 20lxto ii :m32tensor< i, 4tensor<t#x4=blocked4x0>x1 
32xt    xia%f3232rcst_11, , g = ##earith.constantblockedblockedt >1-dense<
>a1      
r>%      c : 81%htensor< = 22=4" = gxtarith.extsif4t xx.%932r215xe 0id:}32u ,, ctensor< #e4tblocked"xr>(1i
%xt    80io%)32ncst_12 <, - = {#sarith.constantaxisblockedc  = 1fdense<2>-127 :  t>itoo : 32 -tensor<}tensor<c4>4fx (x,4{1 x
xc32      iox^bb064ni(, v32%#e, arg16blockedr#: 1tblockedf32>->, 
i
%      n    arg17%d%: 23ecst_13f32 = x = )tt.make_range-arith.constant: {t 
endodense<         = -4194304%128l>209 : l :  = ivtensor<arith.maxnumf32m4 , {x%starti4arg16 = nx,0d32  : ex%ixiarg1732-32 }b, : i# :tblockedf32 w>
tensor<i
        128d    tt.reduce.returnxt% ihcst_14%32= = 209, 0arith.constant #} :ttg,dense< . 126f32slice<{dim = 0, parent = #blocked1}>a>
>l :       
ltensor<}      o4)%cx : 24a4( = txtensor<tt.expand_dimse324 -xx%ai423m32x {d, 32axisg#x = pblockedf320u>,  : -
#is    blocked32h%>}acst_15) ->  r = tensor<:earith.constant4 d xtensor<-dense<4128m2xxe>f32im : , 32otensor<#, r4ttg#yx.ttg,4slice<{dim = 2, parent = #blocked}>. x>slice<{dim = 0, parent = #blocked1}>c32
>ox       ni%->v3282 e,  = tensor<r#ttg.convert_layout1tblocked x->%128t
81xr     ii%:32tcst_16 , o = tensor<#narith.constant4blocked- x1adense<4>m21x
d>f32      g : , %ptensor<#25u4ttg = -x.arith.extsit4slice<{dim = 2, parent = #blocked}> ox>%-32 24lx-> li :v32tensor< m, 4tensor<{#x1ablocked4xr>x128c
f32xh    , i=%#32gcst_17ttg, f = .#xarith.constantslice<{dim = 2, parent = #linear}>blocked9 >15dense<
>028        >%tof : 83 ttensor< = tensor<z4tt.expand_dims1=x xt4%128rx82xu32 {iexaxis64}i = , ,322# ,  : blockedc#i1ablocked32>n>}
o
       n    :%i% 26ccst_18tensor< = a = 4tt.broadcastlarith.constantx i 4%zdense<x22e-1.270000e+02f32 {>, :  : #  tensor<ttgtensor<m4.4axslice<{dim = 2, parent = #linear}>xx4>1-x xi1->itx 64ef32tensor<, r, 4#a#xblockedtblocked41i>x>o
1 n    x->s%f32 =cst_19, tensor<1 = #40arith.constantlinearx  >128mdense<
xa7      ix>%64- : 84, ntensor< = #u4tt.expand_dimsblockedmx 1-32%>rx81
ei {      w16axis%r,  = 27i#2 = tttg : tt.broadcaste.i sslice<{dim = 2, parent = #blocked4}>32%=>}25-
  1    :: %  rcst_20tensor<tensor<e = 41garith.constantxxi 4128odense<xxn-1f32i->, 64s : #, itensor<ttg#m4.blockedpli1slice<{dim = 2, parent = #blocked}>fx>>y32  =x->->ni  o8tensor<tensor<r, 44m#xxattg1284l.xx slice<{dim = 2, parent = #blocked4}>i1t>64xe
, f32s    #, t%blocked#-cst_211blockedc = >>oarith.constant

n             vdense<%%e0x7FC02885r> =  = g : arith.additt.bitcastetensor<  n128%%cx2683e32, =x :fbf16% a, 27tensor<l# 4sblocked:xe5 4 >tensor<xt
41o    xxp%128f32-cst_22x, d = i#oarith.constant64linearw , >ndense<# =7blocked->t>1 r : >tensor<utensor<
4e4      x}x%4,429x x = 1c32tt.addptrxsx iei%32,32arg0,  , ,#c# linearoblocked%>n>18
v
       e    :%r% 86tcst_23! = - = tttt.bitcastcarith.constant. f ptr<bf16>%-dense<,84t1.270000e+02  o>i:- : 64 ltensor<
tensor<l4      4vx%xm4304{x = xi1arith.muli1nx xdf32%f32e, 9, x#,#-blocked blockedb>%>i
c32_i32 t     ->w%: icst_24 tensor<d = i4tarith.constant32xh 
4=dense<      x01.270000e+02%1}>31x, :  = i tensor<tt.make_range32c4 {, oxend#n4 = blockedvx32>e1 : 
rxi      tf3232%-, , 87a#start = rlinear = arith.addii>0 t
 : %h    i85-%32,tcst_25} o =  %-arith.constant:cst_28l   ldense<tensor<:v-1.270000e+0232 m>xtensor<{ : i4itensor<32xn4, 4dx#xe4ttg1xx.x-1slice<{dim = 0, parent = #blocked6}>ibx>32if32
, t,       #w#%linearilinear32>d> = 
t
tt.make_range      h     {%=%end880cst_26 =  = } = 32arith.addi,arith.constant :    i%cdense<3286a2.000000e+00, ,n>start o :  = %ntensor<0cst_1i4 :  cxi:a432 lx}tensor<i1 4zx:xef32 4{, tensor<x #321 linearxxm>iia
3232x    , , -%##icst_27ttgblockedt = .>earith.constantslice<{dim = 0, parent = #blocked3}>
r >      adense<
%t-8388608      89i>% = o : 33tt.bitcastntensor< =  s4tt.make_range%=x {8714end 0x = : 132 mx : tensor<aii4x3232x-, , 4n#startxulinear = 1m>0x-
 : ir    i32e%32, wcst_28}#r =  lineariarith.constant:>t   edense<tensor<->s209715232 =>xtensor<- : i41tensor<32x 4, 4rx#xe4ttg1gx.xi1slice<{dim = 1, parent = #linear1}>iox>32ni
, -32      #s, %lineari#34>mlinear = 
p>tt.splat      l
 %i    %90f%30 = ycst_29 tt.bitcast= = : narith.constant %o i88rdense<32 m127 :a>-> l :  tensor< tensor<tensor<4t432xexx4s4ixtx321-1, xcx#ioittg32n8., v, slice<{dim = 0, parent = #blocked6}>#e#>blockedrlinear
>g>       e
%->n    35 c% = tensor<e=cst_30tt.splat4f =  xaarith.constant%4l 30xsdense< 1e7:x > it : i32otensor<32, p4 #-x->blockedd4 >oxtensor<
wi32      n16x%=, i91t#32 = rttg, arith.andiu.# eslice<{dim = 2, parent = #blocked}>ttg%}>.89,
slice<{dim = 1, parent = #linear1}>,     > c%
%scst_31      cst_27e = % ,arith.constant36:   =  sdense<arith.additensor<y-1 4m>%xb : 344otensor<,xl4 1-x%xd431icx 32ei:, ,8 # , tensor<lineare#32>nttgx
a.i      bslice<{dim = 2, parent = #blocked}>32%l>, 92e
# = -    ttgarith.andilllvm.intr.assume. i slice<{dim = 0, parent = #blocked6}>%n%>90etrue
,-        i:%%n 37cst_4fi =  o1arith.addi:,
       %tensor<cllvm.intr.assume354o ,xn% 4vtrue%xe 331r: xt :i-i 32b1tensor<, u
32#i    xblockedlllvm.intr.assumei>t 32
i%,       ntrue#%- ttg93f:. = u slice<{dim = 1, parent = #linear1}>tt.bitcastni> c1
%-
      91t    % ollvm.intr.assume38:-  =  l%tt.splattensor<ltrue 4v %xm:arg54{  xfi:1t1 xz
ii=    3232tllvm.intr.assume , r ->#u% linearetruetensor<>} 32 ):x->" i ,i32tensor<
1, 4      
#xdisable_threading    ttg4: llvm.intr.assume.xfalse slice<{dim = 0, parent = #blocked6}>1,%>x
true
f32             , verify_each:%#:  39lineartruei = >
1tt.splat
    }
       
    %%  }llvm.intr.assumearg594
   = #-}%:tt.bitcast
true   i%:3292 /tmp/torchinductor_root/55/c55pmollljfhv27acaaqe4aoqag554tycdf4wlwjoa7uvsnwpjrl.py:18:0  i: ->:1error:   
Failures have been detected while processing an MLIR pass pipelinetensor<tensor<    
324llvm.intr.assume/tmp/torchinductor_root/55/c55pmollljfhv27acaaqe4aoqag554tycdf4wlwjoa7uvsnwpjrl.py:18:0xx : i4%note: 32xtruePipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`, 1 
#x:ttgi .32islice<{dim = 1, parent = #linear1}>, 1>#

blocked          >llvm.intr.assume%  40->% =  truearith.remsitensor<  4:%x 364i,x1 1
%x    38f32llvm.intr.assume ,  :#% blockedtruetensor<> 32
:x       i%i32951,  = 
#math.log2    ttg llvm.intr.assume.% slice<{dim = 0, parent = #blocked6}>93%> true
:        :%tensor< 414i = x1arith.remsi4
 x    %1llvm.intr.assume37x ,f32% , true%# 39linear: > :
i       1tensor<%
3296    x = %imath.log2032  = , %tt.get_program_id#94 ttg x[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 2, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank2]:E1112 18:13:31.166000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
.: slice<{dim = 1, parent = #linear1}> :>tensor< 
4i      x32%4
42x     = 1%arith.mulix1 f32 = %, tt.get_program_id7# ,blockedy > %
:5        %i:9732  = 
imath.floor    64 %
%2      95 = % arith.addi43:  =  %tt.make_rangetensor<arg5 {4,endx  = 4%64xc31_i32 : 1 ix:32f32 , , istart#32 = linear
0>     : 
%i      332% = }98arith.divsi  =  :math.floor%  2tensor<%,6496 x %i:c32_i3232  , tensor<:#4 ttgxi.432slice<{dim = 1, parent = #blocked6}>x
>1    
x%      f324%,  = 44#arith.extsi = blocked tt.expand_dims>% 
arg7%       43%: {99 axis = i = arith.subf321   : %toi97 32,i} 64 %
:cst_26      %tensor<:564  = xtensor<arith.extsii4 32x%, 4arg9#x ttg1:.x slice<{dim = 1, parent = #blocked6}>f32i>ler_DP3_TP3: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
, 32 # ->linearto > tensor<
i64      64x%
1100    x = %iarith.subf632  = , %arith.extsi#98 blocked,%6 arg11>% 
cst_5:        %:i45 32 = tensor< arith.extsi4to x %4i44x64 1
:x     f32%tensor<, 764# = xblockedarith.extsi1> x
%i      032% , 101:# =  blockedtt.clampfi6 32>%  99toto,   itensor<%6464cst_25
x,    1 %x%8icst_24 = 64,arith.divsi,   #propagateNan%blocked# 16blocked=,> =   
#none%      ttg 3%.: 46blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> : = 
tensor< tt.expand_dims#4i blockedx32%14
40 = x     {#1%axisttgx9 = .f32 = 0blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>, arith.remsi : 
# i#linear%32blocked>1}2
,  =        :#%% ttg1023tensor<. =  32blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>tt.clampf:x
  i#%i32blocked10032, 3,
# =      ttg#%llvm.intr.assume.ttgcst_18 slice<{dim = 0, parent = #blocked6}>.,%>blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> true 
% ->#cst_23: blocked, tensor<4 i1 = propagateNan1x# 
32ttg=    x. llvm.intr.assumeiblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>none 32
 %, #:true#blocked  blocked5tensor<:6 = 4 >#xi
ttg41      .x
%blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>1    47
xllvm.intr.assume = #f32 tt.splatblocked, % 6#true% = blocked arg10#>: ttg
 :.      i blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>%1i
103
32# =      blockedarith.fptoui%->7 10  = % = tensor<#101arith.cmpi1ttg  x.:sgt32blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}> ,x
tensor< i#4%32blockedxarg6, 84,# = x blocked#1%6ttgxc0_i32>.f32 
blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>, :      
# %#lineari48blocked>32 = 9 
arith.muli = to     # scf.if%ttgtensor< 46.4%,blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>x10 
4 %#x{47linear1
  = x      :#i% ttg811tensor<.,  = 1linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>#arith.mulix
linear 32#>%xlinear
8i1      ,32 = % , #104%#ttg = c4_i32blocked.arith.fptoui 6linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}> :>
% 
#102i      linear 32%2:
49 =         = #tensor<%arith.extsittg412 .x = %linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>4tt.make_range48
x { #1end:sharedx =   = f324tensor<#,  : 1ttg#ix.blocked3232swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>>, x
 starti#to = 32smem 0,  = tensor< : ##4iblockedttgx326.4}>shared_memoryx  
1:tomodulex   attributesitensor<tensor< {841", xxt#i32tblocked32xg>, i.
#64n      ttg, u%.#m105slice<{dim = 1, parent = #blocked1}>blocked- = >6carith.addi
>t       
a%%      s10313%", = 50 =  tt.make_range = 1% {tt.broadcast : cst_29end i  = %32:445,   :  "tensor<i:t432 tx, tensor<g4start64.x = xn101ux : xmiii-83264w, }, a# #rlinear:blockedp> 6s
tensor<>"      4  = %x->4106i  :  = 32tensor<iarith.addi, 6432 #x, %ttg32ttg.target104.x = ,slice<{dim = 1, parent = #blocked3}>i" >64h%
, icst      #p %blocked::146g  = >ftensor<tt.splat
x4       9x%%5411510x  = "1:tt.broadcast, x  "ii%t83249t,   g#->:.blocked  t>tensor<tensor<h
41r      xxe%i32a10732xd = , isarith.subf#64- ttg, p%.#ecst_6slice<{dim = 1, parent = #blocked1}>blockedr,>6- 
>w%       a102%->r 15 p: = tensor<" arith.addi64 = tensor< x644%32 : x14xi4,i32x 64}1%,  x12#{f32 blocked
, :6  # >tt.funcblockedtensor<
 >4      public
x%       i52@%32 = _batched_gemm_afp4_wfp4_pre_quant_kernel108, arith.addi( = # %math.exp2ttg%arg0 .50: %slice<{dim = 1, parent = #blocked1}>,!107> tt 
%.:      51ptr<bf16> %  {tensor<16:tt.divisibility4 =   = xtt.splattensor<164 64 : x%xi1arg43232x x}f32:i, ,  64%#i, arg1blocked32#: > blocked!
->6tt       >.%tensor<
ptr<i8>1094       { = x%tt.divisibilityarith.extfi53 =  32 = 16%, tt.addptr : 78# i ttg%32:.arg1} slice<{dim = 1, parent = #blocked1}>,, tensor<> %4
%arg2x      42: 4% !x17:tt32 =  .xarith.remsi!ptr<bf16>bf16 tt {, %.tt.divisibility#15ptr<i8> = blocked,,16>   :  %iito166432  
}tensor<:      , 4 %%xtensor<54arg344 = : xxarith.extsi!32i ttx32%.f32, arg14ptr<i8>, #  {#ttg:tt.divisibilityblocked.  = >slice<{dim = 1, parent = #blocked1}>i16
>32 :       
 i%      to32110% } = 18i, tt.broadcast = 64% arith.muli
arg4%       : 108%%i 75532:, = ,   arith.muli%tensor<% arg544%: x 7i4:,32x   {1i%tt.divisibilityx6454 = f32
 16,       : : #% iblocked19i32> = 64} tt.expand_dims
, ->       % %%arg6tensor<1756: 4 { = ixaxistt.addptr324 =   {x1%tt.divisibility32 : arg3 = xi,16f3232  : , }%i# 5532blocked: }> :, 
tensor< %      4!arg7%xtt: 111i.i = 32ptr<i8>32arith.mulf, , { # tt.divisibility%ttgi = 109.6416,slice<{dim = 1, parent = #blocked1}>
 :  >      i% %32110->57}   = , :tensor<tt.expand_dims% 4 arg8tensor<x%: 4141ixx {324iaxis {x32 = tt.divisibility32, 1 = x# : 16f32blockedi : , 132i#>}32blocked
 }>      :, 
% %      20tensor<arg9% = 32: 112tt.splatxi =  i32tt.bitcast%32 { arg8, tt.divisibility% # = 111:ttg16  . : :islice<{dim = 1, parent = #linear1}>i 32>32tensor<  }4->->, x  %4tensor<tensor<arg10x432: 32xxix1132f32xx {, iitt.divisibility#3232 = blocked, , 16>## :  blockedlineari->1132 >>}tensor<

, 4            %x%%arg1142158: x =  = i32arith.mulitt.splat32x   {i%%tt.divisibility3219arg15 = , , 16# : : blocked% i>20i32
 32}      : , % ->%113tensor< arg12 = 4tensor<: arith.andix32i 1x32%x1 {112ixtt.divisibility,32i =  , 3216%#,  : cst_7blocked#i 1linear32:>1} 
>, tensor<      
%4%      arg13x22%: 4 = 59ixarith.extsi = 3232 arith.muli {x% tt.divisibilityi21% = 32 5716, :, : #  iblockedtensor<%32>458}
x ,       1:%%x arg14114itensor<:  = 3232iarith.shrui, x32 #1 {%blockedxtt.divisibility1121i = ,>3216  ,  : %to#icst_8 linear32 tensor<1}:4>,  x
%tensor<1      arg154x%: xi60i464 = 32x, arith.extsi)32#  attributesxblocked% {i159noinline32>  = , 
:false#       }blocked%tensor< >2332{
 = x
      tt.make_range1    % {x%115endicst =  = 32 = arith.andi128, arith.constant  : # %ilineardense<114321127,, >> start  : % = totensor<cst_90 4  : tensor<x:i324 32xxtensor<}114 xxx:ii4 648xtensor<, , 32128##xxlinearblockedii1>3232>
, , 
    ##      %blockedttg%cst_0>.61 = 
slice<{dim = 0, parent = #blocked1}> = arith.constant      >tt.make_range %
 {dense<116      end0x7FC0 = % = >arith.andi244 :   =  : tensor<%tt.expand_dimsi4112 32x,%, 128 23startx% { = bf16cst_10axis0,   =  : #:0iblocked  : 321tensor<i}>432 
x}:    4  %x:tensor<cst_132 4 = xtensor<xarith.constanti128i 32x32dense<, i, 2097152#32#>blocked, ttg : >#.tensor<
ttgslice<{dim = 0, parent = #linear1}>4      .>x%slice<{dim = 0, parent = #blocked1}>
4117>      x =  %1arith.addi->62x   = i%tensor<tt.broadcast321151 , ,x%# 12860blocked%x >cst_11i:
 32     :, tensor<% #32cst_2tensor<blockedx = 411arith.constantx>x 4
idense<x      64432%, >x25# : i = lineartensor<32arith.extsi14,  >x#% 4blocked24->x>  16
:tensor<x       32i%tensor<x811814,  = xx#arith.subi128iblocked x642%i, >
cst_1232#    ,, linear% #1c31_i32%blocked> = 1171
arith.constant >       : %31 to63 : tensor<  = i4tensor<tt.expand_dims32x1 
4x%    x12861%32x {cst_3xiaxis = i64 = arith.constant32, 0 , # : dense<#blockedi0.000000e+00blocked132>>>} : 

 tensor<            :4%% x11926tensor<32 =  = 4xarith.cmpitt.broadcastxf32  i, ult%32#,22, blocked  #3%:ttg>115 .
,tensor<slice<{dim = 0, parent = #linear1}>     4>%%x c32_i32cst_121-> =  x arith.constant:itensor<  64132tensor<, x : 4#4ixblockedx3241i
x>32    32 , %x->#c4_i32i linear = 32tensor<1arith.constant, 4> #x
4blocked128       : >x%i
i6432      64 = 
%, tt.broadcast    120# % = blocked%truearith.shrui163 =  > arith.constant%116
: ,       true %tensor<
%271    cst_11 = x% tt.broadcast4c0_i32: x =  %iarith.constanttensor<2532 4 , 0x:# : 4 linearixtensor<132321>
xx     i128->%32x cst_4, itensor< = #6432arith.constantblocked, x >#4dense<
blockedx-8388608      1i>%>32 : 121 , tensor< = ->#4arith.ori linearx tensor<14%4>x120x
1,128      x x%i%i6532cst_1364 = ,  , arith.extsi#:# blocked blocked%>tensor<164
4>     x
:%4       cst_5x%tensor< = 322832arith.constantx = x iarith.addi4dense<32 x2.000000e+00, %i>#2632 : blocked,, tensor<> #4
%linearx      2714% >x122: 1 =  toxarith.shruitensor< f32 4tensor<, %x32#121128xblocked,x4> ix
%64i    118, 64% #, cst_6:blocked# =  1lineararith.constanttensor<>1 4
>dense<x      
0.000000e+004%      >x29% : 32 = 66tensor<xtt.addptr = 4i arith.addix32% 4, arg0%x#,651blocked ,x>% f32
18%,        62#%: blocked123 :> = ! 
arith.selecttttensor<     .32%%ptr<bf16>xcst_7119,4 = ,  xarith.constant%ii 1226464dense<, 
, -2147483648%      #>116%linear :  : 301tensor<tensor< = >44arith.muli
xx       44%%xx9673232, = xx tt.splatii% 321c32_i32%, ,  56##: blockedblocked :>>i 
, 32!    tensor<
tt%4      .cst_8x%ptr<i8> = 431 arith.constantx = -> 32tt.make_range dense<x {tensor<23iend32>32 = x : , 324tensor<# : x4blockedi!x>32tt4
, .x      startptr<i8>32% = , x1240#i =  : linear32arith.maxuii1,  32>#%}
blocked115       >,:%
  68    %tensor< = %cst_1432tt.addptrcst_9 x  = :i%arith.constant 3267 tensor<, ,dense<4# 255xttg%>4.66 : xslice<{dim = 0, parent = #blocked6}> tensor<32>:4x
 xi      tensor<432%32x, 32x32# = 4xblockedtt.make_rangexi> {!32
endtt,        = .#%32ptr<i8>blocked125 : , > = i#
arith.subi32linear     , 1%%start>cst_10124 = , = ,0 arith.constant  : tensor< %i32dense<cst_1432x8388607 }4>: x :  :itensor<tensor< 6444tensor<, xx32#44xlinearxxi1323232>xx, 
ii#      3232ttg%, , .69##slice<{dim = 0, parent = #blocked3}> = blockedblocked>tt.load>>
 

      %          %68%%33 cst_11126 = : =  = tt.make_range arith.constantarith.shli {tensor<  end32dense<% = x1125324>, : x :  i!tensor<%32tt4cst_15, .x startptr<i8>4: = , x 0#32tensor< : linearx4i1ix32>324}
, x       #32:%blockedx 70>itensor< = 
3232tt.trans    , x %#i%cst_12blocked3269 = >,  {arith.constant
#order       ttg = dense<%.array<127127slice<{dim = 1, parent = #linear1}>i> = >32 : arith.shrui
: tensor<       14%%, x1233404, = >x tt.splat}32%  xcst_16%:i 30 32: tensor<,  :32#tensor< xblocked4i4>x32x
4 i    x->8%32 , cst_13xtensor<# = i32lineararith.constant32x1 , i>dense<#32 4194304blocked, ->>>#  : 
ttgtensor<tensor<      .44%slice<{dim = 0, parent = #blocked6}>xx128>324 = 
xxarith.ori      i32 %35 = 8tt.splat%,  x126#%i,ttg3032 . , %slice<{dim = 2, parent = #blocked4}>:#127> blocked 
i>:      32
 %     tensor<71->%4 =  cst_14xtt.splattensor< = 4 32arith.constantx%x 3229idense<x 32126i:, >32 # : , !ttgtensor<#tt.4blocked.slice<{dim = 1, parent = #linear1}>x>ptr<bf16>>4
 
x      ->      32% %x129tensor<36i = 4 = 32arith.addixarith.addi,  128 #%x%blocked128!34>,tt,
 .     %ptr<bf16>%%cst_11, 31cst_15 #  = :blocked:arith.constant 1  tensor<>tensor<dense<4
322x      x>4%i : x7232tensor<32 = , 4xtt.addptr#xi ttg432%.x, 71slice<{dim = 0, parent = #blocked6}>32#,>xblocked 
i>%      32
28%,        37#%: = blocked130 arith.addi> = tensor< 
arith.shrui4%     x35%%128,cst_16129x  = ,!%arith.constant tt33 %. dense<cst_11ptr<bf16>:21 ,  >:#tensor< :  blocked32tensor<tensor<1x44>ixx,3244 , xxtensor<#32324ttgxxx.ii128slice<{dim = 1, parent = #linear1}>3232x>, , i
##64      blockedblocked, %>>#38

blocked =           1tt.splat%%> cst_17131
% =  =       arg5arith.constantarith.minui%   73:dense<% =  28130tt.loadi>, 32 :  % tensor<%72->4cst_22  x :tensor<4: 32x tensor<x32tensor<4ix4x32ix128, 324x#, x!ttg#32tt.blockedx.slice<{dim = 0, parent = #blocked6}>>iptr<bf16>>
32, 
    , #      %#blocked%cst_18blocked139 = >> = arith.constant

tt.splat              dense<%%%-1.270000e+0213274arg5> =  =   : arith.shruitt.splat:tensor<   4%%ix11353324,  x :->1%  xcst_17!tensor<f32 tt32, :.x# ptr<i8>iblockedtensor< 32>4->, 
x #    4tensor<ttg%x64.cst_1932xslice<{dim = 1, parent = #linear1}> = x32>arith.constantix
 32!      dense<, tt%7#.40>blockedptr<i8> =  : >, arith.remsitensor<
# 4      blocked%x%63632133>,x = 
 iarith.ori      %16 %38, %75 #132 = :ttg,tt.addptr .  tensor<slice<{dim = 2, parent = #blocked4}>%%32>13174x
 ,i    : 32% %, cst_20tensor<52# = 4 ttgarith.constantx:. 4 slice<{dim = 0, parent = #blocked6}>dense<xtensor<>-13264
>xx       : i32%tensor<32x414, ! = x#ttarith.remsi32blocked. x>ptr<i8>%i
, 378      #,, %blocked #1346%ttg = >39.arith.trunci, slice<{dim = 2, parent = #blocked4}>  :>%tensor< 
13364tensor<     x32%:32xcst_21 xi = tensor<i32arith.constant464,  x, #dense<4#ttg0x7FC0xblocked.>326slice<{dim = 1, parent = #linear1}> : x>>tensor<i

12832            x, %%32#7642xblocked =  = bf16>tt.loadarith.muli,    #to%%blocked 7575tensor< ,>4cacheModifier 
x %    4=5%x  cst_2232cg: = x  arith.constanti:i 8 64dense<, tensor<
7#64      >blockedx% : >3243tensor<
x = 4      !tt.make_rangex%tt {4135.endx = ptr<i8> = 32tt.reshape, 64x # : i%blockedi32134632,  >, #:
startblocked        = >tensor<%0
477 :     x = i%4ttg.convert_layout32cst_23x } = 32% arith.constantx76: i  dense<8:tensor<1.270000e+02, > 64# : tensor<xblockedtensor<64i>4x32 x32, ->4x# xittgtensor<18.4x, slice<{dim = 1, parent = #blocked6}>xf32#>4, blocked
x#6      16blocked>%x> 442
-> = x     tt.expand_dimsi%tensor< 8cst_2464%,  = x43#arith.constant32 {blocked xaxis7dense<i = >1.270000e+0281
>,  :        : #i%tensor<blocked32outLHS43}, x> %4
:outRHSx        = 1%tensor<tt.splitx7864 f32 = x%, tt.reshapei135# 32 linear%, :>73# 
 ttgtensor<    :.4% slice<{dim = 1, parent = #blocked6}>xcst_25tensor<>4 = 4 xarith.constantx->16 128 xdense<xtensor<2-1.270000e+02bf1664x>, xi : #18tensor<blockedx, 41i#x>32blocked4 , 7x->#>1 blocked xtensor<6->f324> , x
tensor<#4      4linearx%x>32454
x = x    bf16arith.extsi16%,  xcst_26#%i = blocked448arith.constant> ,  
:#dense<       blocked2.000000e+00%tensor<2>7964> :  = x
tensor<math.absf1      4 x%x%i13647832 = x , arith.shli1:# x blocked%f32tensor<6outRHS, 4>,#x  linear4to%>x cst_2
32tensor<     x64:%bf16x cst_27, 1tensor< = #x4arith.constantblockedix >644dense<
, x-8388608      #16>%blockedx : 806itensor< = >84arith.extf
, x       #4%%blockedx794621  = >x:tt.expand_dims
i        32tensor<%%, 440137#x { = linear4axisarith.ori>x =  
320%    x : outLHS%bf16i,cst_28, 32  = #}%arith.constantblocked 136 >: dense<  :2097152totensor< > 32tensor< : tensor<x4tensor<4ix4x324x4, x4x#16x32ttgx1x.ixf32slice<{dim = 0, parent = #blocked6}>8i, >, 32# #, blocked->blocked#> 2linear
tensor<>>      1

%x          8132%% = x138cst_29"i =  = t32tt.reshapearith.constantt,   .#%dense<rblocked137127e6 >d>: : u
 tensor<c      tensor<4e%4x"47x4( = 4x%tt.splatx180 16x)%xi <arg10i8{ 8, axis:, # =  #linear2iblocked> : 322
i >    32-> %} ->cst_30>tensor<  =  (1tensor<arith.constant{x4 
32xdense<      x647^bb0ix>(32i : %, 8tensor<arg16#, 4: blocked#xf326blocked4, >8x%
>iarg17      
16: %      , f3248%#) = 139ttg:arith.muli = .
 tt.reshapeslice<{dim = 2, parent = #blocked}>        % >%46%
209,105     =   %arith.maxnumf%:cst_31 47  = % tensor<arith.constantarg16:4 , xdense< tensor<4-1%1x>arg17x1 :  32xtensor<:xi4 i8xf3232, 4
, #x        #linearitt.reduce.returnblocked>8 6 , %>->#209
 ttg       tensor<.:%4slice<{dim = 2, parent = #blocked}> 49x>f32 = 4

arith.extsix           illvm.intr.assume}%8 )48, % :  #true(:ttg tensor< .:4tensor<slice<{dim = 2, parent = #blocked}> x1>i4x
1x32      
32x%    xi140llvm.intr.assumef3232 =  , , tt.reshape%## trueblockedblocked% >6106:) -> >  tensor< :i4to 1x tensor<
4tensor<4    x1xllvm.intr.assumef32x4 , 32x%#x1truettgix .64i:slice<{dim = 2, parent = #blocked}>, 8 >#, i
blocked#1      6blocked
%>>    82
 llvm.intr.assume =       -> ttg.convert_layout% % 50tensor<true% = 4 81tt.broadcastx:  4 :%xi 45i1tensor< 8
4:,     x #llvm.intr.assume4tensor<linear x642%f32x>true, 1
 #x      :ttgi% .64141islice<{dim = 2, parent = #blocked}>,  = 1>#ttg.convert_layout
 blocked     ->6%llvm.intr.assume >140 tensor<  %4->:truex   4tensor<tensor<:x644 f32xxi, 3241#xx
ttgii    .648llvm.intr.assumeslice<{dim = 2, parent = #linear}>, ,  >##%
blockedlineartrue      62 %>>:83
   =       ->itt.expand_dims% 1 51tensor<
% = 4    82tt.broadcastxllvm.intr.assume { 4 axis%x% = 49itrue2 8  : :, :i # 32tensor<ttgi}1.1 xslice<{dim = 2, parent = #blocked}>
:32>     x
llvm.intr.assumetensor<i       464%%x, 142true4# =  xblockedarith.extui:f326  , >%i# 1411ttg-> 
. :    slice<{dim = 2, parent = #linear}>tensor< llvm.intr.assume>64tensor<  x4%->32xtrue x4 tensor<ix:464i x, 8i4#, 1xblocked#
16ttg    x>.llvm.intr.assumef32
slice<{dim = 2, parent = #blocked}> ,       >%#% truelinear52to > =  :
arith.additensor<        4i%%x184504
 = ,x    tt.expand_dims illvm.intr.assume %16 %51, %81 #true {:ttg axis .: = tensor<slice<{dim = 2, parent = #blocked}> 264>i : x
1i32      
32x%    }i143% 64 = 0:, arith.shli =  # tt.get_program_idtensor<blocked% 46142xx>, 4
 :x      % f32%cst_30i, 53 32# = :
ttgtt.addptr     . tensor<%slice<{dim = 2, parent = #blocked}>%41>arg1x =  ,4tt.get_program_id-> x  %iytensor<4216 4 , :x:# 4 ttgix!.321ttslice<{dim = 2, parent = #blocked}>
x.>    f32ptr<i8>
%, ,      2# % = blockedi144arith.addi>64 =  

tt.bitcast%             arg5%%%,8554143  =  =  %tt.bitcastarith.extsi:c31_i32    %%tensor<:83arg144   xi::432  x
tensor<ii    43216%x , 34to# = x ttgarith.divsi1i. x64slice<{dim = 2, parent = #blocked}>%f32
>2,        ,#%-> linear55 %> = tensor<c32_i32 arith.muli4 -> x: %4 tensor<7xi4,bf1632x , 
4%#    x54ttg%1 .4x:slice<{dim = 2, parent = #blocked}> = i >arith.extsi32i
 , 64      %#
%arg7linear      145 >% = :
56tt.expand_dims        =  i%tt.addptr%3286 144  = % {tott.bitcastarg3axis  , = i% 26484% : 
 55i    : 32% :}5tensor<   = 4!:arith.extsixtt  4.tensor<%xptr<i8>4arg91,x x 4:f32ix , 64bf16i#
, 32blocked      # >%ttgto 57. -> = slice<{dim = 2, parent = #blocked}>i tt.expand_dims>64tensor<  
4%->    x41 %4 {tensor<6xaxis4 = 1 = xarith.extsix14 i : x%32i1arg11, 32x #}bf16:blocked ,  >:#i
 blocked32      tensor<> %32
to87x        = i%iarith.addi3214664 ,  = 
%#tt.broadcast    85ttg %,.%7 slice<{dim = 1, parent = #linear1}>145 = %> arith.extsicst_28 :  -> %: tensor<0 tensor<4 tensor<32x:4x4 x1xi4x132xix 132bf16tox, ,  i##i32linearblocked64, 1>
#>     linear
->%>       8
%tensor< =       584arith.divsi% = x 88tt.splat4% =  x1arith.addi%32, arg15x % bf16%86:, 3, #  iblocked:%32> cst_1 
      %i ->14732:  = 
 tensor<tt.reshape    tensor<32 %4x%9x1146 = 4x arith.remsixi: 132 %x, tensor<1i#4,32linearx , 14%#>x3blocked
32 >      x:
%bf16       59, i% = #3289arith.muliblocked
 =  >    tt.bitcast% llvm.intr.assume 57-> %, %87 tensor<true %4 :58x:  128 tensor<:xi4 bf161xtensor<, 
432#    xxblockedllvm.intr.assume111 xx>%ii
true3232       , , %:##148 linearlinear = i>1amdgpu.scaled_upcast_fp41 > 
->
%           138llvm.intr.assumetensor<%  460scale%x =  true4arith.extsi% x 147:1% { x59axisii  = 132:1
,   :     #tensor<i%linear323210>x} = 
1 arith.cmpi      x: %i sgt9032tensor<, = , 4 tt.bitcast#x% linear64arg6%1x,88>i   8%:to, c0_i32  # tensor<tensor<blocked:4328 xx>i41,32xx 
1itensor<    x644scf.ifi, x 32#128%, linearx10#1bf16 blocked>, {>
#
       blocked      ->%1% 61>11tensor< =   = 4tt.make_range->arith.mulix {  4endtensor<%x = 4814x,x : 128 iix%3232bf16c4_i32, , ,  #start#:blocked = blocked >01i
 : >32      i

%32            91}%% =  14912arith.andi: =  =   arith.cmpitt.make_range%tensor<  {894eqend,x, =  i 4%32% : cst_27, 139i #,32:ttg ,  .%starttensor<slice<{dim = 0, parent = #linear1}>cst_31 = 4> 0x
: : 4       ix%tensor<321624}x = x itt.broadcast4:32 x , %itensor<#6084linear , x>:#i
 ttg32      tensor<., %32slice<{dim = 2, parent = #blocked}>#92x>ttg = 1
.arith.andix      slice<{dim = 1, parent = #blocked1}> i%>%64150
90,  =       ,#tt.expand_dims% linear 13%1% = cst_4>149tt.make_range   { {:->axisend   =  = tensor<tensor<24432 :  : xxii443232xx}, 1i startx64: = i,  032#tensor< : , linear4i#1x32blocked>4}>
x 
      i:      %1 %63, tensor<93 = #4 = tt.expand_dimsttgxtt.bitcast .i %slice<{dim = 2, parent = #blocked}>32%61>, 91 { # axis->ttg: =  . 0tensor<slice<{dim = 1, parent = #blocked3}>tensor< : 4>4ix
x324      4}x%x 1141:x = x itt.splatitensor<1 324, %, x#11#iblocked linear32>:>, 
  #      i->ttg%32 .151 tensor<slice<{dim = 0, parent = #linear1}> = ->4>tt.broadcast x  tensor<4->%4x 150x1tensor< ix1:32f32x , , 4tensor<##x4ttglinearix.>324slice<{dim = 1, parent = #blocked1}>
, x>      #1
%linearx      941i% = >115tt.bitcast
,  =        #arith.addi%%blocked 9264>%  =  14:tt.broadcast->,    tensor<%tensor<%463412x x 4:4:x x 1tensor<32tensor<x1x4ixix3241i, x, 32#i#, blocked32blocked#>, >ttg #
.->linear      slice<{dim = 1, parent = #blocked1}> 1%>tensor<>152
4  =       x->tt.reshape%4  16xtensor<% = 132151tt.splatxx  f324:%, x arg4#itensor< blocked324:>, x 
#4i      linearx32%132 95>x-> = 
i math.log2      1tensor< %, 4%65#x93 = blockedi arith.extsi>32:  ,  %->#tensor<64 ttg4 tensor<.x:4slice<{dim = 1, parent = #blocked1}>4 x>xtensor<128
132x      xxi%f324117, x,  = #i#arith.remsilinear32blocked >, 1%
#>15      linear
,%1       96>%% =  15316math.log2to =    arith.select:%tensor<  9432%tensor< x1524:4, x x%itensor<icst_032464, , x, %#4#148ttgxlinear : .11tensor<slice<{dim = 1, parent = #blocked1}>x>4>f32
x
,       128      #%x%blocked66i18> = 1 = 
arith.addi, arith.muli       # %%blocked%976517 = ,>,math.floor ,   %tensor<%%624495 x  :128:: x  tensor<bf16itensor<32, 644x#
x4blocked      4x1%xi>19164
 = x,       tt.expand_dimsf32#% , linear154%#1 = 17linear>ttg.local_alloc {>
 axis
      % =       %1531%67  : 98 = :i = tt.splat 32math.floor (} %tensor< %564:96 x  :128tensor<: x4 !bf16xtensor<tt, i4.#32xptr<i8>blocked, 4 1#x->>ttg1 ).xtensor< -> slice<{dim = 1, parent = #blocked1}>f3232!>, xttg #4.->blockedxmemdesc<4x128xbf16, #shared, #smem> >!
tensor<
tt      4      .%x%ptr<i8>155199,  = x = #ttg.local_loadiarith.subflinear 32 1%, %>154#97
 blocked,      :1 % >%68!
cst_26 = ttg       tt.addptr.%: memdesc<4x128xbf16, #shared, #smem>20 %  = tensor<67->tt.splat4,  x tensor<%4%4arg8x66x 1 128:x:x f32 bf16i, tensor<, 32#32# linearxttg->>4. 
xdot_op<{opIdx = 0, parent = #blocked3}>tensor<      !>4%tt
x100.      1 = ptr<i8>%xarith.subf, 156i # = 32%lineararith.extui, 981 #,>%blocked ,701%  >cst_5tensor<:
 32       :xtensor<% 4421tensor<xx = 4i32arith.mulix64x 4, i%x#8191linear, ,x1# f32>ttg%, 
.20#      slice<{dim = 2, parent = #blocked4}> blocked%>:>69  
 = totensor<      tt.load 4% tensor<x101%41 = 68xxtt.clampf 32i :x32% i, 99tensor<16#,32, blocked x#1%4ttg>cst_25x.
,!slice<{dim = 2, parent = #blocked4}>       tt>%%.
22cst_24ptr<i8>       = ,, %arith.extsi #157 propagateNanlinear = % 1arith.shli21=>   
%:none      156  %,tensor<:70 4  = %xtensor<tt.transcst_1914  xx%:i469 32x {tensor<, 1order4#x = xblockedf32array<321, ix>#32i linear: 16to>1,  
, #tensor<      0ttg4%>.x102}slice<{dim = 2, parent = #blocked4}>1 =  >xtt.clampf:
i        64%tensor<%, 10032158#,x = blocked 4tt.bitcast1%x >cst_18i%
,8157       ,  %%#:23cst_23linear  = ,1tensor<tt.make_range >4 {propagateNan xend ->32 = = x128 tensor<i : none416i x, 32:32#,  xttgstarttensor<i. = 48slice<{dim = 2, parent = #blocked4}>0x, > : 4# ixttg->321. }xslice<{dim = 2, parent = #blocked4}>tensor< f32>4:, 
x #      32tensor<blocked%x128>71bf16x
 = , i      tt.splat#32% ttg, 103%.# = 29slice<{dim = 2, parent = #blocked4}>ttgarith.fptoui >. :
slice<{dim = 0, parent = #blocked1}>%       >101!%
 tt159      :. = % ptr<bf16>tt.expand_dims24tensor<   = 4->%tt.expand_dimsx 158 4tensor< {%x4axis231x =  {x1282axisf32x :  = , !i0#linear> tt32 : to.}i ptr<bf16> 32tensor<, :}4#  xblockedtensor<:414 x>xtensor<1
32128x      xxi%bf16i872, 32,  = #, #tt.addptrttg#linear .ttg>%slice<{dim = 2, parent = #blocked4}>.
71>slice<{dim = 0, parent = #blocked1}>      , >% -> 104% -> = 28tensor< arith.fptoui 4tensor< :x1% 32x102tensor<x128 41x:xxi 128bf1632tensor<x, , 4!##xttblockedblocked4.41xptr<bf16>>>1, 

x#            f32blocked%%, 116025#> =  = blocked,tt.broadcastarith.extsi>    tensor<%%to415924 x  tensor<128::4x  xitensor<tensor<46441x, xx1#32128xblockedxxi11i8>x32, 
bf16, #      , #blocked%#blocked>73blocked1
 = 4>      tt.load> %  to105%->  = 72 tensor<arith.addi tensor<1 :4x% x128103tensor<32x,4xi x3264%128x, cst_29xbf16# !, blocked:tt#1 .blocked>tensor<ptr<bf16>4
4, >      x#
%4blocked      26x1% = 1>161tt.broadcastx
 =  i      tt.trans%8% 22, 74% # = 160:lineartt.splat { > ordertensor<
% = 4      53array<x% i1106:32x =  : iarith.addi!064 tt, , %.2#104ptr<i8>, blocked, 11 ->>>% } csttensor< -> 64: :x tensor< 32tensor<4tensor<x4x4!x128xtt32x4.xixptr<i8>32641, x, x#bf16#iblocked, blocked86#1, >blocked>#
4
blocked      >      >% %
75->27       =   = %tt.addptrtensor<tt.broadcast107 4  = %x%arith.subf743225 ,x % 32:cst_6%x ,52bf16tensor<  , 1%:#x102 blocked128 tensor<9x:64>i x
64tensor<32      , 4x%#x!162blocked4tt = 1x.tt.reshape>1ptr<i8>  x, %->f32#161 , blocked tensor<#6:4blocked> x>,tensor<128
 4x      tensor<xi%643264108xx,  = 3232#math.exp2xxblocked ibf161%64, >107, #
 #blocked      :blocked9% 6>28tensor<>  = 4
->arith.addix        4%tensor<%x76128261 = x,xtt.load32 f32 x%, %bf1627#75,  blocked #:>cacheModifierblocked 
 5tensor<      =>4% 
x109cg      128 =  %xarith.extf:163i   = 64%tensor<amdgpu.scaled_upcast_fp4, 7864 # x%blocked:32771 x >tensor<!scale
4tt       x.%%4ptr<i8>16229x,  { = 32#axistt.addptrxblocked =  bf1660%, > : arg0#
i,blocked      32 >%}% 77 18to = :  ttg.convert_layout :tensor< tensor< 4%64!x76xtt4 32.x:xptr<bf16>32 i,xtensor<8 f3264, i, x#64#32blocked
blockedx3      >i>%
8,30      ,   = %#tensor<arith.muli110blocked128  = 6x%tt.broadcast>329  x,%->bf16 108 , % tensor<#c32_i32:64blocked  x5:tensor<32> 4x ixi->3248 
x, tensor<      1#128%xblockedx31f32332 = , >xtt.make_range#
bf16 {blocked      , end>%# =  78blocked32-> = 5 :  tt.reshape>itensor< 
324%      , x73%start4 164 = x: = 032 arith.cmpi : xtensor< if324eq32, x,}#128  blockedx%:>bf1670 
, ,tensor<      # 32%blocked%x1111cst_20i = > 32arith.mulf :,  -> #% tensor<ttg109tensor<4.,4xslice<{dim = 0, parent = #blocked6}> x32>%4x
110xi       328%:x, 32 bf16# = tensor<, ttgtt.make_range4#. {xblockedslice<{dim = 2, parent = #blocked4}>end4>> = x

3232             : x%%if327916532,  =  = , #math.absftt.expand_dimsstartblocked   = >%%0
78164 :         {i%:axis32112  = } = tensor<2 tt.bitcast4 : : xi %432tensor<111x}32 32 x:x:i bf16 32tensor<, tensor<, 4#4#xblockedxttg4>32.x
xslice<{dim = 0, parent = #blocked3}>32      i>x%1
f3280,       ,  = #%#arith.extfttg33blocked . = >%slice<{dim = 2, parent = #blocked4}>tt.make_range 79> {->  end :-> = tensor<  324tensor<tensor< : x44i4xx32x432, 32xxstartx321 = ixx032bf16i : , , 1i##, 32blockedblocked#}>>blocked 
 4:      to> % 
tensor<113tensor<      32 = 4%xarith.andix166i 4 = 32%xtt.broadcast, 11232 #,x%ttg f32165.%,  slice<{dim = 1, parent = #linear1}>cst_7#:> blocked 
:>tensor<       
4%tensor<      x344%32 = x81xtt.splat4 = 1 x"x%32ti30xt1 i., :32r# , eblockedi#d432blockedu> >c ->
e->       " tensor<%(tensor<32114%4x = 80xiarith.shrui)3232  <x, %{32#112axisxttg, = i. 21slice<{dim = 0, parent = #blocked6}>% : , >cst_8i#
 32blocked      :}4% >>35tensor< (
 = 4{      tt.splatx
% 4      167%x^bb0 = 3032(tt.trans x% :iarg16% 32: 166i, f32 {32#, order blocked% = ->>arg17array< 
: itensor<      f323232%): x115:0i = 
, 32arith.andi        2,  %, #%2091ttg114 = >.,arith.maxnumf}slice<{dim = 1, parent = #linear1}>   >%%:
cst_9arg16        ,tensor<%: 436 %x = tensor<arg1732arith.addi4 x x:32%4 x34xf32i,32
1 x        , %itt.reduce.return#3132 blocked , %4:#209> blocked  tensor<>:->32
  x      f32tensor<i%
432116      x,  = }32#arith.andi)xttg  : 32.%(xslice<{dim = 0, parent = #blocked6}>112tensor<i>,41
 x,       %4#%cst_10xblocked37 329 = :x>arith.addi f32
 tensor<,       %4#%35xblocked168,4> =  x) -> tt.reshape%32tensor< 33x4% ix167:324  , x:tensor<#f32 32blocked, tensor<x>#4i
ttgx32      .32, %slice<{dim = 2, parent = #blocked}>x#117>32ttg = 
x.arith.addi      islice<{dim = 1, parent = #linear1}> %1>%82, 
115 = #      ,ttg.convert_layoutblocked%  938%%> = cst_1181 tt.splat  -> :: %  tensor<arg5tensor<tensor<128 44x:xx32 44xixxi3232f321 x, , ->i## 32ttgblockedtensor<, .532#slice<{dim = 2, parent = #blocked}>>xblocked>
i>       32
->%,        169#%tensor< = ttg1184arith.select. = x slice<{dim = 0, parent = #blocked6}>arith.subi4%> x168
%f32,       cst_12, %%,#cst_2139 ttg,  = %.%tt.splat117slice<{dim = 2, parent = #linear}>163  > : %:
tensor<arg5       128 tensor<%x:48332 x = xi4tt.expand_dimsi32x 1 32%, ->x82# i {blockedtensor<32axis532,  = >x#2, iblocked : tensor<32>i128, 
32x#      }32ttg% x.119:bf16slice<{dim = 1, parent = #linear1}> =  , >arith.cmpitensor<#
 4blocked      ultx5%,4>40 x
 = %f32      arith.remsi115, % ,#170% ttg = 36%.ttg.local_alloc,cst_12slice<{dim = 2, parent = #linear}>   >%%: 16938 ->  tensor< ::4tensor<  x4(tensor<4xtensor<32x4128x32xxix13232ixx, 32f32bf16#, , , ttg###.blockedlinearblockedslice<{dim = 0, parent = #blocked6}>>>5>

>
            )      %% -> %12084!41 =  = ttg = arith.shruitt.expand_dims.arith.remsi  memdesc<128x32xbf16, #shared, #smem> %%
%11681      37, {%, axis171 % =  = %cst_112ttg.local_load39  :   :i%: 32170 tensor<} tensor<4 :32x: x4 !ixtensor<ttg32324., xxmemdesc<128x32xbf16, #shared, #smem>#i4 ttg32x->., f32 slice<{dim = 1, parent = #linear1}>#, tensor<>blocked#128
>ttgx      
.32%      slice<{dim = 2, parent = #blocked}>x42%>bf16 = 121 , arith.muli = -># arith.ori ttg% tensor<.7%4dot_op<{opIdx = 1, parent = #blocked3}>,120x> ,4
% x      5%1% cst_13x172: f32 =  :, tt.doti # 64tensor<blocked%
4>155      x
,%4       43x%% = 3285171tt.make_rangex = , {itt.bitcast end32 % = , %cst_364#83  : blocked :i>: 32
 tensor<,       tensor<4start%4x = 122x1280 = 4x : arith.shruixbf16i 1, 32%x#}121f32ttg ,, .: #dot_op<{opIdx = 0, parent = #blocked3}> %linear>tensor<118> 64  *x:-> i  tensor<32tensor<tensor<128, 44x#xx32ttg44x.xxbf16slice<{dim = 1, parent = #blocked6}>321, >xx#
iittg      3232.%, , dot_op<{opIdx = 1, parent = #blocked3}>44##> = blockedlinear tt.expand_dims>>-> 

 %            tensor<43%%4 {12386xaxis =  = 32 = arith.selecttt.bitcastx1  f32 : %%, i11984#32,  blocked}%:3 122 >:, tensor<
 %4      tensor<116x%64 : 4173xtensor<x = i41arith.addf32xx , 4f32%#x, 172ttg32#,.xblocked slice<{dim = 1, parent = #blocked6}>i>%>1 cst_3 , -> -># : blockedtensor< tensor<>4tensor<64, x4xtensor<4x14x32xx1xi4xf3232xi, , 3232##x, blockedblockedi#3632blocked>>, >

#
            blocked      %%>%17445
87 =  =        = arith.truncfarith.extsi%arith.addi  124 %% = %17344arith.maxui85   ,::%   115%tensor<tensor<,cst_28464  xx%:321cst_14 xx tensor<f32i:4, 32 x#, tensor<4blocked#4x3blockedx1>64x >xito 3232 tox, tensor< i#4tensor<32linearx64, >32x#
x1blocked      bf16x>%, i
88#64       = blocked, %arith.addi3#125 >blocked = %
6arith.subi86      > ,%
% 175      124% = %,cst_1arith.extsi46    = %:%tt.expand_dimscst_14 13  tensor< %:4:40 x  {tensor<4tensor<axis4x4 = x1x04xi : xi32i3232, 32x, #}i#ttg 32blocked.:, >slice<{dim = 1, parent = #blocked3}> #
>tensor<blocked       32>%tox
89 i       = tensor<32%tt.bitcast4, 126 x# = %ittgarith.shli8764.  , slice<{dim = 0, parent = #blocked6}>%:#>125 ttg ,tensor<.-> 4slice<{dim = 1, parent = #blocked3}> %x>tensor<cst_154
1 x      x:1%32 x176xtensor<i = i432arith.extsi32x,  , 4#%#xlinear11blocked32> 6x :>i-> 
32 i      , tensor<32%#4 47blockedxto = >4 tt.splat
xi       164%%x
arg10127i        = 32%:arith.shrui, 177  # = i%lineartt.splat32123>  ,
%->       176 %% tensor<cst_1690:1  =  x:tt.bitcasti32  64xtensor<% i488->32x  , 4:tensor<#x 4blocked32tensor<x6x4i>ix64
324,       , x#%#1ttg48blockedx. = >islice<{dim = 1, parent = #blocked3}>arith.muli
32>       , 
%%#      46128blocked%, = >178 arith.ori  = % ->arith.addi47%   126tensor<%:,4177  x,tensor<%4 1127x%x 117532:x x i:itensor<32 324, tensor<, x#4#4blockedxblockedx>i632
64>x      , 
i%#      3291ttg%,  = .49#arith.andislice<{dim = 1, parent = #blocked3}> = blocked >arith.extsi>%
 
89      %      ,%48% 179 129% = : = cst_27arith.extsi arith.addi  tensor< :%1% 32x128tensor< 32,4:x x i%4tensor<32cst_11x32,  1x#:xiblocked i326tensor<32, >4, # x#ttgto4linear. x>slice<{dim = 0, parent = #blocked3}>tensor<32
>1x       xi%to323292 x,  = tensor<i#arith.andi3264blocked x, >%i#
9064blocked      ,, 6% #>130%ttg
 = cst_4.      arith.shrui slice<{dim = 0, parent = #blocked3}>% :>50% 
 = 129tensor<      tt.broadcast,4%  x180%%4 = 45cst_11xarith.extsi  1 ::x%  i30tensor<tensor<32 644, :xx# 14blockedixx>32i32
 64x      to, i% #3293iblocked,  = 646#tt.bitcast
>blocked        >%%->
91181         = tensor<%:tt.splat64131  x = tensor<%32arith.minui4180x x i%4:64130x , ,1i# x64blocked%i 6cst_2232->> ,  
:#tensor<       linear32%tensor<>x514 i = x->64tt.broadcast4 ,  xtensor<#%324ttg49xx. i4slice<{dim = 0, parent = #blocked3}>:32x> , 1
tensor<#x      1blockedf32%x>, 18232
# = x      lineararith.addii%> 64132
%,  =       181#arith.shrui%,blocked 94 6% = %>113tt.bitcast179 ,  -> %: %92 tensor<cst_17 tensor<64 :32x: x32 tensor<ixtensor<464i4x, 64x4#, 4xttg#x1.blocked32xslice<{dim = 0, parent = #blocked3}>6xi>>i32

32,             , #%%#blocked18352blocked> =  = > arith.muliarith.addi
->         %%%tensor<7501334,, = x  arith.ori4%% x651%1  132x::,f32   , itensor<%#6464131blocked
x >      32:
%x       184itensor<% = 64495tt.addptr, x =  #4math.log2%blockedx arg2632%,>x93 
i %      32:183%,   53#tensor<: = blocked4 tt.addptr>x! 
4tt%      x.arg1%1ptr<bf16>,134x,  = f32 %arith.trunci, i42 #64 %linear
:133>        
%!:      185tt % = .tensor<96tt.expand_dimsptr<i8>4 =  ,xmath.log2% 4 178ix% {643294axis
x  =       i:1%32  : 54, tensor<i = #432arith.extsiblockedx} >4 % x:arg14to1   xtensor<:tensor<f324 4, xix#i324blocked64 x>, to32
# x      ttgii%.64897slice<{dim = 1, parent = #blocked3}>
,  = >      #math.floor %blocked ->55>%  = 
95tensor<arith.muli       4 %:x%135 17 = tensor<x,tt.reshape4i  x64%%4, 54134x#  1blocked::x3  f32>itensor<, 
644#      
xlinear%      4>186%x
 = 5632      arith.extsi = x% tt.addptri98% 8 = arg13%, math.floor arg3# :,blocked%  >96i%  3255->:    to:tensor<tensor<  44i!xx64tt44
.xx      ptr<i8>161%,xx187 2f32 = ix, tt.expand_dims64i# 
8blocked%      , >175%#
 {57blocked      axis = 7% = tt.expand_dims>991 
 =  : %      arith.subfi41% 32 {outLHS%}axis, 97  = %,:1outRHS   :  = %tensor<itt.splitcst_26432  x}%:i 135 64: tensor<,  :4#tensor< xttg32tensor<4.x4xslice<{dim = 1, parent = #blocked3}>ix1>324x , xf32->#16,  ttgx#tensor<.2linear4slice<{dim = 1, parent = #linear1}>x>x>i
1 8      x->, %i #10064tensor<blocked = , 327arith.subf#x> blocked1 %3x->98>i ,
32tensor<       , 4%%#xcst_5188linear4  = 1x:arith.muli>16  
xtensor<%      i4186%8x,58, 4  = #x%tt.splatblocked1176 2x %>f32:arg15
,         #i:%blocked64 136>
i = 
      32arith.shli      %  %189->%101 =  outRHS = tt.splattensor<,tt.clampf 32  %x%%1861cst_299 x ,:i:  32 %i, tensor<cst_2564#4, linearx ->14% >xcst_24tensor<
16,4      x x%ipropagateNan1598 x = , =iarith.muli# 64 blockednone, %2 #57>:blocked,
 3       tensor<>%%4
58137x        = 4%:arith.orix190  1 = tensor<%xarith.muli32outLHSf32 x,, %1 #189x%linear,i136> 32 
%, :      187# % lineartensor<102:14 =  >xtt.clampftensor<
4 4      x%x%16100160x,x = i iarith.extsi8%64 , cst_18, %#,#59blocked blocked 2%3:>cst_23> 
,
tensor<             32%propagateNan%x138 1911 = = = xtt.reshape tt.addptri none 32% %, 137:184#  ,linear:tensor< 1 4%>tensor<x188 44 toxx: 41 tensor<xx!3216f32ttxx, .1i#ptr<bf16>x8blocked,i, > 64#
i, blocked      64#2%
linear>103      1  = %>->arith.fptoui192
   =       tensor<%tt.expand_dims%4101 61x % = 64:182tt.make_rangex  { {itensor<axisend84 =  = , x04#4 :  : blockedxii813232>x}, 
f32 start      , : = %# 0139lineartensor< :  = >32itt.reshape x32 toi}% 64 105tensor<, : 4# :xttgtensor< 4.4tensor<xslice<{dim = 0, parent = #blocked3}>x41>ixx 324i->, x8 #1, tensor<ttgx#1.ilinearxslice<{dim = 0, parent = #linear1}>8>32>, 
x
#      i      linear%64%>104, 62  = # = ->arith.fptouiblockedtt.broadcast  3 tensor<%>%4102
60x        4:%:x 193 itensor< = tensor<84tt.broadcast32, x x#4%1ttgx190x.1 islice<{dim = 2, parent = #blocked}>x:64>f32 , 
, tensor<#      #4linear%blockedx1140>1> =  x tt.reshapetoi->  64 %tensor<, tensor<1064#32 xblockedx:434 x>xtensor<1 i4x->64xi , 48tensor<#x, 4linear1#x1xblocked32>i>x
8
i      ,       64%#%, 63blocked105# = > = blockedtt.expand_dims arith.addi3 -> >% %
61tensor<103       {4,%axisx 194 = 4% = 0xcst_29tt.expand_dims : i  i8:%32,  179}#tensor< { linear4axis:2x =  >40tensor<
x : 4      1ix%x32i141i}32 = 8 , ttg.convert_layout, :# # ttg%lineartensor<.140>32slice<{dim = 0, parent = #linear1}> 
x>:      i  %64->tensor<106,  4 = #tensor<xarith.addittg14 .xx%slice<{dim = 0, parent = #blocked3}>4i104>x8, i,  ->32#% , linearcsttensor<#2 1linear>:x1  32>->tensor<x
 4i      tensor<x64%44, 64xx# = 41blockedtt.broadcastxx3 ii>%88
63, ,        ##%:ttgblocked195 .> = tensor<slice<{dim = 2, parent = #blocked}>
tt.broadcast1>       x
%%4      107194x% =  i142arith.subf:32 =   , arith.extui%tensor<# cst_61linear%,x1141 32> %x :102i->  64 tensor<:, tensor<4 #32xtensor<blockedx4434xx>xi4 i8x->32, 1 , #xtensor<#ttgf324linear., x1slice<{dim = 2, parent = #blocked}>#32>>blockedx
 >i      to
64%       , 65tensor<%# = 4108blockedarith.extsix = 3 4math.exp2>%x 
64i%       16107%:,  196 #: = tensor<ttg tt.addptr32.tensor< xslice<{dim = 2, parent = #blocked}>4%4>x191x
4,i      x 32%1%, 143x180# = f32 lineararith.shli, :1 # >%blocked! 142>ttto,
.        ptr<bf16>tensor<%%,32cst_30109 x  = i4:arith.extf64x  
itensor<%      64478%, x 197#4: = linearx arith.addi1itensor< >164%
, x195      #4,%ttgx 66.32% = slice<{dim = 2, parent = #blocked}>x193arith.addi>bf16  
, :%      # 65%blockedtensor<,144>4  =  x%tt.bitcastto3262  x %tensor<i:143464  x, tensor<:4#32 xblockedxtensor<32344x>xxf32
i4,       64x#%, iblocked198#16> = linear, 
arith.extsi1#       >ttg%%
.110arg4      slice<{dim = 2, parent = #blocked}> =  %>tt.broadcast:67    = ->%itt.splat 10832 tensor<  %4:to56x   4tensor<i:x464 bf16x
!, 4      tt#x%.ttg1199ptr<i8>.x =  slice<{dim = 2, parent = #blocked}>f32tt.splat->>,   
#%tensor<      blocked19832%> x145 :4 = -> xtt.expand_dims i! tensor<64tt%4 .144x->ptr<i8> {4 , axisxtensor<# = 324linear2xx1 : f321>i, x
32#i      }blocked64% >, 68:
# =        blockedtt.addptrtensor<%3 4111>%x = 
674arith.mulf      ,x % bf16%200%, 109 = 66#,arith.cmpi ttg  :.%slt slice<{dim = 2, parent = #blocked}>110,tensor<>  32 :%x-> 1854 tensor<,xtensor<4 !4x%ttx4199.4x ptr<i8>x32:, 1x #xf32tensor<linearbf16, 41, #x>#blocked1,blocked>x >
itensor<
      6432      %, x%112#4146 = blockedx = tt.bitcast3itt.broadcast >64 %
, %111      #145 %linear :2011:  = > tensor<arith.extsi
tensor<4       4x%%x4arg5694x  = x32:tt.load1x  xf32i%bf16, 3268, #  #blockedto:blocked>  > itensor< ->6432-> 
x tensor<      4tensor<4%x4x202!x4 = tt4xtt.splat.x32 ptr<i8>32x%, xi201#bf1632 linear, , :1## >blockedblockedi
>>64      

 %            ->70%%  = 147113tensor<tt.trans =  = 1 tt.reshapearith.andix%  3269%%x {146112iorder ,64 = : , array< %#itensor<cst_7blocked324 3: x:>14 
, xtensor<      0324%>xx203}bf164 =  , xarith.cmpi:#32  blockedxslttensor<>i,32 32 x->, %4 #192xtensor<blocked,i4> 8x
%, 128      202#x% linearbf16114:1,  =  >#arith.shruitensor< blocked 1->1%x >11232tensor<
,x4       ix%%6432148cst_8, x =  #iamdgpu.scaled_upcast_fp4:blocked8  3, %tensor<>#1384
ttg x      .scale4%slice<{dim = 2, parent = #blocked4}> x204>%32 = 
147xtt.broadcast       {i %axis32%71 = , 200 = 1# tt.splat : blocked: i> %32
tensor<29}      4  %x::1151   = x!tensor<arith.andiitt4 1.x%, ptr<bf16>64114# x,blocked->i 3 8%>tensor<, cst_9 4# ->xblocked: 1288 tensor<x>tensor<4!,4xtt x32.tensor<4xptr<bf16>4xi, x321#128x, blockedxi#1bf1632blocked>, , 3
##>      blockedblocked
%1>      72>
% =        205tt.addptr->% =   116tt.broadcast%tensor< =  714arith.andi%,x 203 128% %x112:28bf16,  ,  tensor<:#%1 blockedcst_10xtensor<1 324>:xx
 i128      tensor<1x%4, !149x#tt = 4blocked.arith.cmpix3ptr<bf16> 32>, eqx #,i->blocked 32 1%, tensor<>139#4,,blockedx  >32tensor<%
x4cst_31      ix %1128:117, x  = #itensor<arith.addiblocked644 3, x%>#4115
blockedx,      1i %>8%206
, cst_11 =       # arith.andi%ttg: 73. % = slice<{dim = 2, parent = #blocked}>tensor<204tt.load>4, 
x %      4%72%x205 15032 : = x: tt.expand_dimsi tensor< 32tensor<4%, 4x149#x128 {blocked32xaxis>x! = 
itt2      1. : %, ptr<bf16>i118#, 32 = blocked#}arith.subi3blocked  >1:%
> cst_12      
tensor<,%      4 207%x% = 744117tt.splat = x  tt.splati:% 1 196%, tensor< 53#4: ttgx :.4! slice<{dim = 2, parent = #blocked}>xtt!>32.tt xptr<bf16>.->i ptr<i8> 32-> tensor<,  ->4#tensor< xblocked4tensor<4>x64x
32x1      x32x%!xi119tt!1 = .tt, arith.cmpiptr<bf16>.# , ptr<i8>blockedult#, >,blocked#
 3blocked      %>6%115
>151,      
 =  %      tt.broadcast%208% cst_12 = 75% tt.addptr = 150: tt.addptr  % :tensor<207% 4,74tensor<x ,44% xx197%432 52xx: 1i :x32tensor< i, 4tensor<1#x64, blocked32x#>x32blocked
!x>      tt! %.tt->120ptr<bf16>.  = , ptr<i8>tensor<arith.shrui#, 4 blocked#x%3blocked4116>6x,,>32  ,x%tensor< icst_114tensor<1 x64, :32x# x32blockedtensor<ix>464i
x, 64      4#, %xblocked#152323blocked = x>6tt.reshapei
> 32      
%, tt.store      151# % blocked%76:>208 =  
,tt.loadtensor<        4%%%x121174754 = , xarith.ori cacheModifier32 % x%206=i120  1,:cg,    #%tensor<:blockedcst_134 > xtensor< :3264-> xx tensor<!32tensor<4ttx4x.!x4ptr<bf16>tt128x, .x32#ptr<i8>ixblocked, 1i3#, 32>blocked#, 
6blocked#    >1blocked}
>>
      

    %            tt.return77%%
 = 153122  ttg.convert_layout =  = } arith.selectarith.shrui
%  }76%%
 152121
:, ,{-# % 
tensor<cst_0%  64, 118externalx% _resources: {32148:
x :      itensor<tensor<mlir_reproducer844: {, xx
#1284      blockedxxpipeline6i32: >1x" , ib->#32u blocked, itensor<1#l64>blockedtx, >i32tensor<
nx4      .ix%m8128123o, x = d#bf16arith.selectublocked,  l3#%e>blocked119(
1, o      >%p%
122t78      , i = %%mtt.reshape154116i  =  : z%ttg.local_alloctensor<e73 4- %xa:1534m  xdtensor<:32-4 xlx(id128tensor<1sx4, -bf16x#u, 128blockeds#x>ablockedbf16, g1, tensor<e>#4{ blockedxl->14d >xstensor<)32-4 -> xlx!ii4ttg32mx., i32memdesc<4x128xbf16, #shared, #smem>#tx
blocked=bf16      >0, %
 #155      tblocked = %a>ttg.local_load124r
  = g      %arith.maxuie%154 t79 %- = :115amath.absf ,r ! c%ttg%h78.cst_14= memdesc<4x128xbf16, #shared, #smem> g: :f -> xtensor< tensor<94tensor<45x4x04x4}x128x,32x32 xbf16xtbf16, ir, #32i#ttg, tblocked.#o>dot_op<{opIdx = 0, parent = #blocked3}>blockedn
>>-      

s%            c80%%f = 156125-arith.extf =  = t arith.extuiarith.subio%  -79%%c 70124f: ,, :  tensor< %c4tensor<cst_14ox4 n4x:vx32 e32xtensor<rxi4tbf168x-, , 4i##xnblockedttg32d>.xe slice<{dim = 2, parent = #blocked4}>ixto>32-  , ttensor<to#o4 blocked-xtensor<>l44
lxx      v3232%mxx126{f32i = i, 16arith.shlin#,  dblocked#%e>ttg125x
.,-      slice<{dim = 2, parent = #blocked4}> b%>%i81
cst_15t =        w"%:it157 dt = tensor<t.arith.shli4hr x=e%40d156x}u,32,c x e%ia"cst_1932l( , l%:#o80 blockedc)tensor<>a <4
t{x      eaxis32%- = x127a2i = m : 16arith.shruidi,  g32#%p}ttg123u>.,- (slice<{dim = 2, parent = #blocked4}> s{>%h

cst_16a             r^bb0%:e(158 d% = tensor<-arg16tt.bitcast4m:  xef32%4m, 157xo% 32rarg17:xy:  i,f32tensor<32 )4, c:x#o
32blockedn        x>v%i
e20916      r = , %tarith.maxnumf#128- ttg = t%.arith.orirarg16slice<{dim = 2, parent = #blocked4}> i,>%t  126o%->,narg17  - tensor<%a:4127m x df3232:g
x p        bf16tensor<utt.reduce.return, 4- #xt%ttg4o209.x- slice<{dim = 2, parent = #blocked4}>32l:>xl 
ivf32      32m
%, {      159#a} = blockedr)tt.expand_dims>c :  
h(%      =tensor<158%g4 {129fxaxis = x4 = arith.addi9x2 532 : %0xi128 f3232,f, } t# %zblocked:cst_11=>  t) -> tensor<:rtensor<4 u4xtensor<ex324}4xx,xbf164 f32, xc, #32a#ttgxnttg.io.slice<{dim = 2, parent = #blocked4}>32nslice<{dim = 2, parent = #blocked}>>, i> #c
->blockeda       >l%tensor<
i824      z = x%ettg.convert_layout32130{ x =  %1arith.shrui 81x m bf16%a:, 129x #,-tensor<blocked i44%tx>cst_11e4
 rx      :af32% t, 160tensor<i# = 4ottgtt.broadcastxn. 4sslice<{dim = 2, parent = #blocked}>%x=>159321  x0->:i   32mtensor<tensor<, a44#xxxblocked-432>nxx
uf321      m, x%-#bf16131rttg,  = e.#arith.minuiwslice<{dim = 2, parent = #linear}>blocked r>4%i
>130t       ,e%-> s83 %= = tensor<cst_22-tt.expand_dims4 1 x: %32 r82xtensor<e {324gaxisxxi = bf164o2, xn : #32-iblockedxs324ii}>32m 
, p:      #l %blockeditensor<161>f4 = 
yxtt.trans      =4 %nx%132of32160 = r,  {arith.shruim#order attg = %l.array<113 slice<{dim = 2, parent = #linear}>i,t>32 e : %s->0cst_17t ,  -tensor<2:c4,  ox1tensor<n4>4vx}xe1 4rx:xgf32 32e, tensor<xn#4iclinearx32e>32, =
x#f      32blockeda%x>l84bf16
s = ,       ett.expand_dims#%  blocked133t%4 = o81>arith.orip {  -axis->%d =  132o2tensor<,w : 4 nix%=3232131t}x r 32:u:x e bf16tensor<}tensor<, 4,4#x xblocked4c49xsx>32ef32
x,,       i #%32cttg162, o. = #nslice<{dim = 2, parent = #blocked}>tt.reshapeblockedv> >e %
r->161      t  %-tensor<:134c4  = fxtensor<arith.trunci-44 txx%o132133-xx lf3232:l, x v#bf16tensor<mblocked, 4{>#xi
blocked4n      9xd%>32e85 xx = ->i-tt.bitcast 32b tensor<, i%128#t83xblockedw 32>i:x d bf16tottensor<,  h4#tensor<=xblocked4045x}x>4,1
x x      32cf32%xo, 163in# = 8vlinearamdgpu.scaled_upcast_fp4, e> #r %blockedt->77>-  
atensor<scale      r4 %ix%135t4162 = hx {tt.reshape-1axis tx = %oi0134-32 :  l, i:l#32 vlinear}tensor<m> 4{
:xi       4n%tensor<xd866432e = xxxtt.bitcast32i- x8b%i, i848#t , blockedw:#>i blocked dtensor<3->t4> hx,tensor<=4 40xtensor<x}11284,xxx f323216c, xxa#bf162nblocked, xo>#in blocked8i->5, c >#atensor< blockedl4->7ix >z4tensor<
ex128      {1x% x32outLHS ix, m32bf16%a, , outRHSx## = -blockedblockedtt.spliti>5 t
>%e      
135r%       a87%:t = 164 iarith.addi = tensor<o arith.cmpi4n% xs85eq4=,,x1  160%%x cst_28702m ,xa: ix %8-tensor<cst_20, n4 #ux:blockedm4 7-xtensor<>r14 exx->wi32 r32xtensor<i, i4t#8xelinear, 4s>#x=
ttg16-      .x1%slice<{dim = 2, parent = #blocked4}>i 88>8r = 
, earith.addi      #g %blockedi%1652o86 = >n,tt.expand_dims
-        s%%%icst_1164136m  { = p:axisarith.shlil  =  itensor<2%f4 : outRHSyxi,=432 nx}%o1 cst_2rx: mi :a32tensor< l, 4tensor< #x4tblocked32xe>x4s
ixt      116-%, xc89#io = ttg8ntt.bitcast., v slice<{dim = 2, parent = #blocked4}>#e%>blockedr87 2g ->>e: 
n tensor<      ctensor<4%e4x137=x32 = f4xarith.oriax1 l1x%sxioutLHSei1, 32,  t, #%o#blocked136plinear4 ->>:d 
 o->      tensor<w %4ntensor<166x=4 = 4txtt.broadcastxr4 16ux%xe1165i}x 8,i:,  32 #c, tensor<blockeds#42elinearx>,>32
 
x      s      1%y%x138m90i = b = 1tt.reshapeott.bitcast,  l #%-%blocked137d884 c >:e:  , ->tensor< tensor< 4e4tensor<xnx44a4xxbx3216l1xxex32i-ix8l32i, i, 1#n#, blockedeblocked#2->blocked>i 4 n->>->f 
 otensor<      tensor<,4%4 x167xc4 = 64oxtt.transxn1 ivx%8ei166, r32 {#t, orderblocked-# = 8bblockedarray<>u>i
i
32      l      : %t%0139i91,  = n = 2tt.reshape-arith.andi,  f 1%u%>105n89} c, :- : t% tensor<ocst_27tensor<4- 4xl:x4l 32xvtensor<x1m432x{xxif4i8tx1, z1, #=x#lineartiblocked>r324 u, >->e#  }linear->tensor<)> 4"
tensor<x,      44
%xx      9232idisable_threading = x8: arith.andi32, false x#,%ittg
901.      ,, slice<{dim = 2, parent = #blocked}>verify_each #>: %blocked
truecst_49      
 >%    }:
140
        =   }tensor<%tt.reshape
4168 #-}x = %
4tt.reshape106x  1%:/tmp/torchinductor_root/3f/c3fmhxf6ysutyyifnloyufszhidrz4yajr6m6axzqc2l4acsxboc.py:18:0x167 : i tensor<error: 32:4Failures have been detected while processing an MLIR pass pipeline,  x
#tensor<4/tmp/torchinductor_root/3f/c3fmhxf6ysutyyifnloyufszhidrz4yajr6m6axzqc2l4acsxboc.py:18:0blocked4x: >x1note: 
32xPipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`      xi
%32893x,  = i#tt.bitcast1blocked , >%# 91blocked-> 9 :>tensor<  4tensor<->x4 4xtensor<x4128ixx8132, xx#iilinear3212, , >##
linearblocked      >5% >141->
 =        ttg.convert_layouttensor<% 4169%x = 1404arith.select x :1% x168tensor<f32, 4, %x#cst_214linear, x>%i
1638       : , %tensor<#94128linear = x2tt.bitcast32> x %i->921  , tensor<:#4[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 5, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank5]:E1112 18:13:31.244000 511 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
 blockedxtensor<544>xx, i4tensor<8x128, 1x#x32ttgix.32bf16slice<{dim = 2, parent = #blocked}>, , >##
blockedblocked      >5% >142->
 =        arith.extuitensor<% 4170%x = 1414ttg.local_alloc x :1% x169tensor<f32 4, :x# 4blocked(x>tensor<i
1288      x, %32#95xttg = bf16.math.log2, slice<{dim = 2, parent = #blocked}> #>%blocked 935to > :)tensor<  -> 4tensor<!x4ttg4x.x4memdesc<128x32xbf16, #shared, #smem>ix
161      , x%#f32171ttg,  = .#ttg.local_loadslice<{dim = 2, parent = #blocked}>linear >>%

170             %%:14396  =  = !arith.shlimath.log2ttg  .%%memdesc<128x32xbf16, #shared, #smem>14294 , -> : % tensor<cst_30tensor<128 4x:x32 4xtensor<xbf1641, xx#4f32ttgx, .i#dot_op<{opIdx = 1, parent = #blocked3}>16blocked>, >
#
      ttg      %.%172slice<{dim = 2, parent = #blocked}>97 = > = tt.dot
math.floor        %%%15514495, =   tt.bitcast:%  171%tensor<,1434  x%:4cst_3 x tensor<1:4x xf32tensor<4, 4x#xilinear12816>x, 
bf16#      , ttg%#.98ttgslice<{dim = 2, parent = #blocked}> = .>math.floordot_op<{opIdx = 0, parent = #blocked3}>  >->%  96*tensor<  4:tensor<x 1284tensor<xx432bf16xx, 4bf16#x, ttg1#.xttgslice<{dim = 2, parent = #blocked}>f32.>, dot_op<{opIdx = 1, parent = #blocked3}>
#>      blocked %>->145
  =       tensor<tt.expand_dims%4 99x% = 32144arith.subfx { f32axis%,  = 97#2,blocked :  3i%>32cst_26
}        :%: 173 tensor< = tensor<4arith.addf4x x4%4x172x1,bf16x , f32%#, cst_3ttg# .linear:slice<{dim = 2, parent = #blocked}>> >
tensor<       4->%x 10032tensor< = x4arith.subff32x , 4%#x98blocked1,3x >bf16%
, cst_5      # %blocked:174>  = 
tensor<arith.truncf      4 %x%1464173 = x tt.broadcast1: x %f32tensor<145, 4 #x:blocked32 >xtensor<
f324      , x%#4101blockedx = 31tt.clampf>x  bf16%to, 99 #,tensor<blocked 4>%x cst_2532->,x  bf16tensor<%, 4cst_24#x,blocked4 3xpropagateNan>32 
x=      bf16 %, none175#  = blocked:arith.extsi>  
tensor<%      413%x 1474: = x tt.reshape1tensor< x4%f32x146, i #32:linear,  >#tensor<
ttg4      .x%slice<{dim = 1, parent = #blocked3}>4102>x =  32tt.clampftox  bf16%tensor<, 1004#,xblocked i>%64 cst_18, ->,#  ttgtensor<%.4cst_23slice<{dim = 1, parent = #blocked3}>x,>128 
xpropagateNan      bf16 %, =176#  = blockednonearith.extsi1  >:%
 11      tensor< %4:148x  = 4iamdgpu.scaled_upcast_fp4x32 1 %xto138f32  , iscale#64 blocked
%>      147
% {      177axis% =  = 103tt.splat1 =   : arith.fptoui%i 17632% }101:   ::i  64tensor<tensor< 44->xx 644tensor<xx4i1x8xi, f3264#, , blocked##8linearttg>>., slice<{dim = 1, parent = #blocked3}> to>tensor< 
4tensor<      x4%128x178x4 = bf16xarith.addi, 1 #x%blockedi17718,>,   #%ler_DP6_TP6: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
->linear175 > tensor<
:4       x%tensor<1281044x = xbf16arith.fptouii,  64#%, blocked102#1 ttg>:.
 slice<{dim = 1, parent = #blocked3}>      tensor<>%4
149x       = 4%arith.cmpix179 1 = eqxarith.extsi,f32  , %%#32139blocked ,>:   %totensor<cst_31 32 tensor<x:4i x32tensor<4, 4x#x1ttg4x.xislice<{dim = 0, parent = #blocked3}>i8>8,  , #to#blocked ttg>tensor<.
32slice<{dim = 2, parent = #blocked}>      x>%i
10564       = , %arith.addi#150 ttg = #%.tt.expand_dimsblocked103slice<{dim = 0, parent = #blocked3}>  = ,>%# 
149ttg%       {.cst_29%axisblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> 180 = 
: = 2# arith.extsi : blockedtensor< i14%32 = x30}#4  ttgx::.1  blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>xitensor<
i324#8 xblocked, to42# x = linearii#>641ttg

, .            #blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>%%ttg
106181.# =  = slice<{dim = 2, parent = #blocked}>blockedarith.additt.splat>3    = %%->#104180 ttg, tensor<. :4blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>% x
csti4# 64xblocked: 14 ->x = tensor< i#4tensor<1ttgx32, .4x#blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>xiblocked
164>#x, 
blockedi#      58ttg% = , .151##slice<{dim = 0, parent = #blocked3}> = ttgblocked>tt.broadcast.>
 blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
      %
      %150#%182 blocked107 = :6 = arith.addi  = arith.subf tensor<# %4ttg%181x.cst_6,4blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>, x
 %1#%179xblocked102 i7 :1 = : , # tensor<#ttgtensor<32blocked.4x>blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>xi 
464->#x,  blocked1#tensor<8xttg4 = f32.x#, slice<{dim = 0, parent = #blocked3}>4ttg#>x.blocked
32blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>>      x

%i#      1831blocked% = , 9108arith.muli# =  =  blocked#math.exp2%>ttg 7
.%,      blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>107 %
 %152#:6 = linear  tt.reshape = tensor<: #4 %ttgxi151.464 linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>x
:
1       #x%tensor<linearf3218441,  = x = #tt.addptr4#blocked xttg>%32.
arg2xlinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>      ,i
% 1#109%, linear = 183#2arith.extf blocked =  :>#%  ttg78!->. tt linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>:.tensor<
 ptr<bf16>4#tensor<,xshared4 128 = xix#464ittgx
1.32      , swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>x%#
bf16185blocked#,  = 1smem#tt.expand_dims> = blocked 
#>%      ttg 178%.to {153shared_memory axis = 
tensor< = arith.selectmodule41  attributesx : % {4i152"x32, t32}%tx cst_0gf32:, .,  %n#tensor<148ublocked4 : m>xtensor<-
i4c      64xt%, 128a110#xs = ttgi"tt.broadcast.1 =  slice<{dim = 1, parent = #blocked3}>, 1%># : 108 blockedi ->132: >,  tensor<, "tensor<4tensor<t4x4tx1xg4x128.xixn164bf16ux, , mf32##-, blockedblockedw#31ablocked>>r>

p             s->%%" 186154 = tensor< =  = 44arith.extsittg.local_alloc : x  i4%%32xarg13153, 32  ttg.targetx:: = f32  ", i(h#32tensor<iblocked 4p>tox:
 128g      ixf%64bf16x111
, 9 =       #5arith.mulf%blocked0 1871"% = >, 109tt.expand_dims)",  -> t %!t%175ttgg110 {.. axismemdesc<4x128xbf16, #shared, #smem>t: = 
h 1      rtensor< : %e4i155ax32 = d4}ttg.local_loadsx  -32:%px 154ef32tensor< r, 4:-#x wblockedi!a>64ttgr
, .p      #memdesc<4x128xbf16, #shared, #smem> "%ttg-> = 112. 64 = slice<{dim = 1, parent = #blocked3}>tensor< : tt.bitcast>4i  x32%->128}111 x  tensor<bf16{:4, 
 x#  tensor<1ttgtt.func4x. xidot_op<{opIdx = 0, parent = #blocked3}>public464> x, 
@32#      _batched_gemm_afp4_wfp4_pre_quant_kernelxblocked%(f323156%, > = arg0#
arith.extui: blocked       !>%%tt 18870.-> =  ptr<bf16> arith.muli: {tensor<  tt.divisibility4%tensor< = x1864164,x : x 32i32%x32x176i}i 8, 32:, %,  #arg1#ittg: blocked64.!>
slice<{dim = 2, parent = #blocked4}>tt
      >.      % ptr<i8>%189to {113 =  tt.divisibility = tt.splattensor< = arith.andi 416 %x : %18632i112 x32,:i}  16, %i, %cst_764#arg2  ttg: :->.!  slice<{dim = 2, parent = #blocked4}>tttensor<tensor<>.44
ptr<bf16>xx       {41%tt.divisibilityxx157 = 32i = 16x64arith.shli : i,  i32#%32, blocked156}#3,, blocked> %>
%arg3
      cst_19:       % !%190:tt114 =  . = arith.mulitensor<ptr<i8>arith.shrui 4 { %xtt.divisibility%18932 = 112,x16, i :  %16i%187, 32cst_8 #} :ttg, : .% tensor<slice<{dim = 2, parent = #blocked4}>arg4tensor<4>: 4x
ix1      324x%, xi158%3264 = arg5x, tt.bitcast: i# i32blocked%32, 3157 {#> tt.divisibilityblocked
: = >       16
%tensor< :       1914i% = x32115tt.addptr32} =  x, arith.andi%i% 18416arg6%,, : 114 #i,%ttg32 188. {% slice<{dim = 2, parent = #blocked4}>tt.divisibilitycst_9:> =    16:!-> :  tt itensor<.tensor<324ptr<bf16>4}x,x, 4 32%xixarg73264bf16: x
, ii      #3232%ttg {, 192.tt.divisibility# = slice<{dim = 2, parent = #blocked4}> = blockedtt.expand_dims>16> 
 : 
%      i      182%32% {159}116axis = ,  =  = tt.expand_dims%arith.andi0 arg8  : %: %i158i11232 {32,}axis {   = tt.divisibility%:2 = cst_10  : 16 tensor<i : :3232i x}32tensor<i }464:, x,  %4#tensor<arg9xttg4: 32.xixslice<{dim = 0, parent = #blocked3}>3232i>x {32 bf16tt.divisibility, ->,  = # #16blockedtensor<ttg : >1.i
xslice<{dim = 2, parent = #blocked4}>32      32>}%x , 117i->% = 64 arg10arith.addi, tensor<:  #4i%blockedx32115332 {,>xtt.divisibility 
1 = %      x16cst_11%bf16 :  193, i: = #32 tt.broadcastblocked}tensor< 4, 4%>%x190
arg114       : x:%i32 16032xtensor< =  {i4tt.broadcasttt.divisibility32x  = , 1%16#x159 : blockedi i>64:32
,  }      #tensor<, %blocked4%1183xarg12 = >32: arith.subi xi ->132% x {cst_12tensor<bf16tt.divisibility,4,  =  x#16%32blocked : 117x4i i>32:64 } , ->, tensor<# %4blockedtensor<arg13x34: 4>xix
323232      x {x%32tt.divisibilityi194x = 32 = bf1616, tt.expand_dims,  : # #iblocked%blocked32>1794}
 {>,       axis
%% =       arg141190%:  =  : 161iarith.cmpii = 32 32tt.trans {ult} tt.divisibility, % =  :16016%  { : 115tensor<orderi,32 = 32 xarray<}%ii, cst_126432% , : arg15:#0:  ttg, itensor<.2324slice<{dim = 0, parent = #blocked3}>, )x>1 attributes4 > {x->}noinline32   = xtensor<:falsei1 }32xtensor< , 324{#xx
blockedi32    >64x%
, 32cst      #x = %blockedbf16arith.constant1203,   = >#dense<arith.shrui
blocked127       4>%%> : 116195 tensor<, = ->4 tt.broadcast x% tensor<4cst_11%4x 194x1: 32x :xitensor< 3284tensor<x, x1bf16#4x, blockedx32#>32xblocked
xi9    i64>%32, 
cst_0, #       = #blocked%arith.constantblocked3162 >> = dense<
 tt.reshape0x7FC0      -> >% % : 121tensor<161tensor< = 4 4arith.orix:x 32 128%xtensor<x120i4bf16,64x,  , 32#%#xblockedcst_13blocked321 3x>:>bf16
 
,     tensor<      #%4%blockedcst_1x1969 = 4 = >arith.constantxtt.addptr  32 ->dense<x% 2097152i191tensor<>32,128 : ,  xtensor<#%324blocked180xx> bf164
:, x       #1%!blockedx122tt5i = .>32arith.shruiptr<bf16>
,  ,      #% %blocked121i163>,64 = 
 
amdgpu.scaled_upcast_fp4    %       %118%%cst_2 19777 = : =  arith.constant arith.addiscale tensor<  dense<4%%4x195162>4, { : x axistensor<32% = 4x1930xi  : 432:ix,  3216#tensor<}xblocked4 i>x:8
32 ,       xtensor<#%i64blocked12364x2 = , 32>arith.select#x
 blockedi    %38%119>, c31_i32, 
# = %      blockedarith.constant122%3 , 198>31% = , : 116arith.extsi i :  tensor<32tensor<%128
4arg4x    x 32%4:xcst_3x bf16 = 32i, arith.constantx32# i blockeddense<1to50.000000e+00,  >>#i  : blocked64->tensor<>
 4,       tensor<xtensor<%128324199xxx = 32f324tt.splatx, x bf16#32%, blockedx198#3i blocked>32:5
,  >    #i
%blocked64      c32_i32> % = 
->164arith.constant        =  %tensor<arith.cmpi321244  :  = xeqiarith.maxui1,32 x 
%i%    1156470%,, ,c4_i32 #  = %blocked%arith.constantcst_143cst_20  > 4:
: :         itensor<%tensor<3242004
x = x    4arith.cmpi32%x xtrue32slti = x,8arith.constanti ,  32%#true, 185ttg
#,.    blocked slice<{dim = 2, parent = #blocked4}>%>%>c0_i32
199
 =              arith.constant%:% 125 1650 = tensor< =  : arith.subi4tt.expand_dimsi x 32%1%
124x164    ,i {% 64axiscst_4%,  =  = cst_14#2arith.constant blocked :  :3idense< >32-8388608tensor<
}>4        : x%:tensor<4201 4x = tensor<x32arith.extsi44x xxi%32132arg5xx,  ii#:132blocked , , >i##
32ttgblocked       .>%toslice<{dim = 2, parent = #blocked4}>
126 >     = i %arith.shli64->cst_5 
  = %      tensor<arith.constant125%4 ,202xdense<  = 322.000000e+00%tt.splatx>cst_15 1 :  %xtensor<:201i4  1xtensor<:, 44 #xxiblocked14644xx >f3232->
, x       #itensor<%blocked321166>, x = 
#32tt.broadcast    blockedx %>i%cst_6
64165 =       ,  arith.constant%#: 127blocked dense< = 3tensor<0.000000e+00arith.shrui>4> 
x : %      32tensor<123%x4,2031x  = x4%arith.cmpiixcst_16 11 slt, x:,#f32  blocked, tensor<%4#4192>blockedx, >4 ->
x%     32202tensor<%x 4cst_7i:x = 32 32arith.constant, tensor<x #132dense<blockedxx-2147483648>32i>
x1 :       i, tensor<%64#4128, blockedx = #44arith.oriblocked>x 3
32%>      x126
%i,      16732 % = , %204tt.trans#127 =  blocked tt.broadcast%>: 166
 % {    tensor<200order%4  = cst_8x:array< = 4 iarith.constantxtensor<32 324: dense<xx023i1, >32x2 : , i, tensor<#114blocked, >x>#}4
blocked x      3:32%> x129 tensor<i = ->432arith.addi x,  tensor<32#%4xblocked128x32>,32x
 xi    %i1%cst_111, cst_9 , # = :#blockedarith.constant blocked4 tensor<3>dense<4> 255x
->>4        : x%tensor<tensor<3220544x = xxitt.broadcast32432 xx, %3232#203xxblocked ii>:132
 , ,       tensor<##%1blockedblocked130x9> = 32>
arith.shruix
     i      %%1%cst_10129, 168 = ,# = arith.constant blockedtt.reshape %3 dense<cst_11>%8388607  167>:->  :   :tensor<tensor<tensor< 444tensor<xxx44432xxxx323232ixxx132ii, x3232#i, , blocked1##3, blockedblocked>#>>
blocked

      9          %>%%206 cst_11131 = -> =  = arith.andi arith.constantarith.minui tensor<  %128dense<%204x1130,32>, x :  %itensor<%20514cst_22 , x :#4: blockedx tensor<532tensor<4>x4x
ix32      324x%, xi169#321 = blockedx, arith.select>i# 
32blocked%    , 3168%#>, cst_12blocked
% = >      cst_21arith.constant
%,        207%dense<% = 163127132tt.splat : > =  tensor< : arith.shrui%128tensor< 196x4% 32x113:x4, ix !132%tt, xcst_17.#i ptr<bf16>blocked32: 5,  ->>#tensor< , blocked4tensor<tensor<>x4128
4xx    x3232%32xxcst_13x!bf16 = itt, arith.constant32.# , ptr<bf16>blockeddense<#, 54194304blocked#>>>blocked
 : 
3      tensor<      >%4%
170x133       = 4 = %ttg.local_allocxarith.ori208 32  = %x%tt.addptr169i132  32,%:,  207 #%,(blocked131 tensor<> %128
:197x      32%tensor<:xcst_144 bf16 = xtensor<, arith.constant44# xxblockeddense<32325126xx>>i!) : 32tt -> tensor<, .!4#ptr<bf16>ttgxblocked, .4>#memdesc<128x32xbf16, #shared, #smem>x
blocked
32      3      x%>%i134,17132 =   = , arith.truncitensor<ttg.local_load# 4 blocked%x%>13332170
 x     :i:% 64 cst_15tensor<, ! = 4#ttgarith.constantxblocked. 43memdesc<128x32xbf16, #shared, #smem>dense<x> 232
->>x        : itt.storetensor<tensor<32 1284, %xx#208324blocked,xx> bf1632 %, xto174#i ,ttg32tensor< ., 4%dot_op<{opIdx = 1, parent = #blocked3}>#x206>blocked4 
>x:      
32 %    xtensor<172%i4 = cst_168xtt.dot = , 32 arith.constant#x% blocked!155dense<>tt,21
. >      ptr<bf16>% : %, 171tensor<135#,4 = blocked xtt.reshape3%4 >cst_3x%
 32134    :x } i:
tensor<32     4, tensor<tt.returnx#4
128blockedx  x>4}bf16
x
,     32}#%x
ttgcst_17i
. = 8{-#dot_op<{opIdx = 0, parent = #blocked3}>arith.constant, 
> #   dense<blockedexternal*28>_resources: { > 
tensor< : ->    128tensor< mlir_reproducerx4tensor<: {32x4
x4x      bf16x4pipeline, 32#xxttg: i16."32xdot_op<{opIdx = 1, parent = #blocked3}>b, 2>u#x iblockedi->l>8 t
, tensor<i    #4n%blockedx.cst_18732m = >xoarith.constant
f32d       , udense<%#l-1.270000e+02outLHSblockede>, 3( : %>otensor<outRHS
p4 =       txtt.split%i4 173mx% = i1135arith.addfzx  ef32:%-,  172a#tensor<,mblocked4 d>x%-
4cst_3l    x d%16:scst_19x - = 2tensor<uarith.constantx4s ixadense<832g7, xe>#f32{ : blocked, ltensor<7#d4>blockedsx 3-32->>lx 
iitensor<      m164%i, x174t#4 = =ttgxarith.truncf0.16  slice<{dim = 2, parent = #blocked4}>x%t>i173a
8 r    , :g%# ecst_20blockedtensor<t = 24-arith.constant>xa 
32rdense<      xc-1%f32h>136, = :  = #gtensor<arith.shliblockedf4 3xx%>932outRHS 5x,to0i  }8%tensor<,, cst_24 # xtttg:32r. xislice<{dim = 2, parent = #blocked4}>tensor<bf16t>4, o
x#n    4blocked-%x3scst_2116>c = x
farith.constanti      - 8%tdense<, 175o0x7FC0# = ->blockedarith.extsic : 2 ftensor<>%,128
13 x       c32%:ox137 nbf16 = tensor<v, arith.ori4e# xrblocked%it5outLHS32->,, i
 #n    %ttgd%136.ecst_22 slice<{dim = 1, parent = #blocked3}>x = :>-arith.constant  t tensor<toodense<4 -7xtensor<l>44l : xxvtensor<16im4x64{xi, i48#nx, ttgd32#.exblockedslice<{dim = 1, parent = #blocked3}>xi2>-32>
b, 
      i#      %tblocked%176w>138 = i
 = arith.extsid    tt.reshape t% %hcst_23%11= = 137 0arith.constant :} : ,dense< i 1.270000e+02tensor<32a>4 l : xtoltensor<4 o4xicx1664a4x
txi      e18%-x, 177af32# = m, blockedtt.splatd#2 gblocked>%p> 176u
-> -     :s%tensor< hcst_244ia = x64rarith.constant64 e x->ddense<i -1.270000e+028tensor<m>, 4e : #xmtensor<blockedio4864rx>, y4
#,x      ttg 1%.cx139slice<{dim = 1, parent = #blocked3}>of32 = >n, tt.reshape
v#       elinear%%r>105178t
  = -    :arith.addit%  rcst_25tensor<%i = 4177tarith.constantx,o 4 ndense<x%--1.270000e+021175a>x m : i:dtensor<8 g4, tensor<px#4u4linearx-x>it1 64ox->, -f32 #l, tensor<ttgl#4.vlinearxslice<{dim = 1, parent = #blocked3}>m>4>{
x
a    i      r%8%ccst_26, 179h = # = =arith.constantttgarith.extsig . fdense<slice<{dim = 2, parent = #blocked}>%x2.000000e+00>329>
 5 :       :0tensor<%  4140tensor<fx = 32t4tt.reshapexzx i=1%32tx106, rf32 #u, :ttge# .}lineartensor<slice<{dim = 0, parent = #blocked3}>,>4> 
x c    4toa%x ncst_271tensor<o = x32narith.constantixi 8icdense<, 64a-8388608#, l>blocked#i : >ttgztensor< .e4->slice<{dim = 0, parent = #blocked3}>{x > 4tensor<
 x4      m1x%ax4180xix = -32iarith.extsii, 8 t#, %elinear#30r>linear a
2:t    > i%
iocst_28      32n = % sarith.constant141to=  =  1dense<ttg.convert_layouti02097152 64 >%
m : 140      atensor< %x4:181-x  = n4tensor<tt.splatux4 m1x%-x4180rix e32i:w, 8 r#, iilinear#64t>linear e
2->s    > =% tensor<-cst_29->321 =  x arith.constanttensor<ir 464edense<x, g1274#i>xttgo : i.ntensor<8slice<{dim = 0, parent = #blocked3}>-4, >sx#
i4ttg      mx.%p1slice<{dim = 2, parent = #blocked}>182lx> = ii
arith.addif8       y, %%=#142181nlinear = ,o>arith.extui r
 %m    %179a%141 lcst_30 :  = : tarith.constant tensor<e tensor<32sdense<4xt7xi->464c : x, otensor<i#n48ttgvx, .e4#slice<{dim = 0, parent = #blocked3}>rxttg>gi.
e16slice<{dim = 2, parent = #blocked}>      n, >%c# 183ettgto = =. arith.mulifslice<{dim = 2, parent = #blocked}>tensor< a>4%l
x7s    4,e%x  cst_31i%t = 166oarith.constant,  p #:-dense<ttg d-1.io>slice<{dim = 2, parent = #blocked}>64w : >
ntensor<
      =4      %tx%184r4143 = ux = tt.addptreiarith.shli }8 %,, %arg2 #142,cttg, s. %eslice<{dim = 2, parent = #blocked}>%183,>cst_30  
 :c    : ollvm.intr.assume !n tensor<ttv%4.etruexptr<bf16>r 4,t:x - iici1664f1, 
-
#      t    ttg%ollvm.intr.assume.185- slice<{dim = 2, parent = #blocked}> = l%>tt.expand_dimsltrue
 v       %m:%178{ 144 {ii = axisn1tt.bitcast = d
 1e    % : xllvm.intr.assume143i-  32b%:}itrue  t tensor<:w:4 i xtensor<di44t1xxh
ii=    16640llvm.intr.assume, , } ##,%ttgttg true..c slice<{dim = 2, parent = #blocked}>slice<{dim = 1, parent = #blocked3}>o:>>n   vi->->e1  r
tensor<tensor<t    44-llvm.intr.assumexxa 41r%xxitruebf16it , 64h:#, - ttg#ti.blockedo1slice<{dim = 2, parent = #blocked}>3-
>>l    

lllvm.intr.assume            v %%m%145186{true =  = i tt.expand_dimsarith.extsin:  d %%ei144arg13x1 { -
axis:b     =  illvm.intr.assume2it  : 32w%i itrue32tod } t: ih :64=i 
01tensor<      }
4%,    x187 llvm.intr.assume4 = c xtt.expand_dimsa%bf16 ntrue, %o #175n:ttg {i .axiscislice<{dim = 2, parent = #blocked}> = a1>1l
  : i    ->izllvm.intr.assume 32e tensor<}{%4  truex:  4 m:xtensor<a 14xixx-1bf16ii
, 64t    #, ellvm.intr.assumeblocked#r >ttga%
.ttrue      slice<{dim = 1, parent = #blocked3}>i %>o:146 n  = ->sitt.broadcast =1 tensor<1
%40    145x llvm.intr.assume 1m :xa% ixtruetensor<64- 4, n:x#u 4blockedmix3-11>r
x
e    bf16      wllvm.intr.assume, %r #188i%blocked = ttrue>arith.mulie   s:->%=  186-itensor<,114  
x%r    4176e%x g032:i = x ott.get_program_idbf16in , 64-x#
s blocked      i:>%m 
189pi       = l32%tt.splati
147 f     = %y%tt.reshape186=1  n = %:ott.get_program_id146 r  imy:64a   l:tensor<->  4 tixtensor<e3244s
xxt    321-%xxc2bf16io = , 64narith.addi#, v blocked#e%>blockedrarg5 3g,->>e  
n%tensor<      cc31_i324%e x190=:128 = f xarith.muliaibf16 l32, %s
#189e    blocked, %1 t3>%o = 
187parith.divsi       - %:d%148 o2 = tensor<w,amdgpu.scaled_upcast_fp44n  x=%%1tc32_i32138xr  iu:scale64e  , }i%#,32147blocked 
 {3c    axis>s% = 
e41      , =  : % arith.extsii191s 32 = y%}tt.addptrmarg7  b :%o: 184l tensor<,-i4 d32x%c 64188etox , i: i8 e64, !n
#tta    blocked.b%8ptr<bf16>l5>,e = , -arith.extsi il tensor<64i%4
narg9x      e 128%-:x192i bf16 = ni, tt.expand_dimsf32# o blocked%,to1182  > {ci axiso64-> = n
 0v    tensor< : e%4ir6x32t = 128}-arith.extsix b bf16:u%,  iarg11#tensor<l blocked32t:1xi >ini
64-32      , f %#uto149ttgn  = .ciarith.cmpislice<{dim = 0, parent = #blocked3}>-64 >t
eq o    ,->-%  l7%tensor<l = 1391varith.extsi,xm  32{%%xf0cst_31it  64z::, =  #titensor<blockedr3243u x>eto4
} x      )ii%"648193,
,  = 
    #tt.broadcast      %ttg disable_threading8.%:  = slice<{dim = 2, parent = #blocked}>190falsearith.divsi> , 
:
%             1%tensor<verify_each,1504:   = xtrue%tt.expand_dims1
3 x    } %i
:14964  }  {, 
iaxis##-}32 = blocked

23     : >%i 932/tmp/torchinductor_root/5a/c5ayjbnqm63pgaogdacjcrd76enk3ajatvfxqr77txwrmcslsldt.py:18:0-> = }:  arith.remsi error: tensor< :Failures have been detected while processing an MLIR pass pipeline4% 
x1tensor</tmp/torchinductor_root/5a/c5ayjbnqm63pgaogdacjcrd76enk3ajatvfxqr77txwrmcslsldt.py:18:032,4: x xnote: i%4Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`643x
,  i#:1blocked , 3i#>32ttg

.          slice<{dim = 2, parent = #blocked}>%llvm.intr.assume>194   = %->tt.expand_dimstrue   tensor<%:4179 x {i4axis1x = 
10    x : llvm.intr.assumeii 132%, }true#  blocked::>  
tensor<i      321%x
151i     = 64llvm.intr.assumett.broadcast,   #%%ttgtrue150.  slice<{dim = 0, parent = #blocked3}>::>   itensor<->14 
xtensor<    41%xx10132 = xxarith.cmpiii 164sgt, , ,## blockedblocked%>3arg6 >,->
        %tensor<%c0_i324195 x = :4tt.broadcast x i32%32x194
i     1:scf.if,  [rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 1, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank1]:E1112 18:13:31.275000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
 #tensor<%blocked110>x 
32{      x
%i      15264% = , 11tt.reshape# =  blockedarith.muli%3 151>%  8:->,   tensor<tensor<%44c4_i32xx 432:xx 32iix6432i, 
1#      , blocked%#312blocked> = >
tt.make_range        {->%end 196 = tensor< = 44tt.addptr : x i128%32x191, i,start1  = , %0#180 : blocked i1:32> }
!       tt:%. 153ptr<bf16>tensor< = ,4arith.select x ii%6432152
, ,       #%%ttgcst_0197.,  = slice<{dim = 1, parent = #blocked1}>%arith.addi>148 
 : %      tensor<195%4,13x  = 128%tt.make_rangex193 {i end1: = ,  4#tensor< : blocked4i1x32>32, , xstarttensor<i = 4640x,  : 128#ixblocked32bf163}, > #
:blocked       1%tensor<>1984
 = x      arith.extsii% 32154%,  = arg4#ttg.local_alloc ttg :.% slice<{dim = 1, parent = #blocked3}>153i> 32
:        to%( 14tensor<i = 464tt.splatx
 128      %x%11bf16199 ,  = :#tt.splat blocked i1%32>198 ) -> -> : ! tensor<ttgi4.64xmemdesc<4x128xbf16, #shared, #smem> i
->32       , %tensor<#1554ttg = x.ttg.local_load1slice<{dim = 1, parent = #blocked1}> x>%i
15464       , %:#15 blocked = !3arith.addittg> .
%memdesc<4x128xbf16, #shared, #smem>      14 %,->200   = %tensor<arith.cmpi124  xslt:128, x tensor<bf16%4, 185x#,ittg 32.%, dot_op<{opIdx = 0, parent = #blocked3}>199#> ttg
:.       slice<{dim = 1, parent = #blocked1}>%tensor<>1564
 = x      arith.extui1% x16%i = 7064tt.splat ,  :#% blockedarg4tensor<3 4>:x
 32      ix%32i201 8 = ->, arith.extsi # tensor<ttg%4.arg5xslice<{dim = 2, parent = #blocked4}> i>:32  , toi# 32ttgtensor< .4toslice<{dim = 1, parent = #blocked1}>x >32i
x64      i
%16      17, % = #202arith.remsittg =  .tt.splat%slice<{dim = 2, parent = #blocked4}> 15>%,
201        %%:16157   = i:arith.shli64   tensor<%->4156 x,tensor<i 132%x, cst_1932# xttg:i. 64slice<{dim = 1, parent = #blocked1}>tensor<, >4#
xblocked      323%x>18i
 = 16      arith.muli, % #203%ttg = 7.arith.cmpi,slice<{dim = 2, parent = #blocked4}>  >slt%
,4        %%:158192  = ,itt.bitcast 64 %
%202      157 % :19:  =  tensor<tt.expand_dimstensor<1 4x%x321732x {xiaxisi64 = 16, 1, # : #blockedittg332.>}slice<{dim = 2, parent = #blocked4}>
 >      : % ->204tensor<  = 4tensor<tt.broadcastx4 ix%3232200, x #bf16:ttg,  .#tensor<slice<{dim = 1, parent = #blocked1}>ttg4>.x slice<{dim = 2, parent = #blocked4}>1->>x 
itensor<      14%, x159#1 = blockedxtt.expand_dims3i >32% , 158-># { blockedaxistensor<1 = 4>2x
 : 32      ix%32i20}1 =  , tt.splat:#  blocked%tensor<3arg84> x
:32       x%ibf1620532,  =  #tt.broadcast->ttg  .%tensor<slice<{dim = 2, parent = #blocked4}>2034> x :1-> x tensor<itensor<1324x, x32#32xblockedxi111>x, 
bf16#      , blocked%#321blocked> = 4 arith.muli>-> 
 %      tensor<19%4,160x  = 32%tt.broadcastx20 i %1:159,   #tensor<:blocked4 3xtensor<>14
xx      i32%32x206, 1 = #xarith.andiblockedbf16 1, %>#204
blocked,      4 %>%22 205 = -> arith.extsi : tensor< %4tensor<21x4 32x:x32 32xtensor<xi4bf161x, , 1##xblockedblockedi4332>>, 

#            blocked%%1161207> =  =  tt.transtt.splatto   %%tensor<1601964 { xorder:1 =  xarray<!iitt6432., : ptr<bf16>#0 blocked, ->12 >, tensor<
14      >x%}3223 x = :!tt.make_range tt {tensor<.end4ptr<bf16> = x, 12832# : xblockedi32x332bf16>, , 
start#       = blocked%04208 : > = i tt.addptr32-> } % tensor<207:4, x tensor<32%128x197x32 ix:32bf16 , , tensor<##4ttgblockedx.932slice<{dim = 0, parent = #blocked1}>>x>
!
      tt      %.%162ptr<bf16>24 = ,  = tt.reshape#tt.expand_dims blocked %3%161>23 , {: axis tensor< = tensor<404x : x32i32x32xi}3264 x, :bf16# , blockedtensor<#3128blocked>x9
i>      32 tt.store, -> # %ttgtensor<208.128,slice<{dim = 0, parent = #blocked1}>x >32% x174->bf16, ,  tensor<#%1blocked206x5 128>:x
 i      tensor<32%4, 163x# = 32blockedamdgpu.scaled_upcast_fp4x1 !>%tt
77.       ptr<bf16>%scale, 25 # = %blockedarith.extsi1623  {>%axis
24 =      0}: : 
 i    tensor<32tt.return1}
x   128:}x 
itensor<}3264
, x
#32{-#blockedx
1i  >8external , _resources: {to#
 blocked    tensor<3mlir_reproducer1>: {x,
128       xtensor<pipelinei128: 64x", 32b#xublockedbf16i1, l>#t
blockedi      5n%>.26 m = ->ott.broadcast d tensor<u%128l22xe 32(:xo bf16ptensor<, t4#ixblockedm15ix>zi
e64      -, %a#164mblocked = d1arith.cmpi-> l eqd->,s  -tensor<%u470sx,a128 gx%eicst_20{64 l, :d# sblockedtensor<-14l>xi
32m      xi%it278= = , 0tt.broadcast#  ttgt%.a25slice<{dim = 2, parent = #blocked4}>r >g:
e       ttensor<%-1165ax = r128tt.expand_dimscx hi%=64164g,  {f#axisxblocked = 9125> : 0 i}->32, } tensor< t4:rx i128tensor<tx4oixn6432-, xs#icblocked1f1, ->#t
ttgo      .-%slice<{dim = 2, parent = #blocked4}>c28>f =  ,arith.addi->   c%tensor<o264n,xv 32e%xr271t x-:ii 1ntensor<, d4#exblockedx1284-x>ti
o64      -, %l#166lblocked = v1tt.broadcastm> {
%i      165n% d29:e =  xtt.addptrtensor<- 4b%xiarg032t,xw 1i%xd18it 1h:, = #0!blocked}tt4,.> ptr<bf16> a,->l  litensor<o644c
xa      32t%xe3032- = xaarith.muliim 1d%, g9#p,blockedu 4-%>sc32_i32
h       a:%r 167ei = d32tt.trans-
 m      %e%166m31 {o = orderrtt.make_range = y {array<,endi  = 32c32: o : 0ni, v322e, , rstart1t = >-0}t :  ri:i32 t}tensor<o 4n:x- 32atensor<xm3232dxxgiip321u, , -##tttgblockedo.4-slice<{dim = 0, parent = #blocked6}>>l> l
->v       m%tensor<{324a = xrtt.make_range32c {xhend32= = xg32if : 1xi, 932#5, blocked0start9  = >f0
t :       zi%=32168t} = r tt.reshapeu: e %}tensor<167,32  x:ci a32tensor<n, 4o#xnttg32i.xcslice<{dim = 0, parent = #blocked3}>32a>xl
ii      1z%, e33#{ = blocked tt.make_range9  {>mend a = ->x32 - : tensor<ii128t32xe, 32rstartxa = it01i : , oi#n32blockeds}5= >1:
0        tensor<%m32169ax = xiarith.select-32 n, %u#168mttg, -.%rslice<{dim = 1, parent = #linear1}>cst_21e>, w
%r      163i% : t34tensor<e = 128stt.splatx= 32-%x130i  1r:, e #giblockedi325o >n->, - tensor<stensor<128i32xmx32pixl32bf16i, , f##yttgblocked=.5nslice<{dim = 0, parent = #blocked6}>>o>
r
      m      %a%170l35 =   = ttg.local_allocttt.splat e %s%169t30 - :c: o (nitensor<v32128e xr->32g xetensor<bf16n32, cx#eiblocked=325f, >a#)lttg -> s.!eslice<{dim = 1, parent = #linear1}>ttg >.t
memdesc<128x32xbf16, #shared, #smem>o      
p%      -36%d = 171oarith.addi = w ttg.local_loadn% =34%t,170r  u%:e31 } !,:ttg  .ctensor<memdesc<128x32xbf16, #shared, #smem>s32 ex->,i  32tensor<c, 128o#xnttg32v.xeslice<{dim = 0, parent = #blocked6}>bf16r>, t
#-      ttgc%.f37dot_op<{opIdx = 1, parent = #blocked3}>- = >tarith.addi
o       -%%l35172l, = v tt.dotm% {33%i 155n:,d  etensor<%x32171-x,bi i32%t, cst_3w# ittg:d. tslice<{dim = 1, parent = #linear1}>tensor<h>4=
x0      128}%x,38bf16  = , ctt.splat#o ttgn%.varg5dot_op<{opIdx = 0, parent = #blocked3}>e >r: t *-i a32tensor<r 128i->xt 32htensor<x-32bf16tx, oi#-32ttgl, .l#dot_op<{opIdx = 1, parent = #blocked3}>vttg>m. {slice<{dim = 0, parent = #blocked6}>->i> n
tensor<d      4e%xx3932- = xbtt.splatf32i , t%#warg5blockedi 3d:>t 
hi      =32%0 173}-> = , arith.addf tensor< c32%ax172ni,o32 n, %i#cst_3cttg a.:lslice<{dim = 1, parent = #linear1}> i>tensor<z
4e      x{%32 40x  = f32marith.remsi, a #x%blocked-363i,>t 
e%      r38%a 174t: = i arith.truncfotensor< n32%sx173=i 132:0,   #tensor<mttg4a.xxslice<{dim = 0, parent = #blocked6}>32->xn
f32u      , m%#-41blockedr = 3earith.remsi>w  r%toi37 t,tensor<e 4s%x=3932- x1:bf16  , rtensor<#e32blockedgx3ii>o32
n,       -#%sttg175i. = mslice<{dim = 1, parent = #linear1}>arith.extsip> l
%i      13f% y42:= =  narith.mulitensor<o 4r%xm7ia,32l ,  %#t5ttge .s:slice<{dim = 1, parent = #blocked3}>t >-i c64too
 n      tensor<v%4e43xr = igtt.make_range64e {, nend#c = ttge64.= : slice<{dim = 1, parent = #blocked3}>fi>a32
l,       sstart%e = 176 0 = t : arith.extsioi p32%-}11d  o::w  ntensor<i=6432tx ritou32 e, i}#64,ttg
 .      cslice<{dim = 1, parent = #blocked6}>%s>177e
 = ,      tt.splat % s44%y = 176mtt.expand_dims b :o% l43i- {64daxis c = ->e1 , : tensor< i4e32xn}ia 64b:, l #etensor<ttg-64.lxslice<{dim = 1, parent = #blocked3}>ii>n32
e,       -#%ittg178n. = fslice<{dim = 1, parent = #blocked6}>arith.addio> , % ->177c ,otensor< n64%vx175e1 rx:ti -32tensor<b, 4u#xiblockedil664t>, i
#n      ttg-%.f45u = slice<{dim = 1, parent = #blocked3}>narith.extsi>c 
-%      t44%o 179-: = l arith.extsiltensor< v64%mx32{1 fx:ti z32tensor<=, 32t#xrblockediu632e>, } #)tottg" .,tensor<slice<{dim = 0, parent = #blocked3}>
64>      x disable_threading1to: x falseitensor<,6432
, x      #iverify_eachblocked64: 6, true>#

ttg    }      .
%slice<{dim = 0, parent = #blocked3}>  }46>
 = 
#-}tt.expand_dims      
 %%18040 =  {arith.extsiaxis/tmp/torchinductor_root/kn/ckn3r7kfl4te5cqtmav6yi5jrm6tiqqkflqhzjqssitwomuk5j5h.py:18:0  = : %0error: 30 : Failures have been detected while processing an MLIR pass pipeline i
:32/tmp/torchinductor_root/kn/ckn3r7kfl4te5cqtmav6yi5jrm6tiqqkflqhzjqssitwomuk5j5h.py:18:0 }: i note: 32:Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`  
totensor< 32ix64i
32      , %#181ttg = .tt.splatslice<{dim = 0, parent = #blocked6}> >% 180->  :tensor< 1ix6432 x->i 32tensor<, 32#xblockedi664>, 
#      ttg%.47slice<{dim = 0, parent = #blocked3}> = >tt.splat
       %%arg10182  = :arith.addi  i%32181 ,->  %tensor<1791 x:32 xtensor<i3232x, i#64blocked, 6#>ttg
.      slice<{dim = 0, parent = #blocked3}>%>48
 =       arith.muli% 183% = 46arith.muli,  %%747,  :% 6tensor< 1:x 32ix64i
32      , %#184blocked = 6tt.addptr>[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 7, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank7]:E1112 18:13:31.289000 513 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
 
%      arg2%,49  = %arith.extsi183  %:48  !:tt .tensor<ptr<bf16>1,x 32ix64i
32      , %#185blocked = 6tt.expand_dims>  %to178  {tensor<axis1 = x132 : xii3264},  #:blocked 6tensor<>4
x      i%6450,  = #tt.broadcastttg .%slice<{dim = 1, parent = #blocked3}>45>  :->  tensor<tensor<644xx11xxii6464, , ##blockedblocked63>> 
->       %tensor<18664 = xarith.extsi32 x%iarg1364 , :# blockedi632> 
to       %i5164 = 
tt.broadcast       %%18749 =  tt.expand_dims:  %tensor<1751 {xaxis32 = x1i : 64i, 32#}blocked 6:>  tensor<->4 xtensor<i6464x, 32#xttgi.64slice<{dim = 1, parent = #blocked3}>, ># blocked->6 >tensor<
4      x%152x = iarith.addi64 , %#50blocked,3 >%
51       %:188  = tensor<arith.muli64 x%32186x,i 64%, 176# blocked:6 >i
64      
%      53% = 189tt.addptr =  tt.splat% arg1%,186  %:42  i:64  !->tt .tensor<ptr<i8>4,x 1ix64i
64      , %#54blocked = 3arith.extsi> 
%      arg14% 190: =  arith.mulii 32% 189to,  i%64187
       :% 55tensor< = 4arith.mulix 1%x7i,64 , %#54blocked 3:> 
i      64%
191       = %tt.addptr56  = %tt.addptr184 ,% arg3%,188  %:55  !:tt .!ptr<bf16>tt,. ptr<i8>i,64 
i      64%
192       = %tt.expand_dims57  = %tt.expand_dims182  {%axis41 =  {0axis :  = i132 : }i 32:}  tensor<:32 xtensor<i3264x, i#32ttg, .#slice<{dim = 0, parent = #blocked3}>ttg>. slice<{dim = 1, parent = #linear1}>->>  tensor<->1 xtensor<3232xxi164x, i#32blocked, 3#>linear
1      >%
193       = %tt.broadcast58  = %tt.splat190  %:arg15  tensor<:4 xi132x i->64 , tensor<#32blockedx31>x i->32 , tensor<#4linearx132>x
i      64%, 59# = blockedarith.muli3 >%
57      ,% 194% = 58tt.expand_dims  :% 179tensor< {32axisx = 10x : ii3232, }# linear:1 >tensor<
32      x%i6064 = , arith.extsi# ttg%.59slice<{dim = 0, parent = #blocked3}> >:  ->tensor< 32tensor<x11xx32ix32i, 64#, linear#1blocked>3 >to
       tensor<%32195x = 1tt.broadcastx i%64194,  #:linear 1tensor<>1
x      32%x61i = 64tt.make_range,  {#endblocked = 34> :  i->32 , tensor<start4 = x032 : xii3264},  #:blocked 3tensor<>4
x      i%32196,  = #tt.addptrttg .%slice<{dim = 0, parent = #linear1}>191>,
       %%18062  = :tt.broadcast  !%tt60. ptr<bf16>:,  tensor<i3264x
1      x%i19764 = , arith.addi# linear%1195>,  ->% 193tensor< 32:x 4tensor<x4ix6432, x#ilinear641, >#
blocked      3%>63
 =       tt.expand_dims% 198% = 61arith.extsi { axis% = arg40  : :i 32i}32  :to  tensor<i464x
i      32%, 199# = ttgtt.splat. slice<{dim = 0, parent = #linear1}>%>198  ->:  tensor<i164x 4->x itensor<324, x#1linearx1i>64
,       #%blocked643 = >tt.broadcast
       %%63200  = :arith.cmpi  tensor<slt1,x 4%x185i,32 , %#199linear 1:>  tensor<->4 xtensor<132xxi464x, i#32blocked, 3#>linear
1      >%
201       = %arith.extsi65  = %arith.extsiarg5  %:64  i:32  tensor<to32 xi464x
i      32%, 202# = lineartt.splat1 >% 201to  :tensor< 32ix644 x->i 64tensor<, 1#xlinear321x>i
64      , %#66blocked = 3arith.addi> 
%      65%,203  = %arith.cmpi62  slt:,  tensor<%32192x,4 x%i20264 , :# lineartensor<11>x
32      x%i6764 = , tt.splat# blocked%356> 
:       %!204tt = .tt.broadcastptr<i8>  %->200  tensor<:32 xtensor<44xx!1ttx.iptr<i8>1, , ##linearblocked13>>
       ->% 68tensor< = 4tt.addptrx 32%x67i,1 , %#66blocked 3:> 
tensor<      32%x2054 = xtt.broadcast! tt%.203ptr<i8> , :# lineartensor<11>x,32 xtensor<i321x, 4#xblockedi364>,  #->linear 1tensor<>4
x      32%x69i = 1tt.load,  #%blocked683 >:
       tensor<%32206x = 4arith.andix !%tt204.,ptr<i8> , %#205linear 1:> 
tensor<      4%x7032 = xtt.transi 1%, 69# {blockedorder3 = >array<
i      32%: 2071 = , tt.splat0 >%}196  ::  tensor<!32ttx.4ptr<bf16>x i->8 , tensor<#4linearx132>x !->tt .tensor<ptr<bf16>4, x#32blockedx3i>8
,       #%ttg208. = slice<{dim = 2, parent = #blocked4}>tt.addptr> 
%      207%,71  = %tt.splat197  %:29  tensor<:4 x!32ttx.!ptr<bf16>tt .->ptr<bf16> , tensor<#4blockedx3128>x,! tttensor<.4ptr<bf16>x, 32#xblockedi164>, 
#      blocked%372> = 
tt.addptr       tt.store% 71%,208 ,% 28% 174:,  tensor<%4206x 128:x !tensor<tt4.xptr<bf16>32, x#!blockedtt1.>ptr<bf16>,,  #tensor<blocked43x>128
x    i}64
,     #tt.returnblocked
1>
      %  73} = 
tt.load} 
%
72{-# 
:   externaltensor<_resources: {4
x    128mlir_reproducerx: {!
tt      .pipelineptr<bf16>: , "#bblockedu1i>l
t      i%n74. = mtt.splato d%u53l e:( o!pttt.iptr<i8>m i->z etensor<-64axm32dx-!lttd.sptr<i8>-, u#sblockeda6g>e
{      l%d75s = -tt.addptrl i%m74i,t =%052  t:a rtensor<g64ext32-xa!rttc.hptr<i8>=, g#fblockedx69>5,0 }tensor<,64 xt32rxiit64o, n#-blockeds6c>f
-      t%o76- = ctt.loadf ,% 75c ocacheModifiern v=e rcgt -:i ntensor<d64exx32-xt!ott-.lptr<i8>l, v#mblocked{6i>n
d      e%x77- = bttg.convert_layouti t%w76i d:t htensor<=640x}32,x ia8l, l#oblockedc6a>t e->- atensor<m64dxg32pxui-8s, h#ablockedr3e>d
-      m%e78m = ott.reshaper y%,73  c:o ntensor<v4exr128tx-bf16t, r#iblockedt1o>n -->a mtensor<d4gxp4ux-32txobf16-, l#lblockedv>m
{      a%r79c = hmath.absf= g%f78x 9:5 0tensor< 4fxt4zx=32txrbf16u, e#}blocked,> 
c      a%n80o = narith.extfi c%a79l i:z etensor<{4 x 4mxa32xx-bf16i, t#eblockedr>a ttoi otensor<n4sx=41x032 xmf32a, x#-blockedn>u
m      -%r81e = w"rtitt.erse=d-u1c er"e(g%i80o)n <-{saxisi = m2p : lii32f}y>= (n{o
r      m^bb0a(l% arg16t: ef32s, t%-arg17c: of32n)v:e
r        g%e209n = carith.maxnumfe =%farg16a,l s%earg17  t:o pf32-
d        ott.reduce.returnw n%=209t r:u ef32}
,       }c)s : e(,tensor< 4cxo4nxv32exrf32t, -#cblockedf>-) -> ttensor<o4-xl4lxvf32m, {#ittgn.dslice<{dim = 2, parent = #blocked}>e>x
-      b%i82t = wttg.convert_layouti d%t81h =:0 }tensor<,4 xc4oxnf32v, e#rttgt.-slice<{dim = 2, parent = #blocked}>a>r i->t htensor<-4txo4-xlf32l, v#mttg{.islice<{dim = 2, parent = #linear}>n>d
e      x%-83b = itt.expand_dimst w%i82d {taxish = =20 : }i,32 }c a:n otensor<n4ixc4axlf32i, z#ettg{. slice<{dim = 2, parent = #linear}> >m a->x -tensor<i4txe4rxa1txif32o, n#slinear=>1
0       %m84a = xtt.expand_dims- n%u81m {-axisr = e2w : rii32t}e s:= -tensor<14 xr4exgf32i, o#nttg-.sslice<{dim = 2, parent = #blocked}>i>m p->l itensor<f4yx=4nxo1rxmf32a, l# blockedt>e
s      t%-85c = ott.bitcastn v%e83r g:e ntensor<c4ex=4fxa1lxsf32e,  #tlinearo>p -->d otensor<w4nx=4txr1uxei}32,,  #clinears>e
,       %s86y = mtt.bitcastb o%l84- d:c etensor<,4 xe4nxa1bxlf32e, -#lblockedi>n e->- itensor<n4fxo4,x 1cxoin32v, e#rblockedt>-
b      u%i87l = tarith.addii n%-85f,u n%ccst_28- t:o -tensor<l4lxv4mx{1fxtiz32=, t#rlinearu>e
}      )%"88, = 
arith.addi       disable_threading%: 86false,, 
%      cst_1verify_each : :true 
tensor<    }4
x  }4
x#-}1
xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear/tmp/torchinductor_root/hj/chjizxbbp7eypno2saafydfl2vfxcrdslosv3xjxgrewcxoizhcq.py:18:0>: 
error:       Failures have been detected while processing an MLIR pass pipeline%
90/tmp/torchinductor_root/hj/chjizxbbp7eypno2saafydfl2vfxcrdslosv3xjxgrewcxoizhcq.py:18:0 = : tt.bitcastnote:  Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`%
88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 3, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank3]:E1112 18:13:31.301000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/72/c72mspx6lumlshyw5zc2vvgownxn3wrqkwojtinmae4qsarid47c.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/72/c72mspx6lumlshyw5zc2vvgownxn3wrqkwojtinmae4qsarid47c.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     Kernel for computing the matmul C = A x B.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bn': 'i32', 'stride_bk': 'constexpr', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 6, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 32, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (11,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank6]:E1112 18:13:31.304000 512 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
[2025-11-12 18:13:31 DP0 TP0] Registering 0 cuda graph addresses
[2025-11-12 18:13:31 DP5 TP5] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/xs/cxslztfaqmgus5kptm6zo62u3amacci5xrg7oleex2qksgvytayl.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP4 TP4] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/ju/cjubc55d2ojzx7225t7q7q43inlrn22qrlpa2xkl7eooojguqcen.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP2 TP2] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/e6/ce6guybqm3nyeervcrcsvxtoikg3c6smzlw5tgur3ylzuqltodue.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP7 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/iv/civnyl5w6a2v763coj62qzuzzjitjepxt2jv3wz5wx26zxslpy6d.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP1 TP1] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/ih/cihv5yrvzhahwdtztk7zfp5gl3zp5ber4izoa6hvvdudabga6tyf.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP6 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/cs/ccsrvxpmlklltw4mrbwjhh25p2w6swohappxgfoj24pwuojdmn7h.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP3 TP3] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/a5/ca5rd7vzwdote4dtvcsxifebgevbyzrtrlwgnnel7lra64oiz6gn.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-12 18:13:31 DP0 TP0] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 520, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 699, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 686, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/kg/ckgc3hmuoxbhr4tbw5ssadpcu2pvfuhzvuvztufwpaptjy2qwf2s.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2701, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 490, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 2006, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[rank5]:[W1112 18:13:32.837037054 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank4]:[W1112 18:13:32.837256790 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank2]:[W1112 18:13:32.878338639 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank7]:[W1112 18:13:33.110002408 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank1]:[W1112 18:13:33.402322493 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank3]:[W1112 18:13:33.402362012 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank6]:[W1112 18:13:33.402473460 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1112 18:13:33.420704752 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
