INFO 10-31 11:30:41 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:41] WARNING model_config.py:707: quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:41] WARNING server_args.py:1144: Attention backend not explicitly specified. Use aiter backend by default.
[2025-10-31 11:30:41] WARNING server_args.py:1333: DP attention is enabled. The chunked prefill size is adjusted to 16384 to avoid MoE kernel issues. 
[2025-10-31 11:30:41] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:41] server_args=ServerArgs(model_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.68, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=16384, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=8, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=461204163, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', api_key=None, served_model_name='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=8, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='aiter', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_amx_weight_path=None, kt_amx_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=16, cuda_graph_bs=[1, 2, 4, 8, 12, 16], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=True, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=-1, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8)
[2025-10-31 11:30:41] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:41] Using default HuggingFace chat template with detected content format: string
INFO 10-31 11:30:48 [__init__.py:241] Automatically detected platform rocm.
INFO 10-31 11:30:48 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:49] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:49] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:57] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:57 DP2 TP2] Process 505 gpu_id 2 is running on CPUs: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]
[2025-10-31 11:30:57 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:57] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:57 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:57 DP2 TP2] Init torch distributed begin.
[2025-10-31 11:30:57 DP6 TP6] Process 509 gpu_id 6 is running on CPUs: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
[2025-10-31 11:30:57 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
INFO 10-31 11:30:57 [__init__.py:241] Automatically detected platform rocm.
[2025-10-31 11:30:57] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:57] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-31 11:30:57 DP5 TP5] Process 508 gpu_id 5 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]
[2025-10-31 11:30:57 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP1 TP1] Process 504 gpu_id 1 is running on CPUs: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-10-31 11:30:58 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP6 TP6] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:58] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:58] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:58 DP7 TP7] Process 510 gpu_id 7 is running on CPUs: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
[2025-10-31 11:30:58 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP5 TP5] Init torch distributed begin.
[2025-10-31 11:30:58 DP3 TP3] Process 506 gpu_id 3 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-10-31 11:30:58 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP1 TP1] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:58] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:58 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP7 TP7] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-10-31 11:30:58 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP3 TP3] Init torch distributed begin.
[2025-10-31 11:30:58 DP4 TP4] Process 507 gpu_id 4 is running on CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]
[2025-10-31 11:30:58 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-10-31 11:30:58 DP0 TP0] Process 503 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[2025-10-31 11:30:58 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP4 TP4] Init torch distributed begin.
[2025-10-31 11:30:58 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-10-31 11:30:58 DP0 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-10-31 11:30:58 DP0 TP0] sglang is using nccl==2.26.6
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-10-31 11:31:05 DP0 TP0] Init torch distributed ends. mem usage=3.22 GB
[2025-10-31 11:31:05 DP7 TP7] Init torch distributed ends. mem usage=3.10 GB
[2025-10-31 11:31:05 DP6 TP6] Init torch distributed ends. mem usage=3.11 GB
[2025-10-31 11:31:05 DP5 TP5] Init torch distributed ends. mem usage=3.17 GB
[2025-10-31 11:31:05 DP4 TP4] Init torch distributed ends. mem usage=3.10 GB
[2025-10-31 11:31:05 DP3 TP3] Init torch distributed ends. mem usage=3.24 GB
[2025-10-31 11:31:05 DP1 TP1] Init torch distributed ends. mem usage=2.82 GB
[2025-10-31 11:31:05 DP2 TP2] Init torch distributed ends. mem usage=3.24 GB
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[2025-10-31 11:31:06 DP0 TP0] Load weight begin. avail mem=284.28 GB
[2025-10-31 11:31:06 DP5 TP5] Load weight begin. avail mem=284.33 GB
[2025-10-31 11:31:06 DP0 TP0] Only Deepseek V3/R1 on NV-platform with capability >= 80 can use shared experts fusion optimization. Shared experts fusion optimization is disabled.
[2025-10-31 11:31:06 DP7 TP7] Load weight begin. avail mem=284.40 GB
[2025-10-31 11:31:06 DP4 TP4] Load weight begin. avail mem=284.40 GB
[2025-10-31 11:31:06 DP1 TP1] Load weight begin. avail mem=284.68 GB
[2025-10-31 11:31:06 DP3 TP3] Load weight begin. avail mem=284.26 GB
[2025-10-31 11:31:06 DP2 TP2] Load weight begin. avail mem=284.26 GB
[2025-10-31 11:31:06 DP6 TP6] Load weight begin. avail mem=284.39 GB
Loading safetensors checkpoint shards:   0% Completed | 0/73 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   1% Completed | 1/73 [00:00<00:10,  6.87it/s]
Loading safetensors checkpoint shards:   3% Completed | 2/73 [00:00<00:13,  5.30it/s]
Loading safetensors checkpoint shards:   4% Completed | 3/73 [00:00<00:18,  3.88it/s]
Loading safetensors checkpoint shards:   5% Completed | 4/73 [00:01<00:19,  3.55it/s]
Loading safetensors checkpoint shards:   7% Completed | 5/73 [00:01<00:23,  2.89it/s]
Loading safetensors checkpoint shards:   8% Completed | 6/73 [00:01<00:22,  2.93it/s]
Loading safetensors checkpoint shards:  10% Completed | 7/73 [00:02<00:24,  2.68it/s]
Loading safetensors checkpoint shards:  11% Completed | 8/73 [00:02<00:24,  2.61it/s]
Loading safetensors checkpoint shards:  12% Completed | 9/73 [00:02<00:23,  2.73it/s]
Loading safetensors checkpoint shards:  14% Completed | 10/73 [00:03<00:21,  2.94it/s]
Loading safetensors checkpoint shards:  15% Completed | 11/73 [00:03<00:21,  2.86it/s]
Loading safetensors checkpoint shards:  16% Completed | 12/73 [00:04<00:21,  2.81it/s]
Loading safetensors checkpoint shards:  18% Completed | 13/73 [00:04<00:21,  2.85it/s]
Loading safetensors checkpoint shards:  19% Completed | 14/73 [00:04<00:20,  2.87it/s]
Loading safetensors checkpoint shards:  21% Completed | 15/73 [00:05<00:27,  2.10it/s]
Loading safetensors checkpoint shards:  22% Completed | 16/73 [00:05<00:24,  2.35it/s]
Loading safetensors checkpoint shards:  23% Completed | 17/73 [00:06<00:20,  2.68it/s]
Loading safetensors checkpoint shards:  25% Completed | 18/73 [00:06<00:21,  2.61it/s]
Loading safetensors checkpoint shards:  26% Completed | 19/73 [00:06<00:20,  2.69it/s]
Loading safetensors checkpoint shards:  27% Completed | 20/73 [00:07<00:19,  2.74it/s]
Loading safetensors checkpoint shards:  29% Completed | 21/73 [00:07<00:18,  2.87it/s]
Loading safetensors checkpoint shards:  30% Completed | 22/73 [00:07<00:18,  2.82it/s]
Loading safetensors checkpoint shards:  32% Completed | 23/73 [00:08<00:17,  2.81it/s]
Loading safetensors checkpoint shards:  33% Completed | 24/73 [00:08<00:18,  2.69it/s]
Loading safetensors checkpoint shards:  34% Completed | 25/73 [00:08<00:16,  2.96it/s]
Loading safetensors checkpoint shards:  36% Completed | 26/73 [00:09<00:16,  2.89it/s]
Loading safetensors checkpoint shards:  37% Completed | 27/73 [00:09<00:16,  2.75it/s]
Loading safetensors checkpoint shards:  38% Completed | 28/73 [00:09<00:15,  2.83it/s]
Loading safetensors checkpoint shards:  40% Completed | 29/73 [00:10<00:15,  2.86it/s]
Loading safetensors checkpoint shards:  41% Completed | 30/73 [00:10<00:15,  2.80it/s]
Loading safetensors checkpoint shards:  42% Completed | 31/73 [00:10<00:14,  2.82it/s]
Loading safetensors checkpoint shards:  45% Completed | 33/73 [00:11<00:08,  4.56it/s]
Loading safetensors checkpoint shards:  47% Completed | 34/73 [00:11<00:09,  3.93it/s]
Loading safetensors checkpoint shards:  48% Completed | 35/73 [00:12<00:14,  2.61it/s]
Loading safetensors checkpoint shards:  49% Completed | 36/73 [00:12<00:13,  2.77it/s]
Loading safetensors checkpoint shards:  51% Completed | 37/73 [00:12<00:12,  2.80it/s]
Loading safetensors checkpoint shards:  52% Completed | 38/73 [00:13<00:11,  2.96it/s]
Loading safetensors checkpoint shards:  53% Completed | 39/73 [00:13<00:11,  2.87it/s]
Loading safetensors checkpoint shards:  55% Completed | 40/73 [00:13<00:09,  3.51it/s]
Loading safetensors checkpoint shards:  58% Completed | 42/73 [00:13<00:05,  5.34it/s]
Loading safetensors checkpoint shards:  60% Completed | 44/73 [00:13<00:04,  6.88it/s]
Loading safetensors checkpoint shards:  63% Completed | 46/73 [00:14<00:03,  8.46it/s]
Loading safetensors checkpoint shards:  66% Completed | 48/73 [00:14<00:02, 10.03it/s]
Loading safetensors checkpoint shards:  68% Completed | 50/73 [00:15<00:05,  4.24it/s]
Loading safetensors checkpoint shards:  70% Completed | 51/73 [00:15<00:06,  3.16it/s]
Loading safetensors checkpoint shards:  71% Completed | 52/73 [00:16<00:07,  2.67it/s]
Loading safetensors checkpoint shards:  73% Completed | 53/73 [00:17<00:11,  1.72it/s]
Loading safetensors checkpoint shards:  74% Completed | 54/73 [00:18<00:12,  1.55it/s]
Loading safetensors checkpoint shards:  75% Completed | 55/73 [00:19<00:10,  1.73it/s]
Loading safetensors checkpoint shards:  77% Completed | 56/73 [00:19<00:09,  1.87it/s]
Loading safetensors checkpoint shards:  78% Completed | 57/73 [00:19<00:07,  2.09it/s]
Loading safetensors checkpoint shards:  79% Completed | 58/73 [00:20<00:06,  2.36it/s]
Loading safetensors checkpoint shards:  81% Completed | 59/73 [00:20<00:05,  2.39it/s]
Loading safetensors checkpoint shards:  82% Completed | 60/73 [00:20<00:05,  2.52it/s]
Loading safetensors checkpoint shards:  84% Completed | 61/73 [00:21<00:04,  2.49it/s]
Loading safetensors checkpoint shards:  85% Completed | 62/73 [00:21<00:04,  2.71it/s]
Loading safetensors checkpoint shards:  86% Completed | 63/73 [00:21<00:03,  2.85it/s]
Loading safetensors checkpoint shards:  88% Completed | 64/73 [00:22<00:03,  2.82it/s]
Loading safetensors checkpoint shards:  89% Completed | 65/73 [00:22<00:02,  2.82it/s]
Loading safetensors checkpoint shards:  90% Completed | 66/73 [00:22<00:02,  2.73it/s]
Loading safetensors checkpoint shards:  92% Completed | 67/73 [00:23<00:02,  2.58it/s]
Loading safetensors checkpoint shards:  93% Completed | 68/73 [00:23<00:01,  2.62it/s]
Loading safetensors checkpoint shards:  95% Completed | 69/73 [00:24<00:01,  2.71it/s]
Loading safetensors checkpoint shards:  96% Completed | 70/73 [00:24<00:01,  2.89it/s]
Loading safetensors checkpoint shards:  97% Completed | 71/73 [00:24<00:00,  2.82it/s]
Loading safetensors checkpoint shards:  99% Completed | 72/73 [00:24<00:00,  3.27it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:25<00:00,  3.12it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:25<00:00,  2.89it/s]

[2025-10-31 11:31:33 DP4 TP4] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.23 GB, mem usage=49.18 GB.
[2025-10-31 11:31:33 DP7 TP7] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.22 GB, mem usage=49.18 GB.
[2025-10-31 11:31:33 DP5 TP5] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.15 GB, mem usage=49.18 GB.
[2025-10-31 11:31:33 DP6 TP6] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.21 GB, mem usage=49.18 GB.
[2025-10-31 11:31:33 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.11 GB, mem usage=49.18 GB.
[2025-10-31 11:31:34 DP3 TP3] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.08 GB, mem usage=49.18 GB.
[2025-10-31 11:31:34 DP1 TP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.50 GB, mem usage=49.18 GB.
[2025-10-31 11:31:34 DP2 TP2] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.09 GB, mem usage=49.18 GB.
[2025-10-31 11:31:34 DP0 TP0] Using KV cache dtype: torch.bfloat16
[2025-10-31 11:31:34 DP0 TP0] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP0 TP0] Memory pool end. avail mem=88.43 GB
[2025-10-31 11:31:34 DP5 TP5] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP5 TP5] Memory pool end. avail mem=88.47 GB
[2025-10-31 11:31:34 DP4 TP4] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP4 TP4] Memory pool end. avail mem=88.55 GB
[2025-10-31 11:31:34 DP1 TP1] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP1 TP1] Memory pool end. avail mem=88.82 GB
[2025-10-31 11:31:34 DP2 TP2] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP3 TP3] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP2 TP2] Memory pool end. avail mem=88.41 GB
[2025-10-31 11:31:34 DP3 TP3] Memory pool end. avail mem=88.40 GB
[2025-10-31 11:31:34 DP7 TP7] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP7 TP7] Memory pool end. avail mem=88.54 GB
[2025-10-31 11:31:34 DP6 TP6] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-10-31 11:31:34 DP6 TP6] Memory pool end. avail mem=88.53 GB
[2025-10-31 11:31:34 DP2 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=88.28 GB
[2025-10-31 11:31:34 DP4 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
[2025-10-31 11:31:34 DP7 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
[2025-10-31 11:31:34 DP1 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=88.70 GB
[2025-10-31 11:31:34 DP6 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=88.40 GB
[2025-10-31 11:31:34 DP5 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=88.34 GB
[2025-10-31 11:31:34 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=88.30 GB
[2025-10-31 11:31:34 DP0 TP0] Capture cuda graph bs [1, 2, 4, 8, 12, 16]
[2025-10-31 11:31:34 DP3 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=88.27 GB
  0%|          | 0/6 [00:00<?, ?it/s]Capturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
ler_DP7_TP7: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 7, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank7]:E1031 11:31:37.620000 510 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP4_TP4: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
ler_DP6_TP6: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16># {blockedtt.divisibility =  = #16ttg : .iblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>32
}#, blocked%1arg3 = : #!ttg.ttblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>.
ptr<i8># {blockedtt.divisibility2 =  = 16# : ttgi.32blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>}
, #%blockedarg43:  = i#32ttg {.tt.divisibilityblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}> = 
16# : blockedi432 = }#, ttg%.arg5blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>: 
i#32blocked {5tt.divisibility =  = #16 : ttgi.32blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>}
, #%blocked6arg6 = : #ittg32. {blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>tt.divisibility
 = #16blocked : 7i = 32#}ttg, .%blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>arg7
: #iblocked328 { = tt.divisibility# = ttg16. : blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>i
32#}blocked, 9%arg8 = : #ittg32. {blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>tt.divisibility
 = 16# : lineari = 32}#, ttg%.arg9linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>: 
i#32linear {1tt.divisibility =  = #16ttg : .ilinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>32
}#, linear%2arg10 = : #ittg32. {linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>tt.divisibility
# = shared16 =  : i#32ttg}., swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>%
arg11#: smemi32 =  {#tt.divisibilityttg = .16shared_memory : 
imodule32 attributes} {, "%targ12t: gi.n32u {mtt.divisibility- = c16t : ai32s}",  = %1arg13 : : ii3232,  {"tt.divisibilityt = t16g : .in32u}m-, w%aarg14r: pis32" { = tt.divisibility4 =  : 16i : 32i, 32ttg.target} = , "%harg15i: pi:32g)f attributesx {9noinline5 = 0false"},  "{t
t    g%.cstt = harith.constantre adense<ds127->p : etensor<r4-xw4axr1px"i = 864,  : #iblocked32>}
     {%
cst_0   = tt.funcarith.constant  publicdense< 0x7FC0@>_batched_gemm_afp4_wfp4_pre_quant_kernel : (tensor<%4arg0x: 128!xttbf16.ptr<bf16>,  {#tt.divisibilityblocked = 116> : 
i    32%}cst_1,  = %arith.constantarg1 : dense<!2097152tt>. : ptr<i8>tensor< {4tt.divisibilityx = 416x : 1ix32i}32, , %#arg2blocked: >!
tt    .%ptr<bf16>cst_2 { = tt.divisibilityarith.constant =  16dense< : 4i>32 : }tensor<, 4%xarg34: x!16ttx.iptr<i8>8 {, tt.divisibility# = blocked162 : >i
32    }%, c31_i32% = arg4arith.constant:  i3132 :  {itt.divisibility32 = 
16     : %icst_332 = }arith.constant,  %dense<arg50.000000e+00: >i : 32 {tensor<tt.divisibility4x = 3216x : f32i, 32#}blocked, 3%>arg6
:     i%32c32_i32 { = tt.divisibilityarith.constant =  1632 :  : ii3232}
,     %%arg7c4_i32:  = iarith.constant32  {4tt.divisibility :  = i1632 : 
i    32%}true,  = %arith.constantarg8 : truei
32     {%tt.divisibilityc0_i32 =  = 16arith.constant :  i032 : }i32, 
%    arg9%: cst_4i32 =  {arith.constanttt.divisibility  = dense<16-8388608 : >i : 32tensor<}4, x%4arg10x: 1ix32i {32tt.divisibility,  = #16blocked : >i
32    }%, cst_5% = arg11arith.constant:  idense<32 {tt.divisibility2.000000e+00 = >16 :  : tensor<i432x}4, x%1arg12x: f32i, 32# {blockedtt.divisibility> = 
16     : %i32cst_6} = , arith.constant% arg13dense<: 0.000000e+00i>32 :  {tensor<tt.divisibility4 = x164 : xi132x}f32, , %#arg14: blockedi>32
 {    tt.divisibility% = cst_716 =  : arith.constanti 32dense<}-2147483648, >% : arg15tensor<: 4ix324)x attributes32 {xnoinlinei = 32false, }# blocked{>

        %%cstcst_8 =  = arith.constantarith.constant  dense<dense<12723>> :  : tensor<tensor<44xx44xx321xxii328, , ##blockedblocked>>

        %%cst_9cst_0 =  = arith.constantarith.constant  dense<dense<2550x7FC0>> :  : tensor<tensor<44xx4x12832xxbf16i, 32#, blocked#1blocked>>

        %%cst_1cst_10 =  = arith.constantarith.constant  dense<dense<20971528388607>> :  : tensor<tensor<44x4xx41xx32ix32i, 32#, blocked#>blocked
>    
%    cst_2% = cst_11arith.constant =  arith.constantdense< 4dense<>1> :  : tensor<tensor<44xx44x32xx16i32x, i#8blocked, >#
blocked    2%>cst_12
 =     arith.constant% c31_i32dense< = 127arith.constant>  : 31tensor< : 4ix324
x    32%xcst_3i = 32arith.constant,  #dense<blocked0.000000e+00>>
 :     tensor<%4cst_13x = 32arith.constantx f32dense<, 4194304#>blocked : 3tensor<>4
x    4%xc32_i3232 = xarith.constanti 3232,  : #i32blocked
>    
%    c4_i32% = cst_14arith.constant =  arith.constant4  : dense<i12632>
 :     tensor<%4truex = 4arith.constantx32 xtruei
32    , %#c0_i32blocked> = 
arith.constant     %0cst_15 :  = iarith.constant32 
dense<    2%>cst_4 :  = tensor<arith.constant4 xdense<4-8388608x>32 : xtensor<i432x, 4#xblocked1>x
i    32%, cst_16# = blockedarith.constant> 
dense<    21%>cst_5 :  = tensor<arith.constant4 xdense<42.000000e+00x>32x : i32tensor<, 4x#4blockedx>1
x    f32%, cst_17# = blockedarith.constant> 
dense<    28%>cst_6 :  = tensor<arith.constant4 xdense<40.000000e+00x>32 : xtensor<i432, x#4blockedx>1
x    f32%, cst_18# = blockedarith.constant>
     dense<%-1.270000e+02cst_7> =  : arith.constanttensor< 4dense<x-21474836484>x : 1tensor<x4f32x, 4#xblocked32>x
i    32%, cst_19# = blockedarith.constant> 
dense<    7%>cst_8 :  = tensor<arith.constant4 xdense<3223x>i : 16tensor<, 4#xttg4.xslice<{dim = 2, parent = #blocked4}>32>x
i    32%, cst_20# = blockedarith.constant> 
dense<    -1%>cst_9 :  = tensor<arith.constant4 xdense<32255x>i : 8tensor<, 4#xttg4.xslice<{dim = 2, parent = #blocked4}>32>x
i    32%, cst_21# = blockedarith.constant> 
dense<    0x7FC0>% : cst_10tensor< = 128arith.constantx 32dense<x8388607bf16>,  : #tensor<blocked45x>4
x    32%xcst_22i = 32arith.constant,  #dense<blocked7>>
 :     tensor<%4cst_11x = 4arith.constantx 32xdense<i132>,  : #tensor<blocked4>
ler_DP2_TP2: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
x    4%xcst_2332 = xarith.constanti 32dense<, 1.270000e+02#>blocked : >
tensor<    4%xcst_124 = xarith.constant1 xdense<f32127, ># : blockedtensor<>4
x    4%xcst_2432 = xarith.constanti 32dense<, 1.270000e+02#>blocked : >
tensor<    4%xcst_134 = xarith.constant1 xdense<f324194304, ># : lineartensor<>4
x    4%xcst_2532 = xarith.constanti 32dense<, -1.270000e+02#>blocked : >tensor<
    4%xcst_144 = xarith.constant1 xdense<f32126, ># : lineartensor<>4
    x%4cst_26x = 32arith.constantx idense<322.000000e+00, ># : blockedtensor<>4
x    4x%1cst_15x = f32arith.constant,  #dense<linear2>>
 :     tensor<%4cst_27x = 4arith.constantx 32dense<x-8388608i>32 : , tensor<#4blockedx>4
x    1%xcst_16i = 32arith.constant#,  blocked#dense< = linear21#>>ttg
 : .    tensor<blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>%4
cst_28x# = 4blockedarith.constantx1 32 = dense<xi#209715232ttg>, . : #blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>tensor<blocked
4>#x
blocked4    2x% = 1cst_17#x = ttgiarith.constant.32 blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>, dense<
#28#linear>blocked> : 3
tensor< =     4#%xttgcst_294. = xblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>arith.constant32
 x#dense<iblocked127324>,  =  : #blocked#tensor<>ttg4
.x    %blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>4cst_18
x = #1arith.constantblockedx 5idense< = 8-1.270000e+02#, >ttg# : .lineartensor<blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>>4x

4#    xblocked%16cst_30x =  = f32, #arith.constant#blockedttg >.dense<
blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>7    
>%# : cst_19blockedtensor< = 74arith.constant = x #4dense<ttgx7>.i : blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>16tensor<
, 4x##32blockedttgx8.i16 = slice<{dim = 2, parent = #blocked}>, #>#ttgttg
.slice<{dim = 2, parent = #blocked4}>.    >blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>%

cst_31    #blocked = %9arith.constantcst_20 =   = #dense<arith.constantttg-1 .>dense<blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}> : -1
tensor<>#4 : linearxtensor< = 44x#x32ttgix.8ilinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>, 8
#, #ttg#linear.ttg1slice<{dim = 2, parent = #blocked}>. = >slice<{dim = 2, parent = #blocked4}>#
>ttg    
.llvm.intr.assume    linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}> %
%cst_21#true = linear arith.constant2:  =  dense<#i0x7FC0ttg1>.
 : linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>    tensor<
llvm.intr.assume128# xshared%32 = truex# bf16ttg:, . #swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>iblocked
15>#

smem         = llvm.intr.assume%# cst_22ttg% = .truearith.constantshared_memory  
:dense<module 7 attributesi> {1 : "
tensor<t    4tllvm.intr.assumexg 4.%xntrue32u xm:i- 32ci, t1#a
blockeds    >"llvm.intr.assume
     =  %1%cst_23 : true = i arith.constant32: ,  dense<"i1.270000e+02t1>t
 : g    tensor<.llvm.intr.assume4xn 4u%xmtrue1- xw:f32, a #riblockedp1>s

"         = llvm.intr.assume%cst_244  =  : %arith.constantitrue  32:dense<,  1.270000e+02ttg.targeti> = 1 : "
tensor<h    4illvm.intr.assumexp 4:%xgtrue1f xx:f329 , 5i#01linear>"

,         "llvm.intr.assume%cst_25t  = t%arith.constantgtrue . dense<t:-1.270000e+02h >ri : ea1tensor<4d
xs    4-llvm.intr.assumexp 1e%xrtruef32-w , a:#r linearpi>"1
     = 
%64    cst_26 : llvm.intr.assume = i arith.constant32% }truedense<  2.000000e+00{:>
  :   itensor<4tt.func1x4 
x1public    x llvm.intr.assumef32, @ #_batched_gemm_afp4_wfp4_pre_quant_kernel%linear(true>% 
arg0:    :  %!icst_27tt1 = .
arith.constantptr<bf16>      {%dense<tt.divisibility0-8388608 =  = >16tt.get_program_id :  :  tensor<ix432 x4}:x,  1%ixarg1: 32i!
32tt    , .%#ptr<i8>1linear { = >tt.divisibilitytt.get_program_id
 =      16y% :  cst_28i: = 32 arith.constant}i , 32dense<%
2097152arg2    >: % : tensor<!24xtt = 4.arith.addixptr<bf16> 1 {%xtt.divisibilityarg5i = ,3216 ,  : %#ic31_i32linear32 >}:
,      %i%arg332cst_29: 
 = !    arith.constanttt% .3dense<ptr<i8> = 127 {arith.divsi>tt.divisibility  :  = %tensor<1624 : ,xi 432%x}c32_i321,  x%:i8arg4 , : i#i32linear32
> {    
tt.divisibility%     = 4%16 = cst_30 : arith.extsi = i arith.constant32% }arg7dense<,  7%:>arg5  : : itensor<i32432 x {to4tt.divisibility x = ii166416 : 
, i    #32%ttg}5.,  = slice<{dim = 2, parent = #blocked}>%arith.extsi>arg6 
: %    iarg9%32 cst_31 {: = tt.divisibility arith.constant = i 1632dense< :  -1ito>32  : }itensor<, 644%
xarg7    4: %xi6i832 = ,  {arith.extsi#ttgtt.divisibility . = %slice<{dim = 2, parent = #blocked}>16arg11> :  
i:    32 llvm.intr.assume}i , 32%% truearg8to :  :ii 3264i {
1tt.divisibility    
 = %    167llvm.intr.assume :  =  iarith.extsi%32 true}% , 0: % iarg9:1:  
ii    3232llvm.intr.assume {  tt.divisibilityto% =  true16i : : 64 i
i32    1}%
, 8    % = llvm.intr.assumearg10arith.divsi :  %i%true321 : {, tt.divisibility i = %1163
 :      i:llvm.intr.assume32  }i%, 32true%
 arg11:     :i% 329i { = 1tt.divisibilityarith.remsi
     =  llvm.intr.assume 16%% : 1truei, 32 :}% , 3i% 1arg12:
:      iillvm.intr.assume3232  {
%tt.divisibility    true = llvm.intr.assume 16 : : % itruei32 1}:
,      %illvm.intr.assumearg131 : 
%i    true32llvm.intr.assume  { :tt.divisibility%  = truei116 
 : :    i llvm.intr.assume32i }1%true, 
 :%     arg14llvm.intr.assumei:  1i%
32true     { llvm.intr.assumett.divisibility:  =  %16itrue : 1 :i
 32    i}%1, 10
% =     arg15arith.cmpillvm.intr.assume:   isgt%true32, ) :  attributes%i1 {arg6
noinline,     =  llvm.intr.assumefalse% }c0_i32%true   {::
      ii%321cst

     =     %arith.constantscf.if0   = dense<%tt.get_program_id12710 > x : { tensor<
:4       x%i41132x = 
1arith.muli    x %i%1 = 88tt.get_program_id , ,y#  blocked%:>c4_i32 
 i    :32% 
cst_0i     = 32%arith.constant
2        = dense<%arith.addi0x7FC012 > = % : tt.make_rangearg5tensor< {,4end x = %1284c31_i32x :  bf16i:, 32 #, iblockedstart321 = 
>0    
 : %    i3%32 = cst_1}arith.divsi =   arith.constant:%  2dense<tensor<,20971524 >x% : ic32_i32tensor<32 4, :x# 4ttgix.321slice<{dim = 1, parent = #blocked1}>
x>    i
%32      4, % = #13arith.extsiblocked =  >tt.make_range%
 {arg7    end % = :cst_24  =  : iarith.constanti32 32 dense<, to4start > = i : 064tensor< : 
4i    x32%4}5x  = 16:arith.extsix  itensor<%84arg9, x #i:blocked32 2, i>#32
ttg     .to%slice<{dim = 1, parent = #blocked3}> c31_i32>i = 
64arith.constant      
     %%63114 =  :  = arith.extsiitt.splat 32 %
%arg11    11 :%  cst_3:i =  32arith.constanti  32todense<  i0.000000e+00->64> 
 : tensor<    tensor<4%74x = xiarith.extsi3232 x, %f32#0, ttg #.:blockedslice<{dim = 1, parent = #blocked1}> i3>32>
 
      to    % %15ic32_i32 = 64 = arith.addi
arith.constant     % %83214 =  : ,arith.divsii  32%%1
12,      %:%c4_i32 3 = tensor< arith.constant4: x 4ii : 3232i, 
32#    
ttg%    .9%slice<{dim = 1, parent = #blocked1}> = true>arith.remsi = 
 arith.constant      % %1true16,
 =      tt.splat%% 3c0_i32 = % arith.constantarg4:   0:i32 :  
ii    3232llvm.intr.assume
      ->%% truecst_4tensor< : = 4 arith.constantxi i1dense<32
-8388608,     >#llvm.intr.assume : ttg tensor<.%4slice<{dim = 1, parent = #blocked1}>truex> 4
:x       1%ix171i = 
32arith.remsi    ,  llvm.intr.assume #%%blocked15true>, 
 :    % %cst_516i =  1arith.constant:
      dense<tensor<%2.000000e+00410>x =  : iarith.cmpitensor<32 4, sgtx#,4ttg x.%1slice<{dim = 1, parent = #blocked1}>arg6x>,f32
 ,       %#%c0_i32blocked18 > = :
arith.muli      i%%32cst_67
 = ,    arith.constant scf.if % dense<4%0.000000e+00 10>:  :  {tensor<i
464      x
%4      11x% = 119arith.mulix =  f32tt.expand_dims%,  8#%,blocked17 > {%
axisc4_i32     =  %1:cst_7 :   = iiarith.constant3232 }
dense< :      -2147483648 %>tensor<12 : 4 = tensor<xtt.make_range4i {x32end4,  = x#432ttg : x.iislice<{dim = 1, parent = #blocked1}>3232>, ,  start#-> = blocked> 0
tensor< :     4i%x32cst_8 = 1}arith.constantx  i:dense<32 23, tensor<>#4 : blockedxtensor<1i324>, x
#4      ttg.x%slice<{dim = 1, parent = #blocked1}>3220>x = 
itt.splat      32 %, %13#arg8 = blocked tt.make_range>: {
 end    i = %324cst_9  :  = ->i32arith.constant ,  tensor<startdense<4 = 255x0 : >1i : x32tensor<i}432 x, :4# xblockedtensor<3214x>xi
i32      32, %, #21#blocked = ttg>arith.muli.
 slice<{dim = 1, parent = #blocked3}>    %>%19
cst_10,       =  %arith.constant%14 20 = dense< tt.splat8388607: > % : tensor<11tensor<4 4x:x1 4xixi323232 x, ->i# 32blockedtensor<, 14#>xblocked
i>      32
%,     22#% = ttgcst_11arith.extsi. =  slice<{dim = 1, parent = #blocked1}>arith.constant%> 21
dense<       1:%> 15 : tensor< = tensor<4arith.addi4x x1%4x14xi, 3232%x, 12i# 32blocked:, 1 #>tensor<blocked 4>tox
 i    tensor<32%4, cst_12x# = 1ttgarith.constantx. islice<{dim = 1, parent = #blocked1}>dense<64>127, 
>#       : blocked%tensor<1164> = x
tt.splat4       x%%3223arg4 x = :itt.make_range 32 {i, end32# =  blocked128->> :  
itensor<    324%, xcst_13starti32 =  = , arith.constant0#ttg  : .dense<islice<{dim = 1, parent = #blocked1}>419430432>>}
 :        tensor<:%4 17xtensor< = 4128arith.remsi xx%32i15x32,i,  32#%, ttg16#. blockedslice<{dim = 0, parent = #blocked1}>:>> 

tensor<          4%%xcst_1424i =  = 32arith.constanttt.expand_dims,   #dense<%ttg12623.slice<{dim = 1, parent = #blocked1}>> {> : axis
tensor< =       40%18x :  = 4iarith.mulix32 32}%x 7i:,32  , tensor<%#1284blockedx >i:
32     , i64%#
cst_15ttg       = .%arith.constantslice<{dim = 0, parent = #blocked1}>19 > = dense< tt.expand_dims2-> > % : tensor<17tensor<1 {4xaxisx128 = 4x1xi : 3232i32x, }i# 32blocked:, 1 #>tensor<blocked
4>      x
%i    2532, % = #ttgcst_16arith.extsi. =  slice<{dim = 1, parent = #blocked1}>arith.constant%> 24 dense< ->21: > tensor< : tensor<4tensor<1x4x1x128x4xixi323232, x, #i#blocked32blocked1, 1>#>
blocked       >to%
 20 =     tensor<tt.splat%1 cst_17x% = 128arg8arith.constantx  i:dense<64 28, i>#32 : blocked tensor<1-> 4>tensor<x
44      xx%13226xx = iitt.broadcast3232 , , %#blocked#221blocked >>:

           tensor<%%421cst_18x =  = 1arith.muli arith.constantx%19 i,dense<64 -1.270000e+02, %>#20 : blocked tensor<1:4> x tensor<4->4x x1tensor<1x4xf32xi, 12832#x, blockedi#>64blocked
, 1    #>%blocked
cst_191       = >%arith.constant
22        = dense<%arith.extsi727 > = % : tt.broadcast21tensor<  4%:x25 32 tensor<4x:xi 116tensor<x, 1i32#x, ttg128#.xblockedslice<{dim = 2, parent = #blocked4}>i1>64>
,      #to%blocked cst_201tensor< = >4arith.constant x ->1dense< x-1tensor<i>464 : x, tensor<128#4xblockedxi13264>x, 
i#      8blocked%, 123#> = ttg
tt.make_range.       {slice<{dim = 2, parent = #blocked4}>%end>28 = 
 = 128    arith.addi : % icst_21%32 = 26, arith.constant,start   = dense<%00x7FC027 : > i : :32tensor< }128tensor< :x4 32xtensor<x128128bf16xx, ii#6432blocked, , 5##>blockedttg
1.    >slice<{dim = 0, parent = #blocked1}>%
>cst_22      
 = %      arith.constant29%  = 24dense<tt.addptr = 7 tt.expand_dims>%  : arg0%tensor<,234  {x%axis418 = x 032: : x ii!3232tt}, . #ptr<bf16>:blocked, > tensor<
i128    64x%
icst_23      32 = %, arith.constant30#  = ttgdense<arith.muli.1.270000e+02 slice<{dim = 0, parent = #blocked1}>>%> : 9 tensor<,->4  x%tensor<4c32_i321x x1:128x xf32ii, 3232, #
#blocked      blocked>%1
31>
     =       %tt.make_range%25cst_24 { =  = endarith.extsiarith.constant =   32%dense< : 241.270000e+02i >32:  : , tensor<1tensor<startx4 = 128x0xi4 : 32xi, 132#x}blockedf32 1, :>#  lineartensor<to>32 
xtensor<    i1%32xcst_25, 128x = #iarith.constantttg64 ., dense<slice<{dim = 0, parent = #blocked6}>#-1.270000e+02>blocked>
1 :       >
tensor<%      432%x = 264tt.make_range = x {tt.broadcast1end x = %22f3232 ,  : :#i linear32tensor<>, 4x
start1     = x%0icst_26 : 64 = i, arith.constant32#blocked }1dense< >2.000000e+00: > -> : tensor< tensor<32tensor<4x4xix432128x, x1#i64xttg, f32.#blocked, slice<{dim = 0, parent = #blocked3}>1#>>linear

>            
%%    3327% =  = cst_27tt.make_rangett.broadcast =  { arith.constantend%  = 25dense<32 -8388608 : :>i  : 32tensor<tensor<, 14startx128x = x40ix : 641i, x32#i}blocked132 >, : # ->lineartensor< >32tensor<
x4    ix%32128cst_28, x = #iarith.constantttg64 ., dense<slice<{dim = 1, parent = #linear1}>#2097152>blocked>
1 :       >tensor<%
434      x = %284tt.splat = x arith.addi1% x30%26i ,32: ,  %#i27linear32 > :
->      tensor<4%tensor<xcst_2932128 = xxarith.constantii 3264dense<, , 127##>ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30blocked 1: : > itensor<4
32 x      ->4% x29tensor<1 = 32xxtt.addptrii 328%, , arg0##linear,ttg> .
%slice<{dim = 1, parent = #linear1}>    18>% 
cst_30 = :      arith.constant % !36 = dense<ttarith.addi 7>.% : ptr<bf16>34tensor<,, 4x %314i x64:i
 16      tensor<, %32x#ttg30i. = 32slice<{dim = 2, parent = #blocked}>arith.muli, > #ttg
%.slice<{dim = 0, parent = #blocked6}>    9>
%cst_31,       =  %arith.constant%37 c32_i32 = dense< arith.addi -1>:% :  35tensor<4i,x432 x
%i      338% , 31:#ttg =  .tt.make_rangetensor<32slice<{dim = 2, parent = #blocked}> {xi>end32
 = ,     32#ttgllvm.intr.assume : . islice<{dim = 1, parent = #linear1}>%true32>
 ,       %:start38  =  = i0tt.splat1 :  %
iarg5     32: llvm.intr.assume }i% 32true: -> :   tensor<tensor<i3232x1xi
i32    32, llvm.intr.assume, # #ttg%truettg. :.slice<{dim = 0, parent = #blocked6}> slice<{dim = 0, parent = #blocked6}>>
i1>      %

39           = llvm.intr.assume%tt.splat  %32%true = arg5 tt.make_range : {: end i1 = i
    3232llvm.intr.assume :   i-> %true32tensor<32 :, x starti32i1 = , 
0#ttg     : .slice<{dim = 1, parent = #linear1}>llvm.intr.assume i>%32
true}       : %40 : = i1 arith.remsi
tensor<     32%llvm.intr.assume x36%truei, 32 :, % #38ittg :1. tensor<
    slice<{dim = 0, parent = #blocked3}>32llvm.intr.assume>x 
i32%true      ,  %#: 33ttg.i1 = slice<{dim = 0, parent = #blocked6}>
tt.make_range>     {
      llvm.intr.assumeend%  = 41%32 = true : arith.remsi i %: 3237i, ,1start %
     = 39llvm.intr.assume0   : :%truei  32tensor<:}32  xii1:32
 ,     tensor<#ttgllvm.intr.assume32.slice<{dim = 1, parent = #linear1}> %x>truei
 32      : , %i1#42
ttg =     .arith.mulillvm.intr.assumeslice<{dim = 1, parent = #linear1}> % %>7true
,        : %%i1345
 =      tt.splat:%  0%i64 = 30
tt.get_program_id        :%x 43 i = :32tt.make_range   {i->end32  = 
tensor<64    32 : %xi1i32,  = 32starttt.get_program_id,  =  #0yttg :  .i32: slice<{dim = 0, parent = #blocked6}>}i32> 

:           tensor<64%2%x = 35iarith.addi = 32 tt.splat, % #arg5%ttg,30.slice<{dim = 1, parent = #blocked6}>  >%:
      c31_i32 %44 i = :32tt.expand_dims   %43i->  {32tensor<axis
32 =     x1%i : i3 = 3232arith.divsi, } # :%2ttg ,.tensor< slice<{dim = 1, parent = #linear1}>64x%>ic32_i32
32       , :%# 36ttgi = .32arith.addislice<{dim = 1, parent = #blocked6}>>
      %%->434  = , tensor<arith.extsi%64 31x% 1arg7:x  i:tensor<32 32, i32x#blocked i6to32> , 
      i64#%
ttg45    . = %5slice<{dim = 0, parent = #blocked6}>arith.extsi  = >%44arith.extsi 
 %      :arg9%  37tensor<:  = 64i32arith.addix1  xito%32,  35#i,blocked64 6
%>     %33to6   = :tensor<arith.extsi 64x tensor<1%32xiarg11 x64:i,  32#i32, blocked #6to ttg>
i64.      
slice<{dim = 1, parent = #linear1}>%    >46%7
 =  =       tt.expand_dimsarith.extsi%  38%40% =  {0 tt.splataxis:   = i%032arg5 :  to i :32i }64i 
    32: % tensor<328 = ->xarith.divsi i tensor<32%132, , x#%ittg332. , slice<{dim = 0, parent = #blocked6}>:#>  ttg->i. 32slice<{dim = 0, parent = #blocked6}>tensor<1
    >x%
329 =       xiarith.remsi%32 39, #%1 = blocked,tt.splat6  >
%3%       arg5%: 47 =  :tt.splat i %arg1032i 
32:      illvm.intr.assume ->32%  truetensor<->  :32tensor< x1iix13232x
    , illvm.intr.assume#32 ttg, %.#trueslice<{dim = 1, parent = #linear1}>blocked :>6> 

i            %1%48 = 
    40arith.muli llvm.intr.assume  = %%arith.remsi46true , % :36%47 , :i  1%tensor<
    381% x32xi3210 = :, arith.cmpi # tensor<blockedsgt326>,x
 i      %32%arg6, 49,# =  ttgarith.extsi%c0_i32.  slice<{dim = 0, parent = #blocked6}>%48:> : 
 i      tensor<32%1
41x     = 32xscf.ifarith.remsii  32%%, 37#10,blocked  6{%>
39 to      %  11:tensor< =  1xarith.mulitensor<32x 32i%x648i, ,32# , blocked6%#>c4_i32ttg
 .      :slice<{dim = 1, parent = #linear1}>% >50 = i32
tt.broadcast 
            %%%4512 = 42 :tt.make_range =   {arith.mulitensor<end 64x = %1x47i64 : ,, #i32 blocked, %6>start = 5 0 -> : : i tensor<32i64}64x 
32:      x %itensor<43644 = , #xitt.make_rangeblocked32 {6>, end
# =       %ttg.6451slice<{dim = 1, parent = #blocked1}> :  = >itt.broadcast
32       %, %13 = start49tt.make_range =  : {0 tensor<end =  : 14ix : 3232i}xi32,  64start = :, 0 # : tensor<blockedi32646}x>  :i->  32tensor<64tensor<4, xx#32ittgx32, .i64#ttgslice<{dim = 1, parent = #blocked6}>, #.>blockedslice<{dim = 1, parent = #blocked3}>
6>>      
      
      %%%445214 =  =  = tt.expand_dimsarith.addi tt.splat %50 %, %1143%  {51:axis   = :i321   : tensor<->i64 32x32tensor<4}xx ii:6432,  , #ttgtensor<#.64blocked6slice<{dim = 1, parent = #blocked1}>x>>
i
            %32%15, 53 = # = arith.addittgtt.addptr . %14slice<{dim = 1, parent = #blocked6}>%,>arg1  ,%12->  : %42 tensor< tensor<464:xx i321!tt, x.#iptr<i8>,ttg.32 slice<{dim = 1, parent = #blocked1}>>, i
      #64
%blocked      16 = 6%tt.splat>54 
 = %      arith.extsiarg4 % : 45%i32 = arg14 ->arith.extsi :   tensor<%i44432x  i32:to ,  i#ttgtensor<64.slice<{dim = 1, parent = #blocked1}>64
      >
x%55      %1 = 17 = xarith.muliarith.remsii  32%%, 715,#, blocked %6%5416> : :   toitensor< 644xtensor<
i64      32, x%56#ttg1 = .slice<{dim = 1, parent = #blocked1}>xtt.addptr>i 
64%      , arg3,%18# % = blocked55arith.muli6 : %> 7
!,      tt. %ptr<i8>,%46 i4 = 64
 :tt.expand_dims      %  57 = i64%tt.expand_dims 
      40%% {4119 = axis {axistt.expand_dims =  =  01% :  : 17ii {3232axis = }}1   : :: i32 tensor<32}tensor<x 32i:x32,  i#ttgtensor<432.slice<{dim = 1, parent = #linear1}>x, > i32#-> , ttgtensor<#.32xttgslice<{dim = 0, parent = #blocked6}>1x.slice<{dim = 1, parent = #blocked1}>>i> 32 ->, -> #linear tensor<1tensor<1>4x
x32      1x%xi58i32 = 32, tt.splat, # #blocked%arg15blocked6 1>: >
i32
       ->      % %47tensor<20 = 32 = tt.splatx1tt.splat x %i%arg1032arg8 , # ::linear  1i32i> 32
      -> % ->59tensor<  = 4tensor<arith.mulix1 1xx%i325732x,, i %#blocked32581,  >#:
blocked tensor<      632%>x21 = 
1arith.muli       x%19%i, 4832%20 = , # arith.mulilinear:  1tensor<%>446
x,      1 %x%60 = i3247arith.extsi,   #blocked:%1> 59 
      tensor<: %221tensor< = x32arith.extsi 32x%x121 ix:32i32 , , tensor<##linear4xblocked11x6>i> 32, 
to #blocked      tensor<1%32> 49x1to = x arith.extsiitensor<4 64, x1%#linearx481i >64, :
#blocked       1>tensor<%
      161%23x =  = 32tt.make_rangett.make_rangex { {iendend = 32 = 128, 4 : # : iblockedi32326, , >startstart =   = 0to0 :   : i32tensor<i}132 x}: 32 tensor<x:128i x64tensor<4i32, x, #i#ttgblocked32.6>, slice<{dim = 0, parent = #blocked1}>
#>      ttg
%.      50slice<{dim = 0, parent = #linear1}>%24 = > = tt.broadcast
tt.expand_dims        %%%4562 = 23 tt.broadcast {: %axis =  600tensor< : : i64 32}xtensor< :132 xxtensor<i1128x64xi32, i64, #, #blocked#ttg.6linearslice<{dim = 0, parent = #blocked1}>>1> > -> -> -> tensor< tensor<64tensor<321xxx128324xxxi64i32i, , 64##, linearblocked1#1>blocked>
      6
%25>       = 
%63arith.extsi        = %24%tt.expand_dims :51 %  = 61tensor<1tt.broadcast {x axis128% = x490 : i32 i, :32#blocked }1tensor< > 1:to x tensor<32tensor<41xxxi128xi32i6464, , , #ttg##.blockedblockedslice<{dim = 0, parent = #linear1}>1>6>
>        ->%26->  =  tensor<tt.broadcasttensor<1 64x%22x4 :32x xi32tensor<4i, x64#1, linearx#1>i64blocked
, #6      blocked>%1
64 = >       tt.broadcast -> %%tensor<52634 =  :xarith.addi 128 tensor<x%1i50x64, ,4#blocked x1%i32>51, 
       #%:linear27 1 = tensor<>tt.broadcast 64 %25x-> 32 tensor<: x32tensor<1ixx644128, xx#iiblocked32646, #, #>linear1blocked1
>>       
->%      % 5365 = tensor<4 = arith.extsixtt.addptr 128 %x%64 i64arg1: , #,tensor<32blocked1 x>%4x
      42i% 3228 = :, arith.addi  #linear%26!1>, tt %.to27ptr<i8>  ,tensor<:  32tensor<ix4644x
x128x      ii64%64, , #54#blocked = linear1arith.extsi1> >
      %
%29arg14       =  %tt.addptr:66   = %iarith.addiarg032 %, 65 to,%  %18i62 64 :
:        tensor<!tt%32.55xptr<bf16> = 4,arith.mulix  ii64%64, 
      7#%,linear30 1 = %>
arith.muli54        %%:67 = 9, tt.splat i %64%56c32_i32
        : : %!i56tt32 = .
tt.addptrptr<i8>      %  31 = %-> tt.make_rangearg3tensor<32 {,x4end =  x32%! : 55tti .32, :ptr<i8>, start =  #linear0!1 : tt>i.
32ptr<i8>      } ,%68:   = tensor<itt.addptr3264 x
%67i32      ,, % #57%66ttg. =  slice<{dim = 0, parent = #blocked6}>tt.expand_dims:>  
      %tensor<%413232 {x4 = axisxtt.make_range = ! {1ttend : . = iptr<i8>3232, # : i}linear132 >, :,start   = tensor<tensor<32032x : x4iix3232i64} , , :## ttglinear1tensor<.>
32xslice<{dim = 1, parent = #linear1}>      i>%32,  69#ttg-> = . tt.loadslice<{dim = 0, parent = #blocked3}>>tensor< 
32%68      x :%331  = xtensor<tt.make_rangei32 {32xend, 4 = #x32linear! : 1tti32>., 
ptr<i8>, start =       #0%linear : 581i32 = >}tt.splat
 :       % %70 = tensor<32arg15tt.transx  i32:%,  69#ttgi {.slice<{dim = 1, parent = #linear1}>32order>  = 
->array<       i32%34tensor<:  = 321tt.splatx,  10%x>30 i}:32  , : i32#tensor< ->linear32 1x4tensor<>x32
i8x      , #i32%linear, 591# = >ttg.arith.muli slice<{dim = 0, parent = #blocked6}> ->>
%       %57tensor<35 = ,4tt.splat  x%30%32x :58i  8i:, 32 # tensor<ttg-> 32.tensor<32xslice<{dim = 2, parent = #blocked4}>>xi1
32, x      #ttgi%.3271slice<{dim = 1, parent = #linear1}>,  = >#tt.splat 
linear%      %12936 = > arith.addi
:        %34%!, 60tt%31 = . :arith.extsiptr<bf16>   tensor<%->3259 x tensor<i:432,  x#tensor<128ttg.32xslice<{dim = 0, parent = #blocked6}>x!>
1tt      x.%iptr<bf16>3732,  = , #blockedarith.addi #1%linear>351
      , >%% 7233to =  : tt.addptr  tensor<%71tensor<3232,xx i1%32x28 , i:#64 ttg, tensor<4.slice<{dim = 1, parent = #linear1}>#x>linear128
      1x%>!38 = 
tttt.splat      . %%ptr<bf16>, arg561#blocked : = 1 tt.make_range>i {, 32endtensor<  = 4x-> 4128tensor< : x32xiii326432, , , #start#ttg. = blocked1slice<{dim = 0, parent = #blocked6}>0>
> :       
i%73      32 = %}tt.load39 =   tt.splat :%% 72arg5tensor<  4::x  itensor<4i3232x , 128-> #xtensor<ttg!tt32x..i32slice<{dim = 0, parent = #linear1}>ptr<bf16>, >, ##ttg
blocked.      1slice<{dim = 1, parent = #linear1}>%>>
62
       =       %tt.broadcast%40 74 = % = arith.remsi60tt.splat   %36:%53,   %tensor<:3832  x!:1tt x.tensor<32iptr<i8>x64 ->i32,  , #tensor<#ttglinear64.1xslice<{dim = 0, parent = #blocked6}>>32x> ->!
       tt%41tensor<. = 32ptr<i8>arith.remsix, # 4blocked6%37x>,i
 64      %%39, 75 # = : lineartt.addptr tensor<1%7432x>,i
 32      %, %52#63 ttg = : .slice<{dim = 1, parent = #linear1}>tt.expand_dimstensor<>
 64      %x%613242 {x = axis!ttarith.muli  = .%0ptr<i8>7 : , #, iblocked%3265}>  , : :tensor<i 6464tensor<x32
4x      xi%43i64 = 32, #tt.make_range, blocked6 {#>end = ttg
64.       : slice<{dim = 0, parent = #linear1}>%i>7632  = , ->tt.load start =  %0tensor<75 : 1 i32xcacheModifier} 4 :x= i tensor<6432cgx,  i#:32linear tensor<, 164x#ttg>32.slice<{dim = 1, parent = #blocked6}>
x>      !
%tt      %64.44 =  = ptr<i8>, tt.expand_dims tt.broadcast#%43 blocked {%6>axis = 63
1        : :%77i32  = } tensor<ttg.convert_layout: 1 tensor<64x%x476ix 32, i:#32 ttg, tensor<.#64slice<{dim = 1, parent = #blocked6}>linearx>132x ->>i  8, tensor<64->#x blocked1tensor<6x32>ix 324->, x #itensor<blocked32646, x32>#xi
      linear8%1, 45 = >#blockedarith.extsi 
3%44      > %
:65        = %tensor<64arith.extsi78 = x tt.reshape1x% i64%7332,   #blocked::6  > tensor<tensor<to324 xxtensor<644128xxx1ibf16x32, i64, #, #blocked#blockedlinear16>1>
      > % ->46 = to tt.expand_dims tensor< tensor<4%32x440xx32 {4xaxisxbf16 = i, 064, #blocked : #>i32linear
}1      % :>79 
 = tensor<      math.absf32x% i3266%,  = 78#arith.addi ttg. :slice<{dim = 0, parent = #blocked6}>% >65tensor< ->,4  xtensor<%4162xx 32x32x:bf16i , 32tensor<#blocked, 32>#x
blocked4      6x%80>i = 
      64arith.extf%47,   = #%tt.splat linear79%1 arg10>:  :
tensor<       4i%x43267x -> = 32 tt.splatxtensor< bf16, 1%#blockedx3256>x  i:to32,   #blocked!tensor<6tt4>.x
      ptr<i8>4% x3248 = ->xarith.muli f32 tensor<, #%4632blocked,x> 4
      %x%8147! =  tt":.tt ptr<i8>.tensor<, r1#exlineardu321cx>ei
"32      (, %%#blocked6880)6 =  <>tt.addptr{
       axis = %49%2 :  = 67iarith.extsi,32  }%48%> ( :66{  
tensor<:      1 ^bb0(x32tensor<%x32arg16i32x: , #4f32blockedx, 6!%>ttarg17 .: f32to ptr<i8>)tensor<, :1#
x32linear        x1%i64>209 = , #,arith.maxnumfblocked  6>tensor<%
      32arg16%50x, = 4 tt.broadcast x%%45iarg17 64 : , :tensor<# 64linearf32x1
        1x>tt.reduce.returni64
 ,       %#blocked%209669 >  = : -> tt.loadf32tensor< 
64x%      3268}x )i: : 64,  (#blockedtensor<tensor<6324>
xx4      4x%51x32 = !xtt.broadcast ttf32%., #49 ptr<i8>blocked:, >) ->  #tensor<4tensor<1linearxx3214x>xi
f3264,       , #%#blocked670ttg> = . tt.transslice<{dim = 2, parent = #blocked}>->  >tensor<%
6469      x {%32order82x =  = i64array<ttg.convert_layout, i #blocked32%816>:  :
      1 %, tensor<5204x = >4xarith.addi }f32% , 50:#ttg,  .%tensor<slice<{dim = 2, parent = #blocked}>5132> x :4-> x tensor<64itensor<x8432, xx#4xilinearf32, 641#, >ttg#blocked .6->slice<{dim = 2, parent = #linear}>>
 >      tensor<
      %534% = x83tt.addptr 32 = %xtt.expand_dims arg1,i% 882%,  {42#axis :ttg =  .2!slice<{dim = 2, parent = #blocked4}> : tt>i.ptr<i8>
32,      } % i6471:
       =  %tt.splattensor<54 4x = %4xarith.extsi 29f32% , arg14 :#:  ttgi!.32 ttslice<{dim = 2, parent = #linear}>to .>i64ptr<bf16> 
       -> %55->tensor< =  4arith.mulitensor<x %447xx,1281xf32 %x, 54!# :ttlinear .>iptr<bf16>
      64, %84
      # = %56blockedtt.expand_dims = 1 tt.addptr>% 
81%       {arg3,%axis 72 = % = 255tt.addptr :   i: %32!tt71}.ptr<i8>, , : % i28tensor<464 x
:4       x%tensor<f32574,  = x#ttgtt.expand_dims128.slice<{dim = 2, parent = #blocked}> x> %41!-> {tt axis.tensor< = ptr<bf16>41, x : #4xiblocked1x32}1f32 :>,,   #blockedtensor<32tensor<>x4
i32x      , 128%85#ttgx = .slice<{dim = 1, parent = #linear1}>itt.bitcast> 64 ->, %83 # :tensor<32blocked x1tensor<1>4x
xi      432%x, #731xlinear1 = f32>
tt.load,        #%%linear58 = 72>tt.splat   %:-> arg15  tensor<4: tensor<xi4432xx ->1281 xxtensor<32!ixtt321., xptr<bf16>#i32, linear, ##>linearblocked
      1>1%
>86      
 = %59      tt.bitcast = % arith.muli 74%84%57 =  ,tt.splat:   tensor<4%58%x 534:  x1tensor<32:xx f321!, #xttblockedi.>32, ptr<i8> ->#linear  1>->tensor<
       4%60tensor<x = 644xarith.extsi x1%32x59xi32 :!, # ttblocked>tensor<32.
xptr<i8>      1, %x#87iblocked = 326arith.addi , #>%linear
851>      , to%  75%tensor<32 = cst_28x1tt.addptr x :i% 6474tensor<4x4x, #,1linear x1%i32>
52,        #%:linear61 > = tensor<
tt.make_range64       {endx% = 32884x =  : !arith.addiitt 32, .%86start = ptr<i8>,0,   : i#%32}blockedcst_1 6 :>: , tensor< tensor<4tensor<4xx644ixx32321, xx#iittg.6432slice<{dim = 0, parent = #linear1}>, , #>
#blocked      blocked>%626
       = >%tt.broadcast 
89 = %60      tt.bitcast :%  76%tensor< = 8732tt.load x1 : x%tensor<4i6475x,  4#cacheModifierx1linear1 x>=i  32-> cg, tensor<32 #x:linear> 4x -> i64tensor<tensor<, 644x4#linearxx1321>xxi
      !32, %63tt# = .lineartt.expand_dims ptr<i8>>%61, 
 {#      axisblocked%90 = 6 = 0>tt.bitcast : 
 i      %8832}%  77:: =  tensor< ttg.convert_layout4tensor< x4%4x76xi 132, :x#ttg i.tensor<32slice<{dim = 0, parent = #linear1}>64, #>xblocked ->32> x tensor<i-> 1x8tensor<4, 4x#x4i32blockedx, 61#linear>x1> i32
->,        #%tensor<blocked>64 = 64
tt.broadcastx       %32%9163 x = :iarith.andi 8 tensor<, %891x#,4blocked xi3%32>cst_27, 
 #      :linear% 1>78tensor<  = 4-> tt.reshapex4tensor< x32%1x73xi4x 32, i32:#,  linear>#lineartensor<
14      >
x%92      128 = %xarith.andi 65 = bf16%arith.extsi, 90 %#,64blocked  :1% >cst_4tensor<  32->:x  4xtensor<tensor<i3244x, #x4linear4x1>x1 to32x xitensor<32bf1632x, , #4#blockedxblocked>
i>      %64
93,        = #%tt.bitcastlinear179 > = %91
      math.absf % :66%  = 78tensor<arith.addi 4 :x%65 4x, tensor<1x%624i x32:4,  x#tensor<3232linearxx>4xbf16 i64, -> , ##tensor<linear1blocked4>>x
      
4x%67      1 = %xtt.splat 80f32, %56 = # :arith.extflinear  >
!tt%      .79%ptr<i8>  94->: =   tt.bitcasttensor<32tensor< x44%xx92!4 tt.x:ptr<i8>32 , #xtensor<linear1bf164>
, x      #4%blockedx68 = >1tt.addptr  xi%67to32, ,  ler_DP0_TP0: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
tensor<#blocked%664> x :4-> x tensor<tensor<32432xx4x4f32xx, 1!#xf32ttblocked, #.ptr<i8>>blocked, #
>linear      
1%      %>,8195  = " = tensor<32tmath.log2xt 4x.%i64r93, e #d:linear1u >
ctensor<      e4x%69"4 = (xtt.load%1 80x%68)f32  <, :{# axislineartensor< = >322
x :       4xi%!3296tt} = .ptr<i8>>math.log2,  ( #linear{%1
94>       
      ^bb0:%( tensor<70 = %4tt.transarg16x : 4%f32x69, 1 {%xf32order = arg17, #array<: #blockedif32blocked = 32)>#: :
      ttg1
%97.,          = blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>0%math.floor
>209 #} = %blocked :arith.maxnumf951    = tensor<%:#32arg16 ttgx,tensor<.4x 4xblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>i%4
8, arg17x## 1xblockedlinear:f32, 21 # = > f32linear#->
>ttg         
      .tensor<tt.reduce.return%blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>4 98 = 
x%math.floor#32209 %blockedx 963i:   = 8f32:#, 
 tensor<ttg#      4.ttg}xblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>.)4x
slice<{dim = 2, parent = #blocked4}> : 1#>(xblocked
tensor<f324      4x,  = %4#blocked#71x>ttg = 32
      .tt.splatx%blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}> f3299 = 
%, arith.subf#29#blocked blocked >%975: ) -> , = !tensor<4 #ttx%ttg.ptr<bf16>4cst_26. x blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>->f32:
 ,  #tensor<#tensor<4blocked4ttgx6x.4x = 128slice<{dim = 2, parent = #blocked}>1#x>xttg!
f32, .tt      #blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>.%linear
ptr<bf16>, 82 = >##blockedttg.convert_layout
      blocked1 %7>%100 = 
81 = #       arith.subf ttg%:%98.72 =  , blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>tt.addptrtensor<%cst_5
 4 #%71x: blocked,4tensor<8 x4x = %f324#28, xttg #1x.:ttgf32blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}> ., #
tensor<slice<{dim = 2, parent = #blocked}>blocked>#4>
      blockedx ->%9128 101 =  = xtensor<4tt.clampf#!x ttgtt4%99..x,blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>ptr<bf16>f32,  %
, #cst_25##ttg,linearblocked.  = 1slice<{dim = 2, parent = #linear}>%cst_24#>>, ttg, 
      propagateNan.tensor<% linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>483=
x =  #128tt.expand_dimsnonelinearx  :1i%  = 6482tensor<#,  {4xttg#blockedaxis = 4x.121xlinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>> : f32, 

i##      32}linear>linear% 
      273: %102 =  = tensor< = #tt.load4tt.clampfttg x %.%4100linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>72x,
 f32 #:, %shared #cst_18, = tensor<ttg. %#4slice<{dim = 2, parent = #linear}>cst_23ttgx> , .128->propagateNan swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>x =
!tttensor<4 none#.ptr<bf16>x4 :smem, x  = #1tensor<#blockedx4xttg1f32, 4.>#xshared_memory
linear1x
      >f32module%
      ,  attributes74%# { = 84blocked>"tt.splat  = 
      t%tt.expand_dims%t53 103g % = .:81arith.fptouin  { u!axis%101mtt =  -.2:cptr<i8> : i t 32tensor<4a-> }x4stensor< x"64:1x = x f32, 132tensor<#linear : x4>i!ttx4 32.xto , ptr<i8>f32tensor<", , 4xt##4tblockedttgxg6.slice<{dim = 2, parent = #blocked}>1.>>xn
 iu      -> 8, m%tensor<#linear-754>w = x
      att.addptr4%r x104 = p%1xarith.fptouis74f32 ",, % =  #1024%blocked  : 52>:i 
       32:%tensor<,  85 = 4ttg.targettensor<tt.bitcastx4 = 64 x1"x%xh3283f32, ix #blockedp!: > :tttensor<tog.4 tensor<fptr<i8>x4xx, 44x9#blockedx11x56xf32i80>,, #, " linear>#, tensor< blocked"64->>tx 
t32tensor<      gx4%.ix105t644 = h, xarith.addi r#1%eblockedx103,a6i %d>32cst_29s
,  -      #linear:p%> tensor<e76
4r =       x-tt.load%4w 86x1a% = xr75tt.bitcastip  8, "cacheModifier%#linear =  84>
64=        :  :%icg 106 = 32 tensor<arith.addi}:4   x%{tensor<4104
64x,  x1 tt.func32x% xf32, cstpublic!#  ttblocked:@.> _batched_gemm_afp4_wfp4_pre_quant_kernelptr<i8> tensor<(, #-> 4%blockedtensor<xarg064x4: >4xx1!
1xtt      xi8.%i, ptr<bf16>77 = 32, # {ttg.convert_layout#blocked>tt.divisibility blocked
       = %>%1071676
 =  :        arith.subf i:%32 87%}tensor< = cst_6,, 64arith.addi %x %%arg13285102: x, :!i  tensor<tt8, %4x.#cst_284ptr<i8>blocked x1 {6:xtt.divisibility> f32 =  tensor<, 16->4#blocked :  x>
itensor<4      %3264x108}x321 = , xxmath.exp2%ii arg2832, %: , #linear107!#> ttblocked
:.3       ptr<bf16>>%tensor< {
      884xtt.divisibility% = 4 = 78arith.addi x116 = %86x : tt.reshape,f32i  , 32%%#blocked}73cst_1>,   
      %::%109arg3   = : tensor<tensor<arith.extf !44%78ttxx :.1284 ptr<i8>xxtensor<4 {bf161xtt.divisibility, x4 = #ix16blocked3232x : 1, bf16i>#, 32 blocked#}->>blocked>,  
 to%tensor<       arg44%tensor<4: x89xi4 = 4x32xtt.bitcast32x {32 f32, tt.divisibilityx%87# = bf16 blocked>16, :
 : #       iblockedtensor<%11032>4 = }
xtt.broadcast,       4 %%%79x108 arg5 = 1: : math.absfxtensor<4i ix32%32, 4 {78#x1tt.divisibility linearxf32 = :>, 16  #blocked : tensor<->> i4 ->32xtensor< }44xtensor<, x44x%32x4arg6x1x32: bf16xxi, i32f3232#, , # {blocked#blockedtt.divisibility>linear> = 
>
16      
            % : %%90111 = i80 = arith.mulf32 = tt.bitcast }arith.extf %,  %109%%88 ,arg779: :   %110i:tensor< 32 4: {tensor<x tt.divisibility44xtensor< = x14164xx : xi4i3232x32x, 32x}bf16#f32, , blocked, %#>#blockedarg8blocked> ->>:   
      itotensor<%32 4112 =  {tensor<xtt.bitcasttt.divisibility44  = xx%1641111 : xx i32i32: 32x, tensor<4}f32#x, , blocked4%#>x32arg9blocked
xf32: >
      , #i      %blocked>32%91  {81 = -> tt.divisibility = arith.anditensor<4 = " x416t%x32 : t.89xir,i3232e , }d%#, ucst_27blocked>%c 
      arg10e:%: " 113 = i(tensor<arith.andi 32%4%112 {80x, tt.divisibility)4% =  <xcst_716{1 : : axisx tensor<i = i432232x} : , 4, i#x32%32linearxarg11}>i32: >
, #i (      blocked>32{
%
       {      92%114tt.divisibility^bb0 =  =  = (arith.andi arith.shrui16%%  : arg1690%i: ,11232f32 ,}, % %, %cst_4cst_8%arg17  arg12: ::: f32  i)tensor<tensor<32:44x {
x44xtt.divisibility        x32 = %1xi16209xi32 :  = 32, #iarith.maxnumf, blocked>32 #
      }%blocked%, arg16>115%,
 = arg13       arith.andi: %%93 iarg17 = %32 tt.bitcast114, {:  %tt.divisibility %cst_9 = f3291  16
: :  :         tensor<4tensor<itt.reduce.returnx4x32 44}%xx, 2091x32% ixarg14:32, i:  #32if32linear, #32
>blocked> {       
tt.divisibility}->       = ) %11616 : tensor< =  : (4arith.andiitensor<x 324x4%112}4x,, x1 %32x%arg15xf32cst_10: f32,  :i, # 32#lineartensor<)blocked>4x attributes>
4 {) ->       x32noinlinetensor<%xi = 49432, falsex = #}4tt.bitcastblocked x >
{f32%      
, 92 %    #ttg: 117 = %.slice<{dim = 2, parent = #blocked}>tensor<arith.addicst>4x  = 
4x%arith.constant      1x115 %i, dense<8232, %127 = #blockedcst_11>ttg.convert_layout> : :    tensor<tensor<%-> 4481tensor<xx 444:xx32x 4xi1tensor<x32x41, ixx#blocked84f32>, x, 
#f32#blocked      blocked, >%>#
118 = 
ttg      arith.subi    .% %slice<{dim = 2, parent = #blocked}>95 = %cst_0> math.log2cst_12 = -> ,arith.constant %  tensor<93%dense<4 1170x7FC0x: :>4   : xtensor<tensor<4tensor<f324x44, xx32x#4xx128ttg1xi32x.f32, #bf16slice<{dim = 2, parent = #linear}>, blocked, >#>#
linear
      blocked      >%1191%
 = >83      arith.cmpi 
 = %ult,    tt.expand_dims96 %  = %115cst_1%math.log2,  = 82 %cst_12arith.constant {%94 : axis  dense< = :tensor<42 x2097152 : tensor<44>i32xx : }432tensor< :xxi4 132, xtensor<x#44f32blockedxx, #>14blocked
xx>      %if32
120 = 32,       arith.shrui, #% %#ttg97116,blocked.slice<{dim = 2, parent = #linear}> =  %>>math.floorcst_11
 ->       %: %tensor<95tensor<cst_24 4x = x:4xarith.constant4 32 xtensor<xdense<14xi324x4, #>f32, xblocked> : #1
      tensor<linearx%4>f32121x
      ,  = 4%#arith.orix84linear 16 = >%120xtt.expand_dims
,i        8%%%cst_13, 8198 =  # {math.floor:blockedaxis  2 = %tensor<4>296x4
 :  x32    i:x%32 tensor<i32c31_i32}4, # =  xblockedarith.constant:4>  x
      31tensor<1% : 4x122ixf32,  = 324#arith.shrui
xblocked     f32, >
%%#ttg      121cst_3.%, = slice<{dim = 2, parent = #blocked}>99 arith.constant> = %  arith.subf118 dense<-> : 0.000000e+00 %tensor<4>tensor<97x4 : 4,x32tensor<x x44%i32xxcst_26, 321 #blockedxx:>f32f32 
      , , tensor<%123##blocked4x = blocked>4xarith.select3
1 >      x%
%f32119    85, , %% = #122, c32_i32tt.bitcastlinear%116 =  > : arith.constant%
      tensor< 83%100432  = x4 : :arith.subfx32i  x32tensor<%i1
4x98,     4,#%x blocked>c4_i321%,  = xcst_5tensor<arith.constantf32,  4x #linear: 44>tensor<x :  4x32xi->4i3232 x, 
tensor<1#blocked    4xx>
%4f32      %truex, 124 = 1# = arith.constantxblockedarith.maxui i> true32
%
, #      115    linear%,%>101 c0_i32
 = %cst_14 =       tt.clampf arith.constant% : 86% 0 = 99tensor<4 : tt.bitcast,xi  432%%x
84cst_2532x     ,i32%: , #cst_4 %blocked> = tensor<cst_24
      arith.constant4x,% 4x 125 = dense<1propagateNanarith.subi-8388608x = >f32 %124 : , none,tensor<#blocked  %4>:cst_14x   4->tensor<:x 4 1tensor<xtensor<4x44x4ixx1x32324xxx, 1f32i#x, 32blockedi#, #>32linearblocked
, >>    #
      
%blocked%102      cst_5> = % = 
tt.clampf 126arith.constant      % =  %100,arith.shlidense<87 % 2.000000e+00 = cst_18%125>arith.addi, , :  % tensor<%cst_23%cst_15485, x, : 4 propagateNantensor<x% 41cst_28= xx none4f32: x,  :32#tensor< xiblocked4tensor<32>x4, #
4xxblocked>    14x
      %x1%cst_6ix127 = 32f32 = arith.constant, , #arith.shrui  #blocked>%dense<linear
1230.000000e+00>      , >
%%cst_16 :       103 :tensor<%88 =  tensor<4 = arith.fptoui4xxarith.addi 4x4 %32x%101x186 i32x, :, f32% #, cst_1tensor<4blocked># x
      blocked: 4x%>tensor<1128
4xx =     4f32arith.ori%x, # cst_71linear%126 = x>,arith.constanti   32to%dense<,  127-2147483648#tensor< >blocked4: : >x tensor<tensor<
44x4      x4x%1x489x32x = tt.bitcastix32 8ix%, 32, i87##32 linear>blocked, :
>
#             %blockedtensor<%129>4x104 = 
4 = arith.addi    xarith.fptoui %1 %cst_8x%128 = i102,arith.constant32,    #: %dense<lineartensor<cst_1123>4 :> x  : ->4tensor<4tensor< xx4tensor<14x4xf32x4x, 32x4#x32xblockedix1>32ix to, 32i #blocked, 32tensor<>#, 4
      blocked#x%>linear4x130 = 
>1arith.shrui    
x %      i%129cst_9%8,  = 90, %arith.constant = #blockedcst_11 tt.bitcast>
 dense<       :255%%105 >88 = tensor<4 :  arith.addixtensor<: 44 %103xxtensor<, 32x44%i32xxcst_29, 324x #blockedx1: >ixtensor<
32i4      , 32x%131#, 4 = blocked#blockedxarith.minui>>1 
 x%130    ->i,% 8 cst_10tensor<, #% = 4linearcst_22arith.constantx>  4
:dense<x       83886071%106tensor<4>x = x : iarith.addi4tensor<32 x324, %xix#104blocked,32> 4, 
%x32#blocked      cstxi>% 32
91:,        =  #%132arith.anditensor<4blocked> =  x4
    arith.shrui %x1%cst_11%11389x = ,,i8arith.constant  , # %%blocked>dense<cst_17 cst_27
1:        %>tensor<:107 =  : tensor<4x arith.subf44tensor< xx324%4xixcst_6x324,32, x x#1%iblocked>x10232
i :, #      %32 tensor<blocked133 = , 4>arith.ori #x
    %linear4%132>xcst_12, 
1x = %131      f32, arith.constant %# : 92blocked>dense<tensor< = 
      127>4arith.andi%108 : tensor<x4  = 4xx%math.exp243290 xxi,%3232 107x, #% i32blockedcst_4:, >  #blocked
      :tensor<4>% x
134tensor<4     = 4x1%cst_13arith.truncixxf32 =  4, #arith.constant%133xblocked>  1
dense<:x      %4194304> i109 =  : tensor<32arith.extftensor<44,  xx4#%784xxblocked :3232> xxi
tensor<4i32      x32, %4x, ##9332blocked>blocked = x
>tt.bitcastbf16,       #blocked%to%>cst_14 =  91 toarith.constanttensor<4  tensor< x:4xdense<4x 412632xtensor<x>i8432 : , xxf32tensor<#blocked4, #4x>
xblocked4      1>
x%x      %32135i110x = 32 = i32tt.reshape , tt.broadcast , #%134#%blocked linear108>:> 
  :     tensor<4->tensor<%x4 4xcst_15 = xtensor<4xarith.constant3241 xixxf32dense<8, 4x, #2>#1blocked : blocked>x> tensor<4 ->f32->x tensor<, # tensor<4x4linear432x4>x4xx
x32i3216x      xf32, #2%, blockedxi94 = #>8, tt.bitcastblocked>
    # 
%blocked7%      cst_16 = >92%arith.constant
 111       : = dense<%outLHS arith.mulf21, tensor< >%4% : outRHS = x109tensor<tt.split4,4 x x4%1%110x135 x 32:i:x tensor<32 i324, tensor<, x4#4x#blockedxblocked4>16x>x32
2x xf32    i->, %8 #cst_17, tensor<blocked> = #blocked4
arith.constant7x      % >4112 = dense< xtt.bitcast 28>->1%111 : tensor< tensor<x 4x4f32:4x,  x4#tensor<32x16blocked>4xx
xii8      4x32, , %32##95xf32blocked>blocked = , #
    2math.log2blocked>%cst_18>
   =       %-> arith.constant%13693tensor<4  =  x4dense<arith.shli :x32-1.270000e+02>%outRHS x : , tensor<itensor<%cst_2432, 4x :x#blocked4x tensor<4>14x
      xx1%113f32, 4xx = #16xf32arith.andi blocked>i, %
8, #112,    #blockedlinear> %2>
%cst_7cst_19 = 
             arith.constant%%:  137 = 96tensor<4dense<arith.ori = x7 math.log24x>% 32 : outLHS,%xtensor< 94i4% 32x136:, #32 : blocked>x tensor<
itensor<44      16, xx%114#ttg4x4 = .slice<{dim = 2, parent = #blocked4}>16xarith.shrui>x1 
    i8x%112%cst_20, f32, = #,  arith.constantblocked#% 2>blockedcst_8dense<
> -1      
:>%        : 138%tensor<tensor< = 97 = 4x4xtt.reshape math.floor4x32% 32xi137%x8,  :95i32#ttg  , #.slice<{dim = 2, parent = #blocked4}>tensor<:blocked>>4x 

4tensor<          x164x%115%x4 = cst_21i8xarith.andi  = , 1%arith.constant#blockedx114 2f32, dense<>, %0x7FC0> ->#cst_9  :  linear: tensor<tensor<4>tensor<4128xx
x3264x      4xxi8%32bf16, , 98xi#blocked# = 32, 5blockedmath.floor#blocked>
8 >
    >%      %
      96%116cst_22%  =  = 139:arith.andiarith.constant =    tt.reshape tensor<%112dense<%1054, 7> x% : : 4cst_10 tensor<4tensor<x:x41 4xx4xtensor<432xx1f32x4i32x, x, i8#32x#blocked, #blocked>i>linear>
32, 
           #blocked%->%>cst_23 tensor<99
       = 4 = %arith.constantx4arith.subf117 =  xi arith.addi dense<8%%1151.270000e+02>, 97,  : tensor<#,%4ttg. cst_11xslice<{dim = 2, parent = #blocked}>% :4x>
cst_26 tensor<1       4xx%:4xf32, 140 32# = tensor<xblocked>tt.reshape4i
 x32    %4, #%cst_24106 xblocked> = : 1
arith.constanttensor<x      % 4xf32118 = dense<4, arith.subi1.270000e+02x#linear >1x>% : tensor<i
cst_124x8      ,4x, #% 1blocked>100%117x  =  f32, -> arith.subf:#lineartensor<  >
4%tensor<4    x98x4%4,xcst_25x 32 = i%xarith.constant8cst_5i , # 32, dense<linear:#-1.270000e+022> blocked>>
tensor<
       : tensor<      4%1194x%141x = 4x = 4arith.cmpi1ttg.convert_layout x x%1ult,f32, 140 x #linear:f32%115> , , 
tensor<4#blocked%    x4>cst_12%xi
 :cst_26 = 8       tensor<arith.constant, #%4x linear1014dense<2 = x322.000000e+00>>tt.clampfxi : tensor< -> 32, 4x %#4tensor<99blocked>x4x,
      14 %120xx% = f32, icst_25arith.shrui #linear8, ,%116>#ttg ,
.slice<{dim = 2, parent = #blocked}>%     >cst_24%%
,cst_11cst_27        : = %142propagateNan tensor<arith.constant =  4x arith.extui=4xdense<  32-8388608%nonex>141 i32 :  :, tensor<:  #blocked4xtensor<4tensor<>
4xx4      14xx%121xi84 = i, xarith.ori32#1 , ttg.x%120#linearslice<{dim = 2, parent = #blocked}>f32,>>,  %
     #cst_13%tolinear cst_28 >: = tensor<4
 arith.constantx      tensor< 4%4xdense<xi1024x2097152>16 = 32 : , tt.clampfxitensor<4# 32, x4ttg%#blockedx1.slice<{dim = 2, parent = #blocked}>100>xi>,
32
       ,       %%%122#linear143cst_18 = > = ,arith.shrui
arith.shli       %%121%%cst_23, cst_29 = 142,%118arith.constant,    propagateNan: dense<%cst_30 tensor<127 =4x>:  4 : tensor<4nonex32tensor<4x xx4x:i324i16 , #x, tensor<blocked>1#4
      xittgx%8.4123 = , #slice<{dim = 2, parent = #blocked}>>x1arith.selectlinear
x >      f32%
%144, 119     = #, %tt.bitcastblocked%122cst_30 =  >, arith.constant%
%116 143        : dense<: %tensor<7tensor<1034x>4x = 4x : tensor<4arith.fptoui324xxi x416, %i1xi#ttg101, 16.slice<{dim = 2, parent = #blocked}> #blocked, >:>#ttg  , .slice<{dim = 2, parent = #blocked}>->tensor<tensor<4> tensor<4x
4x4x    x4432%cst_31xxx = bf16, 1i32arith.constant#x, # ttgf32blocked>dense<.slice<{dim = 2, parent = #blocked}>, 
      -1>#%124>
      linear =  : tensor<%145>arith.maxui4x =   4tt.expand_dimsto%115x % ,i144tensor< 8,  {4%#axis = x4cst_14ttg.2x slice<{dim = 2, parent = #blocked}> : 1:>i32x 
    } itensor<4llvm.intr.assume: 8x tensor<, 4x%4#32truex4linear>xi xbf16
32:,       ,  #%#ittg104blocked1. = >

slice<{dim = 2, parent = #blocked}>>arith.fptoui           -> %125llvm.intr.assume % =  tensor<102arith.subi%4  %truex:124 4 , :x1tensor<% x4cst_14ibf16x 1, 4:
#x     blocked>1tensor<4llvm.intr.assume 
xx%      f324xtrue%, 32 :146 = #xi tt.broadcastblocked>32i  , #1%145toblocked>
      
      llvm.intr.assume:tensor<%126  tensor<4 = %4xarith.shlitruex44  xx%: 1x1125ibf16, x,1#blockedi 
    >8%cst_15llvm.intr.assume ->,    tensor<#:%true4xblocked  :4>tensor<4 ix32
x41xbf16      %x
, #10532    blocked> = xllvm.intr.assume
arith.addii       % 32%147 = %, #truett.reshape103blocked> : ,
       % %i146%127 = 1 :cst_29arith.shrui 
      %123llvm.intr.assumetensor<4:,  x %%4tensor<cst_16 truex324:  :xbf16xler_DP5_TP5: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
tensor< , 44xi#blockedx4x1> 132
-> xx    tensor<ii32llvm.intr.assume48,  x128, #%x#blocked>truebf16, linear
 #blocked>      %:1>

128 =              arith.orii1%148% 
 = 106%    amdgpu.scaled_upcast_fp4  = 126,llvm.intr.assume%arith.addi  138 %% %127 truescale 104:  :%,tensor<4 147 xi {axis%4x1 = cst32
1 :  :x    i32 i32llvm.intr.assume }tensor<, % 4#blockedtrue:x>
 : 4      % tensor<4x129ix1 = 164xxarith.addi 
ii%    88128llvm.intr.assume, #, ,  blocked#%%true8blocked>cst_11 #>,
 :blocked       :   = tensor<%tensor<4i1#4x107x
ttg128 = 4    .xbf16arith.subfxllvm.intr.assumeblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>, # 32 
blocked%x%#1cst_6,i32trueblocked> , # 1 %blocked: = ->102> #  
      i1ttgtensor<4:%
.x128 130 =     blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>xtensor<arith.shrui %
bf164%1290#, x4,  = blocked#x%tt.get_program_id2blocked11cst_11   = >x:x#ttg
      f32,  tensor< .%#4x: blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>149 = blocked>4xi
arith.cmpi 
      3232#eq%xi
    blocked,10832%3  = , 1 = %math.exp2# = #139, blocked>tt.get_program_id ttg. %
yblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>%cst_31107       
  %131:#: : =  blockedtensor< arith.minuii44tensor< 32 = x4%130
    #ttg4xx,%.i4 2blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>8, x% = 
#1cst_22arith.addi#ttgx  blocked.f32:%5slice<{dim = 2, parent = #blocked}>,  arg5 = >#blockedtensor<4,#
      >x ttg%
      4%.150 = %x32c31_i32blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>tt.expand_dims109 = x 
 arith.extfi:#blocked%149 32,  6 {%#blockedi = axis78>
32# =        
ttg2:%    . :  132%blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>i32tensor< = 3 = 
#}4arith.shrui arith.divsiblocked x%113 7:4x, %2 =  32%,#tensor<4xcst_17 ttgxbf16 :%.4,  c32_i32blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>x#tensor< 
iblocked4x: #blocked1>4xi328,  32
 = #tox    #ttg. i32%4ttgslice<{dim = 2, parent = #blocked}>>tensor<, # = . 4blocked>arith.extsiblocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>->x
 
 4      %#tensor<x%arg7blocked432133 9xx = : = 4f32arith.ori  #x, %ittg1x#132,32.iblocked  blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>1>%to
, #
      131 #blocked% ilinear>110 = :64 = 
tt.broadcast 
    #       tensor<%ttg%151%4x5 = . = 1084xarith.extsi linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>tt.broadcast 32%
 : xiarg9 #%150tensor<432, : linear :x#blockedi1 4>32 = tensor<x
 #41      %tottgxx134 .4f32 = i64linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
x, #arith.trunci
    #linear1blocked %2xi>%6 = 1 ->133 = #, #  arith.extsi ttgblockedtensor<:%.>4 arg11linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}> ->xtensor< :
 44x #tensor<x4xi32shared = 43232 to#x4xx ittgx32f32i3264
.x, ,     swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>i##blocked%7
#1blocked>> = smem, 
 arith.extsi = #blocked      to #>% %0ttg
      111tensor<4 :.%152 = x4 shared_memory = arith.mulfx32i32
tt.reshape x module %ito  attributes%1511098, i64 { :,#blocked
    "  >%ttensor<%
      8 = tg4110%135arith.divsi .nx  = %u4:tt.reshape1mx  ,-c32tensor<% txi4x134%3as14x  ", 32:: = #x  1blockedf32tensor<4i32 : >, x
i #4    %32-> blocked>x9, tensor<
32 = "4      xarith.remsitx%i t128x112 = 8%gi1tt.bitcast, 1., # #blocked,nblocked1%>  u>
111->%m        tensor<3-%:4x w153 4:a = tensor<x16 rarith.select 4xxip%1524x232s, 32x
"%xi     = cst_0f328, llvm.intr.assume 4, , #blocked% : %#7truei148 : blocked>> 32tensor< 
:, 4x->        ittg.target = 128tensor<%1"x4outLHS
hix,     i14x%llvm.intr.assumep, 32outRHS :#x = %gblockeditt.splittrue f1>32 :x, , % i9tensor<#135154blocked 
0x128>:    "x
 llvm.intr.assume, bf16,       tensor<4 "#blocked%x4%t1113x16truet> = x2 :g
arith.andix .t       iih%%8, 1r154 = 112,#
ettg.local_alloc  blocked    a%153%7>%ds cst_7 10-: :-> = p   arith.cmpie(tensor<tensor< rtensor<44xsgt-4x4,wax1284x16 rxxxi%pbf16328, arg6", #x#, = blocked1iblocked 64>)322% :  -> , #>c0_i32i!ttgblocked>
 32.memdesc<4x128xbf16, #shared, #smem>
            %:}
%136        114 = i32{% = arith.shli

155arith.shrui        =  %scf.iftt.functtg.local_load%outRHS,   112 %public%,%cst_215410     %: @:{cst_8tensor<_batched_gemm_afp4_wfp4_pre_quant_kernel 
 4(!      :x%ttg% 4arg0.memdesc<4x128xbf16, #shared, #smem>11tensor<x:   = 416!->arith.mulixxtt.  4iptr<bf16>tensor<%x8 {4x832, tt.divisibility = 128,x#blocked16x i2> : ibf16, %32
32#c4_i32, #      }ttg blocked%, .dot_op<{opIdx = 0, parent = #blocked3}>:>137%arg1> 
       = : 
      i%arith.ori !tt%32115%.156
 = outLHSptr<i8> { =       arith.andi,tt.divisibility = arith.extui%  16 :  12%%136i%70 = 114 32 tt.make_range,:}: {  , % end%tensor<arg2tensor< = cst_94: 44 x!x : :4tt.32xi xptr<bf16> {i32tensor<16tt.divisibility = 8, 4x16 : , startx4ii# = x832}ttg032, #, %. : xblockedarg3slice<{dim = 2, parent = #blocked4}>ii2>: > 3232, 
!ttto }#blocked      .ptr<i8>tensor< >% {4x:
138tt.divisibility32        =  = xitensor<%tt.reshape1616, 4116  : i#x = %32ttg.iarith.andi137}, slice<{dim = 2, parent = #blocked4}>32  %>, %:arg4
#112 :       %ttg, tensor<i157 = .%432arith.shlislice<{dim = 1, parent = #blocked1}>cst_10x { > 4tt.divisibility%
:x = 156,       1616 %tensor<x : i%cst_19134xi832  = 4, }:tt.make_rangex#, %  {32blockedarg5: tensor<4endx2i32x32 = i>  {xi432, -> tt.divisibility = 16 : #tensor<16, iblocked4 : i#32>
x32ttg,       64}, .start%x%slice<{dim = 2, parent = #blocked4}>> = 117iarg6: 
0 = 8, i       : arith.addi#32%i blocked {15832%8tt.divisibility = }115,> = tt.bitcast  %
16 :  :cst_11      i32%  %139}, 157tensor<: = % 4 tt.reshapearg7: :xtensor< i i4%32tensor<432x4105 {x32, x :tt.divisibilityx#32  = ittgxtensor<41616.ix : i, slice<{dim = 1, parent = #blocked3}>32432#>, #x}ttg.
blocked1, slice<{dim = 2, parent = #blocked4}>      >x%>%
i8arg8 14      , : i-> = %#32 tt.splat118linear {tensor<  = > tt.divisibility = 4%arith.subi->16x11   : i32 %tensor<432x:cst_12x}, bf16,  ,4%#i xiarg9ttg.32%8: islice<{dim = 2, parent = #blocked4}>> 117, 32 {
-> #tt.divisibility =        :ttg16 : %tensor< .slice<{dim = 2, parent = #blocked}>i321594tensor<>
},  = x4      %tt.expand_dimsix%arg10 324140 = : %, xtt.reshapei32158#32  { {ttgx%tt.divisibilityaxis.i106 =  = slice<{dim = 1, parent = #blocked1}>32,  162>#: : i : 
blocked 32}i      >tensor<, %32%
      4xarg11: }15%4xi  = 119132 {: arith.addi = xtt.divisibility = tensor< arith.cmpii164% 8 : ix14ult, 3232,,#}x  blocked, %bf16%%> arg12, 12115->: # , ittg: tensor<32 {. %4tt.divisibility = slice<{dim = 2, parent = #blocked4}>tensor<cst_12x16 : >4 4i32 ->x: xi} tensor<itensor<48, %432x, arg13: x, 4#i32#xlinear32xttg322 {1x.x>tt.divisibilitybf16slice<{dim = 1, parent = #blocked1}>i
 = , #>32,       16blocked
#% : 4      blocked>141i>%
 = 32
16      ttg.convert_layout}      % = % , 160tt.splat120%% =   = 140arg14: tt.broadcast%arith.shrui i32 arg4 : {% % tt.divisibility = 159:116tensor<16  ,4x : i:i 432} 32%x, tensor< cst_11i8%4-> , arg15x :#: i32xtensor< linear3214tensor<2)xx4> attributes {bf16ix noinline, #324-> = blocked, x false4>#32tensor<} ttgx4 ->.ix{
 slice<{dim = 1, parent = #blocked1}>32, 4x    tensor<>#i8%4
blocked>, cstx32      
# = x%      ttgarith.constant3217%. x = 121slice<{dim = 2, parent = #blocked}>dense<bf16arith.remsi = >127, # arith.ori
>blocked%        : 4>15%%tensor<
      ,1201424% , = x161 = % arith.extui4tt.trans16% x  cst_13%1%160: 141x { : i8ordertensor< :,  = 4tensor< #array<x4tensor<4blockediixx4>32324x
: , xi8    0#32, %, ttgx#ttgcst_02.i. = , 1slice<{dim = 1, parent = #blocked1}>32slice<{dim = 2, parent = #blocked}>arith.constant>>, > }
#blocked dense<       >to0x7FC0: %
 > : tensor<18      tensor<tensor<4x = %4432arith.muli122 = x4xx32 arith.shruix128xbf16% ix, #7%12116, bf16blocked,,#ttg, #4  .blocked> %%slice<{dim = 2, parent = #blocked}>1>->4118>
     tensor<  :
%cst_14:        = x tensor<%arith.constant32i4143 x3264x = dense<x
4xarith.shli2097152>bf16      32  : , %x%tensor<4#19i142x4blocked = 32, , x19tt.expand_dims#%x> blockedcst_30i
      %> 32, %17
: #162 {      tensor<blocked = axis%4x>
tt.reshape = 1234    % 1 = xcst_2% : arith.selecti = 161i 16arith.constant :32%,   }119#dense<tensor<4 , ttg4x:%.> : 32 122slice<{dim = 2, parent = #blocked}>tensor<xtensor<, >432x4%116
      x4bf16, x : %x16#itensor<4144xblocked32x = i89, 4xtt.bitcast, >#32 # ttgx%143blocked2->.i > slice<{dim = 1, parent = #blocked1}>1:
    tensor<>,  tensor<%c31_i32128x #blocked4x = 32x->>4arith.constantbf16 , x , tensor<tensor<i31#blocked44x16 : 5>x4, i
1x#32      x32ttg
%163ix.    % = 32islice<{dim = 2, parent = #blocked}>>cst_3amdgpu.scaled_upcast_fp4 , 32  = %#, ->arith.constant77blocked#   1blockedtensor<4dense<scale>>x0.000000e+00 

4> : %            xtensor<162%%bf164 {20124 = , xaxis = arith.maxui#32x = tt.splat ttgf320 %.,  : %115slice<{dim = 2, parent = #blocked}>#iarg8,>blocked32}  
3 :%      >
:  cst_14%    tensor<i 145%c32_i3264x32: =  = 32x  tt.expand_dimsarith.constanti8->tensor<  ,  4%32 : #tensor<x144iblocked44 {323xxaxis
>,132 =      xx2%tensor<ii32 : c4_i3212832, i = x32, #blocked32}arith.constantx#> : bf16, blocked
 4#blocked1      tensor< : 5>%4i> 
125x32->        = 4
tensor<128%arith.subix    x3221 bf16%x = %, true = bf16arith.muli124#arith.constant,  ,ttg #blocked% .true
519%slice<{dim = 2, parent = #blocked}>    >,cst_14>%c0_i32
        : -> = %%  arith.constant16420tensor<tensor<4  =  4x0 : arith.cmpi :x4ieq 4x32,tensor<x1
     %432x%70xxbf16cst_4,1i,  =  x32#arith.constant%i, blocked cst_2032#>dense< , blocked
-8388608>:#>       :  blocked
%tensor<4tensor<1      146x4>% = 4xx32
126tt.broadcast1xi       =  x8%arith.shli%i, 22 14532# = % , #ttgarith.extsi125: blocked>.slice<{dim = 2, parent = #blocked4}> ,tensor<
>% 4x    %
21%4cst_5       cst_15x = %: 1arith.constant165 :xbf16  = tensor< , dense<tt.expand_dims4tensor<#2.000000e+00> x4blocked> : %1641x ->tensor< {axisx4x tensor<4 = 2i324x : 32xx44i, ixx132#3232x}blocked, xbf16f32 1#, , :>blocked## tensor< >blockedblocked4to
>>x       

    32xtensor<%      %i4127%cst_6 = 1x = 147arith.constant, 1arith.shrui =  #x tt.reshapedense<ttg.i% 0.000000e+00>slice<{dim = 2, parent = #blocked4}>64123% : >, ,146tensor< #  4->blocked%: x 1cst_16tensor<4tensor<4> :4xxx
 4132      tensor<xxf32x%432, 123xx#x = 4bf16, blockeditt.make_rangex#>1 {32blocked
, endx>    # = i %blocked412832-> cst_7 = >
 : , tensor<arith.constant      i#blocked4 %16632>xdense< = , 
128-2147483648tt.broadcaststart      xbf16>  = %,  : tensor<%0128 = #4165 : arith.oriblockedx i 14x:32%>32 tensor<}126
x4x ,      i32: %32x %148, #1tensor<127  = blockedx128:amdgpu.scaled_upcast_fp4>
i1x      , itensor<%%cst_8#blocked324x138 = 4, 4x arith.constant>#32scale  ttgx dense<-> .i%23tensor<slice<{dim = 0, parent = #blocked1}>32, 147>4># { : tensor<x
blockedaxis4x32      > = 4x32%
1x32x24       : xi1 = %ii32, #tt.expand_dims12932}, blocked  =  #blocked4>%arith.addi:>
      23  
% {%tensor<    %167 = axis1284cst_9 = tt.trans = ,xarith.constant 0 64 %166 : %xdense< {icst_11i8255>order32 ,  : tensor< = }:#4xarray<i  blocked4x32: :tensor<48>32x0 x,i32, tensor<4 , 2128xtensor<#blocked, x324>1>ixx
}32i128     :, 32x% #, bf16cst_10 = tensor<4ttg#blocked, arith.constantx.># 32slice<{dim = 0, parent = #blocked1}>
      blockeddense<x32>%18388607x 130>>i-> =   : tensor<1 arith.shrui->4, tensor<  x#1%tensor<4blockedx1294xx4>128,12832x x xi->i%bf16, 32,  32cst_11#blocked#blockedtensor<,  1>
4#:>    x32blocked 
%x1tensor<      cst_11 = 32x>4%arith.constant
i1x149       , #4 = dense<%blocked9xarith.cmpi125 = >32 >arith.extsi
xeq :        %i,tensor<%168 = 32 4x24 tt.reshape, %4: #139x32 %blocked,xitensor<1167> 32x :
%, 128 tensor<      cst_31#xi4% blocked32, x131:>#blocked32 =  
1x32arith.minuitensor<    >x 4% i%xcst_12to11304 =  , ,xarith.constanttensor<1#blocked i x9>%8dense<128x cst_22, 127i64->  #>, #tensor<:ttg : blocked128x .tensor<132tensor<slice<{dim = 2, parent = #blocked}>4x>
xi4>4      1x
x%, #4      3226blockedx%x = 532150itt.broadcast>x = 32 
itt.expand_dims, %22      32 # %169, %blocked: = #149> arith.selectblocked> {
tensor< 
axis    %4%       = cst_13 = x168%2arith.constant1, %132 =  :  xicst_21arith.shruiidense<64,  324194304, %%}> : #163 : 113 tensor<blockedtensor<128,:41x32  x>x%tensor<4 ->icst_174x 1 :x32tensor<, # 4x4blocked5tensor<xix>4i32128, x1, #xtensor<4, blockedi128xx#>
643232ttg    , xbf16x.%#, #islice<{dim = 2, parent = #blocked}>cst_14blockedblocked532, > = 1>># arith.constant

blocked->             > dense<%%170
tensor<12627 =  =       4>tt.broadcastttg.local_alloc %x : tensor< %%1334425169 = xx  arith.ori14:: xx32  %ixtensor<(tensor<1321i1128,, 32x128x #, xi32x%blocked#64, bf16131>blocked>#blocked,  

1#blocked:          >5> %% ->)tensor<151cst_15  -> 4 =  = tensor<!ttgxtt.broadcastarith.constant4.4  xmemdesc<128x32xbf16, #shared, #smem>x%dense<128
      321502x%x >i171 = i: : 64ttg.local_load32 tensor<4, # , #tensor<xblocked%blocked441>170 >xx32
: 
4xi      !      x32%28ttg.%1,  = memdesc<128x32xbf16, #shared, #smem>134x#arith.addi -> = iblocked  tensor<arith.trunci1>%128 , 
    26,x%#% 32133blockedcst_16%xbf16 > = 27, : arith.constant # -> : ttg.tensor< dense<tensor<dot_op<{opIdx = 1, parent = #blocked3}>>4tensor<214
      x4>x128%4x : x172 = x4tensor<itt.dot 32x464%x32x, #155,ix4blocked1 32ix>%171, 132
      ,#, x% blocked#i3229 = %>blocked, tt.addptrcst_3 >#  :to
blocked%        >arg0,tensor<4tensor<%
     x4152%%128x = cst_17 = 18xbf164tt.reshapearith.constant , x  :#ttg32%dense< .x15128!dot_op<{opIdx = 0, parent = #blocked3}>>i >tt *8: : tensor<.ptr<bf16> ,  4,tensor<128#tensor<x4 xblocked4x32i6432>xxi
      x
432%bf16      x, #30 = , %32blockedarith.muli#ttg135x> . = i
%dot_op<{opIdx = 1, parent = #blocked3}>tt.reshape1    9>  , %cst_18, ->%# = % 134blockedarith.constantc32_i32tensor< >  4: dense<:x32 ->-1.270000e+02 xtensor< > : i32f324tensor<tensor<
, #x44      blocked4xx%3x128431 = >32xix1tt.make_range
      x1xf32 {%i, , #end = 1738#blocked32 = , blocked> : iarith.addf#1
32 blocked>    , %>
%start = 172       cst_190,->% =  :  % 153arith.constanticst_3tensor< =  32 4arith.selectdense<}:x 7  4%>:tensor<x152 :  416, tensor<4tensor<xx%x3232x322cst_0xii32xf32x, 16, , i%, ##blocked8148#ttg3>, # : ttg.
blockedtensor<.slice<{dim = 2, parent = #blocked4}>slice<{dim = 0, parent = #blocked6}>      74>>%174>x

       = 
128    %arith.truncf      x%32 %icst_20 = %173outLHS1 = tt.make_range , , arith.constant {:%# end outRHSblockeddense< = tensor< = 1-1324tt.split>> : x32 ,  : ix%tensor<tensor<32f32, 135 44, #:xx32start = blocked3 128x0>tensor<xi8 : i 4bf16, 32tox, #} 4#ttg :tensor<xblocked. 4161slice<{dim = 2, parent = #blocked4}>tensor<x32x>>32xbf162

x, x          %i#i%cst_2132blocked8154 = , 3>,  = arith.constant#
      #ttg.local_alloc ttg%blocked dense<.1757%0x7FC0slice<{dim = 0, parent = #blocked3}> = >153> : >
arith.extsi  -> tensor<      % : (tensor<4x128%13tensor<128x33 4xbf16 = : x32x, tt.make_rangetensor<44bf16# {xx, blockedendi3216#1 = , xblocked>32#i5) : ttg8>
 -> i.slice<{dim = 1, parent = #blocked3}>,     !ttg32, >#%.memdesc<4x128xbf16, #shared, #smem>start =  blockedcst_22
0to 2 =       % : itensor<>arith.constant155324
  = }x      dense<ttg.local_load :i64%7  , 136>%154tensor<32#ttg =  :  x.slice<{dim = 1, parent = #blocked3}>arith.shlitensor<:i32> 4 , 
      %x!#%176outRHS4ttgttg = ,x..arith.extsi  32memdesc<4x128xbf16, #shared, #smem>slice<{dim = 1, parent = #linear1}>%11%x > cst_2i->
: 32        :, tensor<4%34i32 #x =  tensor<blocked128tt.splatto 4>x ix
bf16%64
4    , 30      x%# %16cst_23 = ttg:177 = xarith.constant.dot_op<{opIdx = 0, parent = #blocked3}> tt.splat i >i32%8dense<
 176, 1.270000e+02      -> :#blocked>%  2> : 156tensor<32i
tensor< = x64       4arith.extui i32->%x%,  137470#tensor<4 = x ttgxiarith.ori1:.64 x slice<{dim = 0, parent = #blocked6}>, %f32tensor<>#outLHS, 4
ttg,#x32      %.slice<{dim = 1, parent = #blocked3}> blockedx35>%>
i = 
      136    8tt.splat% %,  178:cst_24#% =   = ttg30arith.addi tensor<arith.constant.slice<{dim = 2, parent = #blocked4}> :%1774x > ,4dense< i32 x1.270000e+02to -> %16> tensor<175x : tensor<32 :itensor<4xxi 8432x32, tensor<4, xi#xi#416, ttg64blockedx#., 21xttgslice<{dim = 1, parent = #linear1}>#>f32, .slice<{dim = 2, parent = #blocked4}>>
ttg.
#>
      slice<{dim = 1, parent = #blocked3}>>      linear      %
      %>%15736 = %138
 = arith.addi 179 =     arith.shli% = tt.reshape% 34arith.extsi cst_25%156,  % = ,%31%137arith.constant  32   %: : :dense<cst_19tensor<tensor<32 -1.270000e+02 32xitensor<> : :x324tensor< i32, x4tensor<4, #4xx#ttgx432ttg.slice<{dim = 0, parent = #blocked3}>16xx.>x1i16slice<{dim = 0, parent = #blocked6}> ix, >to 8f32#ttg
      tensor<32, , .slice<{dim = 2, parent = #blocked4}>%37x##> = iblockedlinear>
arith.addi 64, 2
      %#>    %15835ttg % = ,.slice<{dim = 0, parent = #blocked3}>->cst_26tt.bitcast >  =  %33
      tensor<arith.constant% :%4 157 180 = xdense< :tensor<arith.extsi642.000000e+00 32 x>tensor<x%i : 4i30 8tensor<x32: , 432, i32#xx# toblocked4ittg. 8x16slice<{dim = 1, parent = #linear1}>i64>1, >
      
x#ttg
      %181      f32.% = %, slice<{dim = 2, parent = #blocked4}>38tt.splat 139#>  = % = linear->tt.splat180 tt.reshape>  : 
tensor<% %    4arg5i64105%x32 :  cst_27x ->: = bf16i32 tensor< arith.constant,  32tensor< #ttg-> xi4dense<.tensor<64x-8388608slice<{dim = 2, parent = #blocked4}>32x, 4>>
i32#x :       , ttg.1tensor<%#slice<{dim = 0, parent = #blocked3}>x4159ttg>ix = .
      84tt.expand_dimsslice<{dim = 0, parent = #blocked6}>%, x %>
182 = #1158      arith.addilinearx {% >iaxis = 39 = %181 322tt.splat, -> ,  :  %179tensor<#i% :4linear32arg5 x>} tensor<324
 :: xix     i64i%tensor<32, 8cst_284 #,  = x->ttg#arith.constant32 .ttg xtensor<slice<{dim = 0, parent = #blocked3}>>.slice<{dim = 2, parent = #blocked}>dense<bf1632
>2097152, x      
>#i%183       : ttg.32,  = %tensor<slice<{dim = 2, parent = #blocked4}>#ttgarith.muli1404> .slice<{dim = 1, parent = #linear1}>  = x->>%7tt.reshape4 
, xtensor<       %14%%106xx406 i32x =  :321arith.remsi: , x  tensor<#bf16, %36i644linear#,
x>blocked       4
4%38%184x    >  = 1%
      : tt.addptr xcst_29%tensor<%i = 16032arg2,8, arith.constant = x # tt.broadcasti%blockeddense< %32183 >127159, : > # -> : :ttg! tensor< .slice<{dim = 0, parent = #blocked6}>tttensor<4tensor<>.ptr<bf16>4x4x
, x432      i644xx%41
x1x1 =       iixarith.remsi%18588bf16,   = , , #%tt.expand_dims ##blocked37%178linearlinear4>,  {2> ->%39axis>
   = 
    tensor<:1 :       %4x tensor<i32%cst_3032x32x}141 = 32i : = arith.constantx32,  ttg.convert_layout bf16#tensor<4 dense<, ttgxi%7#blocked.slice<{dim = 1, parent = #linear1}>64140>4>,   : >
#ttg:tensor<
      . 4      %slice<{dim = 1, parent = #blocked3}>tensor<x%42>44x161 =  ->xi = arith.muli tensor<416tt.trans  4x, %%xi#16071x8ttg {,i64, .order , #slice<{dim = 2, parent = #blocked}> = %#blockedlinear>array<53>2
i 
>    32:      % %:  186->cst_310i =   = , 64arith.extsitensor<arith.constant2
       4x , %%arg134dense<143 =  x-1>tt.make_range:i>} { 8 :  :endi32, tensor<4  =  #xtensor<464to ttg4x : i.x32i64
slice<{dim = 2, parent = #blocked}>ix32      %>832, 187
, xstart =       #bf16 = tt.expand_dims %ttg, 0%142.#blocked : 175 = slice<{dim = 2, parent = #blocked}>4i {arith.extui>>32axis 
 } = %    ->  1141llvm.intr.assumetensor<4:  : i  x32tensor<6432}:%x32xi  truex32: tensor< bf16, tensor<4:, #4xx #ttgi644iblocked., x19slice<{dim = 1, parent = #blocked6}>>#ttgi
>
.8    
      %slice<{dim = 1, parent = #blocked3}>, llvm.intr.assume      44> # % = -> ttg%162tt.expand_dimstensor<.true =  4xslice<{dim = 2, parent = #blocked}> tt.reshape%431x>:  {i64  %axis, #toi161 = blocked 1 13tensor<
: : >4     i
xllvm.intr.assumetensor<32      4 4x} %x%32x: 188 = itrue 32tensor<64arith.muli 16:xx%,  bf16i32186,#i, #,  ttg1blocked9#ttg%176.
>. :slice<{dim = 2, parent = #blocked}>     ->slice<{dim = 1, parent = #blocked6}> i>llvm.intr.assume >64
 tensor< ->
      %128       %%truextensor<189143 3264 =  = :xxtt.splat arith.shli bf161%186 i, x %1#i: 142
blocked32i,    5>, 64 llvm.intr.assume
# ->%       blocked tensor<cst_30%true%1636>4   = 
      x1::amdgpu.scaled_upcast_fp4%xi   4564tensor<i% = , 4177arith.extsi#blockedx
  34    scale%>
xllvm.intr.assume 44       i %162:%16% { 190 = , trueaxis = tensor<64arith.muli# 0x1 ttg: : x%189. ii32, slice<{dim = 2, parent = #blocked}>i32, %187>1} #blocked :

: 6>           tensor< totensor<4%llvm.intr.assume64 x1144 %x32tensor<64xi = true xx64, tt.bitcast:i1#blocked  8xi3%i, 64>
1431#,       % 
blocked#191:    3>blocked6 =  llvm.intr.assume ,>tt.addptrtensor<% 
 %4xtruetensor<      1844 128x%46,x:32 =  %i xtt.expand_dims188 16ibf16,  : , 1#%!tt#
blocked540.ttg    >  {ptr<bf16>.llvm.intr.assume->axis,slice<{dim = 2, parent = #blocked}>   =  >%tensor<0i true128 : 64
-> xi       :3232%192tensor< xbf16}  = 4i, :tt.expand_dims x1# %1824
blockedtensor< {x    5>32xaxisbf16llvm.intr.assume
i = ,        32, 0#%true%#ttg : ittg 164.32.: = slice<{dim = 0, parent = #blocked6}>} slice<{dim = 2, parent = #blocked}> arith.cmpi>:>i   tensor<
1eq->32      
, x%     tensor<i145llvm.intr.assume%164,  =  70,x#tt.expand_dims% 32ttg. true%xislice<{dim = 0, parent = #blocked3}>% :cst_2032> 144  , ->  {i:#tensor<axis1 blocked1 = 
tensor<6x2    4x>
32 : llvm.intr.assume32x      xii i%64, 32%847 = #blocked}true, tt.splat 3  #%>::ttg.arg10 
  slice<{dim = 2, parent = #blocked4}>:       tensor<i>i%19341
32 = x
       tt.broadcast 4    %165->%x% =  190 bf160tt.expand_dims tensor<:,  = %1641 #tt.get_program_id {x32tensor<4ttg axis = xx1.x2ixislice<{dim = 2, parent = #blocked}>  : 3264, >:i32, #blocked  } #3->i: blocked>  32tensor<6>->tensor<
4
 tensor<4    x32      %4xx%x4832x4x1i = i1 = 1, arith.muli64, xtt.get_program_id# #blockedbf16 ttg.%463>, yslice<{dim = 2, parent = #blocked4}>, 
# >%      %blocked: 47194> ->  : = 
itensor<4 tt.expand_dims      32xtensor< %
321%179146    xx { = %132xaxistt.broadcast2xi32 = 0  = i1,  : %arith.addi, #blockedi32145 #6}  %blocked>::arg54
  ,>      tensor<32tensor< 
%x4%      49ixc31_i32% = 644 166arith.extsi , x: = %48#1 tt.broadcast ttg.xi :slice<{dim = 0, parent = #blocked3}>>bf1632%165  , 
 tensor<-> #blocked    :1tensor<>% x1x 3tensor<432x32-> = x32ix arith.divsix32i64tensor< 1, , 4%x##x2iblockedblocked34,16>>x ,  to
      32%# %195xc32_i32blockedtensor<1 = bf16 4xtt.broadcast , :> 32x%# ->i194blockedi 64,  :>32tensor<#blocked 

4x6>tensor<1          32
x32%%x32      %x1474x50i64 =  = i = , #tt.reshapearith.extsi1tt.broadcastblocked3  ,  >%%#blocked%45 ->146arg74  tensor<  >:4x::
       32x  %tensor<itensor<i1676464432 = x, #x tt.trans1xblocked4to i3x %16664>
32i {,       x64order#%bf16
 = blocked6196 = ,     array<i> tt.addptr#%32: ->  blocked50tensor<%> = , 64191, ->arith.extsi2x32 %  , x180 tensor<%1i: 4xarg9>64, !128 } #blockedtt.x::6ptr<bf16>,bf16  > , itensor<
i64#blocked324      
1 x%      >to3251 = %
 xtt.broadcast197 =       i32 arith.addi %64xi%49%148
1 :195 =     ,  , amdgpu.scaled_upcast_fp4%6#blockedtensor<1%193  = 4x :%arith.extsi > 32 138%-> xtensor<4 arg11tensor<ix32scale 464x :x, #i64% 32xblocked6, 147i32># {32xi ->blockedaxis 1 3> = to, tensor<
      1 #64% : iblockedx198i64932 = 32
>
xiarith.extsi }          64, %arg4 %%# :7168blocked6:   =  = >itensor<arith.extsitt.reshape
32 4        tox%%167% 640 52i64x : = 
      i: arith.addi%8 tensor<4 199, ix% = #3232x50tt.splat blocked8> 32,%,tox 198   i%:tensor<i151 464, # i64x
blocked: 128    9 -> x%> tensor<64tensor<bf168->x4x,  =  32x1x#blockedarith.divsitensor<i64i641 128, , >%x## 132blockedblocked3->,xi6>>  1
      
tensor<%, %53      %43#blocked = 200 = x 5tt.addptrarith.cmpi 128:> sltx 
      %,bf16i%169arg1 , 32 = ,%185#
arith.select , blocked     %%1%%42199>9168  :
 = , : tensor<      arith.remsi% 4x% cst_21!1x149 = %, tti64arith.cmpi1%.,  ,163ptr<i8>#eq  : ,blocked3,%tensor< i> 3128x64
% 32
            139:xi%54%201,  1 =  = %i, #arith.extsiarith.extsi cst_3132blocked % 
5%arg5:    >, arg14   llvm.intr.assumetensor<:: tensor< 128x i4%32i32xtruex32  4 bf16toto x:,  i64i i#blockedi64
815
            %, 
>%202 = #    
55tt.splatttgllvm.intr.assume        =  %.%%arith.muli201slice<{dim = 2, parent = #blocked}>true170 =   > ttg.local_alloc%:
: 7        %, i%i169%64 1501 54->  = 
: tensor<1tt.expand_dims     : x llvm.intr.assume(i32x% tensor<12864i149%x
64,  {axistrue32      # =  x%blocked2:bf16563> :  ,  = 
ii#blockedtt.addptr       3215>%%203}
)arg3 =       -> ,arith.cmpi : %! slt,tensor<10ttg% 4 = .55%xarith.cmpimemdesc<128x32xbf16, #shared, #smem> 192,4 
: xsgt       %202i,%171!tt 1  = .:, %ttg.local_loadptr<i8> #arg6 , tensor<ttg,%i1x. 1706432xslice<{dim = 2, parent = #blocked}>% 
i64>c0_i32:      , #   %blocked3->:!ttg57 = >  .tt.expand_dims
      tensor<imemdesc<128x32xbf16, #shared, #smem> %432 ->%204 = x
 41tt.broadcast4    tensor< { xscf.if128axis = %1 x1200x%32 :  :i10xi 1 bf16, 32tensor<4, {#}x#
ttg 1xblocked      .:i1>%dot_op<{opIdx = 1, parent = #blocked3}> , #
11>tensor<blocked       = 
      323%arith.muli%172x>151  = i  = %tt.dot32, ->tt.broadcast8 #ttg  ,%155.slice<{dim = 1, parent = #linear1}>tensor<% ,> 4150% -> x32 c4_i32%tensor<x: 17132i :, x11tensor< %cst_3x, #4i :iblockedx32 3234
tensor<, >
x      4#      1%xlinear1%x12128>
205 = i = x      tt.broadcast 1tt.make_rangebf16%%,  {, 58203#end#ttg =  blocked = .tt.splat:>4dot_op<{opIdx = 0, parent = #blocked3}>  tensor<  : >%1x->i arg1532 32* xitensor<,  : 1, 4xstarttensor<i#4 = 128x32blockedx032 ->332 : xbf16 >xi, tensor<32 i32#x-> 1}ttg1tensor<,  .dot_op<{opIdx = 1, parent = #blocked3}>x4#:>ixblocked  3232x>tensor<->, #i
4 linear11      xtensor<>
, %i4x      %#152323259 = blocked3 = , xarith.muli >tt.reshape#ttgf32%
 ., 57      %slice<{dim = 1, parent = #blocked1}>#,%206151>
blocked3  =        >%58arith.andi :%
 %204 13      : ,tensor< = %tensor< %4xtt.make_range173322054 { = x xendarith.addf1x:32 =  i32 x4%, tensor<4i : 172#x1i,linear32x, 32 1i1#, %>
, #blocked>startcst_3      blocked  =  %3>->0:60
        :   = %207tensor<itensor<arith.extsi  = 432}4x%59tt.splat x 32 :%128:x 196x f32, tensor< :itensor<#32 14blockedx1!tt, x3>xi.ptr<bf16>#i
32 blocked32      , #->1, %174linear1 ># = > tensor<
ttgarith.truncfto4x      .  32x%slice<{dim = 1, parent = #blocked3}>%tensor<!tt153>17332. = 
 x1ptr<bf16>, arith.select      :xi# % 64blocked%14tensor<, 3>152,  = 4x#linear
%tt.splat321      cst_0 x>%208, %f32, 
 = %11#      tt.addptr148 blocked%  : :361%207tensor< > = ,4i tt.make_range %x32to {end197128   =  :x->tensor<4 i 4x : itensor<1tensor<432324, xx, x#ibf16start32xblocked32, # = !1, blocked0tt>#3> : .ptr<bf16>, ttg
i, #tensor<.      32}blocked4slice<{dim = 1, parent = #blocked1}>% 3>x>175:,128
 =   x      arith.extsitensor<tensor<bf16% 4x4, 15%ix# = 13 32, 32blockedarith.addi:#xi1>  ttg64
%tensor<.,       144slice<{dim = 0, parent = #linear1}>#%,x>blocked3154 i
> = %32      
ttg.local_alloc12, %        #ttg62 = tt.store%:.tt.broadcast 153 slice<{dim = 1, parent = #blocked3}> %208 tensor<> %60,:4to  % x :174(itensor<4 , tensor<32xtensor<%2064, i32 x#64, x: 128ttg#1xtensor<x.ttgi4xbf16, slice<{dim = 1, parent = #blocked1}>.64, 32#>slice<{dim = 1, parent = #blocked3}>#xblocked
>
linear!tt1            %1>.>%176 ptr<bf16>, )16 = -># ->  = arith.extsi blocked3!tt.splat tensor<>ttg %32
.memdesc<4x128xbf16, #shared, #smem>%11x    
arg4 :4x}        i64
%:i, #    155 32 linear1tt.return = i32to >

ttg.local_load i         ->64%}% 
63
154tensor<       = } 4%tt.expand_dims
:x177 =  %
 itt.splat61{-#
!32  {  ttg, %axisexternal_resources: {.#176 = 
memdesc<4x128xbf16, #shared, #smem>ttg :0     .  : mlir_reproducer: {->slice<{dim = 1, parent = #blocked1}>i64i32
 > }      tensor<
-> pipeline: 4       tensor<: "x%4tensor<bu12817x4ilx = ixtbf16arith.remsi64iin,  %, 32.m#15#, odttg,ttg#u. .ttgledot_op<{opIdx = 0, parent = #blocked3}>%slice<{dim = 1, parent = #blocked3}>.(>16 >slice<{dim = 0, parent = #linear1}>o
:
> pt             %-> i%tensor<178tensor<mi1564 = 1ze = xarith.addi x4-aarith.extuii%xim 32177,32, d%,  #linear-l70#%1751d ttg >s-:.slice<{dim = 1, parent = #blocked1}>:
us >       agtensor<
tensor<4%e4      x64{lx%i = d321864tt.broadcastsx = ,  -liarith.muli#%im8 ttg.63 i, %slice<{dim = 1, parent = #blocked3}>:t#7>
 =ttg,       tensor<10 .%%179x4tslice<{dim = 2, parent = #blocked4}>4 = xiar>  arith.extsi32gto:  , e i%#lineart-tensor<6432 1>a4
:  ->rx      tensor< ch32%32tensor<32=x19xxgi = i4f16tt.expand_dims32, xx,  #ttgi3295#%., 0ttg17slice<{dim = 0, parent = #blocked3}>#linear},. {>1> slice<{dim = 2, parent = #blocked4}>axis to
      t> =  %ri
1tensor<65t       : 32 = on%ixarith.extsi-15732i sc = }64, %farith.shli #64- :ttg. to% slice<{dim = 0, parent = #blocked3}>:-156tensor<>
 cf,4      tensor<,  x%32c%i32180 = x4oncst_19, arith.extsixive # 32, r:ttg%#t .30 linear1-tensor<slice<{dim = 1, parent = #blocked1}>:>in4>  dex i32tox32->  -tx totensor<oitensor< 32-164ixl, x644lv#1
xmttgx      %i64{.i181, islice<{dim = 2, parent = #blocked4}>32 = #nd>, tt.splatlinearex
# %1>-b      blocked180 
      i%1:%tw158> 66i = 
i = dtt.bitcast      64 arith.addi th %->%65=%20 ,0}157 = tensor< , tt.splat 32x%62 a:%i64 l arg8, :ltensor< # oc4:ttg.tensor<32ax slice<{dim = 0, parent = #blocked3}>>x4t32i
xie-x32      64ami %, dg16->182 = #linearp,  arith.addi1>u-#tensor< 
      sttg4%181%67ha.slice<{dim = 2, parent = #blocked4}>x, = r>1 tt.splat e x%179%d--> i :56mtensor<32  :em4, tensor<32 ox#xi!ttr32blocked64.y,x1, ptr<i8>  bf16>#ttg-> co, 
.slice<{dim = 0, parent = #blocked3}>tensor<n#      >32vttg%
      xe.21%1834xrtslice<{dim = 2, parent = #blocked4}> =  = !-t>arith.muliarith.mulittri
  .to      %%ptr<i8>n%197,, #-a159, linear1md =  %6>gptt.expand_dims% 
      u- 20:%to%  68 = -158:itt.addptrll { 64 vmaxis = tensor<
      %67{24%,ar : x184 ci1 = %h=32xtt.addptr 66 gf}i%:x9 32arg2, 5:,  tensor<0 #%18332 ftensor<blocked xtz41:4=x> xt32
!!ttrx      tt.ptr<i8>ubf16%., e, 22ptr<bf16>#},# = , linear ttgarith.extsi i1ca.slice<{dim = 2, parent = #blocked4}>%64>,no>21
 n        tensor<i->: %32c tensor<185 = x4altensor<4tt.expand_dims xiz4x%ie{x117864,  32x {# mxiaxis = linear1a132, 1>xx# : 
-ibf16blockedi      t, 1>32%e# }69rblockedto  = a4 :tt.loadti>tensor<  o
4tensor<4%68n      xxi s%164:=160x,  10 = i#ttgtensor<32 mtt.broadcast64.x4a , slice<{dim = 1, parent = #blocked3}>xx-%#> !ttnu159blocked->.m 1 ptr<i8>-r:>tensor<4, #ew 
      x1linear1ritensor<%x>te423i64
s=x = ,       -32tt.make_range#blocked%1 x {370re1end> = gix = 
tt.transobf16128       n,  : %186%69-#i =  {sblocked32arith.extsi order = i4, %array<m>start = arg13ipl 0 32if-> : :: y= i 1notensor<32i, r4}320mx  >a32:to}lx    32tensor<i:tex12864 stbf16x
tensor<-c, i      32on#32%xveblocked, 187 = 4xr4#tt.expand_dims ige>ttg%8n
.175, ce      slice<{dim = 0, parent = #blocked1}> {#linear=%>axis1f161
 = >al =       1 ->stt.trans% : i e  2432tensor<t% = }4op160tt.expand_dims x- { : 32xdorder%tensor<iow = 2348n=array< {x, tiaxisi#r32 = 64, ttgue: 0#ttg.slice<{dim = 2, parent = #blocked4}>}0 : .>,, islice<{dim = 1, parent = #blocked3}>
       232>%cs, } 71e1 ->  = , >:tensor<tt.splatco}  4 nv:tensor<x%e 128129 rtensor<xxi:t-4i64 cfx32, !tt-32, #blocked.ptr<bf16>tox#3 ->-l32ttg> lx.
tensor<vmbf16slice<{dim = 0, parent = #blocked1}>      %4{i, >188xnd#  = 128eblocked->arith.mulixx-4  !bi>tensor<%186ttt 1x,.ptr<bf16>wi->128 , d x%176#ttensor<i blockedh432, :1>=x# 
      0}32blockedi%72, x164 = c32>
      tt.addptronx
% vbf16      189%er, % = 71t#25tt.splat,-blocked =   ar9arith.extsi%186%it>  28h
%: -      24 i:t% 64 o162: tensor<- =  ->4ltt.reshapetensor< xlv 1tensor<128m%x4x{161128x!in x1ttd:ixi.ptr<bf16>e 3264, x-tensor<, , #b4##blockedblocked1itxblocked3>w321>
, idx32>      %tensor<4tx to190xh=bf16,   = 1280}#tensor<arith.mulix,blocked1 i 9x%64ca> 128189, n->x,#blockedo i 1>nitensor<64%
c128, 187      ax# :%l32blocked 73ix1tensor< = zebf16>4tt.load{ , 
x1  #      xi%72mblocked%64,  ax526#blocked: -> = 3>tensor<i
tt.broadcast
4t             xer%%%191128xat16322 = !io =  tt.addptrttnsamdgpu.scaled_upcast_fp4: .=1  %184ptr<bf16>, 0%tensor<,# m774 blockeda x%1xscale1188>- x 
nu%i:      m16264 %-r {, !74 = eaxis#tttt.splatwr = blocked. it01>ptr<bf16>%es :  , 53 =-i->i: 132 64! r}tensor<
tteg 4      %.ptr<i8>io:x192 n 128 = ->-stensor<xtt.expand_dims i64xi tensor<64m3264%xpx, 18232lii# {xf8blockedaxis = !tty=, 10 : .ptr<i8>no#blocked>i, r3
32#m>      }blockeda,% :6>l 27 
 ttensor< = tensor<      e128tt.broadcast32x%75stx i64 = -c32%, tt.addptronx25# vbf16 ttg.%74e, :slice<{dim = 0, parent = #blocked3}>, rg# >%eblockedtensor< 52 nc51-> : e=>xtensor<tensor<fa 128164ls->xxxe i3232 ttensor<64xxo128, i64!ttp-x#, .d32blocked1#blockedptr<i8>owx>3>, nbf16 
ler_DP1_TP1: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#=t, ->       %blockedr#tensor<1936ublocked4x = >e}5128tt.broadcast,, >x  cs
i%tensor<e      6419064,%,  x s164#: 32y = blockedtensor<4xmbarith.cmpi 1x1i64oleq>x, -,
i#blockeddc       646e%%, >,7028#
 e, = blocked3      %na arith.addi>76 = b%  tt.loadlecst_20%->  - 26tensor<4%75li:,x n  32cacheModifieretensor<%x -427i=ix 64 nf32:, cgox tensor<# , i4blocked:c8x3 o, 128>tensor<64n#x
xvttgi      32#er.64%xblockedtslice<{dim = 2, parent = #blocked4}>, 194 = ! = ->#tt.expand_dimstt#b
blocked .ttgu      1%ptr<i8>.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>il%>179, 
t165
       {##i = %axisblockedblockedntt.expand_dims29 = 61-  = 0> = f%tt.addptr : 
#un164 i      ttgc {%32}%.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>-axisarg0 77
to = ,: = #blocked-2  ttg.convert_layout2 = ll : %tensor< #ttgvmi1832x%.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>{32 i76
#f}:64 blocked3t  , : = z=:!# #ttgt ttttgtensor<.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>rutensor<..slice<{dim = 0, parent = #blocked3}>64
#e4ptr<bf16>>xblocked})x, 324 = ",32 ->x#ttg
xi i.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>      i64tensor<18
#disable_threading: 1
x, blocked5false,       32# = ,#%xblocked6#ttg
      ttg30i>.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>verify_each. = 64 
: slice<{dim = 2, parent = #blocked4}>arith.muli, ->#blockedtrue> # 6 = 
 %blocked3tensor<#ttg    }->9>64.
  } ,
xblocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>

#-}tensor<       32#blocked
4%%195x7xc32_i32 = i = 32 /tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:0tt.broadcast 8#x: : %, ttg1ierror: 194#.x32Failures have been detected while processing an MLIR pass pipeline :blockedblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>i

 3
1      %/tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:0tensor<>#, 31: 1x
blocked# = note: 32      8blockedtt.make_rangePipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`x% = 4 {
i6478#>end,  = ttg
 = #blockedtt.reshape.      32 : 3 blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>%i>%
16632 ->73# = , start tensor< blockedtt.broadcast = 4:9 0x  = % : 32xtensor<#165ii644ttg 32, #x.:} blocked128blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}> : 3x
tensor<tensor<>
bf16#432      , linearxx%# = 32i32196blocked#x,  = 1ttg1#tt.addptr >.xttg% linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>i.191->
1slice<{dim = 0, parent = #blocked6}>, #, > %tensor<linear#
180 41blocked      %:x = 432 =  4#>tt.make_range!xttg  {tt32.->end.xlinear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>  = ptr<bf16>bf16
tensor<32 : ,, #4i i#linearx3264blocked232, 
> = xstart      
#32 = [rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 4, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank4]:E1031 11:31:37.768000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
%197      ttgx0 = %.i : arith.addi 79linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>1i%195 = 
, 32, math.absf##}%193 sharedblocked  :% = 4: tensor<78#> 4x ttg
tensor<32:.      32xxi swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>%i3264, tensor<
167, #4# = #blockedxsmemtt.transttg.3>4 =  slice<{dim = 0, parent = #blocked3}>
x#%>      32ttg166
%x. {      %198bf16shared_memoryorder33 = , 
 =  = arith.extsi #modulearray<tt.make_range%blocked attributesi {arg4> {32end 
":  = :       t032i%t,  : 3280g2i to = ., 32 iarith.extfn1, 64 u>start
      %m} = %19979- 0 :  =  c:itt.splat:t 32  atensor<}%tensor<s4 198 4"x: :x = 32tensor< i41x32x64x : 32i32 32ix, -> x32i#tensor<bf16, 1ttg4, ", .slice<{dim = 1, parent = #linear1}>x1#t#>xiblockedtblocked
64, >g4      # .>%34blockedton  = 3 u->tt.splat>tensor<m  
4-tensor<%      %xw430200 = 4ax arith.cmpixrp32: 32sx slt,x"32i f32 = x32%, 4i 185,# : 1-> blockedi,  tensor<%>32#32x199
, blockedi :      ttg.target932 % = >, tensor<481"
#ttgx = h      .1"i%slice<{dim = 0, parent = #blocked6}>xtp168>
i64t: =       , #.gtt.reshape%35blocked3rf  = >
ex%tt.splat      d9167 %201u5 % = c0:30arith.extsie"  : ", tensor< %("4iarg5%tx32 :80t32  )gx-> i <.32tensor<32{tx32x axishrii32to = e1,  i2a, #64 : d#ttg
      isblocked.%32-9slice<{dim = 1, parent = #linear1}>202 = }p>>tt.splat >e 
%201 (r->       {- %:
wtensor<36 i      a128 = 64^bb0rxarith.addi ->(p32  %"x%tensor<arg16 = i341: 641,xf32 : ,  32, i#%xi%32blocked3164arg17}5 , #:  >: blockedf32{
tensor<323)
      x>
:  %i      %
tt.func16932203 =           = , arith.cmpi %publicarith.select#ttgslt,209  .  = @%slice<{dim = 0, parent = #blocked6}>>%192arith.maxnumf_batched_gemm_afp4_wfp4_pre_quant_kernel168
, (,        %%%%%202arg16arg0cst_2137 ,: ,  = :  !%arith.additensor<%tt163 1xarg17. : %32 ptr<bf16>tensor<35x: {128,i tt.divisibilityx 64, f32 = 32%#
16x33blocked         : i 3>tt.reduce.returni1: 
 32, tensor<32      %}#x%209, blockedi204 %532 = :arg1>, tt.broadcast  : , #%200f32!tensor<ttg :
tt128.       .xslice<{dim = 1, parent = #linear1}>tensor<}ptr<i8>32>4x) {x
1 : tt.divisibilitybf16      xi( = , %1tensor<16#38, #4 : blocked = blockedxi5tt.splat3432> > x}
%-> 32,       arg5tensor<4x%% :x32f32arg2170 xi, :  = i1, #!ttg.local_alloc32#blockedblockedtt  3>>.%-> 
      ) -> ptr<bf16>169tensor<%tensor< { 322054tt.divisibility:x = x =  itt.broadcast 416(32%203x : tensor<,  :f32i128# , 32xttgtensor<#}32.1xttg, xslice<{dim = 0, parent = #blocked6}>32x.%bf16>islice<{dim = 2, parent = #blocked}>arg3, 
      1>: #%, 
!blocked39#blocked      tt5 = 3%.>tt.splat>82ptr<i8>)   =  { -> !%-> ttg.convert_layouttt.divisibilityttgarg5tensor<  = . 4%16memdesc<128x32xbf16, #shared, #smem>:x3281 : 
 x i      ii:32%321,  }171 #tensor<,  = -> blocked4%ttg.local_loadtensor<3>xarg4 32
4: %xi      xi17032%f3232 , 206,  {:#ttg = #tt.divisibility .arith.andi ttg = !slice<{dim = 1, parent = #linear1}>%.16ttg>204slice<{dim = 2, parent = #blocked}> : .
, >imemdesc<128x32xbf16, #shared, #smem>      %205 32 % :->}->40  ,   = tensor<tensor<%tensor<arith.remsi4x4arg5128 32xx: x%i14i3236, x32x,#blockedf32 {bf16 3>, tt.divisibility, %
# = #38      ttg16ttg :%. : .dot_op<{opIdx = 1, parent = #blocked3}> tensor<207slice<{dim = 2, parent = #linear}>i>32 = >32
xtt.splat
}      i       , %32%196%%172,  83arg6 = #ttg: = : tt.dot. tt.expand_dimsi slice<{dim = 0, parent = #blocked6}>! 32%>tt.% {155
ptr<bf16> 82tt.divisibility,      %-> { =  41 axis16% = tensor<4 =  : 171arith.remsi x322i,%37x : 32 ,!tti}% .ptr<bf16>32, cst_3%, }% 39# arg7: blocked::  :3> itensor< 
      tensor<324tensor<%2084 {x32x = xtt.divisibility128i32tt.addptr 4 = x, %x16bf16#207,f32 : , ttg %, i#.197 #32ttgslice<{dim = 1, parent = #linear1}>: ttg}.>tensor<., dot_op<{opIdx = 0, parent = #blocked3}>
4slice<{dim = 2, parent = #linear}>%>      %x>arg8 42 = 32 : *arith.mulix->i  ! 32tensor<%tttensor< {1287,.4tt.divisibilityx ptr<bf16>x = 32%, 416x5#blockedx : bf16 :31i,  >,x32#i f32}ttg64tensor<4, , .
      x#%dot_op<{opIdx = 1, parent = #blocked3}>%4332lineararg9> = x>:  tt.make_rangei
i-> {end64      32  = , % {tensor<64 : #84tt.divisibility4iblocked =  = x323>tt.expand_dims1632, start
  : x =       %if320tt.store8132,  : i  {}#32%axis, blocked}208 = %3 , 2arg10>: %174 : : 
tensor<,ii      64 3232%xi%} {17332206 tt.divisibility = ,  : = arith.addf#ttg:  16 .tensor<tensor< : %slice<{dim = 1, parent = #blocked6}>44i172>x32x32,
      x4} %44!x, % = ttf32%cst_3tt.expand_dims., arg11  ptr<bf16>#: :%, #ttgi 43blocked.32tensor< {3slice<{dim = 2, parent = #blocked}> {4axis>>tt.divisibilityx = 
  = 321    ->16x : }  : f32i
tensor<i, 32}    432# tt.returnx}blocked: 
4, 3tensor<  x%>64}1arg12
x
x:       i}f32i%32
, 32174, 
# { = #{-#
blockedtt.divisibilityarith.truncfttg  > =  .external
16%slice<{dim = 1, parent = #blocked6}>_resources: {       : 173>
%i      8532:->mlir_reproducer = }  tensor<: {tt.bitcast, tensor<64
 %4x1      %arg13xxipipeline83: 3232:  ix, ":32f32#b  {, blocked6utensor<tt.divisibility#>i4 = blocked
lx163      ti4 : >%nxi 45.132to = mx} arith.extsi odf32, tensor<%ul, %444 e#arg14x:(olinear: 32 pt>ixtensor<i 32bf1664m-> {, xi tt.divisibility#1ztensor< = blockedxe4163i-x : >32, a4i
#blockedmdx32      6-1}%> lx, 175todi% =  s32arg15arith.extsitensor<64-, :  xus#i%1alinear3213xg>) ie{
 attributes:64ld       { , s-%noinlinetensor<#blockedl86 = 46im = falsex>itt.bitcast}i
      t  32%=0%{, 46 =  84
#tt.expand_dimst     ttg a:%.%40r cstslice<{dim = 1, parent = #blocked3}> {gtensor< = >axis = et4arith.constant 0 : -ax toirc4dense< 32}h=x127tensor< :gf1>4 x9x : xtensor<325f32tensor<ix0}, 464i32,#x, ,  blocked4##t>xttgttgr 1..it->xslice<{dim = 1, parent = #blocked3}>slice<{dim = 0, parent = #blocked6}>on i>>-tensor<8
 ->s4,        cfx#%tensor<1-4blocked176xtox> = 32-c1
arith.extsixfx     i, i%%32co32cst_011, #n,  =  blockedve#arith.constant:6rblocked  >t->dense<i
in
0x7FC032      %de      > 47x% : to = -87tensor< tt.splat to = 4i%-arith.addix64arg10 ll 128
:v%x       m{85bf16%ii,, 17732n # =  d%blockedtt.splat-> excst_281 tensor<- >%1bi:
176xtw      32idtensor<%:xt4cst_1 i32hx = i, =4arith.constant64#0x  blocked6}1dense<->>,x2097152 
 i>tensor<      %al32 : 448l, tensor<x = o#4iarith.muli clinearx64%at>4, 46e-
x#,a      1ttg m%x.%47d88islice<{dim = 1, parent = #blocked3}> :g = 32> puarith.addi, 
tensor<-s #      1ha%blocked%xr86>17832e,
 = xid     %arith.addi32-%cst_2 , #mcst_1 = %blockede arith.constant1776m: ,>or dense< 
ytensor<4%      ,4>175% x :  49c4tensor<: = onx4 arith.extsi v1xtensor<%48ex44 rixx:t-3216i t, x64tensor<1r#i, xiblocked8#ttg32xt>, .i32o
#slice<{dim = 1, parent = #blocked3}>, n-      blocked>#am%2
blockeddg89>      6>p = 
% utt.bitcast    179to- % =  t%c31_i32arith.extsitensor<o87 =  1x- arith.constant%32l: 32xl 31 i64vtensor< : :, m{4i #ax32tensor<blockedrc4
326hx    x>=1%i
      gfxcst_332%x9i = , 50 = 5032arith.constant#tt.broadcast f,  ttg tz#dense<.%45=linear0.000000e+00slice<{dim = 0, parent = #blocked3}> t>>>: ru  :  tensor<e}->tensor<to64,  4 xcatensor<xtensor<1no43232xinixxx64ca4f32i, lix, 64#z1#, blocked6exblocked#>{ i3ttg -> 32>. m, 
slice<{dim = 0, parent = #blocked3}>tensor<ax#    >64-ilinear%c32_i32
xt> =       32xer
arith.constant%iat       18064io%32 = , ns90 : arith.extsi#=1 = i blocked0 tt.bitcast32%6m 
30>
a%           x88%:%- c4_i32 51 = n: = itt.broadcastum arith.constant32 -rtensor<  %e44to49 wx :  : r4iitensor<1ix3264xt1
    
32xex%      isitrue%64, =32 = 181#-, arith.constant = blocked1 # tt.splat6reblockedtrue >gi>
% o     180-> n->% tensor<- c0_i32:64sitensor< =  xm4arith.constanti32px 64xil40 64, ix : ->#blockedf1i 6>yx32tensor<
      =i
32%no32    x52r, %i = ma#cst_464arith.addi l blocked = , %t>arith.constant#50es
 ttg,t      dense<. -c%-8388608slice<{dim = 0, parent = #blocked3}>%51on91>> ve =  : 
: rgarith.anditensor<      tensor<e 4%64nc%x182x32e894 = x=,xarith.addiif 1 64al%x%, secst_27i181#blocked  32,6t:,  >
o #%      p-tensor<blocked179%d4> 53ox
: = wn4     tt.addptr=x%tensor< tr1cst_532%uex = xarg1}iarith.constanti, ,32 64% c, dense<, 42s#2.000000e+00# :elinear>ttg ,> : .!tt c
tensor<slice<{dim = 0, parent = #blocked3}>.ptr<i8>o      4>,n%x
 ve924      irt = x%64-arith.andi1183
      cf x = %-t%f32arith.muli54o-90,   = ll,#%arith.extsivm blocked7 {i%>,%ndcst_4
 arg14ex     % :-:%6 b cst_6 iitensor< = :32t4arith.constant  towix i dt4dense<64ih=x0.000000e+00
640}1>      
,x : %       itensor<184%55c324 =  = o, xtt.addptrarith.muli nv#4 %eblockedx%7rt>1arg2,-a
x, r      f32 %i%, %54t93#183 h = blocked :-tt.bitcast>: t 
 i64o-%    !
      l91%tt%56l cst_7. = v: = ptr<bf16>tt.addptrm arith.constant, {tensor<  %i4dense<iarg3nx-214748364864,d4>
 ex :       %x1tensor<%55-bx4185 iix = :tw324tt.expand_dims id, x !th#32%tt=0linearx178.ptr<i8>}>i {,,  32axis ic->,  = 64a #1
      notensor<blocked : %ni4>
i57 = cax    32tt.expand_dims l4%}%izxcst_8 41e{1 = : { xarith.constant axis f32 tensor< = m, dense<41a#23x : xlinear>ii-i> : t
64tensor<e32      , 4r}%#xa 94ttg4t:  = .xiotensor<tt.bitcastslice<{dim = 1, parent = #blocked3}>32n32x >xs=i32% i3210, 92->,  m#  #axttg:tensor<blocked-n. 4>uslice<{dim = 1, parent = #linear1}>>tensor<x
m- 41    r->xx%ew 4icst_9ritensor<x64 = t321, arith.constantexx# s1xiblockeddense<=i323255-132, >> :  , ##
tensor<rlinearblocked      4e1>>%xg
       1864i%-> = xo58 arith.extsi32xn = tensor< i-stt.splat4%32i xarg13, #m%4 blockedplarg15 x:>i:1 
f xi    yif3232%=32,  cst_10 = no ->#toarith.constantr blocked  matensor<32>idense<lx
648388607 1      
>tx%       : esi95%tensor<4t32 = 187x-, math.log2 = 4c#linear tt.expand_dimsxo1% 32n>93%xive
       17532r%: {, g59 axis#e = tensor< = blockednarith.muli 41>c%57x : 
e, 4i    =%58x32%f 1}cst_11a:x  = l tensor<f32:arith.constantse32,    x1#tensor<dense<txlinear41>oi32>x : p, 
itensor<-d#      644olinear%, x4w196#xn> = ttg32=
math.log2.xt       slice<{dim = 1, parent = #blocked3}>ir%60%>32u = 94 , e}arith.extsi ->#,  : blockedcs%59 tensor<>
e tensor<4    ,:4x%  x1cst_12stensor<4x = y32xiarith.constantmbx1164 oxx, dense<lif32#127-32, , blocked>dc##3 : elinearblocked>tensor<,1>
4 >
      xe       %4nto %188xatensor<3297 = 32bx = arith.mulixle1math.floor i-x %32li%186, i64, 95,#blockedn#  >elinear:%
-1 176    i>
tensor< %nf      4:cst_13o%x  = , 614iarith.constantc = x64 ontt.make_range1
dense<v {endx      4194304e = f32%>r4, 189 : t : # = tensor<-ilineartt.splat4b32> xui, start
%4xl =       18632xt0 : % iii98:32n32} =  , - math.floori#f: 64blockedu tensor<% >n496->
cx      -ti32:tensor<%o,  4cst_14-#tensor<x = llttg41xarith.constantvm.slice<{dim = 0, parent = #linear1}>xi {f>
464dense<t      x, 126z=%621#>t = xblocked : rutt.broadcastf323tensor<e} , >
4x)%60#      4" :blocked%x, tensor<>19032
32x
 = x      1x      arith.muliidisable_threadingi64% 32: , #99%, #falselinear = 189blocked,
1arith.subf,>      >  
verify_each ->%%    :  97187%truetensor<32, cst_15
    }x : = 
4% arith.constant  }xcst_26tensor< 
i 4dense<#-}64, :x2
#linear 1>1tensor<x : >
4i/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0tensor<4      x64, : x%4#error: 4x63xblockedFailures have been detected while processing an MLIR pass pipeline32 = 13
xtt.expand_dimsx>/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0i32 f32
: , #%,       note: blocked>61#%Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`

     {linear191%axis> = cst_16 = 
tt.addptr = 0 :        arith.constanti32%% }100184dense<  = ,21: arith.subf >tensor< % : 4x%188tensor<i98 4x32,:4,   x#%!32ttg.cst_5ttxslice<{dim = 0, parent = #linear1}>> .i :ptr<bf16>32-> ,,  tensor<tensor< #1x4iblocked4x64>x4

    ix      %321%cst_17, x192 = #linearf32 = arith.constant1, tt.expand_dims  >#%dense<
blocked18228      %> {>64
axis : tensor< =        = 4tt.broadcast %0x%101 : 4x63 = i32 tt.clampf32x: } i32 %:, tensor<99 #1x,tensor<blocked4x 32>i32%[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 6, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank6]:E1031 11:31:37.783000 509 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
x
, cst_25i    #,64%linear , cst_181%# = > cst_24ttgarith.constant->,.   slice<{dim = 0, parent = #blocked3}>dense<tensor<propagateNan>-1.270000e+0232x  >4=-> : x  tensor<4i32nonetensor<x4, # 1xlinear:x11 32x>tensor<xf32
4i,       %x64#654, blocked = x#>arith.extsi1blocked
 x3    %f32>%cst_1964, 
 =  #      arith.constant:linear%  tensor<>
193dense<32x       = 74%tt.broadcast>x102  : i = %tensor<32tt.clampf1904,   x#linear%:321100 x>,tensor<i  416, to%x# cst_181ttgtensor<,x.32 islice<{dim = 2, parent = #blocked4}>x4%64>xcst_23,, 
i #    64, propagateNanblocked%# 3cst_20linear=> = 1  arith.constant>none-> 
  dense<      :tensor<-1% 4>66tensor<x :  = 432xtensor<arith.addixi4 464x%65x, 32, 1#x%xblockedi862f323,  , >#:#
ttg. blocked      slice<{dim = 2, parent = #blocked4}>tensor<>%>32x
194
4       =     x%tt.expand_dims%i103 cst_21 = 64,  = %arith.constant#lineararith.fptoui179 1  {dense<>
%axis0x7FC0      101 = >%67 0 :  = : : tensor<tt.splat  i128%56tensor<32x 4}32:x x 4:bf16, !ttx #.1tensor<blockedptr<i8>x325 f32x>
->, i     tensor<#64%cst_2232linear,  = x>#arith.constant4 ttg xto.dense<! slice<{dim = 0, parent = #blocked3}>7tttensor<>>.ptr<i8>4  : , #x->tensor<linear4 4x1>xtensor<4
11x      xx32%i32x68 = 8xitt.addptr , i32, %#64#67,linear, blocked> >#
%
blocked    66      3% %>cst_23:104
 =   =       arith.constanttensor<32arith.fptoui% x4 195dense<x% = 1.270000e+02!102tt.broadcast> : tt.  tensor<4ptr<i8>:%x,  1944#tensor< x1linear14:x>x f32, ,4tensor<#blocked x1>
tensor<321x    xx32%4f32xcst_24 = x, iarith.constanti64#64 , #blocked, dense<linear>#1.270000e+021 blocked>>
to3 :        >tensor<%tensor< 469 = 4->xtt.loadx 4 4tensor<x%x41681 xxx: 32f32itensor<32x, 8xi#, #464linearblocked>x, >
!#
      ttblocked    %105.ptr<i8>3% = , >cst_25arith.addi #
 = %103linear1      arith.constant,>%  %
      196dense<cst_29% = -1.270000e+02 70 = tt.addptr>:tt.trans  :  tensor< %tensor<4x%1914469,xx { 41order%xx = 1801iarray< :x8i32 f32, : !, #1tt#linear, .linear>0ptr<bf16>>
>,
      }     %106 :i% =  64cst_26arith.addi tensor<
 = %32x      arith.constant1044% ,x197dense< i = 2.000000e+00%8, arith.addi>cst#  :  linear1%tensor<:>1954  ,xtensor<4->  4xtensor<4%x4x321931xx x1i8:f32x,  , i8#ttgtensor<#, .slice<{dim = 2, parent = #blocked4}>4linear#>x>blocked
32
>      %x    
71 = i%      %tt.splat 64cst_27107%29,  =  =  #arith.constantarith.subf:blocked   3dense<%!>-8388608cst_6,tt
> .       : %102ptr<bf16>%tensor< : 1984 -> = xtensor<4 arith.extsi4x4tensor<4 xx1x128%1xxarg4xf32! i, #tt.:32blockedptr<bf16>,  , >#i#
blocked32linear      1> >%
to
108      %      = 72 = i%math.exp2tt.addptr 64cst_28 %71
 = %,      arith.constant107 %  %199dense<:28  = 2097152 : tt.splat>tensor<tensor<4  : 4xx%tensor<41281984xx x1!tt:4x.ptr<bf16> xf32, i1, ##blocked64xblocked1> i>,->32
  ,       %tensor<4tensor<#109x4linear = 128x>arith.extfx1
 ix    %64i%78, 64cst_29 #blocked,  = :1>#arith.constant 
blocked tensor<4      3dense<x%>1274x73
>32x =        : bf16tt.load%tensor<,  2004#% = xblocked>72arith.cmpi4  : xto  slt1tensor<4tensor<4,xx4x128 ix32x%8x!tt185, f32.,#, ptr<bf16>,  linear##%>blockedblocked1199
>>     

      :%      %74 cst_30% = tensor< = 110tt.splat4arith.constant =  x tt.broadcast %1dense<%53 x7108:i>  64 : : !tt, tensor<tensor<4.#4xptr<i8> blockedx4-> 34xtensor<>x164x
ix32      16f32, x%, #blocked!201#> tt. = ttg-> ptr<i8>arith.extsi.tensor<4,  slice<{dim = 2, parent = #blocked}>x#%>4blockedarg5
x6     32>
:%x      % cst_31 = f32, 75iarith.constant# = 32 blockedtt.addptr dense<> to-1
%74 >      , i : %%64tensor<111 = 52 
4arith.mulf:       x tensor<64%202 = tt.splat 4x%%x32109201ix, 8, ! :#tt% ttg.110i.ptr<i8>,  64slice<{dim = 2, parent = #blocked}>#: >blocked ->
6tensor<     >4tensor<llvm.intr.assume,x1  4x%tensor<x32true6432x xxi:32f3264 x, , ii##164blockedblocked
, >3    #blocked
>llvm.intr.assume 6      
%>%      true
112%        = 203: %tt.bitcast = i76 arith.cmpi1 = % 
tt.load111slt      ,llvm.intr.assume%:  %75 %true tensor<192 cacheModifier4x,: 4  = x%icg322021 x 
:f32:     ,  llvm.intr.assume tensor<64#tensor<%xblocked1true32>x x 32:!->x itt i1.ptr<i8>tensor<64
, 4,     #blockedx#llvm.intr.assume64blocked >x3%true
32>       x
:%i       7732%i = , 2041ttg.convert_layout# = 
 blockedtt.broadcast    %> llvm.intr.assume76
%        200%: % truetensor<113: 64 =  :xarith.anditensor< 32 4ix%x1i81121
    , ,xllvm.intr.assume#blocked i1 6%, %>cst_7#true  blocked :->:3   >i1tensor<64tensor< 
x4->    32xx llvm.intr.assumei4tensor< 8x4%, 32xtrue #x32:blockedix i3>32i1
, 1
      #,     %blocked#llvm.intr.assume78>blocked  = 
3%tt.reshape      >true %
 %114      :73 = % i arith.shrui2051:   = 
tensor<%tt.broadcast    4x112 llvm.intr.assume128x,%203 %bf16  true , %:: #blockedcst_8 i1 tensor<1> :1
->  x    tensor<tensor<32llvm.intr.assume 44x%truex4xi x41:32x,  x32#ibf16xblocked1, #i3
blocked>32>    
,  llvm.intr.assume       #->%%blocked true79>tensor< : = 
4 math.absf      xi %321%78115x
      = i%:arith.andi10  , # = tensor<4%blockedtt.get_program_idx1143 4,>xx32 
 x%      : bf16cst_9%i,  20632#blocked: = 
> arith.andi    
      tensor< %%4%180x204 =  = 4,tt.get_program_id arith.extfx y 32% %79x205: i  :32:i ,  32tensor<#tensor<
    4blocked4%2x>x = 4
32xarith.addix      i 32%1%x116, arg5bf16 = #,, #arith.andiblocked3 blocked> >% %
c31_i32to112        ,%:tensor< 207 4% = i32x4cst_10tt.splat
x      32:%%x 1963f32tensor<  = , 4:arith.divsi#x  blocked4!%>
xtt2      32.,%81xptr<bf16>  = i %"32->c32_i32tt,   .#tensor<:rblocked4 ed>xiu
3232c      x
e"%!    (117tt%% = .4 = 80arith.addiptr<bf16>arith.extsi) ,   <%#%{115blockedarg7axis,3  =  >:2%
  : cst_11      ii %3232:208 }  = to>tensor<tt.addptr  (4 i{x%64
4207
      x,    ^bb032 %(x%5%i197 = arg1632 arith.extsi: , : f32# %, blockedtensor<arg9 %>4: arg17: 
xif32      3232 )%xto:118! 
 = tti64        arith.subi.
    %209 ptr<bf16>% = %, 6arith.maxnumfcst_12# =  %,blockedarith.extsiarg16 3 %,%>arg11 117, %  : arg17:tensor<i32  4 :tensor<xto  432if32
xx64        4i
    tt.reduce.returnx64% 32, 7%x# = 209iblockedarith.extsi :323  , >%f32
#
0      blocked       }>tt.store:)
   :       %i(%20832tensor<119, 4x =  to4arith.cmpi% x 174i32xult,64f32, 
,  %    #blocked%206%>115 8) -> ,: = tensor<4  arith.divsix%tensor< %4xcst_1241,f32,  x #:32%ttg x3.tensor<! slice<{dim = 2, parent = #blocked}>4tt:>x. 
4ptr<bf16>i      x, 32%8232#
 = xblocked    ttg.convert_layouti3%9 32> = %, 
arith.remsi81 #     :blocked}% >
1tensor<4
    ,x      tt.return 4%
%x120  3f32 = } , arith.shrui
:# } ttg%
i.slice<{dim = 2, parent = #blocked}>116
32>,{-#
  
    ->%  llvm.intr.assume cst_11external tensor<4 _resources: {%x4:
truex      f32tensor<mlir_reproducer:, 4: { #x
ittg4      1.xpipeline
slice<{dim = 2, parent = #linear}>32:     >x"llvm.intr.assume
      ib %8332u% = , itruett.expand_dims#l  %blockedt:82>i  {
niaxis      .1 = %m
    2121ollvm.intr.assume : i = d 32arith.oriu%true}  l : %e:tensor<120( 4x,oi4 p1x%t
f32cst_13i    ,  m%#:i10ttg z = .tensor<earith.cmpislice<{dim = 2, parent = #linear}>>4-  xasgt-> 4m,tensor<4xd- x32l%4xxdarg61is,x32- f32, u%c0_i32, #s #blockeda:linear>g >
ei32
            {
%%l    84122dscf.if =  = s tt.expand_dimsarith.shrui-%  l10%%i 81121m{ {,i
axis =  t      %2%=11 =  : 1180arith.mulii   32:ta%8} r, tensor<g :4e% xtc4_i32tensor<4- 4xa:x32r 4xci32xih
f3232=      , , g%12#ttg#f = .blockedxtt.make_rangeslice<{dim = 2, parent = #blocked}>>9 {>
5end ->      0 =  %}4tensor<4123, : x4 =  ixarith.selectt321 r, x%istartf32119t = , , o0#%n : blocked122-i>, s32
      %c}%116f 85 : -: = tensor<t tt.bitcast4otensor< x-4%4cx83xfi 32,32, :x # icttgtensor<1o.4, nslice<{dim = 1, parent = #blocked1}>>x4#v
xblockede      1>r%x, t13 = f32, tensor<-tt.make_range#4i {linearxnend> 4d = ->xe4 32x : tensor<4x-ixit32, 4x32ostart1, - = x#l0iblockedl : 32, >vi#
m32linear      {}>%i 
124n:      % = d 86arith.maxuietensor<4 =  xxitt.bitcast %-32%115b, 84 ,i#:  tttgtensor<%w.4xcst_14islice<{dim = 1, parent = #blocked3}>4 d>
x:t      1x h%f32tensor<=14 = , #40tt.splatblocked>x}  ->4,% x 11tensor<432a x4xl:x1il x32oii, c3232#a , blockedt->#blocked>e >
-tensor<
            a4%%mx87125di =  = g32, arith.addiarith.subip#  uttg%85%-.,124sslice<{dim = 1, parent = #blocked1}>> %,h
cst_28 a       :%r% tensor<cst_14e154 d = x:-arith.addi4 m xtensor<e%14m14xxo,i4r 32xy%, #32,12linearx  >ic:
      32o %, ntensor<488#vx = blockedeiarith.addi >r32%86
t, ,      -# %%tttg.cst_1126rslice<{dim = 1, parent = #blocked1}> : = it>
 tensor<arith.shlio      4x n%4%-16x1125a = xi,mtt.splat32 d , %g%#cst_15parg4blocked u >:-:
 t       tensor<oi%894-32 = xl ->tt.bitcast 4l %xvtensor<87 32m4:x{x iaitensor<32r32, 4, c#x4#httgxblocked=.1>gslice<{dim = 1, parent = #blocked1}>x
f>i      x
32%9      %, 127517# = 0 = linear>arith.shrui arith.remsi   f%->%t15 tensor<123z, 4x,=%4 t16x%r 1cst_16u:xi e 32:}tensor<,  ,4#tensor< xlinear4ci>
xan32,       4o#%xnttg90 = 32i.tt.bitcastxcslice<{dim = 1, parent = #blocked1}> ia>%32l
88, i       #z%:blockede18 >{ = tensor<
 arith.muli4        x%m%4x128a71x = x,iarith.ori- %32,  i4#blocked%t :> 126e ->,ri  a64tensor<%t
4127i      %x o194:n = x1 stt.expand_dimsxtensor<= i41%32x017, 4  {#xmaxisblocked32a = >xx1
      i- : %9132ni = , u32}arith.andi#m  blocked-:%>r 89
etensor<,      w4x %ri%129i32, cst_27 = t# arith.addiettg: s. %=slice<{dim = 1, parent = #blocked1}>tensor<4128->x,1 4  ->x1%r xcst_11etensor<i : g4x32tensor<i1, 4ox#xnilinear4-32, >xs#blocked
32i1      xm>%ip
9232l       = , i%20arith.andi #f = %blockedytt.splat90>= ,
n%       oarg8%cst_4%r  130m::  = a tensor<4arith.shruilix4  32x%t 1129e->x,s i32 ttensor<, %-4#cst_11cx1blocked> ox
:ni       v32%tensor<e, 934r# = xgblockedtt.bitcast4e1 xn>%9132c
 xe      %:i=21 32f = tensor<4, aarith.mulix#l 4blockeds%x1>e19x
 ,i      t 32, %o%#131p20linear = - > arith.minuid:-> o  tensor<%wntensor<44x130=x4x,t11 rxx%uif32cst_22e32,  }, #:,#linear  blocked1>tensor<c>
4s
      xe      %944,% = x 22 = tt.bitcast32carith.extsi xo %92in%21 :32v  tensor<, e:4x#r 4blockedttensor<4x>-x1x
c1i32      fx, %-i#132t32, blocked> = o# arith.shrui-lblocked1-> l> tensor<%v to4113m x,{tensor<44x ix1%n1xxcst_17dif32 e64, #:x, blocked> -#
      tensor<bblocked%4i195xt> = 4w
math.log2xi       32d%%xt2393ih =  32=tt.make_range:, 0 { #}endtensor<blocked, = 4> 128x4
c : x      oi321x%n, f32133vstart = , # = e0linear>arith.orir : 
 ti      %-32%132a} 96,r: =  i math.log2%ttensor< 131h128% -x94:ti32 : o,  tensor<-#ttgtensor<4l.4xlslice<{dim = 0, parent = #blocked1}>x4v>4xm
x132{      xxi%f32in24, 32d = #, ett.expand_dimsblocked#x >
blocked-%      >b23%97
i { =       taxismath.floor%w =  134i0% = d : 95arith.trunciti  h32:%=} 1330 :tensor< } 4x:,tensor<4x  1281tensor<cxx4aif32xn32, 4o, #xn#ttglinear32i.>xcslice<{dim = 0, parent = #blocked1}>
ia>      32l %, i->98 = #z math.floor blockedetensor<%>{196  x to 128: mxi tensor<a32tensor<4x, 4xx-#44iblockedxxt1132e>xxr
      f32ia%, 8t25#, i = blocked>#oarith.extsi
blockedn       >s%%
=2499      1  = %0:arith.subf135    = mtensor<%tt.reshapea1x97 x128,%-x 134ni32% u, #cst_26:mblocked  -1:tensor<r>  4etotensor<xw tensor<4x4r14xixx32t1281xexxisif32, 8=64#, -, linear>#1#
blocked blocked      %>r1100 e> = ->g
arith.subf i       %tensor<o%984n26,x- =  4stt.broadcast%xi %cst_516m22 xp :2l: xi tensor<4iftensor<4x8yx4x, =1x1#nixf32blockedo64, 7r, #>m#blocked
ablocked>      l1
      % >%outLHSt 101 = , e->tt.clampf %s %outRHSttensor<99 = -4,tt.splitcx  o128%%nxcst_25,135vi  e64%cst_24:r, ,  g#blockedpropagateNan tensor<e1=4n> xc
none4e       x=%: 16f27tensor<xa = 42ltt.broadcastx4xs x1ie%25x8  f32, t:, ##o linearblockedptensor<>7-1x
>d128       ox%->wi64102 =  n, tt.clampf tensor<=#%4tblocked100,xr1 %4u>cst_18xe ,16}-> x, %cst_23i tensor<,8c4 , sxpropagateNan#e128x =blocked,i 2 64, none>s# 
yblocked:      m1 %b>
tensor<136o      %4 = l28xarith.shli- = 4 darith.addix1%c xoutRHSe,%26f32, , ,# e blocked%n%>cst_2a27
       b %:l:103 e  = tensor<-tensor<arith.fptoui4l4 xix%1014n128x xei:16-64 xi, tensor<in#48fblockedx, o1>4x#,
1blocked       x2c%f32>o29, #
n = linear      vtt.addptr>%e  137r%to = targ0, arith.ori- tensor<4 b%x%u184xoutLHSi 1,l:x t i8%i!, 136ntt# -.linear>:fptr<bf16>
 u,      tensor<n %1044ci = x-64arith.fptoui 4t
%xo      10216-% xl30 = : ilarith.mulitensor<8v 4, m%x#{94blockedf,x12t x>z=%f32
tc32_i32,       r #%u:blocked138e > = }i32 tott.reshape)
  "      %tensor<%,314137
 = x4       tt.make_rangex:disable_threading {1 : end = xitensor<false3284, : , x
i#4      32blocked>xverify_each, 
16: start      %xtrue = 105i
0 = 8    } : arith.addi, 
i32 #  }}%blocked
 1032#-}: ,>
tensor<32  x%->icst_29 32,  :/tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0tensor<# tensor<: 4ttg.4error: xslice<{dim = 0, parent = #blocked6}>>x4Failures have been detected while processing an MLIR pass pipeline64
x1
x      x/tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0i8%32i: ,  = 8note: #tt.make_range, Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`blocked {#
8endlinear>> = 

32 :             i%106%32,  = 139start = arith.addi  = 0%104tt.reshape : i,  32}%% cst105:   tensor<::32x  itensor<4tensor<32, x4#ttg4xx.slice<{dim = 0, parent = #blocked3}>1x4>
i8x      %, 133 = #xtt.make_rangeblocked>i {end
8 =       , 32%# : i107 = linear32, arith.subf>start   = %cst_6->0,  : i tensor<32}%4 :102x  4tensor<32: xxitensor<i32, 4x8#ttg4, .slice<{dim = 1, parent = #linear1}>x#>
1ttg      x.%34f32, slice<{dim = 2, parent = #blocked}> = #>tt.splat blocked>
%30
       :      % %108140i32 =  =  ->math.exp2tt.reshape tensor<  32%%[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 2, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank2]:E1031 11:31:37.801000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
xi10710632,   #::ttg  .tensor<4tensor<slice<{dim = 0, parent = #blocked6}>x44>
xx      %1435 = xf32xtt.splat , 1%#blockedx30 >i: 
8i      , 32 %109#->  = blockedtensor<32arith.extf>x  i%78->32,  : #ttg tensor<.tensor<4slice<{dim = 1, parent = #linear1}>>4x
      x4%4x36 = xiarith.addi328 x, %bf16, #34,#blockedlinear %>231 to> : tensor<
 tensor<4      32xx%i324x141, 32x = #ttgf32ttg.convert_layout., # slice<{dim = 0, parent = #blocked6}>>blocked%
      >140%37
  =       :arith.addi%  %110 = tensor<35,tt.broadcast4 % x33%1084 : :x  itensor<32tensor<8xi4x, 324#, x1linear#ttgx2.f32, >slice<{dim = 1, parent = #linear1}>>#blocked 
      >->%38   = ->tensor<tt.splat  4%tensor<4xarg5 x4: 4xxi3232i xf328->, #,  tensor<blocked#32>ttgxi
.32,       slice<{dim = 2, parent = #blocked}>#ttg%>.slice<{dim = 0, parent = #blocked6}>111
>
 =             arith.mulf%% 14239%109 =  = ,arith.extuitt.splat   %%%arg5110141 :   i::32   ->tensor<tensor< 44tensor<xx3244xixx32, 32i#ttgx8.f32, , slice<{dim = 1, parent = #linear1}>>##
blockedttg      >.%40
slice<{dim = 2, parent = #blocked}> =       >arith.remsi % %36112 = to, tt.bitcast % tensor<38 %4:111x  4tensor<32:xxi i32tensor<416, x4, #ttgx32#.xttgslice<{dim = 0, parent = #blocked6}>>f32, .
      #slice<{dim = 2, parent = #blocked}>%blocked>41> 
 = ->      arith.remsi  %%37tensor<143, 4 = %39xarith.shli 4 : x%tensor<3232142xx,ii32 32, , %##cst_30ttgblocked> .slice<{dim = 1, parent = #linear1}>
:>
             %tensor<%421134 =  = xarith.muli arith.andi 4%%x7112,i,  %16%5cst_7,  : :#  tensor<ttgi4.64xslice<{dim = 2, parent = #blocked}>
4>      %x32
43 = x      tt.make_rangei% {32144end = , # = 64blocked>tt.bitcast : i
 32,       %start = %1141430 =   : iarith.shrui:32}   :%tensor< 1124tensor<64,xx 4i32%x, cst_8i#ttg 16.:, slice<{dim = 1, parent = #blocked6}> #ttg>tensor<.
      4slice<{dim = 2, parent = #blocked}>%44x> = 4 tt.expand_dims x->%32 43xtensor< {i4axis = 32x1, #4 : iblockedx32}>bf16 :
      ,  %#tensor<64115ttgx = .iarith.andislice<{dim = 2, parent = #blocked}>32 >, %114
#ttg,      . %slice<{dim = 1, parent = #blocked6}>%cst_9145>   = -> :tt.expand_dimstensor<64 tensor< x14x%xi414432x {, 32axis#x = blockedi3226>,  : 
#blockedi      >32%45
} =       % arith.extsi 116:%44 =   arith.andi tensor<: %4tensor<64112xx,41 xx%bf16icst_10, 32 :#,  tensor<ttg#4.blockedx4slice<{dim = 2, parent = #blocked}>6>x32> toxi  32, ->tensor<# 64blocked>tensor<x1
      4x%xi64117 = 4, arith.addix# %1blocked6115x>, bf16
      %cst_11, %46 # = : blockedtt.expand_dims tensor<4>%40x
 {4      axisx% = 32x1460 : i = i3232tt.broadcast} , # : blocked%tensor<32>145xi
       32, %:#118 ttg. = tensor<slice<{dim = 0, parent = #blocked6}>arith.subi4>  x->%cst_124 tensor<,x1 %1x117x32x bf16i32:, ,  ##tensor<4blockedblocked6x>>4 
x32->      %xi 47 = 32tensor<tt.splat, #4 blockedx%arg10>
4 :      %x i119 = 3232 arith.cmpix-> bf16 ult,, tensor<1 #x32%115blockedxi,>32,  %
#cst_12      blocked6 %>:147
       tensor< = %4tt.reshape48x  = 4x%arith.muli 32x146%46i ,32: %,  47#blockedtensor< :>4 
xtensor<      41%120xx32 = 32xarith.shruixi32 bf16, %, #116,#blocked6 blocked>
%>      %cst_11 49 =  ->arith.extsi:   tensor<%tensor<4448 xx: 4128tensor<1xxx32bf1632xx, i32i#, #32, blockedblocked6#1> blocked>to>
 tensor<
            1x%%32121148x =  = i64arith.oriamdgpu.scaled_upcast_fp4,   #blocked%%6>120138
,        scale%50%  = cst_13%tt.broadcast  147%45: { : axis tensor<tensor<4 = 64xx11x4 : ix32i64, x32#i32}blocked6,  > #:-> blocked tensor<64>
tensor<x32      4x%122xi64 = 64, #arith.shruixblocked6 %i>
1218      ,, %51 # = %blockedtt.broadcast 1188%49 > :: , tensor< tensor<14tensor<xx4324xxx128i6432x, #xbf16blocked6i, > 32#-> , blockedtensor<64#blocked1x32>>xi
 64      ->, #%123 blocked6 = tensor<>arith.select4
 x      %128%52119x = , bf16arith.addi%122,  %, #50,%116blocked % : 151tensor<> :4
 x      tensor<644%x32x149x32 = i64xarith.cmpi, #i blocked61eq>
, #,      %blocked 53 = >%tt.addptr , 139%tensor<4,arg1x4 ,x% 32xcst_31%42i  :32: , # !ttblockedtensor<.ptr<i8>>4,
      x %4i64124x
 = i      %arith.maxui854 =  , arith.extsi %#%115ttgarg14,.  slice<{dim = 2, parent = #blocked}>:%> cst_14
i       32:% to 150 tensor< = i4tt.expand_dims64x4 
      x%%5532149 = x {arith.muliiaxis 32,  = %7#2, blocked : %54>i :
32       }i64% 
      125:% =  56 = arith.subitensor<tt.addptr 4 %124x%,4arg3, x %i%55cst_141 : ,  :#!tt tensor<ttg.ptr<i8>4x., 4slice<{dim = 2, parent = #blocked}>i64x32>
      x %i->57 = 32,  tt.expand_dims #tensor<%blocked441>
x {      4axis = %x1126 = 1 : arith.shlixi i32%1251} ,, : # tensor<%blocked32xcst_15>i32 
, :       #ttgtensor<%.slice<{dim = 1, parent = #linear1}>4151>x4 =  ->xtt.broadcast 32 tensor<32xi%x132150x, # i32blocked:, > #linear
      tensor<1>%1274
       = x%arith.shrui458 %x = 1231tt.splat,x % %iarg15 cst_16 1: :, i #32 tensor<4blocked-> x>tensor<4 32x->x132 xxtensor<ii32432, , x#linear#blocked41>>x
32      x
%i1      59, #%128 = blocked = arith.muli>
arith.ori        %%%126,57152 =  ,tt.reshape %127 %151 % ::58   tensor<4tensor<:x4 4xtensor<x324x32x32xi1x1, ix#blocked32i> , #32-> blocked, tensor<4>#x
      linear128%1x129 = >i1arith.addi 
, #%128      blocked,%1> 60
      % = %cst_11arith.extsi153 :  =  tensor<%arith.select4x59 4 %152x32:, x %itensor<cst_0, 3232%, #x148 : blocked1tensor<>x4x
i128      32x%130, i1 = #, #arith.shrui linearblocked%12911>,>,  % tensor<4cst_11 tox: 128 tensor<tensor<x4x32bf16, 4xx#blocked3211>xix
      32, i%154#blocked64 = >, ttg.local_alloc
      # %131linear%153 = 1 arith.minui>: 
 %130      (,%tensor< 614% = xcst_22tt.make_range128  {x:endbf16  = , tensor<44#x4 : blockedx32i1>x32)i32,  -> , #start!ttgblocked = .memdesc<4x128xbf16, #shared, #smem>>0
      
       : %%132i155 =  = 32ttg.local_loadarith.shrui}  % %154113: ,  :%cst_17tensor<  :4!ttg x.memdesc<4x128xbf16, #shared, #smem>tensor<i 4x32->4,  x32#tensor<4xittgx12832.x, #slice<{dim = 0, parent = #linear1}>bf16blocked>>, 
      
#ttg%133      .dot_op<{opIdx = 0, parent = #blocked3}> = %>arith.ori 62
      %132 = %156, tt.broadcast = % arith.extui131%  :60%  70tensor<4: :x  4tensor<tensor<x324x32xx32i321xi, #x8blockedi, >64#
      , ttg%134#. = linearslice<{dim = 2, parent = #blocked4}>arith.trunci1> > to%  tensor<133->4  x:tensor<32 32xtensor<4xix4416, xx#32xittg.i3264slice<{dim = 2, parent = #blocked4}>, , >#blocked#
      >linear% 1157to> =  
arith.shli tensor<      %1564%, x463%x32 = cst_19xtt.expand_dims :i  8, %tensor<4#61x32blocked> {x
axisi       = 16, %0#ttg135 : . = islice<{dim = 2, parent = #blocked4}>tt.reshape 32>%134}
        %: :158 = tensor< tt.bitcast4xtensor< 44%xx157 32xi: i32tensor<8, , 4x##32blockedttgx>.i16 slice<{dim = 0, parent = #linear1}>, ->>#ttg  .slice<{dim = 2, parent = #blocked4}>tensor<->> 4 -> tensor<x4tensor<4xx16132x2xxx4bf16i8x, , #i#ttgblocked32.slice<{dim = 2, parent = #blocked4}>7>, >

      #      %%linear159outLHS1 = , >tt.expand_dims%outRHS
  =       %158tt.split% { 64axis%135 =  =  tt.broadcast2:   : itensor<%324x63} 4x : 16x:tensor<42 x32xtensor<xi81bf16, , x#ttg#4.blocked7xslice<{dim = 2, parent = #blocked4}>>i> ->32  , ->tensor<# 4lineartensor<4x41x32x>x116 xxi->bf168,  , #blockedtensor<#blocked2>324>
      x
%1364      % = x160 = arith.shliitt.broadcast  32%159%,  :outRHS,#  lineartensor<%14xcst_2>32x 
1:       xbf16tensor<%, 465#x = blocked4xarith.extsi4>16  xi%-> 864tensor<, # 4xblocked2:32> x
      tensor<32x%32bf16, 137x#blocked = 44arith.ori x>
%outLHSi      ,32%161 %,  = 136 #tt.trans:linear  tensor<1%1604x> {4 order = x16toarray<ixi 32: 8tensor<0, #32, blockedx22>4, 1
x>}      i :%13864  = , tensor<tt.reshape #4x%137linear32x :132x >bf16, tensor<4
#blockedx      4>4x% ->16x66 i = tensor<48arith.addix, # 32xblocked%322>65xbf16 ->,, #  blocked9tensor<%>462
      x64 %162x: = i tt.reshape 8tensor<%161, 32 :#x blocked84tensor<>
x4x      i32x%1396432x = , bf16, tt.reshape ##blocked%105linear9> :1 -> > tensor<
tensor<4x      128x4x%32x1x67bf16, i = #blocked8tt.splat5,  >
#%      linear56%>  163-> : = tensor< amdgpu.scaled_upcast_fp44! x4tt%77xi. 8, ptr<i8>scale #ttg %.slice<{dim = 2, parent = #blocked}>->162>
  {      tensor<axis = %320140x :  = 4itt.reshape x32}%106! : tt :.tensor< ptr<i8>64tensor<, x4x#324xlinearx1x1i8i>, 8, 
#blocked#      3blocked>%>, 68 tensor<-> = 128 tt.addptrx32tensor< xbf164x%, 4x67#blockedi8,5>, #  ->linear% 266tensor<> 128
:x      % 32141tensor<xbf16 = 32, ttg.convert_layout x#blocked%45>140x
 :!      % tensor<tt164 = 4.arith.cmpi xptr<i8>eq4, ,xi# 8linear%, #170linear2>,>,   %-> tensor<cst_20tensor<432 x4x: xi4tensor<8, x4x#i32ttg.64xslice<{dim = 2, parent = #blocked}>>, i8
#,       linear#%1ttg.142>slice<{dim = 2, parent = #blocked4}>> = 

      arith.extui      %165 % = %14169tt.expand_dims   = %:tt.load164   {tensor<4%axis = x6824  : xi:i8,  32}#ttgtensor< :.slice<{dim = 2, parent = #blocked}>32 >xtensor< 44toxx !32tensor<ttx4.i1x4ptr<i8>, xi, #ttg16#., linearslice<{dim = 2, parent = #blocked4}>#1> ttg>-> .
tensor<slice<{dim = 2, parent = #blocked}>>      4x
%32x      701% = x143 = tt.transi1arith.shli ,  %#%14269blocked,  {4>%order
      cst_30 = % array<166: i = tensor<32tt.broadcast 4: %165x1 :4,  x0tensor<i>4x16}32,  x#ttg:1.slice<{dim = 2, parent = #blocked}> x>
tensor<i      321%x, 144 = 4#blockedtt.bitcastx4 i> %1438->  :, tensor<4 #xtensor<4linear32xx1324>xx ii16->1, ,  #blocked#tensor<4ttg.4>slice<{dim = 2, parent = #blocked}>x
> 32      ->x%167 i = tensor<8tt.trans4x,  4#%xttg166bf16, . {#ttgslice<{dim = 2, parent = #blocked4}>order = .>array<slice<{dim = 2, parent = #blocked}>
i>      32: 
      %0, %712145 =  = , tt.expand_dims tt.splat1%144 >} {% :axis29  =  tensor<2 : :4xi 3232}!x32 :ttx tensor<.i14xptr<bf16>, 4x #blockedbf16, ->4>#  ttgtensor<-> .slice<{dim = 2, parent = #blocked}>4tensor<4>xx ->12832x x32tensor<4!xx4tti1x1., #xptr<bf16>blocked9bf16, >, ##
      blocked>blocked%
1168 =       %>tt.reshape146 = 
 tt.broadcast       %167%145% : :72 tensor<  = 4xtensor<4tt.addptr32xx4 32xx1%i1x71, #bf16,blocked9, # > blocked%->> 28 -> tensor< :128xtensor<4 32xx4tensor<i1x4, #32xblockedxbf161285>, #x
      blocked>!%169
tt =       %.arith.select 147 = ptr<bf16>%tt.reshape, 168 #, %146blocked% :1cst_21,  >%163tensor<, : 4 tensor<128x4tensor<x32x324xixbf16x1, , 128#blocked#blockedx5>>i, tensor< 64128-> , x32tensor<#x4blockedbf16, x1281#blockedxbf16>5>, 

      #      %blocked1%170 = >
73ttg.local_alloc       % = %169148 = tt.load amdgpu.scaled_upcast_fp4 :  %(%13872tensor<  128scale:x  32%147tensor<xbf16 {axis4, # = xblocked1 : 1285>ix)32}! ->  tt!ttg: ..memdesc<128x32xbf16, #shared, #smem>tensor<ptr<bf16>
4x,       %64#171 = xblockedttg.local_load i81%170, > #blocked
: 8>      !ttg,%.memdesc<128x32xbf16, #shared, #smem> 74 tensor<4 = -> x128tt.splattensor<xbf16 128x, %32x#blocked53bf16, 1 #> :ttg-> . !dot_op<{opIdx = 1, parent = #blocked3}>>tensor<4tt
x.      128ptr<i8>%x 172 = bf16, ->tt.dot#  blockedtensor<%1>64155
      x,%32 149x% = !171arith.cmpitt, . eq,ptr<i8>% %, cst_3139,#  blocked:%6 cst_31>tensor< :
4x       128xtensor<%bf164x75, 4x = #ttgitt.addptr.dot_op<{opIdx = 0, parent = #blocked3}>8,  >#ttg% .slice<{dim = 2, parent = #blocked}>74*>
,        tensor<128%%x150 = 5232tt.expand_dims  xbf16%149:,  {axis #ttg = 2tensor<.dot_op<{opIdx = 1, parent = #blocked3}> : 64> i32x->} 32 :xtensor< !4xtensor<4tt32x4.xxptr<i8>f32i, , #1, #blocked3#blocked>ttg6
.slice<{dim = 2, parent = #blocked}>>      > ,%173->   = tensor<4tensor<arith.addfx64 4x%x321721xx,i1i , #64%blocked>, cst_3
#       blocked:%6 151>tensor< = 
4tt.broadcast       x32%%x15076f32  = , : tt.load#tensor< blocked4x%34x75>1 
xicacheModifier      1,  %174#= = blocked arith.truncf> cg ->  %173tensor<: 4x :4xtensor< 3264tensor<4xixx321, 32x#blockedxf32, >!#
      ttblocked3%.>152ptr<i8>  = , tott.reshape#  blockedtensor<%15164x :>32 tensor<
x4      bf16, x%#4x77blocked332 = >xttg.convert_layout
      i1 %175, % = #blocked76arith.extsi > %13 ->: : tensor<  4tensor<tensor<x128644xxxi32i321x, , #i#ttgblocked8.slice<{dim = 1, parent = #blocked3}>1, >># 
blockedto      %6 153>tensor<4 =  xarith.select->i64  , %tensor<#ttg15264.slice<{dim = 1, parent = #blocked3}>, x>%32
cst_0x      , i%176%1488 =  : , arith.extsi tensor<4#%11xblocked 1283:xi> 1, 
i#blocked      32 1>%to , 78itensor<4 = 64xtt.reshape
      128x %177bf16, % = #73tt.splatblocked1  >:%
       176 %tensor<: 154 = 4i64ttg.local_allocx -> 128 %153xtensor<4 bf16x:, i #64(blocked, tensor<41#ttgx128>.slice<{dim = 1, parent = #blocked3}>xbf16 >
, #->      blocked1 %178>tensor< = )4arith.addi -> x %!ttg4177,.memdesc<4x128xbf16, #shared, #smem>x 
32%      x175%bf16 :155 = ,  ttg.local_load#tensor<4 blockedxi%154>64,  
#ttg:      .slice<{dim = 1, parent = #blocked3}> %>
!79      ttg = %179.memdesc<4x128xbf16, #shared, #smem>math.absf =   arith.extsi ->%%32 78 tensor< :4x: tensor<128x 32xbf16, tensor<i32#ttg4, .dot_op<{opIdx = 0, parent = #blocked3}>x#ttg>4.slice<{dim = 0, parent = #blocked3}>
      x>%15632  = xtoarith.extuibf16  , tensor<%70#32x :blockedi64 >, tensor<
#ttg4      .slice<{dim = 0, parent = #blocked3}>x%>3280
xi =       8, arith.extf%180#  = ttg.%arith.extsi slice<{dim = 2, parent = #blocked4}>>79%30   to:: tensor<  4tensor<ix32432 xxto i4i6416, x
      #ttg32%181.slice<{dim = 2, parent = #blocked4}>x = >bf16tt.splat
      ,  %157#%180 = blocked :arith.shli > i%156 64 , to-> %cst_19 tensor< :tensor<32x 4itensor<x64, 4x4#ttg32x.slice<{dim = 0, parent = #blocked3}>xi32>16, x
      #ttgf32%182.,  = slice<{dim = 2, parent = #blocked4}>>#arith.addi 
      blocked%181%>,158
  =       %tt.bitcast %179%15781  : = :  tensor<"tensor<324xtxi32xt64i16., , r##ettgttg.d.slice<{dim = 0, parent = #blocked3}>slice<{dim = 2, parent = #blocked4}>>u> ->c
       tensor<e%1834" = x32(arith.mulix% bf16, 80%7#),ttg. < slice<{dim = 2, parent = #blocked4}>>{%
axis6       =  %1592:  =  : i64tt.expand_dimsi
 32      %158}% {axis>184 =  =  (tt.addptr2 : { i
%arg232}      ,  ^bb0%183: ( tensor<4%:x32arg16 x: !ttbf16f32., , ptr<bf16>#ttg%,.slice<{dim = 2, parent = #blocked4}>arg17 >: i f3264->)
 tensor<:      4
%x        185 = 32x%tt.expand_dims 1209%178x =  {bf16, arith.maxnumfaxis = #blocked 14>% : i
      arg1632}%, 160 =  : tt.broadcast %tensor<4%159arg17x : i :64, tensor< #ttg4xf32.32
slice<{dim = 1, parent = #blocked3}>x        > 1xtt.reduce.return-> bf16,  tensor<4#%x1blocked209x4> i ->:64,  tensor< #4xf32blocked332
>
x            32x}%186bf16) = , # : arith.extsi blocked(%4>tensor<arg13
      4 :%161x  = 4itt.transx32 32 to%x 160f32i64 {, 
      order#% = blocked187array<> = i32) -> tt.expand_dims : tensor<%04175, x {24axis, x = 1>f321} ,  : i:#32} ttg :tensor<. 4slice<{dim = 2, parent = #blocked}>tensor<x>4x32x
i6432      , xbf16%#ttg, 82.slice<{dim = 1, parent = #blocked3}>#blocked = > ->4ttg.convert_layout > tensor< ->%4x 811xtensor<4 i64x32:, x32 #blockedxtensor<3bf16, 4>
#blockedx      9>4%188
      x = %f32arith.muli162 = ,  tt.reshape#% ttg186%161.,  slice<{dim = 2, parent = #blocked}>%: >176tensor<4  x32->: x32 i64xbf16tensor<
      , #4%189blockedx = 94tt.splat> x -> f32%186tensor<128,  :x32# xttgi64bf16. , #slice<{dim = 2, parent = #linear}>->blocked5> >
tensor<
      4x      %%1x16383i =  = 64amdgpu.scaled_upcast_fp4 tt.expand_dims, %77 #blocked scale%3> %82
      162 {%190 {axis = axis = arith.muli  = 2%1890 :  : , ii%3232187} } ::   tensor<64:tensor<4x x132tensor<xx4ii8x64, , 4#blocked#x3blocked3f32>
>,,       % #191 = tensor<ttgtt.addptr 128x.%18432slice<{dim = 2, parent = #linear}>,xbf16> , # %188blocked5-> > : tensor< ->4! xtttensor<1284.ptr<bf16>xx, 321ixbf16x64, #f32
      blocked5, %192># = 
lineartt.expand_dims      > %164
%182 =        {arith.cmpi %axis = eq,840  =  : i%tt.expand_dims32}70,  : % %81tensor<cst_20 {32 axisx: = i64 2, tensor<4 : #ttgx32i.slice<{dim = 0, parent = #blocked3}>x32>i} ->8  , :tensor<#ttg 1x.slice<{dim = 2, parent = #blocked4}>tensor<32>
4xi      x64, %4#165xblocked = f323tt.expand_dims , >
%164#       {ttg%193axis = . = 2slice<{dim = 2, parent = #blocked}>tt.broadcast  : i>%19032  :}->   tensor<4: tensor<x1tensor<4xi4xx64, 324#xxblocked3i11>, x #f32->ttg.,  slice<{dim = 2, parent = #blocked4}>#tensor<4> blockedx32-> >xitensor<
64, 4x      #blocked32x%3>185
      x = %194i1tt.bitcast = , # tt.expand_dimsblocked% 4>83%179
  {      :axis%  = 166tensor<0 = 4 : tt.broadcastxi 432%x1} 165x: :f32  , tensor<tensor<#32x4xlineari6432x>, 1 #xi->ttg.1 slice<{dim = 0, parent = #blocked3}>, #tensor<> blocked44-> > xtensor<1->4x32 xxitensor<4164, x32x#blockedx32i3>x32
i1,       , ##%195blockedlinear = 4>tt.broadcast>
 
            %194%167% : = 86 tt.trans  = tensor<1%166tt.bitcastx32 {order xi = %64, array<84#blockedi 3>32: ->: 0  , tensor<tensor<2, 44x1>x32x} 4i64:x,  1#blockedtensor<4x3>x32f32
      x32, %196xi# = 1, blockedtt.addptr #>%191blocked4 ,>->   %180->tensor< : tensor<4 4x!ttx324.ptr<bf16>x32x,x1 ii1x64, #i
      blocked932%197>,  = 
      #arith.addi %168blocked%195 = >,tt.reshape
  %      %193167%  :87:  tensor< = tensor<44xarith.addix3232x xi32x%64, i85#1, ,blocked3#blocked >
9>%       cst_28%->  198 = tensor<128:arith.extsi x32 %xtensor<arg4i4 1, x:#4 blockedxi3251 >
xto       %ii64169 = 32
      arith.select, % %#199 = 168lineartt.splat , >%%
198cst_21       , %%: 16388i64 :  =  tensor<128arith.addi-> x tensor<432x%x1i186xi, #,64, blocked5 #blocked>, %3>tensor<128cst_1
      x32 %200xbf16: = ,  arith.cmpi#blockedtensor< 54slt>
x,       %4%185170x, = 1 ttg.local_alloc x%199%169i : 32 :, tensor< (#4tensor<128blockedx1x>xi32
64x      , bf16%#blocked, #893>blocked5 = 
      >)tt.bitcast%201 ->   = !ttg%arith.extsi .memdesc<128x32xbf16, #shared, #smem>87%arg5
        :%171: i =  32ttg.local_loadtensor< to 4 %170xi :464
 x      !1%202ttg.x = memdesc<128x32xbf16, #shared, #smem>itt.splat  32%-> , 201 tensor<#: 128xlineari32x>64 bf16,  -> #->tensor<1ttg x.dot_op<{opIdx = 1, parent = #blocked3}>tensor<32>4x
xi64      %4, #172 = xblocked3tt.dot 1>
%x      155,i%203 32 = %171, arith.cmpi ,#slt, linear %>%cst_3
192,        : %%202tensor<90 :4x =  128tt.bitcasttensor<1x xbf16%32x, 88i64# , ttg.:#blockeddot_op<{opIdx = 0, parent = #blocked3}>> 3> *tensor<
       4%tensor<x2041284 = x32xtt.broadcast xbf161%200, x :#ttgi .32tensor<dot_op<{opIdx = 1, parent = #blocked3}>>, 4x #1-> blockedxtensor<>i14 , #x->blocked332x > f32, tensor<-> #blocked4tensor<43>xx32
      4x%xi17311 = x, arith.addfi# 32blocked3%, >172#
,blocked       >%205%
 = cst_3      tt.broadcast % :91%203  =  :tensor<4arith.andi x tensor<32x%1f3289x, ,32x#blocked i3%1>
cst_27, #       blocked3%:>174 =   ->arith.truncftensor< tensor< 44x%x321734x xi1:1,  x#tensor<iblocked34x32>
32x,       %f32#206 = , #lineararith.andi blocked3>%204>
, to        %%tensor<492205 x = :32xarith.andi bf16 tensor<4, %x32#90xblocked3,i1> , #
      %blocked3%175cst_4>
 =        arith.extsi :%207%  = 13 tensor<tt.splat : 4%196tensor<4x :xi4 32, x!tt#1.ttg.xptr<bf16> slice<{dim = 1, parent = #blocked3}>i->> 32 tensor<to , 4xtensor<4#32xxblocked!i64>tt, 
.#ttg      ptr<bf16>.slice<{dim = 1, parent = #blocked3}>%, #>93blocked
       = 3>%tt.bitcast
      176 =  %arith.extsi %208 = %1191tt.addptr   ::%207  , itensor<%197324 : x to4tensor<4 xxi64132x
      x!tt%177i. = 32ptr<bf16>tt.splat, #, # linearblocked%>3176  >,: -> i64 tensor<4 ->tensor<x32 4xtensor<4xi64x4, #i64xblocked3, 1>#ttgx
      .f32tt.storeslice<{dim = 1, parent = #blocked3}>,  >
#%208      linear,%178>  = 
%174arith.addi       , %177%%206,94   = : %175tt.bitcasttensor< : 4x %32xtensor<492!x tt.i:ptr<bf16>, 64 #blocked, tensor<3>#ttg4
.slice<{dim = 1, parent = #blocked3}>x    }>
4
      %x    179 = 1tt.returnarith.extsi x
%i  }32 32
:, } #
tensor<blocked
32x>{-#
i   32, ->external_resources: {#ttg 
.tensor<    slice<{dim = 0, parent = #blocked3}>>4mlir_reproducer x: {
to 4      tensor<32xpipeline: xi1"64xb, f32u#ttg, il.#tslice<{dim = 0, parent = #blocked3}>>blockedin
      >.m%180
od =       uarith.extsi %l%3095e(  = o:math.log2pt  ii32%mi to93z  e-i64:am
 d      %tensor<-l1814ds = x-utt.splat 4s%xag180 1e{: xldi64f32s- ->, li tensor<#mi32xlineart=i64>0 , 
t#ttg      ar.slice<{dim = 0, parent = #blocked3}>%ge>96t
       = -a%math.log2rc182 =  h=arith.addi %gf%18194x9,  50%179:}, :  t tensor<ritensor<324toxixn-64, 4sc#ttgxf-.1tslice<{dim = 0, parent = #blocked3}>xo->f32c
      , f,%# c183 = blockedoarith.muli >nv%7
er,      t- %%in697d : = ex imath.floor-t64
 o-      %ll%18495v =  mtt.addptr :{i%arg2 nd, tensor<ex%1834-b xit:4w xi!tt1dt.ptr<bf16>xh=, f320}i, , 64#a
linearl      >l%185
oc =       att.expand_dims %t%17898e- {axis = am = 1math.floordg : i p32%u-}96s  ha::r  etensor<4tensor<dx4-mi64xem, 4o#ttgxry.slice<{dim = 1, parent = #blocked3}>1,> x -> f32ctensor<, o4#nvx1blockederxi>t-64, 
tr#blocked      i3>%to
99n       = -a%186arith.subfmd =  gparith.extsi%u 97-%arg13,t : o- i%ll32 cst_26vto m{ i:ar64 c
tensor<h=      4g%xf1874x9 = x5tt.expand_dims10  xf%f32tz175, = {axis#tr = linearu1 : >e}i
,32       c} %an:100on  = itensor<arith.subfc4x ali64%i, 98z#ttg,e{.   slice<{dim = 1, parent = #blocked3}>>%ma ->cst_5x tensor< -i4:tex ra1tensor<txi4io64, xn#blocked4s=3>x10
1 m      %xax188 = f32-narith.muli , um%#-r186blockedew,>r 
i%      te176%s= 101-:  = 1 itt.clampfre64
 gi      %o%18999n- = ,stt.splat  im%186%pl :cst_25if i,y=64 n %o-> cst_24rmtensor<4,ax1 l xipropagateNante64 st, #=-cblocked3 on>nonev
       er%:ge190 =  ncarith.muli tensor<e=%4fa189,xl %4se187x  1t:xop tensor<f32-d4, owx1#n=xilineartr64, >ue#
}blocked      ,3>% c
      102s% = e191 = tt.clampf, tt.addptr c %%on184100v, ,er% t-188 %cf:cst_18-t ,o! -ltt.%lvptr<bf16>cst_23m{,,i i n64
propagateNande       x-%192=bi =  ttt.expand_dimsnonew  i%:dt182 h {axistensor<=0 = 4}0 : x, i4co32}xnv :1er tensor<xf3232x, it#64, -blocked>#a
      ttg.r%103slice<{dim = 0, parent = #blocked3}>i = > tarith.fptoui->h  tensor<-%1011xt 32o:x- iltensor<464, lx4#vx1blockedmxf323{, #>ilinear>
      n %dto193e  = xtensor<tt.broadcast-4x %b4x190i1x ti8: w, #tensor<ilinear>4d
      xt%1041xh = i=arith.fptoui640 , }%102#blocked, :3  >ctensor<4 ax->n4x o1xtensor<nf32, 4i#blockedxc> 32xato iltensor<64i4, #zx4blockedex13{x> i
 8,       m#blocked%a>
194x      % = -105tt.expand_dimsi =  tarith.addi%179e  {r%103axisa, = t 0i% : ocst_29i32n :}s tensor< :=4x 14xtensor<0132x ximi864, a, ##ttgxlinear>.-
slice<{dim = 0, parent = #blocked3}>n      > u%106-> m = tensor<1-arith.addi x32r%104xie, 64w%cst, #r :blockedi 3ttensor<4>ex4
      sx1%195=x = -i8tt.broadcast1,   #%194rblocked> :e
       g%tensor<i107 = 1oarith.subf xn%32-cst_6xis, 64i%, m102#blockedp :3l >itensor< f4-> yx4tensor<=x14xnxf3232xo, #i64rblocked, m>#a
blockedl      %3 108 = >tmath.exp2
      e %196s%107 = t tt.addptr-: c %otensor<4191nx4, vx1%ex180 rf32, :g#blocked e>
!n      %tt.c109 = ptr<bf16>earith.extf,=  f%78i64a :
l tensor<      %s4197 = ex4arith.addi  x32%195tx,obf16,  p#%-blocked>193d to :o  wtensor<tensor<4n4xx=4x32t32xrxi64uf32, , e#blocked#}>
blocked,      3 %110>c = 
      stt.broadcast %198e%108 = , :arith.extsi   stensor<4%yx4arg4mx :b1x iof32, 32 l#blockedto-> d i64c-> 
etensor<      ,4x% 4199ex32 = nxtt.splataf32,  b#blocked%l>
198 e      %: -111il = 64iarith.mulf ->n  e%109tensor<-,4i xn%1101f xio:64, , # tensor<4blockedcx43ox32>nxf32
v, #      eblocked>%r
      200 = t%112arith.cmpi - = slt,btt.bitcast  u%111%185i :,l  %ttensor<4199ix n4: -x32tensor<fxf324xu, #1nblockedxc> i64-->, t #otensor<4blocked-x43>lx32
lx      vi%m32201{, # = fblockedarith.extsi t>
%z      %arg5=113 =  tarith.andi : r%112i32u,  e%to}cst_7  ): i"tensor<464,x4
      
x32%      x202 = disable_threadingitt.splat: 32,  false#blocked%,>
201 
      :      %114 verify_each = i: arith.shrui64 true ->
%     }112tensor<
,1  } x
%32x#-}cst_8i
 64, :# blocked3tensor<4>x/tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0
      4: %xerror: 203 = 32Failures have been detected while processing an MLIR pass pipelinearith.cmpi x
slti/tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0,32:  , note: %192#Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
, blocked%202>
 :       tensor<%1151x = 32xarith.andi i64%, #114,blocked3 %>cst_9
       :%204  = tensor<4tt.broadcast x4%200x32 :x i32tensor<4, x1#blockedxi>1, 
      #blocked%1163> =  ->arith.andi  %112tensor<4,x32 %xicst_10 1, : #blockedtensor<3>4x
      4%205x32 = xtt.broadcast i32%203, # :blocked >
tensor<1      x32%117xi = 1, arith.addi#blocked 3>%115 ->,  %tensor<4cst_11x32 :xi 1, tensor<4#blockedx3>4x
32x      %i206 = 32, arith.andi #blocked%204>, 
      %205%118 : =  tensor<arith.subi4x 32x%i1cst_12,, # blocked3%117>
       :%207 [rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 0, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank0]:E1031 11:31:37.831000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
 = tensor<4tt.splat x4%196x32 xi: 32!tt, #.ptr<bf16>blocked> ->
       tensor<%1194x = 32xarith.cmpi!tt .ptr<bf16>ult, #, blocked3%>
115,       %%208cst_12 =  :tt.addptr  %207tensor<4, x4%197x32 :x i32tensor<4, x32#blockedx>
!tt      %.ptr<bf16>120, # = blocked3arith.shrui >,% 116,tensor<4 %x32cst_11xi :64,  tensor<#blocked43>x4
x32      xitt.store32,  #blocked%208>, 
%174      %, 121%206 =  :arith.ori  tensor<4%120x32,x !tt%.ptr<bf16>cst_13,  #blocked: 3>tensor<
4x    }4x
    32tt.returnxi
  32}, #
blocked}>


      %{-#
122 =   externalarith.shrui_resources: {
     mlir_reproducer%121: {
,       %118pipeline:  :" tensor<bu4xil4tix32n.ximo32, du#blockedle>
(o      pt%123im = izarith.selecte- am%119d-, ld%122s-, us%ag116e{ : ldtensor<4s-x4lix32mixit=10 , #tablockedrg>et, -atensor<4rcxh=4gfx32x9x50i32},,  t#blockedri>to
      n-%124sc = f-arith.maxuito -c%f,115 c,on ve%cst_14rt -i:nd extensor<4-txo-4llxvm32{ixind32ex, #-bblocked>it
wi      dt%125h= = 0}arith.subi , %124al,lo ca%tecst_14-a :md gptensor<4u-xsh4xar32xedi32-m, #emblockedor>y,
       c%on126 = vearith.shlirt -t%125ri,to n-%amcst_15dg pu:-t o-tensor<4llx4vmx32{axrcih=32, gf#blockedx9>
50       f%127tz = =tarith.shrui ru%e}123,,  %cacst_16 no:ni catensor<4lix4zex32{ xi m32ax, #-iblocked>te
      ra%128ti = onarith.ori s=%12610, m ax%127-n um:-r tensor<ew4rix4tex32s=xi-132,  r#egblocked>io
n-      %si129 = mparith.addi li%fy128,=n %orcst_11ma :l  tetensor<4stx-c4onxve32xrgi32en, #ceblocked>=f
      al%130se =  tarith.shrui op%-d129ow, n=%cst_11tr :ue },tensor<4 cxse4x, 32coxinv32, er#t-blockedcf>
-t      o-%ll131 = vmarith.minui{i nd%130ex,-b it%wicst_22dt h=:0} , tensor<4cox4nvxer32xt-i32ar, it#h-blockedto>-l
      lv%m{132 = inarith.shrui de%x-113,bi tw%idcst_17 th: =0tensor<},4x c4anx32onxiic32, al#izblockede{>  
      ma%133x- = itarith.ori er%132at,io ns%131=1 :0  matensor<4x-xnu4xm-32xrei32wr, it#blockedes>=-
      1 %134re = giarith.truncion -s%im133pl if:y= notensor<4rmx4alx32 txesi32t-, #coblocked>nv ertoge nctensor<4e=x4fax32lsxie 8, to#blockedp->do
wn      =t%135ru = e}tt.reshape , %134cs e,:  stensor<4ymxbo4xl-32dcxie,8,  e#nablocked>bl ->e- litensor<4nex4-ixnf16xo,2 cxion8ve, #rtblocked-b7>ui
lt      in%outLHS-f, un%c-outRHSto = -ltt.splitlv m{%135ft :z= tensor<tr4xue4x})16"x,2x
      idisable_threading: 8, false#blocked,
7>       ->verify_each:  truetensor<4
    }x
  }4x
#-}16x
i8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, /tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0#blocked: 2error: >
Failures have been detected while processing an MLIR pass pipeline      %
138/tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0:  = note: tt.reshape Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
%137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 5, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank5]:E1031 11:31:37.835000 508 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=trueCapturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:02<?, ?it/s]}
, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 1, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank1]:E1031 11:31:37.837000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP3_TP3: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 3, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank3]:E1031 11:31:37.854000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
[2025-10-31 11:31:37 DP0 TP0] Registering 0 cuda graph addresses
[2025-10-31 11:31:38 DP5 TP5] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/tm/ctmceenu2imu4zi3rrqe5pil7qagahbhgnw5fnxnwfpfmryd77bb.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP2 TP2] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/xv/cxvgv42f65hkiltj6b5iwoiz2l5sndhmjhvwbjdojjhantp37qny.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP7 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/ak/cakbedn2f7cj4eqs3al5ygu2rdzforicyweesoc6i3q2nhz66hnv.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP4 TP4] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/kb/ckbholskekd5monmzoob5oljoxgfz4xlzonoap6m2ll232d6zm3s.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP6 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/pj/cpjly2vl4nqwtzgee66y5vt32vu6dgbpxnwply3m77qu7msp2omg.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP0 TP0] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/qg/cqgsnoaf7qv573naauflw76hoe7lt2j53i52yzx23qgjtfr4l44p.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP3 TP3] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/fp/cfplyp6avjs7k66evomdrkblvk3x7vmq4xbwl45377k5xadqi4oz.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-10-31 11:31:38 DP1 TP1] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 688, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 675, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/u4/cu4fnpc62wbtrsq3q6m4vrhrnsfq72pxqfvfwbdlgyuapc53vmbi.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2775, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 312, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 235, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 314, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 471, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1931, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
