INFO 11-10 11:30:44 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:30:44] WARNING model_config.py:715: quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:30:44] WARNING server_args.py:1186: Attention backend not explicitly specified. Use aiter backend by default.
[2025-11-10 11:30:44] WARNING server_args.py:1392: DP attention is enabled. The chunked prefill size is adjusted to 16384 to avoid MoE kernel issues. 
[2025-11-10 11:30:44] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:30:44] server_args=ServerArgs(model_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_path='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=30000, grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.68, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=16384, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=8, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1010902276, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', api_key=None, served_model_name='/mnt/raid/models/deepseek-ai/amd-DeepSeek-R1-MXFP4-Preview', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=8, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='aiter', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_amx_weight_path=None, kt_amx_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=16, cuda_graph_bs=[1, 2, 4, 8, 12, 16], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=True, enable_piecewise_cuda_graph=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=16, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, decrypted_config_file=None, decrypted_draft_config_file=None)
[2025-11-10 11:30:44] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:30:45] Using default HuggingFace chat template with detected content format: string
INFO 11-10 11:30:51 [__init__.py:241] Automatically detected platform rocm.
INFO 11-10 11:30:51 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:30:52] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:30:52] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00 DP4 TP4] Process 504 gpu_id 4 is running on CPUs: [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-10 11:31:00 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP3 TP3] Process 503 gpu_id 3 is running on CPUs: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
[2025-11-10 11:31:00 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00 DP2 TP2] Process 502 gpu_id 2 is running on CPUs: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:31:00 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
INFO 11-10 11:31:00 [__init__.py:241] Automatically detected platform rocm.
[2025-11-10 11:31:00 DP5 TP5] Process 505 gpu_id 5 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP4 TP4] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP4 TP4] Init torch distributed begin.
[2025-11-10 11:31:00 DP3 TP3] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP3 TP3] Init torch distributed begin.
[2025-11-10 11:31:00 DP7 TP7] Process 507 gpu_id 7 is running on CPUs: [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
[2025-11-10 11:31:00 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
[2025-11-10 11:31:00 DP2 TP2] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP2 TP2] Init torch distributed begin.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:31:00 DP5 TP5] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP5 TP5] Init torch distributed begin.
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:00 DP7 TP7] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP7 TP7] Init torch distributed begin.
[2025-11-10 11:31:00 DP1 TP1] Process 501 gpu_id 1 is running on CPUs: [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
[2025-11-10 11:31:00 DP6 TP6] Process 506 gpu_id 6 is running on CPUs: [96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
[2025-11-10 11:31:00 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:00 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/awq.py:67: UserWarning: HIP does not support fused_marlin_moe currently.
  warnings.warn(f"HIP does not support fused_marlin_moe currently.")
/sgl-workspace/sglang/python/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF q uantization currently.
  warnings.warn(f"Only CUDA support GGUF q uantization currently.")
[2025-11-10 11:31:01] INFO trace.py:52: opentelemetry package is not installed, tracing disabled
[2025-11-10 11:31:01 DP6 TP6] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:01 DP6 TP6] Init torch distributed begin.
[2025-11-10 11:31:01 DP1 TP1] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:01 DP1 TP1] Init torch distributed begin.
[2025-11-10 11:31:01 DP0 TP0] Process 500 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[2025-11-10 11:31:01 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:01 DP0 TP0] quark quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-11-10 11:31:01 DP0 TP0] Init torch distributed begin.
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-11-10 11:31:02 DP0 TP0] sglang is using nccl==2.26.6
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-11-10 11:31:08 DP7 TP7] Init torch distributed ends. mem usage=3.10 GB
[2025-11-10 11:31:08 DP0 TP0] Init torch distributed ends. mem usage=3.22 GB
[2025-11-10 11:31:08 DP6 TP6] Init torch distributed ends. mem usage=3.11 GB
[2025-11-10 11:31:08 DP5 TP5] Init torch distributed ends. mem usage=3.17 GB
[2025-11-10 11:31:08 DP4 TP4] Init torch distributed ends. mem usage=3.10 GB
[2025-11-10 11:31:08 DP3 TP3] Init torch distributed ends. mem usage=3.24 GB
[2025-11-10 11:31:08 DP2 TP2] Init torch distributed ends. mem usage=3.24 GB
[2025-11-10 11:31:08 DP1 TP1] Init torch distributed ends. mem usage=2.82 GB
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[2025-11-10 11:31:10 DP0 TP0] Load weight begin. avail mem=284.28 GB
[2025-11-10 11:31:10 DP0 TP0] Only Deepseek V3/R1 on NV-platform with capability >= 80 can use shared experts fusion optimization. Shared experts fusion optimization is disabled.
[2025-11-10 11:31:10 DP4 TP4] Load weight begin. avail mem=284.40 GB
[2025-11-10 11:31:10 DP5 TP5] Load weight begin. avail mem=284.33 GB
[2025-11-10 11:31:10 DP7 TP7] Load weight begin. avail mem=284.40 GB
[2025-11-10 11:31:10 DP1 TP1] Load weight begin. avail mem=284.68 GB
[2025-11-10 11:31:10 DP2 TP2] Load weight begin. avail mem=284.26 GB
[2025-11-10 11:31:10 DP3 TP3] Load weight begin. avail mem=284.26 GB
[2025-11-10 11:31:10 DP6 TP6] Load weight begin. avail mem=284.39 GB
Loading safetensors checkpoint shards:   0% Completed | 0/73 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   1% Completed | 1/73 [00:00<00:11,  6.31it/s]
Loading safetensors checkpoint shards:   3% Completed | 2/73 [00:00<00:17,  4.13it/s]
Loading safetensors checkpoint shards:   4% Completed | 3/73 [00:00<00:18,  3.74it/s]
Loading safetensors checkpoint shards:   5% Completed | 4/73 [00:01<00:20,  3.31it/s]
Loading safetensors checkpoint shards:   7% Completed | 5/73 [00:01<00:23,  2.85it/s]
Loading safetensors checkpoint shards:   8% Completed | 6/73 [00:01<00:20,  3.25it/s]
Loading safetensors checkpoint shards:  10% Completed | 7/73 [00:02<00:22,  2.96it/s]
Loading safetensors checkpoint shards:  11% Completed | 8/73 [00:02<00:21,  3.09it/s]
Loading safetensors checkpoint shards:  12% Completed | 9/73 [00:02<00:20,  3.15it/s]
Loading safetensors checkpoint shards:  14% Completed | 10/73 [00:02<00:18,  3.45it/s]
Loading safetensors checkpoint shards:  15% Completed | 11/73 [00:03<00:21,  2.92it/s]
Loading safetensors checkpoint shards:  16% Completed | 12/73 [00:03<00:21,  2.89it/s]
Loading safetensors checkpoint shards:  18% Completed | 13/73 [00:04<00:20,  2.93it/s]
Loading safetensors checkpoint shards:  19% Completed | 14/73 [00:04<00:27,  2.16it/s]
Loading safetensors checkpoint shards:  21% Completed | 15/73 [00:05<00:25,  2.30it/s]
Loading safetensors checkpoint shards:  22% Completed | 16/73 [00:05<00:22,  2.56it/s]
Loading safetensors checkpoint shards:  23% Completed | 17/73 [00:05<00:18,  3.02it/s]
Loading safetensors checkpoint shards:  25% Completed | 18/73 [00:06<00:18,  3.04it/s]
Loading safetensors checkpoint shards:  26% Completed | 19/73 [00:06<00:17,  3.13it/s]
Loading safetensors checkpoint shards:  27% Completed | 20/73 [00:06<00:16,  3.19it/s]
Loading safetensors checkpoint shards:  29% Completed | 21/73 [00:07<00:17,  3.04it/s]
Loading safetensors checkpoint shards:  30% Completed | 22/73 [00:07<00:16,  3.06it/s]
Loading safetensors checkpoint shards:  32% Completed | 23/73 [00:07<00:16,  2.94it/s]
Loading safetensors checkpoint shards:  33% Completed | 24/73 [00:08<00:17,  2.74it/s]
Loading safetensors checkpoint shards:  34% Completed | 25/73 [00:08<00:18,  2.66it/s]
Loading safetensors checkpoint shards:  36% Completed | 26/73 [00:08<00:16,  2.82it/s]
Loading safetensors checkpoint shards:  37% Completed | 27/73 [00:09<00:15,  2.97it/s]
Loading safetensors checkpoint shards:  38% Completed | 28/73 [00:09<00:14,  3.06it/s]
Loading safetensors checkpoint shards:  40% Completed | 29/73 [00:09<00:13,  3.25it/s]
Loading safetensors checkpoint shards:  41% Completed | 30/73 [00:09<00:12,  3.34it/s]
Loading safetensors checkpoint shards:  42% Completed | 31/73 [00:10<00:12,  3.25it/s]
Loading safetensors checkpoint shards:  45% Completed | 33/73 [00:11<00:14,  2.84it/s]
Loading safetensors checkpoint shards:  47% Completed | 34/73 [00:11<00:14,  2.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 35/73 [00:11<00:13,  2.79it/s]
Loading safetensors checkpoint shards:  49% Completed | 36/73 [00:12<00:12,  2.91it/s]
Loading safetensors checkpoint shards:  51% Completed | 37/73 [00:12<00:12,  3.00it/s]
Loading safetensors checkpoint shards:  52% Completed | 38/73 [00:12<00:11,  2.96it/s]
Loading safetensors checkpoint shards:  53% Completed | 39/73 [00:13<00:11,  2.92it/s]
Loading safetensors checkpoint shards:  55% Completed | 40/73 [00:13<00:09,  3.43it/s]
Loading safetensors checkpoint shards:  56% Completed | 41/73 [00:13<00:07,  4.16it/s]
Loading safetensors checkpoint shards:  59% Completed | 43/73 [00:13<00:04,  6.11it/s]
Loading safetensors checkpoint shards:  62% Completed | 45/73 [00:13<00:03,  7.09it/s]
Loading safetensors checkpoint shards:  64% Completed | 47/73 [00:13<00:03,  8.52it/s]
Loading safetensors checkpoint shards:  67% Completed | 49/73 [00:14<00:02, 10.54it/s]
Loading safetensors checkpoint shards:  70% Completed | 51/73 [00:14<00:01, 12.45it/s]
Loading safetensors checkpoint shards:  73% Completed | 53/73 [00:15<00:05,  3.40it/s]
Loading safetensors checkpoint shards:  75% Completed | 55/73 [00:16<00:06,  2.70it/s]
Loading safetensors checkpoint shards:  77% Completed | 56/73 [00:17<00:07,  2.26it/s]
Loading safetensors checkpoint shards:  78% Completed | 57/73 [00:18<00:07,  2.15it/s]
Loading safetensors checkpoint shards:  79% Completed | 58/73 [00:18<00:07,  2.04it/s]
Loading safetensors checkpoint shards:  81% Completed | 59/73 [00:19<00:07,  1.81it/s]
Loading safetensors checkpoint shards:  82% Completed | 60/73 [00:19<00:07,  1.82it/s]
Loading safetensors checkpoint shards:  84% Completed | 61/73 [00:20<00:07,  1.64it/s]
Loading safetensors checkpoint shards:  85% Completed | 62/73 [00:21<00:06,  1.69it/s]
Loading safetensors checkpoint shards:  86% Completed | 63/73 [00:21<00:05,  1.95it/s]
Loading safetensors checkpoint shards:  88% Completed | 64/73 [00:22<00:04,  2.00it/s]
Loading safetensors checkpoint shards:  89% Completed | 65/73 [00:22<00:03,  2.32it/s]
Loading safetensors checkpoint shards:  90% Completed | 66/73 [00:22<00:02,  2.54it/s]
Loading safetensors checkpoint shards:  92% Completed | 67/73 [00:22<00:02,  2.60it/s]
Loading safetensors checkpoint shards:  93% Completed | 68/73 [00:23<00:01,  2.60it/s]
Loading safetensors checkpoint shards:  95% Completed | 69/73 [00:23<00:01,  2.64it/s]
Loading safetensors checkpoint shards:  96% Completed | 70/73 [00:24<00:01,  2.82it/s]
Loading safetensors checkpoint shards:  97% Completed | 71/73 [00:24<00:00,  2.76it/s]
Loading safetensors checkpoint shards:  99% Completed | 72/73 [00:24<00:00,  3.47it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:25<00:00,  2.84it/s]
Loading safetensors checkpoint shards: 100% Completed | 73/73 [00:25<00:00,  2.92it/s]

[2025-11-10 11:31:37 DP0 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.11 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP6 TP6] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.21 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP4 TP4] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.23 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP3 TP3] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.08 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP5 TP5] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.15 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP7 TP7] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.22 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP1 TP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.50 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP2 TP2] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=235.09 GB, mem usage=49.18 GB.
[2025-11-10 11:31:38 DP0 TP0] Using KV cache dtype: torch.bfloat16
[2025-11-10 11:31:38 DP2 TP2] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP2 TP2] Memory pool end. avail mem=88.41 GB
[2025-11-10 11:31:38 DP5 TP5] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP5 TP5] Memory pool end. avail mem=88.47 GB
[2025-11-10 11:31:38 DP1 TP1] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP4 TP4] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP3 TP3] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP1 TP1] Memory pool end. avail mem=88.82 GB
[2025-11-10 11:31:38 DP4 TP4] Memory pool end. avail mem=88.55 GB
[2025-11-10 11:31:38 DP3 TP3] Memory pool end. avail mem=88.40 GB
[2025-11-10 11:31:38 DP0 TP0] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP0 TP0] Memory pool end. avail mem=88.43 GB
[2025-11-10 11:31:38 DP7 TP7] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP7 TP7] Memory pool end. avail mem=88.54 GB
[2025-11-10 11:31:38 DP6 TP6] KV Cache is allocated. #tokens: 2201897, KV size: 144.11 GB
[2025-11-10 11:31:38 DP6 TP6] Memory pool end. avail mem=88.53 GB
[2025-11-10 11:31:39 DP5 TP5] Capture cuda graph begin. This can take up to several minutes. avail mem=88.34 GB
[2025-11-10 11:31:39 DP0 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=88.30 GB
[2025-11-10 11:31:39 DP0 TP0] Capture cuda graph bs [1, 2, 4, 8, 12, 16]
[2025-11-10 11:31:39 DP3 TP3] Capture cuda graph begin. This can take up to several minutes. avail mem=88.27 GB
[2025-11-10 11:31:39 DP1 TP1] Capture cuda graph begin. This can take up to several minutes. avail mem=88.70 GB
[2025-11-10 11:31:39 DP2 TP2] Capture cuda graph begin. This can take up to several minutes. avail mem=88.28 GB
[2025-11-10 11:31:39 DP4 TP4] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
[2025-11-10 11:31:39 DP6 TP6] Capture cuda graph begin. This can take up to several minutes. avail mem=88.40 GB
[2025-11-10 11:31:39 DP7 TP7] Capture cuda graph begin. This can take up to several minutes. avail mem=88.42 GB
  0%|          | 0/6 [00:00<?, ?it/s]Capturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
/opt/venv/lib/python3.10/site-packages/torch/_dynamo/variables/functions.py:1652: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
  torch._dynamo.utils.warn_once(msg)
ler_DP6_TP6: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dims %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, #blocked>
      %85 = tt.bitcast %83 : tensor<4x4x1xf32, #linear> -> tensor<4x4x1xi32, #linear>
      %86 = tt.bitcast %84 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %87 = arith.addi %85, %cst_28 : tensor<4x4x1xi32, #linear>
      %88 = arith.addi %86, %cst_1 : tensor<4x4x1xi32, #blocked>
      %89 = tt.bitcast %87 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xi32, #linear>
      %90 = tt.bitcast %88 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xi32, #blocked>
      %91 = arith.andi %89, %cst_27 : tensor<4x4x1xi32, #linear>
      %92 = arith.andi %90, %cst_4 : tensor<4x4x1xi32, #blocked>
      %93 = tt.bitcast %91 : tensor<4x4x1xi32, #linear> -> tensor<4x4x1xf32, #linear>
      %94 = tt.bitcast %92 : tensor<4x4x1xi32, #blocked> -> tensor<4x4x1xf32, #blocked>
      %95 = math.log2 %93 : tensor<4x4x1xf32, #linear>
      %96 = math.log2 %94 : tensor<4x4x1xf32, #blocked>
      %97 = math.floor %95 : tensor<4x4x1xf32, #linear>
      %98 = math.floor %96 : tensor<4x4x1xf32, #blocked>
      %99 = arith.subf %97, %cst_26 : tensor<4x4x1xf32, #linear>
      %100 = arith.subf %98, %cst_5 : tensor<4x4x1xf32, #blocked>
      %101 = tt.clampf %99, %cst_25, %cst_24, propagateNan = none : tensor<4x4x1xf32, #linear>
      %102 = tt.clampf %100, %cst_18, %cst_23, propagateNan = none : tensor<4x4x1xf32, #blocked>
      %103 = arith.fptoui %101 : tensor<4x4x1xf32, #linear> to tensor<4x4x1xi8, #linear>
      %104 = arith.fptoui %102 : tensor<4x4x1xf32, #blocked> to tensor<4x4x1xi8, #blocked>
      %105 = arith.addi %103, %cst_29 : tensor<4x4x1xi8, #linear>
      %106 = arith.addi %104, %cst : tensor<4x4x1xi8, #blocked>
      %107 = arith.subf %cst_6, %102 : tensor<4x4x1xf32, #blocked>
      %108 = math.exp2 %107 : tensor<4x4x1xf32, #blocked>
      %109 = arith.extf %78 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %110 = tt.broadcast %108 : tensor<4x4x1xf32, #blocked> -> tensor<4x4x32xf32, #blocked>
      %111 = arith.mulf %109, %110 : tensor<4x4x32xf32, #blocked>
      %112 = tt.bitcast %111 : tensor<4x4x32xf32, #blocked> -> tensor<4x4x32xi32, #blocked>
      %113 = arith.andi %112, %cst_7 : tensor<4x4x32xi32, #blocked>
      %114 = arith.shrui %112, %cst_8 : tensor<4x4x32xi32, #blocked>
      %115 = arith.andi %114, %cst_9 : tensor<4x4x32xi32, #blocked>
      %116 = arith.andi %112, %cst_10 : tensor<4x4x32xi32, #blocked>
      %117 = arith.addi %115, %cst_11 : tensor<4x4x32xi32, #blocked>
      %118 = arith.subi %cst_12, %117 : tensor<4x4x32xi32, #blocked>
      %119 = arith.cmpi ult, %115, %cst_12 : tensor<4x4x32xi32, #blocked>
      %120 = arith.shrui %116, %cst_11 : tensor<4x4x32xi32, #blocked>
      %121 = arith.ori %120, %cst_13 : tensor<4x4x32xi32, #blocked>
      %122 = arith.shrui %121, %118 : tensor<4x4x32xi32, #blocked>
      %123 = arith.select %119, %122, %116 : tensor<4x4x32xi1, #blocked>, tensor<4x4x32xi32, #blocked>
      %124 = arith.maxui %115, %cst_14 : tensor<4x4x32xi32, #blocked>
      %125 = arith.subi %124, %cst_14 : tensor<4x4x32xi32, #blocked>
      %126 = arith.shli %125, %cst_15 : tensor<4x4x32xi32, #blocked>
      %127 = arith.shrui %123, %cst_16 : tensor<4x4x32xi32, #blocked>
      %128 = arith.ori %126, %127 : tensor<4x4x32xi32, #blocked>
      %129 = arith.addi %128, %cst_11 : tensor<4x4x32xi32, #blocked>
      %130 = arith.shrui %129, %cst_11 : tensor<4x4x32xi32, #blocked>
      %131 = arith.minui %130, %cst_22 : tensor<4x4x32xi32, #blocked>
      %132 = arith.shrui %113, %cst_17 : tensor<4x4x32xi32, #blocked>
      %133 = arith.ori %132, %131 : tensor<4x4x32xi32, #blocked>
      %134 = arith.trunci %133 : tensor<4x4x32xi32, #blocked> to tensor<4x4x32xi8, #blocked>
      %135 = tt.reshape %134 : tensor<4x4x32xi8, #blocked> -> tensor<4x4x16x2xi8, #blocked7>
      %outLHS, %outRHS = tt.split %135 : tensor<4x4x16x2xi8, #blocked7> -> tensor<4x4x16xi8, #blocked2>
      %136 = arith.shli %outRHS, %cst_2 : tensor<4x4x16xi8, #blocked2>
      %137 = arith.ori %outLHS, %136 : tensor<4x4x16xi8, #blocked2>
      %138 = tt.reshape %137 : tensor<4x4x16xi8, #blocked2> -> tensor<4x64xi8, #blocked8>
      %139 = tt.reshape %105 : tensor<4x4x1xi8, #linear> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %140 = tt.reshape %106 : tensor<4x4x1xi8, #blocked> -> tensor<4x4xi8, #linear2>
      %141 = ttg.convert_layout %140 : tensor<4x4xi8, #linear2> -> tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %142 = arith.extui %141 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>> to tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %143 = arith.shli %142, %cst_30 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %144 = tt.bitcast %143 : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>>
      %145 = tt.expand_dims %144 {axis = 2 : i32} : tensor<4x4xbf16, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xbf16, #blocked>
      %146 = tt.broadcast %145 : tensor<4x4x1xbf16, #blocked> -> tensor<4x4x32xbf16, #blocked>
      %147 = tt.reshape %146 : tensor<4x4x32xbf16, #blocked> -> tensor<4x128xbf16, #blocked1>
      %148 = amdgpu.scaled_upcast_fp4 %138 scale %147 {axis = 1 : i32} : tensor<4x64xi8, #blocked8>, tensor<4x128xbf16, #blocked1> -> tensor<4x128xbf16, #blocked1>
      %149 = arith.cmpi eq, %139, %cst_31 : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
      %150 = tt.expand_dims %149 {axis = 2 : i32} : tensor<4x4xi1, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xi1, #blocked>
      %151 = tt.broadcast %150 : tensor<4x4x1xi1, #blocked> -> tensor<4x4x32xi1, #blocked>
      %152 = tt.reshape %151 : tensor<4x4x32xi1, #blocked> -> tensor<4x128xi1, #blocked1>
      %153 = arith.select %152, %cst_0, %148 : tensor<4x128xi1, #blocked1>, tensor<4x128xbf16, #blocked1>
      %154 = ttg.local_alloc %153 : (tensor<4x128xbf16, #blocked1>) -> !ttg.memdesc<4x128xbf16, #shared, #smem>
      %155 = ttg.local_load %154 : !ttg.memdesc<4x128xbf16, #shared, #smem> -> tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>>
      %156 = arith.extui %70 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>> to tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %157 = arith.shli %156, %cst_19 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %158 = tt.bitcast %157 : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %159 = tt.expand_dims %158 {axis = 2 : i32} : tensor<4x32xbf16, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xbf16, #blocked4>
      %160 = tt.broadcast %159 : tensor<4x32x1xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked4>
      %161 = tt.trans %160 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xbf16, #blocked4> -> tensor<4x32x32xbf16, #blocked9>
      %162 = tt.reshape %161 : tensor<4x32x32xbf16, #blocked9> -> tensor<128x32xbf16, #blocked5>
      %163 = amdgpu.scaled_upcast_fp4 %77 scale %162 {axis = 0 : i32} : tensor<64x32xi8, #blocked3>, tensor<128x32xbf16, #blocked5> -> tensor<128x32xbf16, #blocked5>
      %164 = arith.cmpi eq, %70, %cst_20 : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %165 = tt.expand_dims %164 {axis = 2 : i32} : tensor<4x32xi1, #ttg.slice<{dim = 2, parent = #blocked4}>> -> tensor<4x32x1xi1, #blocked4>
      %166 = tt.broadcast %165 : tensor<4x32x1xi1, #blocked4> -> tensor<4x32x32xi1, #blocked4>
      %167 = tt.trans %166 {order = array<i32: 0, 2, 1>} : tensor<4x32x32xi1, #blocked4> -> tensor<4x32x32xi1, #blocked9>
      %168 = tt.reshape %167 : tensor<4x32x32xi1, #blocked9> -> tensor<128x32xi1, #blocked5>
      %169 = arith.select %168, %cst_21, %163 : tensor<128x32xi1, #blocked5>, tensor<128x32xbf16, #blocked5>
      %170 = ttg.local_alloc %169 : (tensor<128x32xbf16, #blocked5>) -> !ttg.memdesc<128x32xbf16, #shared, #smem>
      %171 = ttg.local_load %170 : !ttg.memdesc<128x32xbf16, #shared, #smem> -> tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>>
      %172 = tt.dot %155, %171, %cst_3 : tensor<4x128xbf16, #ttg.dot_op<{opIdx = 0, parent = #blocked3}>> * tensor<128x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #blocked3}>> -> tensor<4x32xf32, #blocked3>
      %173 = arith.addf %172, %cst_3 : tensor<4x32xf32, #blocked3>
      %174 = arith.truncf %173 : tensor<4x32xf32, #blocked3> to tensor<4x32xbf16, #blocked3>
      %175 = arith.extsi %13 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> to tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %176 = arith.extsi %11 : i32 to i64
      %177 = tt.splat %176 : i64 -> tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %178 = arith.addi %177, %175 : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %179 = arith.extsi %32 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> to tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %180 = arith.extsi %30 : i32 to i64
      %181 = tt.splat %180 : i64 -> tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %182 = arith.addi %181, %179 : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %183 = arith.muli %7, %6 : i64
      %184 = tt.addptr %arg2, %183 : !tt.ptr<bf16>, i64
      %185 = tt.expand_dims %178 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %186 = arith.extsi %arg13 : i32 to i64
      %187 = tt.expand_dims %175 {axis = 1 : i32} : tensor<4xi64, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<4x1xi64, #blocked3>
      %188 = arith.muli %186, %176 : i64
      %189 = tt.splat %186 : i64 -> tensor<4x1xi64, #blocked3>
      %190 = arith.muli %189, %187 : tensor<4x1xi64, #blocked3>
      %191 = tt.addptr %184, %188 : !tt.ptr<bf16>, i64
      %192 = tt.expand_dims %182 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %193 = tt.broadcast %190 : tensor<4x1xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %194 = tt.expand_dims %179 {axis = 0 : i32} : tensor<32xi64, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi64, #blocked3>
      %195 = tt.broadcast %194 : tensor<1x32xi64, #blocked3> -> tensor<4x32xi64, #blocked3>
      %196 = tt.addptr %191, %180 : !tt.ptr<bf16>, i64
      %197 = arith.addi %195, %193 : tensor<4x32xi64, #blocked3>
      %198 = arith.extsi %arg4 : i32 to i64
      %199 = tt.splat %198 : i64 -> tensor<4x1xi64, #blocked3>
      %200 = arith.cmpi slt, %185, %199 : tensor<4x1xi64, #blocked3>
      %201 = arith.extsi %arg5 : i32 to i64
      %202 = tt.splat %201 : i64 -> tensor<1x32xi64, #blocked3>
      %203 = arith.cmpi slt, %192, %202 : tensor<1x32xi64, #blocked3>
      %204 = tt.broadcast %200 : tensor<4x1xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %205 = tt.broadcast %203 : tensor<1x32xi1, #blocked3> -> tensor<4x32xi1, #blocked3>
      %206 = arith.andi %204, %205 : tensor<4x32xi1, #blocked3>
      %207 = tt.splat %196 : !tt.ptr<bf16> -> tensor<4x32x!tt.ptr<bf16>, #blocked3>
      %208 = tt.addptr %207, %197 : tensor<4x32x!tt.ptr<bf16>, #blocked3>, tensor<4x32xi64, #blocked3>
      tt.store %208, %174, %206 : tensor<4x32x!tt.ptr<bf16>, #blocked3>
    }
    tt.return
  }
}

{-#
  external_resources: {
    mlir_reproducer: {
      pipeline: "builtin.module(optimize-amd-lds-usage{lds-limit=0 target-arch=gfx950}, triton-scf-to-cf, convert-index-to-llvm{index-bitwidth=0}, allocate-amdgpu-shared-memory, convert-triton-amdgpu-to-llvm{arch=gfx950 ftz=true}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, convert-cf-to-llvm{index-bitwidth=0}, convert-arith-to-llvm{index-bitwidth=0}, canonicalize{  max-iterations=10 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-builtin-func-to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/mt/cmte7uqiegy3xzybpv3snopvoa4gjnqcdjusmrtprrx2tq2xn7qt.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 6, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank6]:E1110 11:31:41.060000 506 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
ler_DP5_TP5: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
#blocked = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked6 = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked7 = #ttg.blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked9 = #ttg.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>
#linear = #ttg.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
#shared = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32} {
  tt.func public @_batched_gemm_afp4_wfp4_pre_quant_kernel(%arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %arg3: !tt.ptr<i8> {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}, %arg6: i32 {tt.divisibility = 16 : i32}, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}, %arg9: i32 {tt.divisibility = 16 : i32}, %arg10: i32 {tt.divisibility = 16 : i32}, %arg11: i32 {tt.divisibility = 16 : i32}, %arg12: i32 {tt.divisibility = 16 : i32}, %arg13: i32 {tt.divisibility = 16 : i32}, %arg14: i32 {tt.divisibility = 16 : i32}, %arg15: i32) attributes {noinline = false} {
    %cst = arith.constant dense<127> : tensor<4x4x1xi8, #blocked>
    %cst_0 = arith.constant dense<0x7FC0> : tensor<4x128xbf16, #blocked1>
    %cst_1 = arith.constant dense<2097152> : tensor<4x4x1xi32, #blocked>
    %cst_2 = arith.constant dense<4> : tensor<4x4x16xi8, #blocked2>
    %c31_i32 = arith.constant 31 : i32
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<4x32xf32, #blocked3>
    %c32_i32 = arith.constant 32 : i32
    %c4_i32 = arith.constant 4 : i32
    %true = arith.constant true
    %c0_i32 = arith.constant 0 : i32
    %cst_4 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #blocked>
    %cst_5 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<4x4x1xf32, #blocked>
    %cst_7 = arith.constant dense<-2147483648> : tensor<4x4x32xi32, #blocked>
    %cst_8 = arith.constant dense<23> : tensor<4x4x32xi32, #blocked>
    %cst_9 = arith.constant dense<255> : tensor<4x4x32xi32, #blocked>
    %cst_10 = arith.constant dense<8388607> : tensor<4x4x32xi32, #blocked>
    %cst_11 = arith.constant dense<1> : tensor<4x4x32xi32, #blocked>
    %cst_12 = arith.constant dense<127> : tensor<4x4x32xi32, #blocked>
    %cst_13 = arith.constant dense<4194304> : tensor<4x4x32xi32, #blocked>
    %cst_14 = arith.constant dense<126> : tensor<4x4x32xi32, #blocked>
    %cst_15 = arith.constant dense<2> : tensor<4x4x32xi32, #blocked>
    %cst_16 = arith.constant dense<21> : tensor<4x4x32xi32, #blocked>
    %cst_17 = arith.constant dense<28> : tensor<4x4x32xi32, #blocked>
    %cst_18 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_19 = arith.constant dense<7> : tensor<4x32xi16, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_20 = arith.constant dense<-1> : tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
    %cst_21 = arith.constant dense<0x7FC0> : tensor<128x32xbf16, #blocked5>
    %cst_22 = arith.constant dense<7> : tensor<4x4x32xi32, #blocked>
    %cst_23 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #blocked>
    %cst_24 = arith.constant dense<1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_25 = arith.constant dense<-1.270000e+02> : tensor<4x4x1xf32, #linear>
    %cst_26 = arith.constant dense<2.000000e+00> : tensor<4x4x1xf32, #linear>
    %cst_27 = arith.constant dense<-8388608> : tensor<4x4x1xi32, #linear>
    %cst_28 = arith.constant dense<2097152> : tensor<4x4x1xi32, #linear>
    %cst_29 = arith.constant dense<127> : tensor<4x4x1xi8, #linear>
    %cst_30 = arith.constant dense<7> : tensor<4x4xi16, #ttg.slice<{dim = 2, parent = #blocked}>>
    %cst_31 = arith.constant dense<-1> : tensor<4x4xi8, #ttg.slice<{dim = 2, parent = #blocked}>>
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %0 = tt.get_program_id x : i32
    %1 = tt.get_program_id y : i32
    %2 = arith.addi %arg5, %c31_i32 : i32
    %3 = arith.divsi %2, %c32_i32 : i32
    %4 = arith.extsi %arg7 : i32 to i64
    %5 = arith.extsi %arg9 : i32 to i64
    %6 = arith.extsi %arg11 : i32 to i64
    %7 = arith.extsi %0 : i32 to i64
    %8 = arith.divsi %1, %3 : i32
    %9 = arith.remsi %1, %3 : i32
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %10 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    scf.if %10 {
      %11 = arith.muli %8, %c4_i32 : i32
      %12 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %13 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked3}>>
      %14 = tt.splat %11 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %15 = arith.addi %14, %12 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %16 = tt.splat %arg4 : i32 -> tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %17 = arith.remsi %15, %16 : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>>
      %18 = arith.muli %7, %4 : i64
      %19 = tt.expand_dims %17 {axis = 1 : i32} : tensor<4xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<4x1xi32, #blocked1>
      %20 = tt.splat %arg8 : i32 -> tensor<4x1xi32, #blocked1>
      %21 = arith.muli %19, %20 : tensor<4x1xi32, #blocked1>
      %22 = arith.extsi %21 : tensor<4x1xi32, #blocked1> to tensor<4x1xi64, #blocked1>
      %23 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>>
      %24 = tt.expand_dims %23 {axis = 0 : i32} : tensor<128xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x128xi32, #blocked1>
      %25 = arith.extsi %24 : tensor<1x128xi32, #blocked1> to tensor<1x128xi64, #blocked1>
      %26 = tt.broadcast %22 : tensor<4x1xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %27 = tt.broadcast %25 : tensor<1x128xi64, #blocked1> -> tensor<4x128xi64, #blocked1>
      %28 = arith.addi %26, %27 : tensor<4x128xi64, #blocked1>
      %29 = tt.addptr %arg0, %18 : !tt.ptr<bf16>, i64
      %30 = arith.muli %9, %c32_i32 : i32
      %31 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %32 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>>
      %33 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %34 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %35 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %36 = arith.addi %34, %31 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %37 = arith.addi %35, %33 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %38 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %39 = tt.splat %arg5 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %40 = arith.remsi %36, %38 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>>
      %41 = arith.remsi %37, %39 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>>
      %42 = arith.muli %7, %5 : i64
      %43 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>>
      %44 = tt.expand_dims %43 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked6}>> -> tensor<64x1xi32, #blocked6>
      %45 = arith.extsi %44 : tensor<64x1xi32, #blocked6> to tensor<64x1xi64, #blocked6>
      %46 = tt.expand_dimsler_DP4_TP4: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
 %40 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked6}>> -> tensor<1x32xi32, #blocked6>
      %47 = tt.splat %arg10 : i32 -> tensor<1x32xi32, #blocked6>
      %48 = arith.muli %46, %47 : tensor<1x32xi32, #blocked6>
      %49 = arith.extsi %48 : tensor<1x32xi32, #blocked6> to tensor<1x32xi64, #blocked6>
      %50 = tt.broadcast %45 : tensor<64x1xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %51 = tt.broadcast %49 : tensor<1x32xi64, #blocked6> -> tensor<64x32xi64, #blocked6>
      %52 = arith.addi %50, %51 : tensor<64x32xi64, #blocked6>
      %53 = tt.addptr %arg1, %42 : !tt.ptr<i8>, i64
      %54 = arith.extsi %arg14 : i32 to i64
      %55 = arith.muli %7, %54 : i64
      %56 = tt.addptr %arg3, %55 : !tt.ptr<i8>, i64
      %57 = tt.expand_dims %41 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<32x1xi32, #linear1>
      %58 = tt.splat %arg15 : i32 -> tensor<32x1xi32, #linear1>
      %59 = arith.muli %57, %58 : tensor<32x1xi32, #linear1>
      %60 = arith.extsi %59 : tensor<32x1xi32, #linear1> to tensor<32x1xi64, #linear1>
      %61 = tt.make_range {end = 4 : i32, start = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>>
      %62 = tt.broadcast %60 : tensor<32x1xi64, #linear1> -> tensor<32x4xi64, #linear1>
      %63 = tt.expand_dims %61 {axis = 0 : i32} : tensor<4xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x4xi32, #linear1>
      %64 = tt.broadcast %63 : tensor<1x4xi32, #linear1> -> tensor<32x4xi32, #linear1>
      %65 = arith.extsi %64 : tensor<32x4xi32, #linear1> to tensor<32x4xi64, #linear1>
      %66 = arith.addi %65, %62 : tensor<32x4xi64, #linear1>
      %67 = tt.splat %56 : !tt.ptr<i8> -> tensor<32x4x!tt.ptr<i8>, #linear1>
      %68 = tt.addptr %67, %66 : tensor<32x4x!tt.ptr<i8>, #linear1>, tensor<32x4xi64, #linear1>
      %69 = tt.load %68 : tensor<32x4x!tt.ptr<i8>, #linear1>
      %70 = tt.trans %69 {order = array<i32: 1, 0>} : tensor<32x4xi8, #linear1> -> tensor<4x32xi8, #ttg.slice<{dim = 2, parent = #blocked4}>>
      %71 = tt.splat %29 : !tt.ptr<bf16> -> tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %72 = tt.addptr %71, %28 : tensor<4x128x!tt.ptr<bf16>, #blocked1>, tensor<4x128xi64, #blocked1>
      %73 = tt.load %72 : tensor<4x128x!tt.ptr<bf16>, #blocked1>
      %74 = tt.splat %53 : !tt.ptr<i8> -> tensor<64x32x!tt.ptr<i8>, #blocked6>
      %75 = tt.addptr %74, %52 : tensor<64x32x!tt.ptr<i8>, #blocked6>, tensor<64x32xi64, #blocked6>
      %76 = tt.load %75 cacheModifier = cg : tensor<64x32x!tt.ptr<i8>, #blocked6>
      %77 = ttg.convert_layout %76 : tensor<64x32xi8, #blocked6> -> tensor<64x32xi8, #blocked3>
      %78 = tt.reshape %73 : tensor<4x128xbf16, #blocked1> -> tensor<4x4x32xbf16, #blocked>
      %79 = math.absf %78 : tensor<4x4x32xbf16, #blocked>
      %80 = arith.extf %79 : tensor<4x4x32xbf16, #blocked> to tensor<4x4x32xf32, #blocked>
      %81 = "tt.reduce"(%80) <{axis = 2 : i32}> ({
      ^bb0(%arg16: f32, %arg17: f32):
        %209 = arith.maxnumf %arg16, %arg17 : f32
        tt.reduce.return %209 : f32
      }) : (tensor<4x4x32xf32, #blocked>) -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>>
      %82 = ttg.convert_layout %81 : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>>
      %83 = tt.expand_dims %82 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #linear}>> -> tensor<4x4x1xf32, #linear>
      %84 = tt.expand_dims %81 {axis = 2 : i32} : tensor<4x4xf32, #ttg.slice<{dim = 2, parent = #blocked}>> -> tensor<4x4x1xf32, ##blockedblocked = >
#      ttg%.85blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> = 
tt.bitcast# blocked%183 =  #:ttg .tensor<blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>4
x#4blockedx21 = x#ttgf32., blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>#
linear#>blocked 3-> =  #tensor<ttg4.xblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>4
x#1blockedx4i = 32#, ttg#.linearblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>>

#      blocked%586 =  = #tt.bitcastttg .%blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>84
 #:blocked 6tensor< = 4#xttg4.xblocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>1x
f32#, blocked#blocked7> =  #ttg->. blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>tensor<
4#xblocked48x = 1#xttgi.32blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>, 
##blockedblocked>9
 =       #%ttg87. = blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>arith.addi
 #%linear = 85,# ttg%.cst_28linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}> 
:# lineartensor<14 = x#4ttgx.1linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>x
i#32linear, #2linear = >#
      ttg%.88linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}> = 
arith.addi# shared% = 86#,ttg .%swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>cst_1
 #:smem  = tensor<#4ttgx.4shared_memoryx
1modulex attributesi {32", tt#blockedg>.
n      u%m89- = ctt.bitcastt a%s87"  = :1  : tensor<i432x, 4"x1txtig32., n#ulinearm>- w->a rtensor<4pxs4"x = 14x : ii3232, , #ttg.targetlinear = >"
h      i%p90: = gtt.bitcastfx 9%5880 ":,  "tensor<t4txg4x.1txhir32e, a#dblockeds>-p e->r -tensor<w4axr4px1"x = i6432 : , i#32blocked}> 
{      
%  91tt.func =  arith.andipublic  %@89_batched_gemm_afp4_wfp4_pre_quant_kernel,( %%arg0cst_27:  !:tt .tensor<ptr<bf16>4 {xtt.divisibility4 = x16 : 1ix32i}32, , %#arg1linear: >!
tt      .%ptr<i8>92 { = tt.divisibilityarith.andi =  16% : 90i,32 }%, cst_4% arg2::  !tensor<4tt.xptr<bf16>4 {xtt.divisibility1 = x16i : 32i, 32#}blocked, >%
arg3      : %!93tt. = ptr<i8>tt.bitcast { tt.divisibility% = 9116  : :i 32tensor<}4, x%4arg4: xi132xi {32, tt.divisibility# = 16linear : >i 32->} , tensor<%4arg5x: 4ix321 {xtt.divisibilityf32 = , 16# : lineari>32
}      , %%94arg6 = : tt.bitcasti 32 {%tt.divisibility92 =  16: :  itensor<324}x, 4%x1arg7x: ii3232,  {#tt.divisibilityblocked = >16  : ->i 32tensor<}4, x%4arg8x: 1ix32f32 {, tt.divisibility# = blocked16 : >i
32      }%, 95% = arg9math.log2:  i%3293 { tt.divisibility: =  16tensor< : 4xi432x}1, x%f32arg10, : #i32linear {>tt.divisibility = 
16      % : 96i = 32math.log2} , %94% arg11::  itensor<32 {4tt.divisibilityx = 416x : 1xif3232, }#, blocked%>arg12
:       i32% {97tt.divisibility =  = math.floor16  : %i9532 }:,  %tensor<4arg13x4: xi132x {f32tt.divisibility,  = #16linear : >i
32      }%, 98% = arg14: math.floori 32% {96tt.divisibility  = :16  : itensor<324}x, 4%xarg151: xif3232, )# attributesblocked {>noinline
 =       false%}99  = {arith.subf
     %%97cst, =  arith.constant% cst_26dense< 127:>  : tensor<tensor<44xx44xx11xxf32i, 8#, linear#blocked>>

          %%100cst_0 =  = arith.subfarith.constant  %dense<980x7FC0,>  : %tensor<cst_54 x:128 xtensor<bf164, x#4xblocked11>x
f32    , %#cst_1blocked> = 
arith.constant       %dense<1012097152 = >tt.clampf :  tensor<%499x,4 x%1cst_25x,i 32, %#cst_24blocked,> 
propagateNan     %=cst_2  = nonearith.constant :  dense<tensor<44>x : 4tensor<x41xx4f32x, 16#xlineari>8
,       #%blocked1022 = >tt.clampf
     %%100c31_i32, =  arith.constant% cst_1831, :  i%32cst_23
,     %propagateNancst_3  = =arith.constant  nonedense< 0.000000e+00:>  : tensor<tensor<44xx432xx1f32x, f32, ##blockedblocked3>>

          %%103c32_i32 =  = arith.fptouiarith.constant  %32101 :  i:32 
tensor<    %4c4_i32x = 4arith.constantx 14x : f32i, 32#
linear    >% totrue  = tensor<arith.constant4 xtrue4
x    1%xc0_i32i = 8arith.constant,  #0linear : i>
32      
%    104% = cst_4arith.fptoui =  arith.constant% 102dense< -8388608:>  : tensor<tensor<44xx44xx11xxf32i, 32, ##blockedblocked>> 
to     %tensor<cst_54 = xarith.constant4 xdense<1x2.000000e+00i>8 : , tensor<#4blockedx>4
x      1%x105f32 = , arith.addi# blocked%>103
,     %%cst_29cst_6  = :arith.constant  tensor<dense<40.000000e+00x>4 : xtensor<14xxi48x, 1#xlinearf32>, 
#      blocked%>106
 =     %arith.addicst_7  = %arith.constant104 ,dense< -2147483648%>cst :  tensor<:4 xtensor<44xx324xxi132x, i#8blocked, >#
blocked    >%
cst_8       = %arith.constant107  = dense<arith.subf23 >% : cst_6tensor<,4 x%4102x 32:xi 32tensor<, 4#xblocked4>x
1    %xcst_9f32,  = #arith.constantblocked >dense<
255      >% : 108tensor< = 4math.exp2x4 x%32107x i:32 , tensor<#4blockedx>4
x    1%xcst_10f32 = , arith.constant# blockeddense<>8388607
>       : %109tensor< = 4arith.extfx 4%x7832 x:i 32tensor<, 4#xblocked4>x
32    x%bf16cst_11,  = #arith.constantblocked >dense< 1to>  : tensor<tensor<44xx44xx3232xxif3232, , ##blockedblocked>>

          %%cst_12110 =  = arith.constanttt.broadcast  dense<%127108>  : :tensor< 4tensor<x44xx432xx1ix32f32, , ##blockedblocked>>
 ->     %tensor<cst_134x = 4arith.constantx 32dense<x4194304f32>,  : #tensor<blocked>4
x      4%x111 = 32arith.mulfx i%32109, ,# blocked%>110
     :% cst_14tensor< = 4arith.constantx 4dense<x12632>x : f32tensor<, 4#xblocked4x>32
x      i%32112,  = #tt.bitcastblocked >%
111     %:cst_15  = tensor<arith.constant4 xdense<42x>32 : xtensor<f324, #xblocked4>x 32->x itensor<324, x#4blockedx>32
x    i%32cst_16,  = #arith.constantblocked >dense<
      21%>113 :  = tensor<arith.andi4 x%4112x,32 x%icst_732 , : #blockedtensor<>4x
4    x%32cst_17x = iarith.constant32 , dense<#28blocked>> : 
tensor<      4%x1144 = xarith.shrui32 x%i11232, ,# blocked%>cst_8
     :% cst_18tensor< = 4arith.constantx 4dense<x-1.270000e+0232>x : itensor<432x, 4#xblocked1>x
f32      , %#115blocked = >arith.andi
     %%114cst_19, =  arith.constant% cst_9dense< 7:> :  tensor<tensor<44xx324xxi3216x, i#32ttg, .slice<{dim = 2, parent = #blocked4}>#>blocked>

          %%cst_20116 =  = arith.andiarith.constant  %dense<112-1,>  : %tensor<cst_104 x:32 xtensor<i48x, 4#xttg32.xslice<{dim = 2, parent = #blocked4}>i>32, 
#    blocked%>cst_21
 =       arith.constant% 117dense< = 0x7FC0arith.addi>  : %tensor<115128,x 32%xcst_11bf16 , :# tensor<blocked45x>4
x    32%xcst_22i = 32arith.constant,  #dense<blocked7>>
 :       tensor<%4118x = 4arith.subix 32%xcst_12i,32 , %#117blocked >:
     tensor<%4cst_23x = 4arith.constantx 32xdense<i1.270000e+0232> : , tensor<#4blockedx>4
x      1%x119f32 = , arith.cmpi# blocked>ult
,     %%cst_24115, =  arith.constant%cst_12  :dense< tensor<1.270000e+024>x : 4tensor<x432xxi432x, #1blocked>x
f32      , %#120linear = >arith.shrui
     %%cst_25116, =  arith.constant% cst_11dense< -1.270000e+02: >tensor< : 4tensor<x44xx432xx1ix32f32, , #blocked#>linear
>      
%    121% = cst_26arith.ori =  arith.constant% 120dense<,2.000000e+00 >% : cst_13tensor< 4:x 4tensor<4xx14xx32f32x, i#32linear>, 
#    blocked%cst_27> = 
arith.constant       %dense<122 = -8388608arith.shrui>  : %tensor<121,4 %x1184 x:1 xtensor<i432x, 4#xlinear32>x
i    32%, cst_28#blocked = >arith.constant
       dense<%2097152123> =  : arith.selecttensor< 4x%4119x, 1%122x, i%11632 : , tensor<#4linearx>4x
32    x%icst_291 = , arith.constant# blockeddense<>, 127tensor<>4x : 4tensor<x432xx4ix321, x#iblocked8>, 
#      linear%>124
 =     arith.maxui% cst_30% = 115arith.constant,  dense<%7cst_14>  : :tensor< 4tensor<x44xx4ix3216x, i32#ttg, .#blockedslice<{dim = 2, parent = #blocked}>>>

          %%125cst_31 =  = arith.subi arith.constant% 124,dense< %-1cst_14>  : :tensor< 4tensor<x44xx4ix832, xi#32ttg, #.blockedslice<{dim = 2, parent = #blocked}>>>

          %llvm.intr.assume126 =  arith.shli% true%125 ,:  %icst_151 
:     llvm.intr.assumetensor<4 x%true4 x:32 xii32, 1#blocked
>    
llvm.intr.assume       %%127true =  arith.shrui:  %i1231,
     %llvm.intr.assumecst_16  :% truetensor<4 x:4 xi321x
i    32llvm.intr.assume, # blocked%>true
 :       %i128 = 1arith.ori
     %126llvm.intr.assume,  %%true127  ::  itensor<14
x    4llvm.intr.assumex 32%xtruei 32: , i#1blocked
>    
llvm.intr.assume       %%129 = truearith.addi :  %128i,1 
%cst_11     :llvm.intr.assume tensor< 4%xtrue4 x:32 xii132, 
#    blockedllvm.intr.assume>
       %%true130 =  arith.shrui:  i%1129
,     llvm.intr.assume% cst_11% true:  :tensor< i41x
4x    32llvm.intr.assume x%itrue32,  #: blockedi>1
      
%131     = %arith.minui0  = %tt.get_program_id130 ,x  %:cst_22  i:32 
tensor<    4%x14 = xtt.get_program_id32 xyi 32, :# blockedi>32

          %%132 = 2arith.shrui =  arith.addi% 113%,arg5 %,cst_17  : %tensor<c31_i324 x4:x 32ix32i
32    , %#3blocked = >arith.divsi
       %%1332 = ,arith.ori  %132%,c32_i32  %131:  :i 32tensor<
4    x%44x = 32xarith.extsii 32%, arg7# blocked:>
       %i13432 =  arith.truncito  %i13364 
:     %tensor<45x = 4arith.extsix 32%xarg9i32 , :#blocked >i 32to  totensor<4 xi464x32
x    %i68 = , arith.extsi#blocked >%
      arg11% :135  = itt.reshape32 % 134to  i: 64tensor<
4x    4%x732 = xarith.extsii 8%, 0# blocked:>  i->32  tensor<to4 x4i64x
16    x%28x = i8arith.divsi, # blocked%71>
,       %%outLHS3,  %:outRHS  = itt.split32 
%    135% :9  = tensor<arith.remsi4 x%41x,16x 2%x3i8 , :# blockedi732>
     ->llvm.intr.assume  tensor<%4xtrue4 x:16 xii18
,     #blockedllvm.intr.assume2 >%true
       :% 136 = iarith.shli1 
%    outRHSllvm.intr.assume,  %%cst_2true :  :tensor< 4xi41x
16    %x10i = 8arith.cmpi,  #blockedsgt2,>
       %%137arg6 = ,arith.ori  %%outLHSc0_i32,  :%136  :i 32tensor<
    4scf.ifx 4%x1016x i{8, 
#      blocked%211> = 
arith.muli       %%138 = 8tt.reshape, % 137% c4_i32:  tensor<:4 xi4x3216x
i      8%, 12# = blockedtt.make_range2 {>end  = ->4  : tensor<i4x3264, xstarti = 8, 0# : blocked8i>
32      }% 139: =  tt.reshapetensor< 4%x105 i:32 , tensor<#4ttgx.4xslice<{dim = 1, parent = #blocked1}>1>x
i      8%, #13linear = >tt.make_range  {->end  = tensor<44x : 4i32x, istart8 = , 0# : ttgi.32slice<{dim = 2, parent = #blocked}>}> 
      :% 140tensor< = 4tt.reshape x%106i 32: , tensor<#4xttg4.xslice<{dim = 1, parent = #blocked3}>1>xi
8      , #%blocked14>  = ->tt.splat tensor< 4x%411x i8:,  #ilinear322 >->
       tensor<%4141x = ittg.convert_layout32 , %140# ttg: .tensor<slice<{dim = 1, parent = #blocked1}>4x>4
x      i%815,  = #arith.addilinear 2%> 14-> ,tensor< 4%x124 x:i 8tensor<, 4#xttgi.32slice<{dim = 2, parent = #blocked}>>, 
#      %ttg142 = .arith.extuislice<{dim = 1, parent = #blocked1}> >%
141       %:16  = tensor<tt.splat4 x%4arg4x i8:,  #ittg32. slice<{dim = 2, parent = #blocked}>->>  tensor<to4x itensor<324, x#4ttgxi.16, slice<{dim = 1, parent = #blocked1}>#>ttg.
slice<{dim = 2, parent = #blocked}>      >%
17       = %arith.remsi143 % = arith.shli15 ,% 142%, 16% cst_30:  :tensor< 4xtensor<i432x, 4#xttgi16., slice<{dim = 1, parent = #blocked1}>#>ttg.
slice<{dim = 2, parent = #blocked}>      >
%      18% = 144arith.muli =  tt.bitcast% 7%,143  :%4  tensor<: 4ix644
x      i%16, 19#ttg = .tt.expand_dimsslice<{dim = 2, parent = #blocked}> >% 17-> { axistensor< = 41x : 4ix32bf16},  #: ttgtensor<.4slice<{dim = 2, parent = #blocked}>x>i
32      , %#145ttg = .tt.expand_dimsslice<{dim = 1, parent = #blocked1}> >% 144-> { axistensor< = 4x2 : 1ixi3232},  #:blocked 1tensor<>4
x      4%xbf1620,  = #tt.splatttg .%slice<{dim = 2, parent = #blocked}>arg8>  :->  tensor<i432x 4->x 1tensor<x4bf16, x#1blockedx>i
32      , %#146blocked = 1tt.broadcast> 
%      145% 21 = :arith.muli  tensor<%419x4,x 1%x20bf16 , :# blockedtensor<>4 x->1x itensor<324, x4#xblocked321x>bf16
,       #%blocked22> = 
      arith.extsi%147  = %tt.reshape21  %:146  tensor<:4 xtensor<14xx4ix3232, x#blockedbf16, 1#>blocked>  to->  tensor<tensor<44x1xx128xibf1664, , ##blockedblocked11>>

            %%14823 =  = amdgpu.scaled_upcast_fp4tt.make_range  {%end138 =  128 : scalei 32%, 147start { = axis0 =  : 1i : 32i}32 } ::  tensor<tensor<1284xix32, 64#xttgi.8slice<{dim = 0, parent = #blocked1}>, >#
blocked8      >%,24  = tensor<tt.expand_dims4 x%12823x {bf16axis,  = #0blocked : 1>i 32->}  tensor<:4 xtensor<128128xxbf16i, 32#, blocked#1>ttg
.slice<{dim = 0, parent = #blocked1}>      %>149 =  arith.cmpi->  eqtensor<,1 x%128139x,i 32%, cst_31# blocked:1 >tensor<
4      x%425x = iarith.extsi8 , %#24ttg .:slice<{dim = 2, parent = #blocked}> >tensor<
1      x%128x150i = 32tt.expand_dims,  #%blocked1491> { axisto =  2tensor< : 1ix32128}x i:64 , tensor<#4blockedx14>x
i      1%, 26# = ttg.tt.broadcastslice<{dim = 2, parent = #blocked}> >% 22->  :tensor< 4tensor<x44xx11xxii164, , #blocked#>
blocked      1%>151 =  tt.broadcast->  %150tensor< :4 xtensor<1284xx4ix641x, i#1blocked, #1blocked>
>       %->27  = tensor<tt.broadcast4x 4%x2532x i:1 , tensor<#1blocked>x
128      %x152 = i64tt.reshape,  #%blocked1511 >:  tensor<->4x 4tensor<x324xxi1281x, i#64blocked, > #->blocked1 >tensor<
4      x128%xi281,  = #blockedarith.addi1 >%
26      ,% 153% = 27arith.select  %:152 , tensor<%4cst_0x, 128%148xler_DP7_TP7: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
 : itensor<644, x#128blockedxi11>, 
#blocked      1%>29,  = tensor<tt.addptr4 x%128arg0xbf16,,  #%blocked181 >: 
!      tt%.154ptr<bf16> = ,ttg.local_alloc  i%64153
       :% 30( = tensor<arith.muli4 x%1289x,bf16 , %#c32_i32blocked 1:> )i -> 32!
ttg      .%memdesc<4x128xbf16, #shared, #smem>31
       = %tt.make_range155 { = endttg.local_load =  32% : 154i 32: , !startttg = .0memdesc<4x128xbf16, #shared, #smem> :  i->32 }tensor< 4:x 128tensor<xbf1632, x#ittg32., dot_op<{opIdx = 0, parent = #blocked3}>#>ttg
.      slice<{dim = 0, parent = #blocked6}>%>156 = 
      arith.extui% 32% = tt.make_range70 { end:  = tensor<432x32 : xii328, , start# = ttg0.slice<{dim = 2, parent = #blocked4}> : >i to32 }tensor<4 x:32 xtensor<i3216x, i#32ttg, .slice<{dim = 2, parent = #blocked4}>#>ttg
.      slice<{dim = 0, parent = #blocked3}>%>157 = 
arith.shli       %%33156, =  tt.make_range% {cst_19end  = :32  : tensor<i324x, 32start#x = blockedi0 :  = 16i32#, }ttg# .ttg.:blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>slice<{dim = 2, parent = #blocked4}> 
>tensor<#
32xblocked      i321%,  = 158#ttg# = .ttgtt.bitcastslice<{dim = 1, parent = #linear1}>. >blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>%157

       #:%blocked tensor<3424 =  = xtt.splat#32 ttgx%.i30blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>16 :
,  i##ttg32blocked. 3 = slice<{dim = 2, parent = #blocked4}>-> #>tensor<ttg 32.-> xblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>tensor<i32
4, #x#blocked32ttg.4 = xslice<{dim = 0, parent = #blocked6}>#bf16>ttg, 
.#      blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>ttg.%
slice<{dim = 2, parent = #blocked4}>35#> = blocked
      tt.splat5 = %159 # = %30ttgtt.expand_dims . : blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>%158i32
 { #axis->blocked =  62 : tensor< = i3232#}xttg i32.:, blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}> #ttg
tensor<.#4slice<{dim = 1, parent = #linear1}>>blockedx
732       = xbf16%#, 36ttg# = .ttg.arith.addiblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>slice<{dim = 2, parent = #blocked4}> 
#>%blocked 348->, =   #tensor<%ttg431.x32 :blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>x 
1tensor<#x32blocked9bf16xi = , 32##, ttgblocked#.4ttgblocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>>.

      slice<{dim = 0, parent = #blocked6}>#%>linear160 = 
 = tt.broadcast      #ttg %.%15937linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>  = 
: arith.addi#tensor< linear14% = x35#32, ttgx%.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>133
x :#bf16 linear, tensor<322#xi = blocked432#>, ttg ->#. ttg.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>tensor<slice<{dim = 1, parent = #linear1}>>
4x
#32      %sharedx38 = 32x = #bf16, tt.splatttg# %.blockedarg5swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>4 :
#> smem
i =       32 #%161->ttg =  .tt.transtensor<shared_memory 32x
%i32module160,  attributes {# {order = ttg"array<.tislice<{dim = 0, parent = #blocked6}>>t32
      g: %.0, 39n2 = u, tt.splatm1 ->%c}arg5 t : a:i32s  ->"tensor<4  = xtensor<13232 : xxii32x3232bf16, , , #"#ttg.tblockedslice<{dim = 1, parent = #linear1}>>t4
g.>      %n ->40u  = mtensor<arith.remsi-4 wx%36a32,rx p32%38sx "bf16, : = # 4 : blocked9tensor<i>
3232      x, %162ittg.target = 32 = tt.reshape, " #h%ttgi161.p slice<{dim = 0, parent = #blocked6}>:g:>fx 
      9tensor<%54x41032 = "xarith.remsi, 32 "x%37tbf16,t,  %g#39.blocked :t9 h>tensor<re 32a->xid 32, s-tensor<#ttgp128.slice<{dim = 1, parent = #linear1}>erx32>-x
wbf16      a, %r#blocked42p5 = ">arith.muli = 
 64      % : %7i163 = ,32amdgpu.scaled_upcast_fp4 } %% 775{  
scale :  % tt.func162i  {64publicaxis
  =       @0%_batched_gemm_afp4_wfp4_pre_quant_kernel : 43(i = %32}tt.make_rangearg0  {: :end = ! 64tttensor< : .64iptr<bf16>x32 {32, starttt.divisibilityx =  = i0168 :  : , ii32#32}blocked}, 3 %>,:arg1:   tensor<!tensor<64xtt128i32.x, ptr<i8>32#ttg {xbf16.tt.divisibility, slice<{dim = 1, parent = #blocked6}> = #>16blocked
 : 5>      i32 %}-> 44, tensor< = %128xtt.expand_dims arg232x%43: bf16 {axis!,  = tt#1.blocked : ptr<bf16>5i {>
32tt.divisibility      } = % :16164 tensor< :  = 64xiarith.cmpii32 32, }eq#ttg, ,.% slice<{dim = 1, parent = #blocked6}>arg3%>: 70 !,->tt  .%tensor<ptr<i8>cst_2064 { x1tt.divisibility:xi =  3216tensor<,  : 4#blockedix63232>}x
, i      %8%45arg4,  = : #arith.extsiittg. 32slice<{dim = 2, parent = #blocked4}>% {>44tt.divisibility
 : =        tensor<16%64 : 165 = xitt.expand_dims132 x}%i, 16432ler_DP2_TP2: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
% {axis, arg5 = #: 2blocked6i : > 32ito {32 tt.divisibility}tensor<64 =  x16:1x :  iitensor<64, 324x#}32blocked6, x>%i
      arg61, %: #46 = ittgtt.expand_dims 32.% {slice<{dim = 2, parent = #blocked4}>40tt.divisibility> {axis =   = 16-> 0 : tensor< : i4i32x32}32} , x1: %xtensor<32arg7ix: 1i32i, #, 32blocked4#ttg {>.slice<{dim = 0, parent = #blocked6}>tt.divisibility
>  =       -> 16%tensor< : 1661xi = 3232tt.broadcastx} i, %32, %165#arg8 :blocked:  6itensor<>324x
 {32      %tt.divisibilityx47 =  = 1tt.splat 16x% : iarg10i1 32, :}# , blocked4i%>32 arg9:  ->i-> 32 tensor< {tensor<41tt.divisibilityxx = 323216xx : 32xiii32321, }, #, #blocked%blocked6arg104>: >

i            32#%% {blocked16748tt.divisibility =  =  =  = #tt.transarith.muli16ttg  % : .%46iblocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>166,32
 { }, #order%%blocked = 47arg11: 1 = array< i#i:32ttg32  {.: tensor<tt.divisibilityblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>01x = 
, 3216#blocked2, 1>} : tensor<4x : 32ix23232x = }xi#, i32ttg%1, .arg12, #blockedblocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>: #6
#iblocked>blocked324
3 {>       = tt.divisibility %# = -> 49ttg16tensor< = . : 4xarith.extsiblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>i32 %
#32x48 blocked}32:4, x  = %itensor<#arg1311ttg: , x.i#32blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>32blockedx
# {9iblockedtt.divisibility>325 = 
,  = 16      ##ttg : %blocked.i1686blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>32 = >
}, tt.reshape #% toblockedarg14% 6 = : 167tensor<#i :1ttg32 x. {tensor<32blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>tt.divisibility4x
 = xi#163264blocked : x, 7i32#blocked = 32xi6#}1>ttg, , #
.%blocked      blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>arg159%
: >50#i  = blocked832->tt.broadcast = )  # attributestensor<%45ttg {128x .noinline32: blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}> = xitensor<
false164#}, xblocked #19{blockedx = 
5>i#    
64ttg%      , .cst%#blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}> = 169 = blocked
arith.constantarith.select6#  >lineardense<%  = 127168->#>,  ttg : %tensor<.tensor<cst_2164xlinear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>4, 32x
#x%ilinear416364, 1x : # = 1tensor<blocked6#x128>ttgix
.832      %linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>, x51
##i = linear2blocked1, tt.broadcast = ># #
blocked%49ttg    5 .%>, :linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>cst_0tensor< 
 = 128tensor<#arith.constantx1xshared 3232 = dense<xx#0x7FC0bf16ittg>, 64. : #, swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>tensor<blocked#
#45>blockedsmemx
6 = 128      >#x% ttgbf16170->.,  =  shared_memory#ttg.local_alloctensor<
blocked 64module1%x attributes>16932 {
 x"    :it% 64, #tcst_1(blockedg = tensor<1286.arith.constantx>nu 32
mdense<x      -2097152bf16%c>, #52t : blocked = atensor<5arith.addis4>) "x -> % = 4!501xttg., : 1memdesc<128x32xbf16, #shared, #smem> ix
      %32i%17151, 32 =  ", ttg.local_load:t# % tgblocked170tensor<.> 64xnu
: 32m    !x-%ttgiwcst_2.64, ar = memdesc<128x32xbf16, #shared, #smem>#blockedparith.constant 6s" ->> = dense< 
      44tensor<128% : >x53i : 32 = 32tensor<xtt.addptr, 4bf16 ttg.target = x, %"4#arg1hxttg, ip16.dot_op<{opIdx = 1, parent = #blocked3}>%:x>42gi
 :f8       x, %172!9# = tt5blockedtt.dot.02 ptr<i8>,">% , 
155i"    ,64t% 
tc31_i32%      g = 171%.tharith.constant,54 = r  %arith.extsiea31cst_3 ds :  %-pi:arg14e32  r
tensor<:-    4 w%xiacst_312832r = x parith.constantbf16to" ,   = dense<#i64640.000000e+00ttg
 : >.dot_op<{opIdx = 0, parent = #blocked3}>      i : >%32tensor< *55}4  =  xtensor<arith.muli{32128 
xx%  f32327tt.func, x, #bf16 publicblocked, %54 3# @>ttg:_batched_gemm_afp4_wfp4_pre_quant_kernel
    . (%dot_op<{opIdx = 1, parent = #blocked3}>i%c32_i32>64arg0 =  
: arith.constant->      !  %56tt32tensor< = . : 4xtt.addptrptr<bf16>i32  {32x%tt.divisibility
f32arg3 =     , ,16%#  : c4_i32blocked%i = 355 32arith.constant>:} 
 !, 4      tt.% : %ptr<i8>,arg1: i173 !32 = itt
arith.addf64.     
ptr<i8>%%      % {true17257tt.divisibility = , =  = arith.constant tt.expand_dims16 %cst_3  : true %i
:4132      {}%tensor<axis, c0_i324 = % = x321 : arg2: arith.constantxi!tt f3232.0, }ptr<bf16> { : # :tt.divisibilityiblocked3  = 32>tensor<3216

xi :           32i%%, 32}cst_4174#,  =  = ttg%arith.constantarith.truncf.arg3  slice<{dim = 1, parent = #linear1}>>: dense<% !-8388608173-> tt.> tensor<ptr<i8> : :32 {tensor< xtt.divisibility4tensor<41 = xxx16432i : xxf3232i1, , 32x#blocked#}i3>linear, 32 1>%, to
arg4#       : blockedtensor<%i>45832
x =  {    32tt.splattt.divisibility%xbf16  = cst_5, %16 = #arg15 : arith.constantblocked3 i >:32dense<
 }, 2.000000e+00      i%>%32arg5 : 175 : tensor< = ->i4arith.extsi 32x tensor< {4%32tt.divisibilityx13x = 1 116x:x : f32 ii, tensor<3232#4, }blockedx#linear, >i321%
, >arg6    #
: %ttg      icst_6.%32 = slice<{dim = 1, parent = #blocked3}>>59 {arith.constant  = tt.divisibility toarith.muli  = dense< %160.000000e+00tensor<57 : >4,i : x 32}tensor<i%, 464, 58%x#ttg arg74.:: xslice<{dim = 1, parent = #blocked3}> i1>tensor<32x
32 {f32      xtt.divisibility, %1 = #176x16blocked = i : >arith.extsi32i32
 , },     %#%%cst_711lineararg8 =  1arith.constant: : > ii
dense<3232      -2147483648  {%>to tt.divisibility = 60 =  : i16arith.extsi tensor<464 : %x
i594x      32} 32%, :x177%arg9 i = : tensor<32tt.splati32,  32x#% {1blocked176tt.divisibility = x> :16i
  : 32    i64i32, % }, #cst_8 = ->%lineararith.constant arg101 tensor<: >dense<4i 23x32to>i {  : 64tt.divisibility = tensor<tensor<, 16324# : xxttgi3214.}xxslice<{dim = 1, parent = #blocked3}>, i32>%64xi
arg11, 32      : #, %ilinear#178 = 32 {1blockedarith.addi tt.divisibility = >>%16

177 :           ,i%% 3261cst_9 = %} = arith.constant175, tt.make_range  % {enddense<:arg12:  = 255 i4>tensor<432 :  : x {itensor<itt.divisibility32464 = , x4, 16startx# :  = 32ttg.i320xslice<{dim = 1, parent = #blocked3}>},  : i>%i32
arg1332,       : }#%i blocked17932:> =  { 
arith.extsi tt.divisibility = tensor<    %164%32  : xcst_10:ii =  3232arith.constanttensor<},  32, #dense<x%ttg8388607iarg14.>32, : slice<{dim = 0, parent = #linear1}> : #i>tensor<ttg32 {
4.tt.divisibility      xslice<{dim = 0, parent = #blocked3}> = %4>1662x  :  = 32toitt.broadcast x 32}%itensor<32, 6032xi% , 64, arg15:#blocked#:  >ttgi32tensor<
.)32    slice<{dim = 0, parent = #blocked3}>> attributesx%
 {1cst_11      noinlinex = % = iarith.constant180false64  = }, dense<arith.extsi  #1%30{
linear> :    1 :  %>tensor<icst 432 = ->x toarith.constant 4  tensor<xidense<323264127xx
      >4i% : x32181tensor<i,  = 464, #tt.splatx#blocked 4linear>%x1
1801>     x
%:i      cst_12 =  8%arith.constanti, 63 64# = dense< blockedtt.expand_dims127->> > 
% : tensor<32    61tensor<x% {4i64cst_0 = axisx, arith.constant = 4x#ttg 032.dense< : xslice<{dim = 0, parent = #blocked3}>0x7FC0ii>>3232
 : },       tensor< #%4:blocked>182x 
 = 128tensor<    arith.addix4% bf16, xcst_13%#blockedi = 181,132arith.constant >,  %179
#dense< :    ttg4194304 %.>tensor<cst_1slice<{dim = 0, parent = #linear1}> : 32 = >tensor<xarith.constant 4xi64 ->4, dense< tensor<x#2097152132ttg>xx. : 4islice<{dim = 0, parent = #blocked3}>tensor<x32>4i, 
      x32#%1834x, blocked = 1#>arith.mulixlinear
 i1    %32>%7, 
cst_14,#       =  blocked%arith.constant%>64 6
 = dense<     tt.broadcast126: % >icst_2 = % : 64arith.constant63tensor<
  :4      dense< x4%4>tensor<x184 : 1x32 = tensor<4xtt.addptr4xxi 4i32%x32, arg2,16, # x#blocked%ilinear>1838, 1
     #>%:blocked cst_15 2-> = !> arith.constanttt
    tensor< .%32dense<ptr<bf16>c31_i32x2, = 4> arith.constantx : i64 itensor<
31324       : , x%i#linear4185321x = 
    >32tt.expand_dims%
x cst_3 =       i%arith.constant%6532, 178  = # {dense<arith.extsiblockedaxis0.000000e+00 > = >%
1 :  : 64    itensor< %324x:cst_16}32 tensor< =  x32arith.constant:f32, x  #blocked4dense<tensor<3x214>i>x
32 : i64    , tensor<4, %#x#c32_i32linear4ttg = 1x.arith.constant> 32slice<{dim = 1, parent = #blocked3}> tox> 32 i-> : tensor<32 i32, tensor<32x#4x
4blocked1    x>xi%i
64c4_i3264    ,  = , %#arith.constant#cst_17 = blocked3 lineararith.constant>41 
 : >dense<      i
28%32      >186 = 
    % : arith.extsi %66tensor<4%arg13true =  = x4 arith.constantarith.addix32:  x true%ii
653232    ,,  % #blockedtoc0_i32%>  = 62
iarith.constant     64 :%
0 cst_18       : tensor< = %i32arith.constant18732x  = 
4dense<tt.expand_dims     %x-1.270000e+02%175cst_4i> { = 64 : axisarith.constant, tensor< =  #41dense<linearx : -838860814i>>x32 : 
1}tensor<      x 4%f32, :x467# x = blockedtensor<1tt.splat>4x 
xi%56    i32,  %64#:cst_19, blocked  = #>!arith.constantttg
tt .slice<{dim = 1, parent = #blocked3}>    .dense<>%ptr<i8>7 cst_5 >-> = -> :  arith.constant tensor<tensor< tensor<44dense<32xx2.000000e+00x321>4xx : xiitensor<!16644tt, , x.##4ptr<i8>ttgblockedx1, .3x#slice<{dim = 2, parent = #blocked4}>>f32linear>
, 1
      #>    %188blocked
% = >      cst_20 = arith.muli 
%arith.constant%    68 =  186%tt.addptr dense<, cst_6 = %-1%arith.constant67>176 , :  dense< %tensor<: 0.000000e+00>664i64 :  x
tensor<:32      4 x%xtensor<i1894328 = xx, tt.splat14# %xxttg186f32!. , ttslice<{dim = 2, parent = #blocked4}>:#.> blockedptr<i8>
i64>,      
#%->    linear1cst_21 %> = tensor<cst_7,arith.constant4 =   xarith.constanttensor<dense<1 320x7FC0xdense<x>i-21474836484 : 64>xtensor<,  : i128x#tensor<6432xblocked34x, bf16>4#, 
xlinear#      321blocked%x>5190 = i
>arith.muli32      
 , %    %#69%189blocked = cst_22,>tt.load =  
 arith.constant%187    %  %68dense< :cst_87:  = > tensor<arith.constant : tensor<4 tensor<32xdense<4x123x4x>4xi : x!64tensor<32tt, 4x.#xiptr<i8>blocked432, 3x, #>
32#linear      xblocked1%191i>> = 32

      tt.addptr,     %70 #% = %blockedcst_23tt.trans184> =  ,
arith.constant%      69%%dense< {188cst_91.270000e+02order : = > =  arith.constant : array<!tt tensor<i.dense<432ptr<bf16>255x: ,>41  : x, i64tensor<410
xx>      4xf32}%19232,   = x#:tt.expand_dimsiblocked  32>tensor<32%, 
x182#    4 {blocked%xaxis>cst_24i = 
 = 80 :     arith.constant, i32% #}cst_10dense<linear  = 1.270000e+021:arith.constant>>    : ->tensor<32dense<tensor< x83886074tensor<i>x464 : 4x, tensor<x32#ttg41x.xxi8slice<{dim = 0, parent = #blocked3}>4f32, >x, # 32#ttg->xlinear. tensor<i32>slice<{dim = 2, parent = #blocked4}>1, #
>xblocked    
32x>%      %i64
    cst_2571 = , % = tt.splat#cst_11arith.constant blocked3 =  %>arith.constantdense<29
 -1.270000e+02       dense<>:%1 :  193>tensor<! = tt.broadcast : 4tt tensor<x.%44ptr<bf16>190xx  :4x1-> 32x tensor<xf32tensor<4i, 4x32#x1, linear128x#blocked>xi>

!64        tt, %%.#cst_12 = cst_26ptr<bf16>blocked3arith.constant = , > arith.constant# dense< blocked->127dense<1> >2.000000e+00
tensor< : >      %4tensor< : 72 = x324ler_DP3_TP3: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
tensor<tt.addptrxx44 ixx%6432471, xx,#i1 blocked32x%3, f3228>#blocked,  
>#:      
linear %    >tensor<194%
4 = cst_13    xtt.expand_dims = %128x arith.constantcst_27!%  = tt179dense<arith.constant. {4194304 ptr<bf16>axis>dense<,  =  : -8388608#0tensor<>blocked : i4x : 1324xtensor<>,} 324 :xxtensor<4 i4xtensor<3232, x128x#1xiblocked>xi64, 
i64#ttg    %32, .cst_14, #slice<{dim = 0, parent = #blocked3}> = #blocked>arith.constantlinear1  >>-> dense<

tensor<126          1>%%x : cst_287332tensor< =  = x4xarith.constanttt.loadi4  64xdense<%, 32209715272#x> blockedi : :332tensor< >, 4#tensor<
#xblocked4      %blocked>4 = x195
x1#128x =     xttg!tt.broadcast%i32.tt cst_15 = , blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>.%arith.constant#
ptr<bf16>194 linear#,  dense<>blocked#:2>
1blocked  :     % = 1tensor<tensor<cst_29#>14 = ttg
xxarith.constant.blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>      324 
%xxdense<#blocked74i321272 = 64x> = tt.splat, i32 : # #, tensor<ttg.%blocked3#blocked4blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>53>>x
#  
4blocked:->    x3 =   tensor<%cst_161#ttg!4 = x.ttxarith.constantiblocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>.32x 8
ptr<i8>idense<, ##blocked 64, 21linear4->#>> =  blocked : 
    #tensor<3tensor<%ttg64>4cst_30.x
x = blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>32      4xarith.constant
x%19632 #! = xdense<blockedtttt.addptri75. 32> = ptr<i8>, %191,  : #ttg#,#tensor<4.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>blocked blocked>x
6%180
4#blocked>     x6 = 
:%i#       cst_1716, ttg%! = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>75tt.arith.constant.slice<{dim = 2, parent = #blocked}>
 = ptr<bf16> >#blockedtt.addptr ,dense<
7 = % 28    %#74i>cst_31 = ttg.,64 : arith.constantblocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}> 
      tensor< 
#%%1974xdense<blocked852 = 4-1> =  arith.addix : #: 32tensor<4ttg %xx4.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>tensor<195,i32x
#64 , iblockedx%#8932193blocked,  = x >##ttg!:
    ttg.tt %.blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>.tensor<cst_18slice<{dim = 2, parent = #blocked}>
#ptr<i8>4 = >linear, #xarith.constant
 = blocked32     #ttg6xdense<llvm.intr.assume.>i64-1.270000e+02> linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>,,  : %
 #tensor<true#lineartensor<blocked34x 164>
4: = x      x #ttg32%1i.linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>x198 = x1
iarith.extsi f32
#64%,     linear, arg4#llvm.intr.assume2# blocked>  = blocked:
%#ttg6     .>i%truelinear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>
32 cst_19 
      to = :#% arith.constant shared76i i =  = 64dense<1#tt.load 
7
ttg%      %>    .swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>75199 : llvm.intr.assume 
#  = tensor<4%smemcacheModifiertt.splatxtrue =   32 #=%x:ttg 198 i16 .cg: , ishared_memory i#1
:64ttg
module  .     attributestensor<->slice<{dim = 2, parent = #blocked4}>llvm.intr.assume  {64 >%"xtensor<4
truet32x     tx1%:g!xcst_20 .tt.i = inptr<i8>64arith.constant1um, #, # 
-blockedblockeddense<    ct63>-1llvm.intr.assume as>
>%true"
       :   =       %200tensor<:1% = 4 i : 77 = arith.cmpi x1ittg.convert_layoutslt32
32 ,x    , % illvm.intr.assume"t76%1858,  t ,#%g: ttgtrue.n %199. :utensor< slice<{dim = 2, parent = #blocked4}> m-64:>iwx 
1ar32tensor<    
psx4%    "ixcst_21llvm.intr.assume  = 81 = %true4, xiarith.constant : : #64  iblocked, dense<i326#0x7FC01, >blocked>
ttg.target 3> :      = ->
tensor<llvm.intr.assume "       %128%htensor<201 = xtrueip64arith.extsi32 :x x: gf32%bf16, i1xxarg5#
9i blocked    508:5llvm.intr.assume",  >
 , #i    %true"blocked32 % tt3>tocst_22:g
  =  .      iarith.constantit%64 1h78
dense<
    r =       7llvm.intr.assumeett.reshape%> %ad 202 =  : trues%tt.splattensor< -73 4:pe %x r:201 4i1- :x
    watensor< 32llvm.intr.assumer4xix p12864i32%" = x , true64bf16->#  : ,  blocked:i#tensor<> 32blocked1
i}1x32    1 >x%
{
 icst_23      -> 64,  = llvm.intr.assumett.functensor<#arith.constant % 4blocked3 truepublicx>dense<  4
      1.270000e+02:@x%203> _batched_gemm_afp4_wfp4_pre_quant_kernel32 =  : i(xarith.cmpitensor<1%bf16 4x
    arg0, slt,4%: # x10!ttblocked%x = .>192f32tt.get_program_idptr<bf16>
,,   {       #blockedxtt.divisibility%%>  = 79202
:16 =        : imath.absf:%i32  tensor<cst_2432}%1 = 
, 78xarith.constant    %arg1 32 %: :xdense<1! i1.270000e+02 = tttensor<64, >tt.get_program_id.4#blocked :  ptr<i8> {x3tensor<ytt.divisibility4>4  = x
x:1632      4x  : x%1iibf16204x3232,  = f32
}#tt.broadcast,     , blocked #%2%>%linear = arg2
200>arith.addi:        
 !%:    %tt80 %arg5. = tensor<cst_25,ptr<bf16>arith.extf4 =   { xarith.constant%c31_i32tt.divisibility = %1x  1679idense<: :  1-1.270000e+02 i:, #>i32 blocked : 32}tensor<3tensor<
, 4> 4x    %x->4%arg34 x3: xtensor<1 = !tt324xarith.divsi.xxf32 ptr<i8>bf1632, %2 {, x#,tt.divisibility#ilinear  = blocked1>%16>, 
    c32_i32 :  #% i32toblocked3cst_26 = :},  >arith.constant %tensor<
       iarg44%dense<32: x2052.000000e+00
i4 = >    32 {xtt.broadcast : %tt.divisibility32 tensor<4 =  = x%4arith.extsi16f32203x  : ,  :4x%i32# tensor<1arg7}blocked1x , >xf32:%
32,  arg5      xi#i: %1linear32i3281, >  { = #
tott.divisibility"blocked3      = t>%i16t cst_2764 : .-> = 
    ir arith.constant%32}etensor< 5, d4dense< = %arg6ux-8388608arith.extsi: c32> i32ex : % {"itensor<arg9tt.divisibility = (14x 16%, 4: : 80#x i)blocked1i32 <3x32}, {>i %axis
32toarg7 =       %,  : 2206#ii32 :  = linear64 {iarith.andi>
tt.divisibility32 
     = }%    %16>204%6 :  (,cst_28 = i{  = arith.extsi32
%arith.constant %}      205 arg11, ^bb0 dense< %(:2097152:arg8% > : arg16tensor< : ii: 4xtensor<43232f3232x  {, x4xto tt.divisibility = %i1i16arg171x64 : : , i
if32#blocked32    32})3, %, :>
#7%
      linear = arg9        %207>arith.extsi: % = 
 i32209tt.splat    %0 { =  %% tt.divisibilityarith.maxnumf196cst_29: =   : =  i16% arith.constant32 : iarg16!  32,ttdense<to} .ptr<bf16>127 , % >i64%arg10arg17-> : 
:   tensor<    i:tensor<4%32 4xx8 =  {f32324arith.divsitt.divisibility
xx1  =         !x%16tt.reduce.returntti81, :  .ptr<bf16>,  i%, #%32209#linear3},  blocked> %:3
:arg11 >     : if32
%i3232 {
      cst_30 = 
tt.divisibility      %208arith.constant    % = } =  916)tt.addptr dense< =  :  : %7arith.remsii32(207> }tensor<, : %1, 4 tensor<,%x%4 arg124197 x%: x:43i32 x 32xtensor<4i: {f32x16 tt.divisibility, 32, i = #x#3216blocked!ttg
 : >tt..    i32) -> ptr<bf16>slice<{dim = 2, parent = #blocked}>llvm.intr.assume}, tensor<, > %arg134#blocked
    %: ix3>%true324,cst_31 : {x  =  tt.divisibilityf32tensor<arith.constanti = , 4 116#x32dense<
 : ttgxi-1>    i32.64 : llvm.intr.assume}slice<{dim = 2, parent = #blocked}>, #tensor< , >blocked4%%arg14
3>x4true:       
x :i%      i 32 {82tt.store8itt.divisibility =  , 1 = ttg.convert_layout%#
16 208ttg     : %,.llvm.intr.assume i3281 slice<{dim = 2, parent = #blocked}>%},  %>true%arg15:174
 :  ,    :itensor< llvm.intr.assume 324% i)x206%1 attributes4 :true
     {x  %noinline = f32tensor<:10false, 4  = }#xiarith.cmpi ttg321 {ler_DP1_TP1: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
.x
sgt
slice<{dim = 2, parent = #blocked}>!    ,    >ttllvm.intr.assume % . %cst->ptr<bf16>%arg6 =  , true,arith.constanttensor<#   4blocked:%dense<x3 c0_i321274>i >x
1: : f32    
 tensor<, }    i324#
llvm.intr.assume
xttg         4x.tt.return%scf.if1slice<{dim = 2, parent = #linear}>
true x>
   %i      }: 108%
i , 83}1{# = 


blockedtt.expand_dims
          > {-#llvm.intr.assume %11
%
%true =     82   arith.muli%cst_0 {external:  = axis_resources: {
 %arith.constant =     i8 2mlir_reproducer: {1,dense< : i

 0x7FC032          %>}pipeline: llvm.intr.assume c4_i32 :  "% tensor<:btrue:#4 u  blockedxtensor<i:i = 1284l 32#xxti
ttgbf16, 4xi1      .#blockedf32n
%12blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>1>, .     = 

#mllvm.intr.assumett.make_range#    ttg.o  {blocked%slice<{dim = 2, parent = #linear}>d%end1cst_1>utrue =  =  =  l 4#arith.constant->e:  : ttg  (ii32.dense<tensor<o1, blocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>2097152>4p
start = 
 : xt    0#tensor<4illvm.intr.assume  : blocked4xm%i322x41itrue} = xxze : #1f32- :ttgx, ai .i32#m1tensor<4blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>, #lineard-
x
blocked>ld    i32#>
sllvm.intr.assume , blocked
      -%#ttg3    %%utrue.slice<{dim = 1, parent = #blocked1}> = cst_284s ># =  = ag:
ttgarith.constanttt.expand_dims e       . %{i%13blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>dense<81l1 = 
4> {d
tt.make_range# : axiss     {blockedtensor<4 = -llvm.intr.assumeend = 4x2li 4 = 4 : m%true : #xi32i ittg16}t:32.x = , blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>i:0istart
8  1 = #, #tensor<t
0blockedblocked4a     : 52>xrllvm.intr.assumei = 
4g 32}#    xe%true :ttg%c31_i32f32t : . = , -a tensor<4blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>arith.constant#rix
 ttgch1i32#31.=
, blocked : slice<{dim = 2, parent = #blocked}>g    #ttg6i32>fllvm.intr.assume.slice<{dim = 1, parent = #blocked3}> = 
 ->x %>#    % 9true
      ttgcst_3 = tensor<5 %14.arith.constant40: = blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}> x} tt.splat
dense<4,i #0.000000e+00x 1%blocked>1t
117 : xri      = tensor<f32, tllvm.intr.assume:#4x#on  ttg32blocked-%i.x>strue32blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>f32
c  
,       f:->##%-  blockedblocked85titensor<483> = o1x = 
tt.bitcast-
i#     c    32ttg%c32_i32%f%, . = 83,0#ttgblocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>arith.constant :  = .
  cott.get_program_idslice<{dim = 1, parent = #blocked1}>#32tensor<n >blocked : 4vx
9ixe        = 32
4rt: %#    x-i15 = ttg%c4_i321xi32arith.addi. = f32n
 blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>arith.constant, #d    %
 linearex%14,#4>-1 linear :  t = %12 = i->ott.get_program_id :#32
 -  ttg    tensor<lytensor<.%4l 4linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>true = xv:x
arith.constant4xm{ i# 1ii32lineartrue
xn32, 1    ide
# = %32x    ttg#c0_i32 = , -%.ttgarith.constant#b2slice<{dim = 1, parent = #blocked1}>. lineari = >linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>0>tarith.addi
      
 : 
w %#i      i%16 = linear32
%darg5tt.splat2    %86 = t,  = cst_4tt.bitcasth %# =  =0%arg4ttgarith.constant%84}c31_i32 :.  ,  linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>dense<: :i32
-8388608> a  # : tensor<li-> sharedtensor<4lo32tensor<4 = 4xxc
x#4x4at    i32ttg1xe%, .x1-3#swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>i32xa = ttg
, #f32marith.divsi.#blocked, d slice<{dim = 1, parent = #blocked1}>smem>#g%> = 
blockedp2
#    >u-,      ttg%cst_5 s %. = ->ha%17shared_memoryarith.constant tensor<rc32_i32 = 
 4e arith.remsimoduledense<xd:  attributes2.000000e+00>4- %15 { : x1mi,"tensor<xe32 t4im
%tx32ory    16g4, ,% .x# 4:n1blockedc =  ux>oarith.extsitensor<4mf32, 
      n xi-#blocked%v%32c>87earg7, t
 = rt #a    arith.addi-t:ttgs% r .slice<{dim = 1, parent = #blocked1}>"cst_6 = %ii32> = arith.constant85t 
      1 ,oto% : dense< n 18 = i0.000000e+00>%-iarith.muli 32 : cst_28a64%, tensor< m
7"4:d    , tx g%%4t4tensor<p5 :gx4u =  .1x-arith.extsiinx4t 64uf32, x1o%
      m#x-larg9%-blockedil 19w>32v: = a
, m tt.expand_dimsr    #linear{ai32 p%>r %scst_7
chto17" =       %=g  { = arith.constant88 = fxi64axis4 arith.addi9
 =  : dense< 5    1i-2147483648%860% : i32>, 632,  :  f = }ttg.targettensor<%tarith.extsi  = 4cst_1z :"x :=t% h4 tensor<rarg11tensor<ix324u 4xpxxe: i:i4}i32g32, x,32, f#blocked1  #x>xcto ttg.9
    iaislice<{dim = 1, parent = #blocked1}>5%32n64>0cst_8 = , on
 "arith.constant#blockedi    %->,  >c7 =  "dense<
      aarith.extsitensor<t23>%l 4xt : 89i%01gtensor< = ze :x.4tt.bitcast { i32tx4%87 i, hx  32 #blockedr32:mto1>ex a 
      aitensor<4xi%20d32, x-64 = s#4i
tt.splat-blocked>xt     p
    1e%%e%cst_9xr8 = arg8r = iaarith.divsi :-arith.constant32, ti  w #o%iadense<linearn132r255>>s, ->p :  =  "tensor<->1%tensor< = 4x 034644xtensor<  x : 324m:1xixxa i32i324xi32, }, #x-32#blocked blocked>1n
1>{
    xium    

%32-%        cst_10 = , r9%21tt.funcarith.constant#ew =  =   linearrarith.remsiarith.muli publicdense<>i %19 8388607
t%,@>      e1 _batched_gemm_afp4_wfp4_pre_quant_kernel : %s,%(tensor<490= 20%x4 = -% arg0xtt.bitcast13:: 32    !x%r:tensor<tti3288 e 4., :gi32x1ptr<bf16>#blocked io
x {>tensor<n    itt.divisibility
4-llvm.intr.assume32,  =     %xs #16cst_114im%blocked :  = xptrue1>iarith.constant1xl 
      32 ii:%22}dense<32f  = , 1, yiarith.extsi %>#=1%21arg1 : blockedn
 : tensor<>o    :!4 rllvm.intr.assume ttx4->m tensor<.x a%4ptr<i8>32tensor<ltruex {x4  1tt.divisibilityixt:x = 32, 4e i16#x1si32 : blocked>xit-1, i
32, co
#blocked32    #n    1>}%blockedvllvm.intr.assume , cst_12 = >e to%arith.constant
r% arg2       gtruetensor<: dense<%en 4x!127>91c:1xtt :  = e i64.tensor<4arith.andi=i, ptr<bf16>x f1# {tt.divisibility = 16 : i32a}lblocked, %s1%489e
>arg3x32,     
      : x t%%!i32%o10 = 23tt, #cst_27parith.cmpi = .blocked - tt.make_rangeptr<i8>>:dsgt { {
     o,end = tt.divisibility%tensor<w 128 = cst_13 = 4n% : 16arith.constantx=targ6i :  4r,32idense<xu , 3241943041e%start}>x}c0_i32 = ,  : i,  0%tensor<432c: : iarg4x4, s 32: x#ei} i32linear,32:32x> 
  {i32
      co    tensor<tt.divisibility, %92nvscf.if128 = # = e x16blocked>arith.andir%i : 
     t1032, i32%%- #}cst_14 = 90c{ttg, arith.constant,f
.%  -      slice<{dim = 0, parent = #blocked1}>arg5dense<%t%>: 126cst_4o11
      i> :- = %2432 :  larith.muli =  {tensor<tensor<l tt.expand_dimstt.divisibility44v%8 % = xxm,231644{  { : x32xi%axisix1nc4_i32 = 32}i32xd 0, , #ie: : %blocked>32x iarg6
    , -i3232: %#bi
}icst_15blockedtw       :32 = >i%  {arith.constant
d12tensor<tt.divisibility       th = 128x = dense<%=tt.make_rangei3216293 = 0 {,  : >tt.bitcast},end#i :    = ttg32tensor<%c4.slice<{dim = 0, parent = #blocked1}>}4x91o : >, 4x ni32 %32x:v, -> arg7i32 estarttensor<: , #tensor<4rt = 1iblockedx-0x32>4xar : 128x {
    1iii32tt.divisibility%cst_16xt32,  =  = ih}#16arith.constant32, - blocked :  #t:1idense<linearo >
3221>-tensor<      %}> l425 = ,  : ->lxarith.extsi%tensor< vi32 arg84tensor<m, %24: x44x{i#ttg ix324n.: 32xxdslice<{dim = 1, parent = #blocked1}>tensor<1 {i321xe>xtt.divisibility, #f32x
128x = blocked, -      i16>#b%1332 : 
linear>i = , i    %
ttt.make_range#blocked32cst_17 =       w {1}arith.constant%94idend>,   = t =  to%dense<tt.bitcasth4 arg928 =0 : tensor<: >%}i1i : tensor<92 ,32, x324: start128 {x4 c = xtt.divisibilityxtensor<a0i64 = 324n : , 16xixoi# : 32, 4n32blocked1i#blockedxi}>
32>1c       }
xa:%,     il 26 = %%cst_1832, itensor<tt.broadcastarg10 = #z4 %: arith.constantblockedex22i >{i 32dense<  32: {-1.270000e+02-> ,  tt.divisibility> m#tensor<4 =  : tensor<attgx116tensor<44x.x : xx-slice<{dim = 1, parent = #blocked3}>ii44i>64, 32x1xt
#blocked}x1e      1>, f32xr% %, f32a14 = ->arg11#blocked, ttt.splat : >#io tensor<i
    blockedn%432%cst_19>s11x { = 
= 128tt.divisibilityarith.constant      1:x =  %0 i16dense<95 =  mi3264,  : 7math.log2a #i> x->blocked32 : %- 1}tensor<93ntensor<4>, 4x ux
%32:mi      arg12x -r32, %: i16tensor<e#27i, 4wttg. = 32#ttgxrslice<{dim = 1, parent = #blocked1}>tt.broadcast  {.4xit>%25tt.divisibilityslice<{dim = 2, parent = #blocked4}>1e
  = >xs      : 16
f32=%tensor< :     , -151i%cst_20#1 = x32 = linear arith.addi128x}arith.constant>re i,  
g%64%dense<      %io14, arg13-1>96n,#:  :  = - blockeditensor<4math.log2 s%12132x32%i > {x94m: ->tt.divisibilityi p   = 8, :ltensor<tensor<416#ttg i4x : .tensor<4fx128islice<{dim = 2, parent = #blocked4}>xyix32>4=n32, i}
    xo#64, , %cst_211rttg#blocked% = xf32m.1arg14arith.constant, aslice<{dim = 1, parent = #blocked1}>>:  #blockedl>
idense<> 
      320x7FC0>
t      %28 { :       e% = tt.divisibilitytensor<%s16 = arith.addi = 128x97ttt.splat  1632 = -%%26 : xmath.floorcarg4,ibf16 on  32, %v:%27}#95e  :, blocked ri %5>:g32tensor<arg15
     e 4: %cst_22tensor<n->xi = 4c 12832arith.constantx4etensor<x) x=4i attributesdense<1fx64 {7>xai, noinline : f32l32#blocked = tensor<, s, 1false4#e#ttg>}xlinear> .
       4
tslice<{dim = 1, parent = #blocked1}>%29{x      o> = 
32%p
      tt.addptr    x98-%17 %i32 = d = %cst, #math.flooroarith.remsiarg0 = blocked> w ,arith.constant
%n%      96=t15,%dense<% :r 18127cst_23 =  u% >arith.constanttensor<4e}16: :  x,  tensor<dense<4x c:!41.270000e+02>1s ttx : xetensor<.ptr<bf16>4tensor<f32,4,x4x, # x 14blockedsiixx1>y3264ix
      m, 
8f32, %b#      , #blocked99ottg%30#> = l. = blocked
    arith.subf-slice<{dim = 1, parent = #blocked1}>arith.muli >%cst_24 d>%
 = %97c
9    arith.constant,e      , %  ,%18%cst_0dense<%  = c32_i32 = 1.270000e+02>cst_26earith.muli :arith.constant :  n   tensor<:a%idense<4x b7320x7FC04tensor<l,
      >x14e- % : xxli%31tensor<f324xn4 = 4, #1e tt.make_rangexlinearx-: {128>f32i end = x
    , nfi6432bf16%#o
 : , cst_25linear,      i# = > %32blockedarith.constant
c19, 1       o = start = >dense<%100ntt.expand_dims0
-1.270000e+02> = v  :      : arith.subfe%i32%tensor< r17} cst_14x%t {: = 4x98-axis arith.constant1, b = tensor< x%u132dense<f32, cst_5i : x2097152# lii32>linear:t32,  : > i}#tensor<
    tensor<4n ttgler_DP0_TP0: /app/triton/third_party/amd/lib/TritonAMDGPUDialectToLLVM/ScaledUpcastToLLVM.cpp:73: virtual llvm::LogicalResult {anonymous}::ScaledUpcastFp4Pattern::matchAndRewrite(mlir::triton::amdgpu::ScaledUpcastFp4Op, mlir::ConvertOpToLLVMPattern<mlir::triton::amdgpu::ScaledUpcastFp4Op>::OpAdaptor, mlir::ConversionPatternRewriter&) const: Assertion `inputVals.size() % 4 == 0' failed.
4%x4-f:.xcst_26 = xun slice<{dim = 0, parent = #blocked6}>4arith.constant1ctensor<>x x-4
      1dense<f32tx%x2.000000e+00>, oi32i : #-32 = 32tensor<blockedl, tt.make_range, 4x>l# {#4
vttgend = blockedx      m.32>1%101{fslice<{dim = 1, parent = #blocked1}> : i
x = t>32    f32, tt.clampfz= , %#linear tr->startcst_2>%u  =  = 
    99,e}tensor<0arith.constant% )4 : i cst_27 = %"x32}dense<arith.constantcst_25,
1x 4 ,      i:>dense< disable_threading32  : -8388608%: , tensor<tensor<>cst_24false#324 : ,,blockedxxtensor< 
1i3244xpropagateNan      >, x4x verify_each
##ttg161=:       blocked.xx true% = slice<{dim = 0, parent = #blocked3}>ii32none
20#ttg>
8, #     } = .blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}>      , linear:
tt.splat
%#>   } #33blocked
    tensor<
%blocked = 2%4#-}arg81 = tt.make_range>cst_28 = x
 # {
arith.constant4x:ttgend     1 . = %dense</tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0xiblocked<{sizePerThread = [1, 2], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
32c31_i322097152: f3232#blocked : i = >error: ,  232arith.constant : Failures have been detected while processing an MLIR pass pipeline#-> = ,  tensor<
linear #ttgstart314x/tmp/torchinductor_root/w2/cw2lz77gyfknswdzrahmgf7qi372of6mx54o2swuti5vcmefwljl.py:18:0>tensor<.blocked<{sizePerThread = [1, 1, 1], threadsPerWarp = [1, 4, 16], warpsPerCTA = [4, 1, 1], order = [2, 1, 0]}> =  : 4: 
4
0ixnote:       x# : i321Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`%1blocked332
x
102x = }    i = i# %32tt.clampf32ttg:cst_3,  , .blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>  = #%#
#tensor<arith.constantlinear>100,blockedblocked432 
 %1 = xdense<    cst_18,>#ttgi0.000000e+00% 
.blocked<{sizePerThread = [1, 1, 2], threadsPerWarp = [1, 32, 2], warpsPerCTA = [1, 1, 4], order = [1, 2, 0]}>32, >cst_29%      
##ttg :  = cst_23%blocked5.slice<{dim = 1, parent = #linear1}>tensor<arith.constant, 21 = >4 propagateNan = #ttg
xdense< =arith.muli.blocked<{sizePerThread = [2, 1], threadsPerWarp = [2, 32], warpsPerCTA = [4, 1], order = [1, 0]}>      32127>  
%34x : none%#blocked = f32tensor<4 196 = tt.splat, x4:,#ttg #x  .%blocked1xtensor<%blocked<{sizePerThread = [8, 1], threadsPerWarp = [8, 8], warpsPerCTA = [1, 4], order = [0, 1]}>
30 3i420#:>8, x4 blocked7 
#linearx: = i    >1 #ttg32%
    xtensor<. c32_i32%f324blocked<{sizePerThread = [1, 1, 1, 2], threadsPerWarp = [1, 4, 16, 1], warpsPerCTA = [4, 1, 1, 1], order = [3, 2, 1, 0]}>-> = cst_30 = , #x
 arith.constantarith.constantblocked1#tensor<  >xblocked832x32dense<[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 5, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank5]:E1110 11:31:41.127000 505 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed

i = i : 7      %32#ttg32, i>103, .blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>#ttg32 :  = #
.
tensor<4arith.fptouiblocked#blockedslice<{dim = 0, parent = #blocked6}>    x4 19>%x%> = 
      c4_i32i16101
#% = ,        ttg.35 = arith.constant#ttg:%blocked<{sizePerThread = [1, 2, 1], threadsPerWarp = [1, 2, 32], warpsPerCTA = [1, 4, 1], order = [2, 1, 0]}>tt.splat  .slice<{dim = 2, parent = #blocked}> 22
%304>tensor< = #linear  : 
    4arith.extsi = :i%x4 #ttg 32cst_31x%.linear<{register = [], lane = [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 1, 0], [0, 2, 0]], warp = [[1, 0, 0], [2, 0, 0]], block = []}>i32
 = 1x21
     arith.constantf32 #-> % , :linear1tensor<truedense<#  = 32 = -1>lineartensor<#xarith.constant : >4ttgi tensor< x.32true4to1linear<{register = [[0, 1], [0, 2]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 0]], warp = [[0, 0], [0, 0]], block = []}>, 
x x
##ttg    4tensor<ilinear2.slice<{dim = 1, parent = #linear1}>%x432 = >c0_i32ix4, #ttg
 = 8, x#.linear<{register = [[0, 0]], lane = [[0, 0], [0, 0], [0, 0], [0, 0], [0, 1], [0, 2]], warp = [[1, 0], [2, 0]], block = []}>      %arith.constant#ttg1xblocked
#36 .slice<{dim = 2, parent = #blocked}>i81> to shared =  = 0>, tensor<#arith.addi : 
    #4ttg illvm.intr.assumelinearx.%32 >
1swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [1, 0]}>34,
%      %x
#     true104 = ismem = %% arith.fptoui64#31cst_4: , ttg  =  %#.:arith.constanti102 blockedshared_memory  1:1
tensor<32dense<
     >modulex-8388608llvm.intr.assumetensor<
 attributes {i> 4      "32 : %x%t, tensor<true423t#4 x = gttgx: 1tt.make_range..4ixf32 {nslice<{dim = 0, parent = #blocked6}>x1, #endum>
1
blocked = -      x    > 128c%37illvm.intr.assumeto : t = 32  iasarith.addi, %tensor<432" =  #truex, 1%35blocked :4start : ,> x = i 
i1032%33    1xi : ,  %
    8, i"t:cst_5llvm.intr.assume #blocked32tg  = %true>}.ntensor<32arith.constant 
 umxi :      :-w32dense< % a, 2.000000e+00i105tensor<r#>1 = 128psttg : 
    arith.addi x" = .tensor<llvm.intr.assume %i4slice<{dim = 1, parent = #linear1}>4%true103,32 : i>
x : %, 32      4 cst_29#, %xi ttgttg.target = 38 = 11: ."tt.splat x
    tensor<slice<{dim = 0, parent = #blocked1}>hi%f32llvm.intr.assume4x>parg5,  4
:g :#%truex1      f blocked :x%x9i> i24532 
i8 = 0->    1, #tt.expand_dims" %
    linear> , tensor<cst_6llvm.intr.assume 
%"t32x = %true      %23tgi32arith.constant 106 =  {.,  : arith.addi axisth#dense<i% = rettg0.000000e+0011040ad.slice<{dim = 0, parent = #blocked6}>>
, : s-> :      %ipe
tensor<llvm.intr.assume cst32r-      4%true }w%39x :: a = 4  tensor<:rptt.splatxi4 " =  11x4tensor<64%x
x128 : iarg5f32    1x32 , llvm.intr.assume xi}:#%truei32  blocked :8, {
i> , ##  32 
iblockedttgtt.func->     1>. tensor<%
    
slice<{dim = 0, parent = #blocked1}>public32cst_7llvm.intr.assume       > x = %%107 @iarith.constanttrue = ->_batched_gemm_afp4_wfp4_pre_quant_kernel32,   arith.subf (#ttgdense<:  tensor<%arg0.slice<{dim = 1, parent = #linear1}>-2147483648i%1: >
>1cst_6,x!tt      % : 
 128.ptr<bf16>40tensor<    %102x { = 4llvm.intr.assume itt.divisibility = arith.remsix :3216 :  4% , i%xtruetensor<#323632 :4blocked},x x1,  ii4x>%%3211
arg1: 38, 
    xf32      ! :#llvm.intr.assume , %tt blocked%#blocked25.ptr<i8>tensor<>true> =  {32
 :
arith.extsitt.divisibility = x            16 : i%i%%i3232cst_81108 = 24},  = 
math.exp2 , #arith.constant     :%ttg. %% arg2: slice<{dim = 0, parent = #blocked6}>dense<0107tensor<!tt>23 =  1.
      >tt.get_program_id:xptr<bf16> {% :   128tt.divisibility = 41 = tensor<xtensor<4x16 : arith.remsi4 xii x:43232%4 x, }37xi1#, %,3232xblockedarg3:  %x
    f321!tt39i%, >.ptr<i8> 321 = #blocked  {:, tt.get_program_id >
tott.divisibility =  #y      % 16 : tensor<32blocked :109tensor<i32x>  = 1}, i
iarith.extfx%arg432    32 128: , %
%xi32#cst_9    78i {ttg = % 64tt.divisibility = .slice<{dim = 1, parent = #linear1}>arith.constant2 = : , 16>
 arith.additensor<4# : i      dense< xblocked32}%42255%41, % = >arg5x32>arg5arith.muli : ,x
:  tensor< bf16,       i32%4%c31_i32#% {7x blocked26tt.divisibility,4:> =  =  x  tt.broadcast16 : %32i32to i325x
     tensor<%} i%3422, :32 = x4 % , arith.divsix:arg6: i# 32x i64blocked%2f32tensor<32
>,, 4 {      
 #xtt.divisibility = %    %blocked11643%c32_i32>
x :  = cst_10       ii32tt.make_range = :%64},  {arith.constant 110, %arg7end i32 = #:  = dense<
    tt.broadcast blockedi648388607%4%108132 { : > =  >tt.divisibility = i : arith.extsi:  16 : 32tensor< tensor<->i32, 4%4 }, start = xarg7xtensor<%arg804 44:  : ix:xxi323232 1x128 {} xi32f32xtt.divisibility = :i , i16 32to#64 : itensor<,  blocked, 32}64#i64>#, %xblocked
     ->blockedarg9: i>%5 tensor<1i32, 
 = 4>32#    arith.extsi x4
 {ttg.%%x      tt.divisibilityslice<{dim = 1, parent = #blocked6}>cst_11arg9 32% = > = : x2716 : 
      arith.constantif32 = i%44 32 , tt.broadcast32} = dense<to # , %tt.expand_dims1i64blocked%arg10:  >
    >25i32% : %6
        {43tensor< = %:tt.divisibility =  {4arith.extsi 111 16 : axisx% = tensor<i32 = 4arg11arith.mulf1}, 1x : x% : 32 %128arg11: i32xi32109xi32}i to,i { 32  %64tt.divisibility = :, i64110, 16 :  #
     #itensor<blocked%7:blocked32}64> =  1, %x
arith.extsitensor<>arg12: i     4 i3232%%0x-> {, cst_12 4 tt.divisibility = # = :xtensor<16 : ttgarith.constant 324i32.slice<{dim = 1, parent = #blocked6}> i32xx}, >dense< tof32, 128%arg13 127 #blockedx: i->>i64>i32 {  : 
    
64tt.divisibility = tensor<tensor<%      %, 166448 = 112# : ixxarith.divsi  = blocked3214%1tt.bitcast1}xx, >, %i3232 %%
arg14: , x3111      i32#i : % {blocked632 :28tt.divisibility = >, i tensor< = 16 : 
#324arith.addii32      blocked
    x }, %45>%94%% = 
 = x3226arg15: arith.extsi    arith.remsix,i32 % f32 )%cst_13%1, #% attributes44 = ,blocked>27 { arith.constant   noinline = :  %->:falsetensor<64dense<3  }x4194304 tensor<4tensor< 1>:x4{x :  4x
i32tensor<i32x128    , 4
32x%cst#x    xi = blocked64llvm.intr.assume i3264arith.constant>x%, ,   to32true#blocked#dense< x :>blocked127tensor<64i 
      1>x32i%> : 1x, 1113 = 
tensor<i64#
    arith.andi      4x, blockedllvm.intr.assume  %4x#>%%112291blocked
true, = x6     : tt.addptri8>% % , 
cst_14icst_7%#blocked       = 1 :arg0>%arith.constant
     ,
46 llvm.intr.assume tensor<4      = dense<%x4%%tt.expand_dims126truex18cst_0 > :32x  = %40 :  ii:arith.constant {tensor<132  axis = 4
, #!dense<0x    blockedtt0x7FC0 : 4%10>
.>i32x =       ptr<bf16> : }32arith.cmpi%,tensor< x 114 4x:isgt = i128 32,arith.shrui64xtensor<,   
bf16, 32x#%%      #blockediblockedarg6112%1>32>,,30
, 
  % =     #ttg    %cst_8arith.muli%cst_1.slice<{dim = 0, parent = #blocked6}>%c0_i32   = >cst_15 :%arith.constant -> = : 9  arith.constant tensor<,dense<tensor< i4 20971521dense<32x%> : x2
4c32_i32tensor<32>    x 4xx : scf.if32x:4xitensor< i 1x324%32ii32, x10, 32, #4 #
#blockedx{
blocked>      blocked>632      
%
    >x%11      31%cst_2
      i = % =  = %32arith.muli115tt.make_rangearith.constant47 = ,   =  { tt.splat#%8arith.andienddense< blocked,  = 4>%> %32 : tensor<arg10
%114 : 4x :    c4_i32,i4 %  32xi32cst_16:%, 16x  =  cst_9starti->arith.constanti32  = 8,   
:0#blockedtensor<dense<        : 2>121%12tensor<4i
x> = x32    32 : tt.make_range4x}%xitensor< {32x c31_i32 = 324end = i:arith.constant, x432  #4 : , #tensor<31blockedxi32blocked32 : 6>32, >
xi32
      xstart =       i
    %i0%11632%cst_34832 :  = ,  =  = , i32arith.andi#arith.constantarith.muli #} ttg %blocked %.dense<46>:112slice<{dim = 0, parent = #blocked6}>0.000000e+00,
 ,>> :      tensor< 
tensor<4%%4%      x3247cst_17xcst_10%x  = i32 32f32, : arith.constant, : = #blockedtensor< #ttg tensor<tt.make_range3>1dense<.slice<{dim = 1, parent = #blocked1}>4 {
    x28>xend%32>
4x = c32_i32 = x :       32x32arith.constantitensor<%13i32 :  324 = , i32 : , xtt.make_range#32i#4 {blocked, 32blocked6xend = >start
>324
 =     %
x :       0c4_i32 =       ii32% : arith.constant%32, 117i 49, start =  = 324 = #0arith.addi } : iarith.extsiblocked : %115 32
 >i,:    %%
32 % true48    }cst_11tensor< =  % : 32arith.constant:cst_18 :x   = tensor< itruetensor<arith.constant4tensor<32
1 x4x,     %xdense<i4#c0_i32 = 32-1.270000e+0232, xttgarith.constantx>#32. i : ttg.xislice<{dim = 0, parent = #blocked3}>032, tensor<slice<{dim = 1, parent = #blocked3}>32> : i#4>, 
32blockedx
#      
    64      blocked%%cst_4>x%14>33 =  to1 = 
 = arith.constant xtt.splat      tt.make_range tensor<f32 %118 {dense<1x, %11 = end-8388608>32# arith.subi =  : xblocked: 32tensor<i> % : 4x64, 
i32cst_12i4#blocked     ,32x6>%-> , 1x
cst_19 %starti32       = tensor<4117 = , %arith.constantx 0#blocked50 i32: : > = dense<,  i
    tt.broadcast7#ttgtensor<32%cst_5 >.slice<{dim = 1, parent = #blocked1}>4x} = % : >4 arith.constant45tensor<
x32:  4      x dense<:x%15itensor<2.000000e+00 32 = 3232> : tensor<xarith.addi, xtensor<464xi #ix4116%14blocked>32x1x, ,
, xi64# %      %#f32, , ttg12119ttg##blocked. : = .blocked6slice<{dim = 2, parent = #blocked4}> arith.cmpislice<{dim = 1, parent = #linear1}>>>>tensor< >
 
4xult
    %->    i32,      cst_6 =  %,  %arith.constanttensor<64cst_20#ttg%11534 x = .slice<{dim = 1, parent = #blocked1}>, = dense<32arith.constant>
 %tt.splat0.000000e+00>x       cst_12  : i64dense<%16 :%tensor<4, -1 =  tensor<30x4#>tt.splat4x x1blocked :  4:xf326tensor<%x32 , #>4arg4xiblocked>
x :i32
          32 32,  %%xi32#blocked->cst_7 = 51i >
 arith.constant = 8->       tensor< tt.broadcast, tensor<4%12032dense< #x = x-2147483648%49ttgi32arith.shruii> .,  %32 : :slice<{dim = 2, parent = #blocked4}>#ttg116, tensor<4 >.slice<{dim = 1, parent = #blocked1}>,#x4tensor<
>
 ttgx321          %cst_11.xx%% :slice<{dim = 0, parent = #blocked6}>i32xcst_2117 =  >32, i = arith.remsitensor<
#blocked64arith.constant 4      >, # %15x%
    blockeddense<,435%60x7FC0 x = cst_8>>%1632tt.splat =   :  x arith.constant-> tensor<128: i32% tensor<xtensor<, 30dense<64324x#blocked 23>x32xi>: : xbf1632, 
 tensor<4i64, #ttg      ix4, ##.slice<{dim = 1, parent = #blocked1}>%32x32blockedblocked>
121 =  xi65      arith.ori->32, >>%18  #blocked

 = %tensor<>
          arith.muli12032    %%% ,xcst_952cst_22% i =  =  = 7%32arith.constantarith.addi arith.constant, cst_13,  % %4 #dense<50,dense< :ttg255> 7:  . : %>i64tensor<slice<{dim = 1, parent = #linear1}>tensor<51 : 
4x>4x :tensor<      4
4x 4%19x32      32tensor<x = x%xi64x4tt.expand_dimsi3632, 32xx 32,  = #blockedi6432%17#arith.addi>
, x {blocked>     #blockediaxis = 
%%cst_106321      34 = >,  : %122,arith.constant
      #i32 =   %53blocked}arith.shrui%dense< = >  %318388607tt.addptr
:121 > :       ,:tensor<4%%tensor<  x4arg1cst_234x%tensor<x32, = i3211832xi arith.constant,  :x32, % #ttg i#42dense<.tensor<432blocked> 1.270000e+02slice<{dim = 1, parent = #blocked1}>x, 
    : >>4#%! :  x32ttgcst_11 = tttensor<->x.arith.constant.ptr<i8>4 i32slice<{dim = 0, parent = #blocked6}> , xtensor<, >dense<i6444x#
1>
x1xblocked       : tensor<      1i32>%4x%x, 
374x54f32#       = 32x = , blocked%arith.addii32arith.extsi#1>123 , # blocked
       = %blocked>%>%20arith.select35
    arg14
 =  ,%     tt.splat % cst_12:%%119% =  cst_24arg8, 33arith.constanti32 =  :%   arith.constant 122:dense<to  i, % 127>idense<32 116tensor< : 641.270000e+02-> : 32tensor<4
      > tensor<xx4%55 : tensor<4ix32 = tensor<4xx32xiarith.muli 41x4, 32%xi32x#, 74, #32xttg#blocked,xblockedi1.> %11>, #slice<{dim = 1, parent = #linear1}>
    54x
blocked>% :f32      >
cst_13 =  , %,       arith.constanti#linear21tensor<% 64> = 438dense<
      
arith.mulix4 = 4194304>%     %xtt.splat : tensor<56%19,32 4x = cst_25 x%4xtt.addptr  = %20iarg532x%arith.constant 32 i32arg3 : , :, #,dense<tensor<#blocked blocked> -1.270000e+024>i
    %>x
      32%55  : 1x%124 cst_14: tensor<i32 = -> = !4, arith.maxui arith.constantttx#blocked tensor< .41%11532dense<ptr<i8>,x>
,x126 1      % i> : i64x22 = %32tensor<
f32arith.extsi cst_14, 4      , %21 #x%57# ::ttg4 = linear  .xtt.expand_dims>tensor<4tensor<slice<{dim = 0, parent = #blocked6}>32 
x4>xi%41    1xx4
32,  {%i32x      #blockedaxis = cst_26, 32x%>
1 = #blockedi39    % : arith.constant132 = cst_15i > , tt.splat = 32dense<to#blocked arith.constant}2.000000e+00> >
%   : tensor<4      arg5dense<: tensor<x1% 2>tensor<4x125 = : : tensor<32xi64arith.subi 4x4, # ix4ixblocked1%32x321>124 32x, x
,->i#f32      %  32, ttg., 23 = %tensor<#blockedslice<{dim = 1, parent = #linear1}>#tt.make_rangecst_1432>
>linear { x    % ->>end = :icst_16 =  
128 32arith.constanttensor<     : tensor<,  32%i324#dense<xcst_27, startxttg21>1x =  = 4. : iarith.constant0 : xslice<{dim = 1, parent = #linear1}>tensor<432 i3232>x, dense<}xi
4#-8388608 :32      xlinear> , %32x1> : tensor<#40i32
      tensor<128xblocked> = , #%4i
      arith.remsiblocked58x32%126 >
 = 4,  = %    tt.splat x#ttgarith.shli36%%1.slice<{dim = 0, parent = #blocked1}> %,cst_17 = arg15 x>125 arith.constant:i
,%  i32       38dense<32, %24%cst_15 28> -># =  : : tensor< lineartt.expand_dims : 4tensor<>% tensor<x432
23tensor<432xx     {xx32x1%axis = 4iixcst_280x3232i =  : 32x, , 32arith.constanti32i32##blocked,  }, ttg>#dense< #.
linear2097152: blockedslice<{dim = 0, parent = #blocked6}>    1>>tensor<128>
>%cst_18
 : x      
 =       tensor<i32%      arith.constant%4, 127 = % 59 = x#arith.shrui41dense<arith.muli 4ttg.  = -1.270000e+02%xslice<{dim = 0, parent = #blocked1}>%arith.remsi> : 571> 123, tensor<4, x-> %%x%58i cst_16 374x 32tensor<1: ,1x:, xtensor< f32 #1284%, #tensor<linearxx439blocked>32>i32x 
    x
, 32:%cst_191    #blockedx  = xi%1>i32tensor<arith.constant32, cst_29
      , 32 # = %25#blockedxdense<linear1arith.constant = >i7>> arith.extsi
32 : 
      dense<       , tensor<4%127%%#x3260>24 128ttgx =  : :  = .iarith.extsitensor<tensor<1arith.ori slice<{dim = 1, parent = #linear1}>16 4x%>, %x128x126
#ttg59 4i32,      .slice<{dim = 2, parent = #blocked4}>:x, # %> 1blocked1%12742
    tensor<x>   = %32ito :arith.mulicst_20x8tensor< tensor<  = 1, 1x4x%arith.constantx#128x47 ilineari64x,dense<32, >, #32 -1>#linear
blocked1xi% : 1    >
32, 5tensor<>%      # 4x cst_30%26blocked:32xto =  = > i arith.constanttt.broadcast
      i8, tensor<  %64#32dense<%22129
ttg.x17  =       slice<{dim = 2, parent = #blocked4}>x>: arith.addi%>i64 : tensor< %43
    , #tensor<4x128, = %cst_21linear41x tt.make_range = 1xi64% {arith.constant>4, #cst_11end 
xblocked  = dense<      %i1>: 640x7FC0>61 = 16 ->tensor< :  : tensor<tt.make_range,  4i128x {#tensor<4x43232end = ttgx128x, x4.x32xstartbf16 : slice<{dim = 2, parent = #blocked}>ii = , i>64, 320#32
#blocked,  : blocked5,     1>#i>
start%
blocked32     = cst_31      >}%0 = %27
       cst_22 =  : arith.constant = %130:arith.constanti32 tt.broadcast =   }dense< arith.shruitensor<dense< :-1%25 647 > :%x> : tensor< :  129itensor<44tensor<tensor<1,32x4xi4x , x3232x128x%cst_11#xi, 4i64 ttg32, #x, #:.#ttgiblocked1 tensor<slice<{dim = 1, parent = #blocked6}>blocked>.8> 4>
    slice<{dim = 0, parent = #linear1}>, -> x4
%>#tensor<x32      cst_23 = 
      ttg4xx%arith.constant%62.128xi44  = slice<{dim = 2, parent = #blocked}>>i6432,  = dense<tt.broadcast
, ##tt.expand_dims1.270000e+02>     blocked1blocked  : tensor<%llvm.intr.assume>
>%4x60       
434 :%%28       {x1 true = %axisxtensor< arith.addi 131 = f32, 32:%26 = 1#blockedx ,arith.minui : >
1i  i    %x1%%13032cst_24 = i
27,}arith.constant64        , llvm.intr.assume: %cst_22:dense<# tensor<4  1.270000e+02linear1%x:tensor<> : >true128x tensor<4x644xxii32 64 32tensor<x-> , :, 4xitensor<# #432, 32blockedittgx#x11.1xblocked4>
slice<{dim = 1, parent = #blocked6}>f32, >x
    >#linear
i      llvm.intr.assume >      64% ->
    %, 29% %cst_25132# = truetensor< =  = linear1tt.addptr 64arith.constantarith.shrui> :x  
% 1dense<%      arg0ix-1.270000e+02113,%,1i> 63 
32 : tensor<% = %    , 4cst_17tt.expand_dims18llvm.intr.assume#x4    blockedx1: %:%6xtensor<61 true>f32, 4 {! 
#xaxistt:      linear>4 = . %
    x0ptr<bf16>i45%cst_2632 : ,1 =  = xi 
arith.extsiarith.constanti32i      32}64llvm.intr.assume%dense<,  
 442.000000e+00#:      % > : blocked %true:tensor<>tensor<30  4
4 = :tensor<x4      xarith.muli 64x%133i ix1 = 32%11xarith.ori, 9
xf32,  #,    i#linear%ttg llvm.intr.assume32>132.% , 
    ,slice<{dim = 0, parent = #linear1}>c32_i32%#% > trueblockedcst_27 = %131 ->: 6arith.constant   :> :tensor<i  dense< tensor<132ito-83886084x
1 > : x4      
tensor<tensor<4x%    644xxi3231llvm.intr.assumex4x32,  =  11xx#tt.make_range%xi32ilinear {truei, 321end 64#, >
 = :, linear#      32 #>blocked%64 : iblocked
    > = i16%
tt.broadcast32
>cst_28 =        ,     
arith.constant%134%startllvm.intr.assume        = 63 =  %dense<arith.trunci 0%462097152 : : true = > : %133 i tt.expand_dimstensor<4 tensor<32: x4:1} %x x i401tensor<4:1 {x4x 
axisi32x4itensor<     = , #x32, 32llvm.intr.assume0linear>32#x  : 
    xlineari%i%cst_29i132true32 = 32>,  }arith.constant,  #:  #->ttg :dense<blocked> .i 127 totensor<32slice<{dim = 0, parent = #blocked6}>1tensor<> x>
32 : tensor<4
    xtensor<44x      llvm.intr.assumeixxi% 324x43232%, 1x,  = true#x32x#tt.make_range ttgiilinear1 {:.8, 8, >end slice<{dim = 0, parent = #blocked6}>#linear#
 = i>>blocked      321 
    >% : 
    ->%cst_30
65illvm.intr.assume  =        = 32 tensor<arith.constant%arith.extsi , %1 135%starttruexdense< = 64  =  327>tt.reshape:0:x :    :  itensor<%tensor<ii324x13432321, 4x x}
#i:4     llvm.intr.assumeblocked16 x: 6, tensor<i %>#ttg432tensor<true
.x, 32       slice<{dim = 2, parent = #blocked}>4#x:%>xlineari 47
    32132i = %x>, 1tt.splatcst_31i #
  = 8tottg    %arith.constant, # .%arg10 blockedtensor<slice<{dim = 0, parent = #blocked3}>0 dense<>32> = :-1> x
tt.get_program_id  : tensor<-> 4       i4xtensor<x%x324x4i33  ix64 = :->8, 4x, tt.make_range  #ttg16# {itensor<.slice<{dim = 2, parent = #blocked}>xlinearend321>21 = 
x
    x>
32    32llvm.intr.assumei       : %x 8, %i1i%#66 = 32 = 32trueblocked7arith.addi , tt.get_program_id,  >%start #: 
      65 = yblockedi%,0 61outLHS  : :>
    , %62i 
llvm.intr.assume % 32i      %trueoutRHS:}32%  =   
48: tt.splittensor<:     = i 32 %arith.muli1%135xtensor<2 
     432 = %llvm.intr.assume :xxarith.addi46%true i64i , : tensor<, 32% i4x#, arg5%14xlinear1#,47
16>ttg      x
      .%:llvm.intr.assume2%slice<{dim = 1, parent = #linear1}>c31_i32  %x67> tensor<true i8 = 
:1:, tt.splat        x #%%i32i1blocked563432x
    7  = 
illvm.intr.assume>:tt.splat    32    %, %true->!%3# : tt30 = blocked itensor<.ptr<i8> arith.divsi614x : >
4-> %
    x i2      llvm.intr.assume16tensor<32,% %x32  49truei8x->% =  :, 4 c32_i32arith.extsi #xtensor<  i1blocked!32:%
    2ttx 48llvm.intr.assume>.ii  
      ptr<i8>3232:%%136, #, 
 true = linear1#    tensor< arith.shli>ttg%1:  
.4xi1%      slice<{dim = 0, parent = #blocked6}> = 32
    outRHS%>arith.extsixllvm.intr.assume,68
 i %  =       %32true%tt.addptr%arg7,  cst_2 35 #:  % = :blockedi1: 67tt.splat 6
tensor<,  i>    4%%32 llvm.intr.assume x6630 to%4  to truex: : tensor< 16tensor< i1: x32i64xi1ix32
32
    8, 4     xllvm.intr.assume#x->%i blocked! 564%2tttensor< = , true >.ptr<i8>32arith.extsi#: 
, x blocked6i1      #i%>
    %linear32arg9
llvm.intr.assume1371,         % = >#:%true arith.ori,ttg 50:   .i = i1%tensor<slice<{dim = 1, parent = #linear1}>32tt.broadcast
outLHS32>      ,x
to%llvm.intr.assume  4       45%true%x%i  :136i3664: i 64 = 
 1: , arith.addi    tensor<
    tensor<#linear %64%41%6x0 = x>34 = 1tt.get_program_id4
,arith.extsix x        ix16%%%64 x6931arg11, : i8 =   :#i, tt.load: blocked32#  i6
blocked%tensor<32 >    26832to %1> x -> = 
:ii tt.get_program_id        3264tensor<y%138tensor<, 
64 : = 32#    x itt.reshapexttg%3232 4.7x
    %xslice<{dim = 0, parent = #blocked6}> = i%137!>arith.extsi642 =  tt
 , arith.addi:.      %#  ptr<i8>%0blocked%tensor<4, 37 6arg5x# = :>,4linear1arith.addi 
 x> i      %16
%32%c31_i32x      35 51 i%,to = :870  tt.broadcast ,  = %i i32#tt.trans3364%
blocked  
49    %2>%69:     3 =   { %:arith.divsi->ordertensor<8    = 32 = tensor<%tensor<array<xarith.divsi124ii x, x3232%32%64: , 1xc32_i32x1#,i i, ttg 64:80.%,  , >slice<{dim = 1, parent = #linear1}>3#i32#} > blocked
blocked:
:6    8        >%>tensor<32%i 4
x3832-> =       4 = 
 arith.extsi%xtt.splat    tensor< 139 = i %64%tt.reshape 8%9xarg7%, arg5 = 32 105# arith.remsix:  linear: ii:1 %6432 >i1,  totensor< 32,# 4->  blockedi64x ->%6
4tensor< 3>    %x4xtensor< 
513232:       = xxx %arith.extsii8iii52 %, 83232 = arg9 #, , 
arith.addi: linear##     i>ttgttgllvm.intr.assume%32  .slice<{dim = 2, parent = #blocked4}>. 50to->>slice<{dim = 0, parent = #blocked6}>%, i 
>
true 64tensor<4             %
x%%:51    47139  %6x =  = i: = itt.splattt.splat1 arith.extsi8  
tensor< , %%    64%arg11#29arg5llvm.intr.assumex ttg  : 32:.: %x slice<{dim = 2, parent = #blocked}> itrueii>!32 6432 
tt : , to      %.ptr<bf16>->i# i140 =  -> 1blocked64
tt.reshape tensor<
6    % tensor<32    >7 = %4xllvm.intr.assume
arith.extsi106xi         12832%%%:x, true530 !#  =  :tensor<ttttg:tt.addptr i4..  32 xptr<bf16>slice<{dim = 1, parent = #linear1}>i%to 4, >1arg1i64x#

,
    1blocked           %8x1%%% = i>401042arith.divsi 8
 =  =  %1,       arith.remsiarith.cmpi:,#%    blocked72%sgt!%3> = 36,tt  tt.addptr, .: ->  %ptr<i8>i %%arg6,32
tensor<7138,     %4,  i9 = x :%64arith.remsi4% c0_i32
 x28tensor<       %i 32:%18:x 54,,  ii =  #tensor<3232arith.extsi%3linear4, 
  2x#    %:>128ttgscf.ifarg14 
x.  i32      !slice<{dim = 0, parent = #blocked6}>%:
    %tt>10 llvm.intr.assume141.
 i % = ptr<bf16>      {32true ttg.convert_layout, %
 : #41      to i%blocked = % 11401arith.remsi11i
 >  = 64    :,%arith.muli
llvm.intr.assume   tensor<37       %tensor<4,%%true4x 855 x128%, = :4x39 arith.muli xi % i1i64:c4_i32%
    8,   7llvm.intr.assume, #tensor<:, %#blocked32  true linear1xi%:2>i3254 >
32
 i1       ,       :
    ->%#% % 73ttg12i10tensor< = . = 64 = 4tt.loadslice<{dim = 1, parent = #linear1}>tt.make_range
arith.cmpix > {       4%
end%sgtx72       = 56,i %4 =  8:42 : tt.addptr %,   = i%arg6#tensor<arith.muli32arg3,ttg4 , , .x%start %c0_i32slice<{dim = 2, parent = #blocked}>128x7 = % >!,055: 
tt  :  i32      .%i:
    %ptr<bf16>532 scf.if142,  }!  = #: tt%10arith.extuiblocked :. { 1i ptr<i8>
%>64tensor<,      141

4 %11             xi = :%%i64arith.muli 744332
 tensor< =  = ,       %84tt.splattt.make_range#%,x  {ttg57 4%end. = %xi53  = slice<{dim = 1, parent = #blocked1}>tt.expand_dimsc4_i328: 64>  , ! : 
%:#tti      41 ttg..32% {islice<{dim = 2, parent = #blocked}>>ptr<i8> , 13axis32 -> start =  = 
totensor< = tt.make_range1 :        640 {i%12tensor<x : end32 = 432i = }tt.make_rangex4x324  {x!} : :end = itt i 4 : 16.:32tensor<i32, ptr<i8> , 32, #, tensor<startxstart = ttg#blocked64 = i0.6x032 : slice<{dim = 2, parent = #blocked}>>i : , i32>
32i#}
      , 32ttg       %#}.: %75ttg slice<{dim = 1, parent = #linear1}>tensor<4143 = .:>x = tt.addptr slice<{dim = 1, parent = #blocked6}>  iarith.shli%>tensor<->32 74
4 , %,      xtensor<#142 %i32ttg,%4432x.slice<{dim = 1, parent = #blocked1}> 52 = , 1>% tt.expand_dims#x
      cst_30: ttgi%13  %.32 = :tensor<43slice<{dim = 1, parent = #blocked3}>, tt.make_range tensor<64 {># {end4xaxis
linear = x32x =       14 : 4x!tt1%>ii. : 14
32, 16ptr<i8>i =       start = , , #32tt.splat%0 : #blocked} 58i32ttg.6 % = } slice<{dim = 2, parent = #blocked}>>:11tt.splat:>,    tensor<
 tensor<:%4x      tensor<64 arg15i32%64xi , 144xi32:# = 3232  ttg.tt.bitcastx, ->islice<{dim = 1, parent = #blocked3}>> i# 32
      %64, ttgtensor< %14143#blocked.4-> =  6slice<{dim = 1, parent = #blocked6}>x tt.splat:>>itensor<  
 3232%11tensor<      ->, x :4% #1 x76tensor<ttgxi324 = 64.i xtt.loadxslice<{dim = 1, parent = #blocked1}>32->i 1>,  16%75x
#tensor<,  i      linear4x#cacheModifier32%1i32ttg , 15>, .=# = 
#ttgslice<{dim = 2, parent = #blocked}> blockedarith.addi      .slice<{dim = 1, parent = #blocked1}>>cg6 %>
  >%59      %->:
14 = 15 =         ,arith.muliarith.addi tensor<tensor<%  %1446445%%, xx = 1257%12432xarith.extsi , x! : :bf16tt% % , .44tensor<58tensor<4#ptr<i8> 4 xittg, :x:32, .# i #ttgslice<{dim = 2, parent = #blocked}>blockedtensor<32tensor<.slice<{dim = 1, parent = #blocked1}>>664, 32>

>x#x      %16      
1ttg1 = %      x.xtt.splat 145 = %islice<{dim = 1, parent = #blocked1}>i%arg4tt.expand_dims7732>32 :  = , 
,  %ttg.convert_layout#      #i32144 blocked%linear -> {%6161 axis76> = >tensor<4 =   tt.splat
xi2:to       32,  :   %%#ttgitensor<tensor<arg460.slice<{dim = 1, parent = #blocked1}>326464  = >}xx:arith.extsi
       321  %17:xxi% =  ii3259arith.remsitensor<864   %4, , ->:15,x##   %4blockedblockedtensor<tensor<16x66432 bf16>>xx: ,  
i1tensor<4#->      32xxttg %, ii32.tensor<46#32, slice<{dim = 2, parent = #blocked}>>64 = ttg, #ttg xtt.expand_dims.#.slice<{dim = 1, parent = #blocked1}>->32 slice<{dim = 1, parent = #blocked1}>linear> x%>1
      tensor<i40
>%1848 {        = x, axis%toarith.muli 4#blocked = 17 %x13>0 = tensor<7x
       : arith.remsi32, bf16%i x%, 7832%14# = }15x :blockedtt.reshape ,i > : %64i
% 16, 64
      73tensor< #      %% 32:linear19146:x 1 =  =  itensor<>tt.expand_dimstt.broadcasttensor<324
  4, x      %17%x#i% {145128ttg3261axis =  x.,  = 1: bf16slice<{dim = 0, parent = #blocked6}>#tt.make_range : tensor<, >ttg {i4# .end32}xblocked->slice<{dim = 1, parent = #blocked1}> =  41 >4: x1>tensor<
 : tensor<4x 1      ixbf16->x%32i32,  3218, , #blockedtensor<x = start#>4iarith.muli = ttg. x32 0slice<{dim = 1, parent = #blocked1}>-> 4, % : > tensor<x#7i-> 432blocked,32tensor<4xx6 }x14bf16>% xix, 
4:32, 32#        #blockedxblocked%:tensor<1>bf16>47 4
      , 
 = ix%20#      tt.splat64i = blocked>% 
32tt.splat 
79%      , %       = arg10%#arg8 %math.absf 19ttg: 147 : = .i = % tt.expand_dimsslice<{dim = 0, parent = #linear1}>32 tt.reshape78i >->   32%
tensor<4%: 17      x1146 -> {%xi tensor< axis6232, :4tensor< =  = #blocked x11tt.broadcast1>tensor<4xx :  
43232i%      %xxx3260214bf16i}  = x, 32 :arith.muli32#, :  %xblocked# tensor<19bf16, >
blockedtensor<32,#      64x %blocked%>x120>80
ix   =       32i: ->arith.extf%, 64tensor<4  48#, xtensor<% = ttg#1479arith.muli.linearxix128  slice<{dim = 1, parent = #blocked1}>132, x:%>>#bf16 46  blocked1, #tensor<,->->>blocked4   
1x%tensor<tensor<      >447432%
x xx22      32:14 = %148xbf16 xxarith.extsi  = , tensor<ii%amdgpu.scaled_upcast_fp4#1326421 blockedx, ,  %>32##: 138 xblockedlineartensor<4 toi11x1scale 32>>x tensor<, 

i32%4#            , 147xblocked%%# {462063blockedaxisx> =  = 1 = 32
tt.splattt.expand_dims> 1x        to  : f32%%%tensor<i, 49arg8614x32# =   {1x} blockedarith.extsi:axisi64:>   = , # 
      %i0blockedtensor<4%814832 : 1x =   i>64x":->32
      it  }%238ttensor<tensor<  = , .14:tt.make_range#blockedrexx  {8d321tensor<end>uxx4 = , ceiix128tensor<"3232i : i4(, , 3232, x%##, start = 12880blockedblocked#0 : x)61ttgibf16 <>>.32}, { 
slice<{dim = 0, parent = #linear1}> :#axisto      > blocked1 =  % tensor<128>2tensor<21->x  : 1 =  i->ixarith.mulitensor<32,  32}32 1#tensor<>x%19xttg4 (i,4.x{64 xslice<{dim = 0, parent = #blocked1}>128
, %i32>
x      #20,       bf16^bb0blocked #%, (6:linear24 = #%> 1tt.expand_dimsblockedarg16
tensor<> %1>:       4
23
f32%x       {axis      , 501% = %% = x640 : 149arg17tt.broadcasti = i32 = :  32tt.broadcast} arith.cmpif32%,  :  )45#%tensor<eq: blocked63128x,
:1 i          >:32, %%tensor<
 #13920964      tensor<ttg, = x1%1.slice<{dim = 0, parent = #blocked1}> arith.maxnumfx22x> % i = 4-> cst_31%64arith.extsixtensor<1 arg16,  ix:,#%32128x  blocked21, i32tensor<%6 #, #4arg17>:linearblocked1x   1>4:->tensor<>
      x  4 %if32tensor<x->25 = 8, 
641 arith.extsi#        xxtensor< %ttgtt.reduce.return32i3224. x32x :slice<{dim = 2, parent = #blocked}>%i, 4 tensor<>20964#x1x
       , blockedi128x%:#132i150 blocked>, 32 = f32
6 #, tt.expand_dims      >tolinear#blocked }
 11>%)      tensor<> to149 : %4
  {(51x      tensor<axistensor< = 1%1 = 4tt.broadcastx65x1282x i = x : 4%64arith.extsii64i32x49,  , #} 32 #%blocked1:x:blocked64> f32 1 
tensor<, tensor<>:      4#1
 %x4blockedx      tensor<26x>32%32 = i) -> xi23xtt.broadcast1tensor<64 = 4 %, 4, tt.make_rangex22#x# {i :ttg.4blockedend32 slice<{dim = 2, parent = #blocked}>xf326 = , tensor<4>, >128#x #  : linear1->ttg->i1x . 32>i64tensor<slice<{dim = 2, parent = #blocked}>tensor<,  , 4>64startto#x
x =  blocked4x      320tensor<1>1%x : 32 x82iix-> i = 64324tensor<1ttg.convert_layout, }x4x,  # i128x#%blocked:64i64blocked816 , , #> >tensor<#blocked
:
128linear1             x1>
%tensor<%i>      %15145232
27 = x = ,        = tt.broadcast4arith.addi#%tt.broadcast x ttg66 %f32%. = %150, 50slice<{dim = 0, parent = #blocked1}>arith.addi25 #,>  :ttg 
%:  .%      65tensor<tensor<slice<{dim = 2, parent = #blocked}>51%,14> 24 xx : = %1284->  tt.expand_dims62xxtensor<tensor<  i1464%:64, xxx23 #i432 {tensor<blocked1xxaxis321, f32i = x>#, 6404 blocked#,  : x-> >ttg.#iitensor<4 slice<{dim = 2, parent = #linear}>blocked3264x->>6}, 128x 
> #itensor<4      
:linear64x%       1, #483%tensor<>blocked1x = 53128
>
32tt.expand_dims = x            %xi tt.addptri%28 = 1% 3267arith.addi , #82%,  = %26blocked {arg1#tt.splat,>axis = ,ttg  %27
2 .% :       : %slice<{dim = 0, parent = #blocked1}>56 %i42> tensor<415232  :x128 = }:-> xtt.reshape   !i64 :!tensor<tt, % tt1.#151tensor<.xptr<i8>blocked1 4ptr<i8>128 >:x,x->
 4 i       tensor<4xi32tensor<%xf3264, 32294x, 
#x = 32#      blocked4tt.addptrxttg%1x i.54>!%arg01slice<{dim = 2, parent = #linear}> = 
tt, , >arith.extsi      .%18# -> %ptr<i8> :blocked %25,  > tensor<arg14 = #!tt->4 arith.extsilinear.ptr<bf16> x: 1, tensor<4 %>i4xi24
64
x132             %128xf32 :%30 = x, to 68arith.muli i#linear tensor< = %91>i1tt.addptr, , 
      64x %#%
128%c32_i32blocked84      x67 :1 = %i, >tt.expand_dims5532 i
  = , %32      %81arith.muli#66
% { blocked       %153axis%1:31 =  = 7>  = arith.select2, tensor<tt.make_range  : i to32 {%32% xend152}54tensor<4 = ,   1x32 : %::x!i32cst_0,   128tt, %tensor<ix.start = 148464iptr<i8>0 :  : x
64, itensor<4      , #324x%#linear} xf3256blocked1:128,  = 1> x#tt.addptr>,tensor<ittg 
 32x1.%      tensor<i, slice<{dim = 2, parent = #blocked}>arg3%3232, #>,26x#ttgblocked1   = 4.slice<{dim = 0, parent = #blocked6}>>->%tt.broadcastx>, tensor< 55 i
      4tensor< %64%32x4:22,  = 128x  #tt.make_rangexbf164x!:linear {end, 1tt 1 = #xf32.tensor<>32blocked, #ptr<i8>4
 : i1blocked,x      32, >
> 1%start =       %
ixi690154      6464 =  :  = %
, tt.loadi32ttg.local_alloc85      # }   = %blocked%: %tt.bitcast57168tensor<153  = >32  %tt.expand_dims x::83 ->i   % 32tensor<(:41tensor<, 32tensor<  {4#x4tensor<axisxttg4x4 = 128.x128x1xislice<{dim = 0, parent = #blocked3}>!x4 : 64>ttbf16xi, 
., #132#      ptr<i8>blockedx}blocked%, #1f32 133linear>, :> = 1>)#linear 
tt.make_range
 -> >tensor<       {      ! 32%end%ttg->x27 = 70 = . i = 32tt.transmemdesc<4x128xbf16, #shared, #smem>tensor<432tt.broadcast :  
x,  i%69      4#%32 {%xttg25, order1551. start =  = xslice<{dim = 1, parent = #linear1}>: = array<ttg.local_loadi> 0i 32 tensor< : 32%, ->1i: 154# x321 lineartensor<128}, :>32xi 0 
x64:>!      1,  } ttg%86x#tensor<: . = iblocked32tensor<memdesc<4x128xbf16, #shared, #smem>tt.bitcast321x32  , >ix->%# 324 84linear->, xtensor< 1 #i4:>tensor<ttg8, x 
4.#128tensor<      xslice<{dim = 1, parent = #linear1}>linear1x4%128>>bf16, x58x
 #4 = i      ->ttgxtt.splat64% .1 , 34tensor<dot_op<{opIdx = 0, parent = #blocked3}>x%# = 4x>f32arg15blockedtt.splat32x
,  1 i      %#:>%8, 156blocked> 
30# =  ->i       ttgarith.extui 32%:. tensor< 28 slice<{dim = 2, parent = #blocked4}>%4-> = i>70x arith.addi32
       4tensor<  %: x132%->71tensor<4xx26  = xi1,tensor<tt.splat3232x 32 x, i%x%i#3227i298, blocked,  32 #>
#:, :ttg      linear # .%1tensor<ttg!slice<{dim = 2, parent = #blocked4}>87 = >4.tt>arith.addi
xslice<{dim = 0, parent = #blocked6}>.  %      128>ptr<bf16> to85%x
->  ,59i      tensor<tensor<  = 64%44%arith.muli, 35xxcst_28 # = 128x32 %blockedtt.splat!x:571 tt.i ,>%ptr<bf16>16tensor< 
30, , 4%       ##x58%:blockedttg4 29 1.x: = i>slice<{dim = 2, parent = #blocked4}>1 tt.addptr32
      >xtensor<  %72
i32%-> =       32, xarg0, tt.addptr%157#1 tensor<  = linear>x%32%arith.shli 
i18x71%      32 i,156%, :32 ,88# , %28  = linear!# %arith.addi 1tt.ttg:cst_19%>ptr<bf16>.  86
,slice<{dim = 1, parent = #linear1}>tensor<:,       >4  %i
xtensor<%6064      128x4cst_1 = 
%!x arith.extsi      36tt.32: % = ptr<bf16>, x %30arith.addi#blockeditensor<59 =  1164 arith.muli%>, x: 34,#4 %, ttgxtensor<9 tensor<.132, %4slice<{dim = 2, parent = #blocked4}>xx%31x>i321c32_i32 128x
, x :i      #i: 64%158blocked>32 tensor<, # = 
      , i32blockedtt.bitcast%#32x1> 89linear
i
% = 1      32      157tt.bitcast>%, %73   31# = :%87to = ttgtt.load    tt.make_range.%tensor<:tensor< {slice<{dim = 0, parent = #blocked6}>724 32end> xtensor<x = 
:324132       xxx : %tensor<i4ii37416x6432 = x, 1, , arith.addi128#x#start xttgilinear = %!.321035ttslice<{dim = 2, parent = #blocked4}>, > : ,.ptr<bf16>>#
i ,  linear      32%#->>%}33blocked1  61  >tensor<4-> = ::
x tt.make_range        32tensor< {tensor<tensor<%x4end32x3274bf16x = ix = , 4432, itt.splat #x : #32%ttg.1ittg, 53 slice<{dim = 2, parent = #blocked4}>xi32.#: >32, slice<{dim = 0, parent = #blocked6}>ttg!
, start>.tt.      # = 
slice<{dim = 1, parent = #linear1}>ptr<i8>%linear0      > 159> : %
-> = 
i32       tt.expand_dims      32 = %tensor< %}tt.make_range3864%90  { = x32158 = :endtt.splatx {tt.bitcast  =  !ttaxis tensor<32%. = %884 : arg5ptr<i8>2 xi ,  : :i32:#i 32,  blocked32tensor<4, starti6}x# = 32> 4ttg0 
:x. : ->      % 1slice<{dim = 0, parent = #linear1}>i 75tensor<4xi>32tensor< = x32
}32tt.addptr32,        x x#%:i%74bf16blocked62 32, , > = tensor<, %52# tt.broadcast32# ttg-> xttg: . %i.tensor<slice<{dim = 2, parent = #blocked4}>tensor<6032slice<{dim = 0, parent = #blocked6}>64> 4 , >x->x:#
32x 4 ttg      !tttensor<xtensor<.%.4132slice<{dim = 0, parent = #blocked3}>39ptr<i8>xxx> = , 32i1
tt.splat#x32x       blocked61, i%%>x#6433arg5,bf16, blocked>,  =   #
#tt.make_range:tensor<64blocked      linear { x4%1endi32>91> = 32x
 =  32 i      arith.andi-> : ->64%  tensor<i , 160%3232tensor<# = 89x, 32blocked6tt.broadcast,4startx>
  x = i      %%i032%76159cst_2764 : ,  =   , i#tt.load: :#32ttg tensor< linear}.%754tensor<1 slice<{dim = 1, parent = #linear1}> x4>:>cacheModifier32xx4
 
 1x      tensor<      =x1%32% bf16x63x40cg, i32 = i =  #, tt.expand_dims32arith.remsi:blocked# ,   4linear%#%tensor<>>61ttg3664 
 {.,x->      axisslice<{dim = 1, parent = #linear1}> 32 % = >%xtensor<920
38!4 =  :        :tt.xarith.andi i% ptr<i8>32%3234tensor<, #x3290,} = 32blockedx  tt.splatx6bf16%: i>, cst_4 %32
#blocked :tensor<30,       4 4 #%>tensor<x:ttg77 = 
4i .ttg.convert_layout      x32islice<{dim = 0, parent = #blocked6}> %4, 32>%161x1# 
76 = xittg->       tt.trans32. %:  , slice<{dim = 0, parent = #linear1}>tensor<41tensor<%#>32 = 64160blocked xarith.remsix32 {>->i xorder
 32%i =       tensor<, 378, array<i%931#,#blocked32 = xttg 6: tt.bitcast4.%>0 xslice<{dim = 0, parent = #blocked6}>39 , %i> ->29132
: ,  :,        tensor<1 #%tensor<64>tensor<linear3532x32}41 = xx :x4>tt.splatii x
 328tensor<1      %, , 4x%30##xi64 ttgblocked33232 = :.>x, tt.broadcast slice<{dim = 1, parent = #linear1}>
32# i>      xlinear%32
%78bf16>63        = ,   ->%tt.reshape#->: 42 blocked  tensor< = %4tensor<tensor<32arith.muli73>41x   xxi%:->4x4327  1x, ,tensor<tensor<xi# 44f3232ttg%xx, , .512832##slice<{dim = 1, parent = #linear1}> xxlinear>linear>:bf1632
1
 , x      >      i#bf16% %64blocked, 94->36
1# =   =       > blockedtt.bitcasttensor<arith.addi%->9 32 43 >%92x% = tensor<
 434tt.make_range4x      : x, {4%tensor<i endx32162432% = x = x, 3164bf16, tt.reshape4#  : # xlinear:iblocked%11 32>161x>tensor<, 
       i
32start%:32      x = 79 , %i0 = tensor<#6532 : math.absf4blocked = , i x32>arith.extsi#32%x  ttg}7832->%.  x 64slice<{dim = 0, parent = #blocked6}>::bf16tensor< >  , 4:
tensor<tensor<#x       644blocked94tensor<%xx>x13237i4 ->x = 32xx tensor<4arith.addi, 32f32128x #x, xi%ttgbf16#323235., blockedx, ,slice<{dim = 1, parent = #blocked6}>#>bf16# >blocked
, linear%
>      #133      
%blocked> %      %955 :4480 = >to  =  = math.log2
 tensor<tt.expand_dimsarith.extf       tensor<32  %%32x%%93163 = xi4379 amdgpu.scaled_upcast_fp4432 { : x, axis: %i# =  tensor<7764ttg1tensor<4 , . : 4xscale#slice<{dim = 1, parent = #linear1}>ix4 linear>324x%1
}x1162>       32x {
%: xf32axis      38tensor<bf16,  = % = 64, #066tt.splatx#blockedlinear :  =  i>>iarith.addi%32 
32 arg5, to      }% # % 65:ttgtensor<96: , .4 = tensor< islice<{dim = 1, parent = #blocked6}>xmath.log264%32>4 x62  x%32 ->->3294x:  x i tensor<tensor<f32, :8tensor<3264#blocked , #32xx>tensor<blockedxi1
43>432x      x,x, i%4 i#3281xtensor<64ttg,  = 1128, .#"xx#slice<{dim = 0, parent = #blocked6}>blockedtf32, 32linear>6t#x1
>.rblockedbf16>      
e>, 
%      du
      #      39%ce%blocked% = 45"(97567tt.splat = % = > =  arith.extsi80math.floor tt.splat% ) ->  arg5% <%95tensor<% :44{ 12856   axis:x:i: =  32 32 2tensor<x! tensor< : 4bf16tt->64ix, . x324#ptr<i8>tensor<1}xblocked 32x>15->xi (x> i32{f32
tensor<32, 
,       32, #      #%x#blocked^bb0linear1644ttg6(> = x.>%
arith.cmpi!slice<{dim = 1, parent = #linear1}>> arg16       tt
to: %eq.ptr<i8>       f3298,, %tensor<,  =  %#4064%math.floor70linear = xarg17 ,1arith.remsi1: % > xf3296%
%i) cst_20      3664:: %,, 
 :68 #        tensor<  = %blocked%4tensor<tt.addptr386209x4  > = 4x%:
arith.maxnumfx3267        1x,tensor<%%xi 3246arg16f328%x = ,, , 66itt.expand_dims ## 32 %blockedttg:, %arg17>. #40 
slice<{dim = 2, parent = #blocked4}>tensor<ttg {:      >32.axis %
xslice<{dim = 0, parent = #blocked6}> = f3299      4>0
         = %x
 : tt.reduce.returnarith.subf165!      i   = tt%32%%tt.expand_dims.41}20997 ptr<i8> =   ,%, arith.remsi:: 164#   % {linear%tensor<f32cst_26axis13732
  = >,x      :2, i}  :  %32)tensor<itensor<39,  : 43232 #(x}x:ttgtensor<4 4 .4x:xtensor<slice<{dim = 0, parent = #blocked6}>x1 i32>4xtensor<64x x32f324, i->x, x#32 f32, #32linear, tensor<#blockedlinearx1#1>>i>ttgx) -> 
1
.32tensor<      ,       slice<{dim = 1, parent = #linear1}>x4%#%>ix100ttg.69
324 = slice<{dim = 2, parent = #blocked4}> =       , xarith.subf>tt.load%#f32  -> 42blocked, % % = 6#98tensor<68arith.muli>ttg,4  
.slice<{dim = 2, parent = #blocked}> x:%      >%32x 7%
cst_51tensor<,47       x32  = %:ix%tt.splat82 145  = tensor<, x %ttg.convert_layout4#!:arg10 xblocked4tt  %4>.i:81x
ptr<i8>64  :1      %, 
i x166#      32tensor<4f32 = linear% x, tt.broadcast143->4# > =  xblocked%
tt.make_rangetensor<f32>165       {1, 
 %endx#ttg      :70 = 32.%  = 64xslice<{dim = 2, parent = #blocked}>101 = tensor<4tt.trans : i>tt.clampfx i32  32%32, ->%x69, # 991 {startblockedtensor<4,xorder = 6x i = 0>4%1array< : 
xcst_25, ii      f32,#blocked3232%,  4: }48#ttg%>1  = .cst_24 , :arith.mulislice<{dim = 2, parent = #linear}>,->0  >  >tensor<%
propagateNantensor<}6446       4 x,%=x:i 83 32 32% = nonextensor<, 47tt.expand_dims  3232# %:xxttg:82 i4.  {tensor<1xslice<{dim = 1, parent = #blocked6}>tensor<axis4, i>1 = x#8
x24blocked,       32 : x4#%xi1>linear44i32x
1 = 32} f32      >tt.expand_dims, : , %  #tensor<#167->%blocked4linear =  436x4>tt.trans tensor< {>x
%4axis
f32      166x =       , % {321%#102orderx : 49ttg =  = ii = .tt.clampfarray<832arith.extsislice<{dim = 2, parent = #linear}> i, } >%32# % 100: ttg:48-> , 0, .  tensor<%2slice<{dim = 2, parent = #blocked4}>:tensor<4cst_18, > 64x,1
tensor<x4 >      1ix%}%x321cst_23 7132, x,:  = x#f32 tensor<tt.splatittg, propagateNan4 32.# x%, slice<{dim = 1, parent = #blocked6}>linear>=32x29#>
 32 blocked       nonex:6->% i1 > 84 = :, ! tensor<tt.expand_dims #ttto64 tensor<blocked. x%44>ptr<bf16>tensor<181x4  1x {x->->xiaxis = 1  32322xtensor<tensor<x,  : f3244i#i32, xx64blocked} #32128, 6:blockedx32x#> >x!blocked
tensor<
itt6      4x      1.>%4%, ptr<bf16>
45x103#,        = f32 = blocked#%arith.extsi, arith.fptoui9>blocked50 #ttg 
1 = %.slice<{dim = 2, parent = #blocked}>%      >tt.broadcast44> 101%168
  ->  =       %: :tt.reshape%45 tensor<  72 tensor<4xtensor<% = :644x4167tt.addptr x1x  tensor<1x4:%64xf32, x 71xi#blocked1tensor<,132>x4 x, 
f32x%i#      , 322864blocked%85#x32 , 6 = linearx:#>tt.bitcast>i blocked   1tensor<6to%83to, 4>   #x tensor<:tensor<blocked128->64 49>x xtensor<x !tensor<144->tt64xxx .xi4x1tensor<ptr<bf16>32641x128x, x, xi832#i#f32, xblocked64blocked, #i1, 6#linearlinear1>#>> >, ,blocked
->
# 6             blockedtensor<>%tensor<%54
464x104>
x       = 4x =       128%tt.expand_dims1arith.fptoui%x51 x 169i = %i% = 64tt.broadcast 4032, 102arith.select, % {#linear  #49axis>:%blocked  = 
 1681:0      tensor<, >  : %4%
tensor<i86 = xcst_21      132tt.bitcast4, %x} x%7332 %841163 = x: :x : tt.loadi  f32tensor< 64tensor<tensor<, 128%, 324x#x72#x4blocked>32 blockedix x:6321toi >, x 1tensor< #f32tensor<, 4->ttg, 4#x .#xblocked128tensor<slice<{dim = 0, parent = #blocked6}>blocked45x64>> x>!x ->1, tt32x-> xtensor<.i tensor<i128xptr<bf16>64tensor<4832, , 1x4, x##xx1#bf16blockedblocked32xblocked, 16xi>#>>i32
blocked

32,       5            , #%>
%%#blocked>105 =       7452blocked
arith.addi% =  = 6       170tt.splatarith.addi>%87% =   
 = 103ttg.local_alloc%%      arith.addi, 5350%  % ,47%85%169:  = ,cst_29  %tt.splat  :!51 %: tt %cst_28 (.:arg10 :tensor<tensor<ptr<i8>   4128 tensor<:tensor<xx->64 4x432 xi4xxxtensor<323211bf1664x xx, xi->ii#3264 32, 8blockedx, tensor<#linear, 5!#1>#>ttblockedx
      linear).632%88> -> ptr<i8>>x = 
!, 
iarith.addi      ttg#      32 %.blocked%, %106memdesc<128x32xbf16, #shared, #smem>653#86 = 
> = blocked, arith.addi      
tt.addptr6% %       >cst_1%104171%%
 :, = 75arg1        ttg.local_load = ,%tensor<% tt.addptr 484cst% % = x 170 %42arith.muli4:: 74  x1 !ttg,:%xtensor<.  46i4memdesc<128x32xbf16, #shared, #smem>%!,32, x 52tt #4-> .%blockedx :ptr<i8>47>1tensor< , 
x128tensor< :      ix64i %832x64tensor<89, x32
1 = #bf16x      xtt.bitcastblocked>, !%32 
#ttgtt54x%      .. = i87%dot_op<{opIdx = 1, parent = #blocked3}>ptr<i8>arith.extsi32 107>,  , : = 
      #%# arith.subf%blockedarg14blockedtensor< 1726 64% = >:>xcst_6tt.dot, 
4x,  i      1 %155tensor<32%x%,64 49i32102 xto = ,  %32 arith.extsi#linear:171xi >  ,i64%-> tensor< 64
48tensor<4%,        4xcst_3#%:x4 blocked55 4x:6 = tensor<x11 >arith.muli1xxtensor<
 xif324      %3232, x%7x, ##12876,ilinearblockedx =  32>>bf16tt.load%, 
      
,  54#%90      #% blocked = %ttg75:6tt.bitcast108.dot_op<{opIdx = 0, parent = #blocked3}>  >  = >cacheModifieri %88math.exp2  64to : *=
  %        tensor<tensor<107tensor<128cg%14x x 56x4:32: = 32x x tt.addptrx1tensor<bf16tensor< ix4, 64%64i32x#xarg3, , 4ttg32,##blockedx.x blocked> 1dot_op<{opIdx = 1, parent = #blocked3}>!%6->x> tt55> f32, ->. 
tensor<# ptr<i8>:      4xblockedtensor<,  %4>4x#!50x
32blockedtt = 1      x6.tt.broadcastx%f32>ptr<i8> i109, 
,%32 = #       45, arith.extfblocked%i #blocked 37764:>%> = 
 
78
      ttg.convert_layout      tensor<       % %64%:173%57x91 =   = 76 = 1arith.anditensor<arith.addf tt.expand_dimsx 4 : %i%89x% 4164,4172tensor< {,  x,64axis#%32 x = blockedcst_27x%3216 bf16cst_3x : >:,  ii  #:832->tensor<blocked , } tensor<4x>tensor<# 644x 4blocked:x1tox6 32x 32>tensor<xitensor<x 32i32, 4f32->x64#linearx,  i, >
4#tensor<32#      xblocked64, blocked%323x#692 = x>32ttg>arith.andi f32
x.
%90,       islice<{dim = 1, parent = #linear1}>      ,#%8>% blocked174 = ,  51%>arith.truncf#-> = cst_4
 blocked tt.broadcast :      %3tensor<  %173>32%tensor<110 
x494 = :      1 x4tt.broadcast %x:x tensor<78i 1%4 = 32tensor<x108xtt.reshape, 1i 32 #x32, : x%linear32#blockedtensor<f32731x>
4,  >i      x#:
64%4blocked       , 93 = x3tensor<%#tt.bitcast1>458blocked x tox = 6%91f32 128tt.splat> :, tensor<x   #4bf16%->tensor<blockedx, arg15 4x>32# tensor<4x xblocked:641->bf161 xx , >i32itensor<# 32x324blocked-> i, x3 ->64#4>tensor< , linear>x
4tensor<# 32      %x32blocked-> x1754xx6tensor<f32 = 321>4x, arith.extsixx
4# bf16i      x1blocked%, 32%x>13#, 52f32
 blocked# = ,       :>lineararith.addi#% tensor<
1 linear1114      >%> = x%
50
arith.mulfi79      ,       32 = % %%, math.absf59%94 = 109#  = 51tt.bitcast,ttg%arith.muli   .78 :%%slice<{dim = 1, parent = #blocked3}>> % 92110 :57tensor<  to ,64: : tensor< xtensor<4 tensor<4%32xtensor<4x58x4x4x4 i1xix:64x46432 , ix, xtensor<#3232#bf1632blocked, xttg, x6#f32.#1>blocked, slice<{dim = 1, parent = #blocked3}>blockedx
> #>>i      ->blocked

32% >            , 53tensor<
%%# = 4      176 = 80lineartt.addptrx4%arith.extsi = 1 x112 %arith.extf>%1 = 11 
arg1xtt.bitcast %      ,f32 :79% , %  60%#111i: = 42blocked 32 arith.extsi >
: tensor< :       to4% %tensor< x59!954i4 tt = x64x:.math.log24
32 ptr<i8> x      xtensor<,%32%bf1632 93x177, xi f32 = #164:, tt.splatblockedx
 #blocked >i      tensor<>%176 32%4x  to, 544x->: # = 1  tensor<lineararith.extsixtensor<i41 f32464x>%, #x 4 arg14linear4->xto >x 32 :
      32tensor<xtensor< %96x4f3232i = ix, x32math.log232i#1  , 64blockedxto%#, >i 94blocked>#
64i :
ttg      , 64       .%#
tensor<%slice<{dim = 1, parent = #blocked3}>81linear      4x113> = 1%4 = 
">55x1arith.andi      %t
 = x 178 = t      arith.mulif32, %arith.addi.% #blocked112 r61%>,%e = 7
 177dtt.make_range,      %,u { %cst_7 cend%97 %e = 54 = : 175"4 math.floortensor< ( : : 4:%i %x 8032i954tensor<), 64 x4 <start
:32xi{ =        x64axis0%tensor<i,  =  : 56432#2i = x, ttg : 32tt.addptr4#.i} xblockedslice<{dim = 1, parent = #blocked3}>32 %1>>}:arg3x

> ,f32,              (tensor< #linear%%{4%>114179
x55
       =  =       i %98arith.shruiarith.extsi^bb032: =   (,  math.floor%%%#! 11232arg16ttgtt%, : ..96 : f32slice<{dim = 0, parent = #linear1}>ptr<i8> :%tensor<, >, cst_832%
 tensor< xiarg17      i4x:32: %644 , f3262
x1tensor<#ttg) =       x4.:tt.broadcast%f32xslice<{dim = 0, parent = #blocked3}>
 57, 4>        % = #blockedx %60tt.expand_dims >32to209 %
x  = :41      itensor<arith.maxnumf  {%3232 tensor<axis99, #xi%32 =  = blocked64arg16x1arith.subf>, ,1 :  
# xi%      ttg%i3297%.arg1764},115slice<{dim = 0, parent = #blocked3}> ,    = >:#:%arith.andi
 linear cst_26       f321tensor< %%
>32:114180         x , = tt.reduce.return->itensor< arith.extsi  324x% %tensor<, 4xcst_9%20932#1 30  xttgx:::4.f32   xslice<{dim = 1, parent = #linear1}>, tensor<if32i>#linear432
64 >x       , ->
      4to}# %x )lineartensor<100 = 32i : 132arith.subfx64
(>x i      tensor<
1%32, %1814      x98# = x%i,blockedtt.splat46332 > x = , %
%32tt.expand_dims #cst_5      180 x%linear %:f32611:116 ,  {>  = i#axis
tensor<arith.andi64blocked =       4  >0%x%->) ->  : i584x112 tensor<32 = 1,tensor<4}tt.splatx 32x  f32%x4:%, cst_10ix arg15#blocked 64f32tensor< >:, , 4:
       ##x %tensor<ttgttgii1014..3232 = xslice<{dim = 0, parent = #blocked3}>slice<{dim = 2, parent = #blocked}>,  tt.clampf4>>#-> x

ttg %32            .tensor<99x%%slice<{dim = 0, parent = #linear1}>32,i18282>x 32 =  =  1%, arith.addittg.convert_layout->xcst_25# %  i,blocked181%tensor<32 >,811, %
  x#cst_24      %:4linear,%179 x1 117 tensor<i>propagateNan = : 432
 arith.additensor<x,       = 324#% %xxlinear59none115i64f321 =  ,, , >arith.muli: ##
  %ttgttg      %tensor<cst_11..%574 slice<{dim = 0, parent = #blocked3}>slice<{dim = 2, parent = #blocked}>64, x4:>> = %x 
 tt.broadcast581tensor<      ->  xf324% %:, #x183tensor<63 linear>4 = 4 tensor<
      xarith.mulix:32%32 4 x102 = x%xtensor<1tt.clampfi7f321x 32,, xi%,  #432100,#%ttgx,  blocked6.i#%> slice<{dim = 2, parent = #linear}>32linearcst_18
:>, 1,        
#>%%i      linear
cst_2311864%1      , = 
83>% propagateNanarith.subi       =  60  %tt.expand_dims-> = = %184  arith.extsinonecst_12 = %tensor<  ,tt.addptr8232x%:   {459 %%axisx tensor<117arg2 = i:4x ,232 4:  : , tensor<x %i#321tensor<18332linearxx4 }11f32x: >x, 4 :
i#x!       32blocked>32tttensor<%, 
      x.465#%iptr<bf16>x = linear10332,4arith.extsi1 = ,  x >arith.fptoui#i64f32%  blocked
, 64to%>      #  101
%ttg:tensor<       185. 32:% = slice<{dim = 2, parent = #linear}>tensor<x 119tt.expand_dims>321tensor< =   xx4xarith.cmpi%->4i4 178 x64xult {tensor<i, 1,axis432#x  = x, linearf32, %14#1#linear115 : ixlinear>>,3211
  }x>      to% :f32 % cst_12 , to61tensor< tensor<4#  = 4: xilineartensor<tt.make_rangextensor<64>32 {44, 
xendxx#ttg      4 = 14.%x4xxslice<{dim = 1, parent = #blocked3}>>84i : i32  = 64i8x->tt.expand_dims, 32, #i  #, linear32tensor<%linearstart>
, 4811 =       #x {>0%104blocked1axis
 :  = >x =       iarith.fptoui 
i2%32%102      64 : 66} :%, i =   120#32arith.addi:tensor< = blocked3}  4xarith.shrui> %tensor<4x 
:6541%       ,xx116%tensor< if32,1864%32,   = x62, #blocked%arith.extsi 4 #>cst_11 %x:ttg to:arg13f32 .   , tensor<slice<{dim = 0, parent = #linear1}>tensor<tensor<:#32>44 ttgx
xxi.4      44x32slice<{dim = 2, parent = #blocked}>x%x32 >i621xto 64 = xi ->, tt.broadcasti32i # 8, 64tensor<linear%, #
4160#blockedblocked      x> >>%4
:

187x                    = 1%tensor<%%tt.expand_dims x6732105121%f32 = x =  = 175, tt.splat1arith.addiarith.ori {# x  axisblocked%i%103% = >5664,1201
 ,  , :       :#% %i% linearcst_29cst_133285!1  } = tt>:: tt.bitcast.   : ptr<i8>->tensor<tensor<4 %  4xtensor<83->tensor<x444  32xxxi:tensor<x13264 324xx, tensor<xxii#44i8, 32ttgxx64#, .4!, linear#slice<{dim = 1, parent = #blocked3}>xtt#>
blocked>1.linear      > xptr<i8>1%
->f32, >106 =        , #
arith.addi %tensor<#linear      %1224xlinear1%104 = 1>>63,arith.shrui x 
 =  %i->      tt.expand_dims%12164 % cst, , #tensor<68% %blocked4 = 61:1183>xtt.addptr {  
4 axistensor<:      x1% = 4x %x6704tensor<188i, : x4 = 32 i1xarith.muli, %32x4 #66}ix%linear  8, 32186>::#x,
  blocked>i       tensor<tensor<
32%%324      %, 17686xx107 = #  = 4iarith.subfblocked:tt.bitcastx32 >  !, %
i%tt#cst_6,      6484.ttg %
 ptr<i8>.%123      :, slice<{dim = 0, parent = #linear1}>102 = % #> arith.select189tensor<linear :  = 41-> %tt.splatx> tensor<4119 4,tensor<x4, %186x 1x% 1tensor<x1122:x324x,  f32xxf32%i, 4i, 11664#x32#blocked :  blockedi, >tensor<4->>64#
      x  , linear%4tensor<4->#1108 = xx linear>math.exp2321tensor<1
 xx4>      %iix
%1071644      64 , , x% = :##169tt.broadcast blockedblockedx =  tensor<>3itt.load%4x, >32 634tensor<
, % x14      #68: xx%190blocked :f324 = >tensor< , xarith.muli
1tensor<#32       x32blockedx%%4x>i18987x4
      32, = ix%,  arith.addi32!tt109 = #% , .arith.extf blocked187%#ptr<i8>%> 85linear, 78
:,1#         >linear:%tensor<% 1 1244cst_28->>tensor< = x  
4arith.maxui1:tensor<      x x 32%4x%itensor<x70321156444 = x,, xxtt.transbf16 #4i , #%blockedx32%blockedcst_1431, 69> >
x# { :      ilinearorderto %321 =  tensor<191, >array<tensor<4 = #
i4xtt.addptrlinear      32x4 >%: 4x%
651x32184       = , 32x,%arith.extsi0xi 88 >f32, 32%188 = %}#,  arith.addi64 blocked#blocked:  :>> %: 

      !86 tensor<      %tt,tensor<32%125. 32x110 =  = ptr<bf16>%x4tt.broadcastarith.subi,cst_14x    xi%%i:i810812464 32,  :,
tensor<, #        4#lineartensor<4%%xlinear1x4cst_1419241>x  = x> 1:tt.expand_dims1 ->x  xto f32, tensor<%i tensor<#418232tensor<4blockedx {, 32x>4axis#x32 ->x = blocked4x 320>xitensor<4x : 
i8x4ii      64, x3232%, #32, }89#ttgx#  = linear.f32blocked:tt.bitcast1slice<{dim = 2, parent = #blocked4}>, >  >>#blocked
tensor<%

>
      3287                  %x %%%111126i:6671 =  = 64  =  = arith.mulfarith.shli, #tensor<arith.additt.splat  ttg4  %109%.slice<{dim = 0, parent = #blocked3}>x%%,125>46529 , x, %110 ->1 : % x% :cst_15tensor<i62!  132 tttensor<:x, :.4x 32# ptr<bf16>4tensor<xlineartensor< x4i>32x->32x64 4 x4, ->xtensor<f32, x# i4#32blockedtensor<64xblocked>x34, 128
i>x#x      32
4linear!%,       x1tt112 = #%1>.tt.bitcast blocked193 = x
ptr<bf16>%111>tt.broadcasti      ,  :
 32%#       %, 67blockedtensor<%190# = 14x127 lineartt.splat>4 = :> 
xarith.shrui 
%      32 tensor<      56%x%4% 72f32, 123x90: = #blocked,1 =  tt.addptr>  xtt.bitcast! -> %i tt%tensor<cst_1664%.714 , #88ptr<i8>,x:blocked   4x 3:->%32tensor<>   28x4->tensor<tensor< ix 432:324tensor<xx , x444xtensor<#32xx!4blocked>x321ttx
      ixx.128%32i64iptr<i8>x113, , #32, ! = #blocked, #ttarith.andiblocked3#linear.ptr<bf16> %>>blocked1, 112,
      
>># %       
blocked%128%->      1cst_7 = 194 %> :arith.ori = tensor<68,  tt.expand_dims4x =  tensor<% 4tt.addptrtensor<4126%x 4x,1791%x4x  {x6712832%axisi,xx127 = 32 ii 0, %6432: : i#66, ,  32blocked ##tensor<}>:blockedblocked>4 
 1
x:      tensor<>      4x %32x
%32tensor<914      114x32 = x% = ixarith.andi!73arith.shrui32i tt =  , 64%.tt.load%112#, 89ptr<i8> ,blocked#,, % >ttg #72%
.%linear cst_8      slice<{dim = 0, parent = #blocked3}>cst_271: %> > :129 :,tensor<  = ->  4tensor<arith.addi tensor<tensor<x4 tensor<432128x4%1xxxx128,x44!32 32xxttx%x1i.icst_11i64x64ptr<bf16>32,  , i, , #:#32##blocked blocked, linearblocked>tensor<3#1>1
4>
linear
>      x      >      
%4x%
%      11532195      69% = x = % = 74arith.andi itt.broadcast92tt.load = %32,   =  tt.splat 114,#%arith.andi%% blocked194 6853%> %  cst_9
:90:: :       ,   %tensor< tensor<!tensor<1301%32tt4x = xcst_4x.4arith.shrui32 4ptr<i8>x32 x:x x%i !->i12964tensor<tt 32,, 4.tensor<64, # #xptr<i8>x32blocked%blocked4, x>cst_113x#!
 >1lineartt      : x1.% ->i>ptr<i8>116 = tensor< 32
, arith.andi4tensor<,       # x44#%blocked%xxblocked706112,3232> = > xx
tt.trans
%ii             cst_103264%%% :, , 936975 ## =  { = tensor<4blockedblockedtt.bitcastordertt.addptrx>3  =  4x
>
%array<%32            91i74x%% 32,i32131 = 196::  , #arith.minui =  1%blocked tt.addptrtensor<, 52>% 40 
      130%x>:%,191,4} 117 =   x tensor<arith.addi %%1:64%115cst_22180x x,  itensor<32 ::3232x%  , x!cst_11tensor<4!#4tt xttlinearx.:4.>iptr<i8> xptr<bf16>, 8, tensor<32 ->, #4xxi #blocked4xi64tensor<linear63232
41>x,       x>,i#%4  32, blocked197x->tensor<#blocked> = 1 64>
arith.addixtensor<x32
             f324x%%%, xi118132195#3264 =  = ,linearx, arith.subiarith.shrui >i#  %
8blocked%%193      , 6cst_12113 %#>,,:94ttg
    = .      %%tensor<tt.bitcastslice<{dim = 2, parent = #blocked4}>%117cst_174 >76  x%
 = ::3292      tt.load  x % tensor<tensor<i:71%4x464  = 754xx, tensor<tt.splat 324#4 cacheModifierxxblockedx% i323429=32, x>x  #blockedi
1: cg>32      x! 
      , %itt:%#19832. 119 = blocked = , ptr<bf16>tensor<arith.cmpi>arith.extsi# 64 
 blocked->xult      %> 32,%arg4 tensor<x 133 :->4x!% =   128tt115arith.oriitensor<x.,  324!ptr<i8>%% xtt, cst_12132to 4.# :,ixptr<bf16>blocked  641, 6tensor<4%
x#>x131      f32blocked
4x %, 1      32:199#>%x  = blocked
77itensor<tt.splat>       = 324 
%ttg.convert_layout, x%      72 #blocked4198% = %>
x 95tt.addptr76      32: =   %120x math.log2%: = ii 71 arith.shrui3264%,tensor< ,  93 64%#-> %x116blocked :2832, >tensor<  x%
4tensor<:icst_11       x4 8:%1xtensor<,  134x44#tensor<4 = ixxblockedxarith.trunci64112864x , #xx>32%blockedf32! x1333, tt->i >#linear. 32:
>ptr<bf16>tensor<, #       
, 64blockedtensor<%      #x>
4200%blocked32      x = 961x%1214arith.cmpi = >i = x math.log2,8arith.ori32slt  ,  x,%tensor<#%i 944blocked12032% x3,, 185:128> #, x
%blocked tensor<i      cst_13>%464%  199x, 78:to 4# =   :xblockedtt.reshapetensor<tensor< 11 4x4tensor<x>%4x4f32
73x4x1,        32xx#%:x32iblocked73 ix64> = tensor<32i, 
tt.load4, #8#       xblocked>, blocked%%128
      #39772x%122blocked> =  :bf16 = >
math.floor , arith.shrui
       tensor<#       %%4blocked%121%20195x1,135 =  128>  = arith.extsi:x %118tt.reshape  !-> : %tensor<tt.  %arg54ptr<bf16>tensor<tensor<134 x, 44x :4#x4:  xblocked4xtensor<i11x32432x>32xx f32
xi324xto,       bf16, #32 #%, blocked>xi64linear74#
i
> = blocked      8      
tt.splat>%123, %       
 = #202%%      arith.selectblocked = 9853% >tt.splat =  79%  math.floor: = 119->%  math.absf,  201 %! %122tensor<:96tt%, 4  .78%xi:ptr<i8> 116464  : : x ->tensor<-> tensor<16 4 tensor<4xxtensor<xtensor<44x21x464x32x32xx4xix132xi8i64xx321, , f32!x, ###, ttbf16blockedblockedblocked#., >73blockedptr<i8>#, >>>, blockedtensor<4


#>x                  blocked
4%%%6      xoutLHS20399>%32,  =  = 
80x%arith.cmpiarith.subf       = ioutRHS  %arith.extf32 = slt,%75 , tt.split 97 = %# %,tt.addptr79blocked%135192   > ,%%:
      : cst_2674 % % ,tensor<124 = tensor<202: 4arith.maxui4  %x x:tensor<524%4 4 x115xtensor<x:32,1614 x xxxtensor<bf16%232164, cst_14xxxx# iif3232blocked:864, x> , , #! tensor<4##lineartttoxblockedblocked>. 4x73
ptr<i8>tensor<32>>
      , 4x       %#xi32->%100blocked4, # 204 =  = 6xblocked>tensor<4tt.broadcast arith.subf>32
x% ,x      4200 % f32%x:98tensor<, 125 = 16 ,64#arith.subixtensor< xblocked i4%32>%1248xcst_5x
,, 1 i       %#x:64%cst_14blockedi1 , 81 2, tensor<# = : >#4blocked"ttensor<4
      blockedx6tx4%34>.x136>x
r32 =  1      exarith.shli->x%di32  f3276u, #%tensor<,  = cblocked>outRHS4#tt.load e
      ,xblocked%"% 32>75(126 = %x
 %arith.shlicst_2i      cacheModifier80  1% )%:, 101= <{125 #blocked =  axis,tensor<3tt.clampfcg =  4>  :2%x
      %  : cst_154%99tensor<i x205,6432:16 =  x} xtt.broadcast%32>tensor<4i cst_25x (x48%,!{x, 203 tt
32# %.      xblocked:cst_24ptr<i8>^bb0i322 ,, (, #>
tensor< #%blocked      1propagateNanblockedarg16>%x 6: 
13732=>f32       = x 
, %arith.oriinone      %127 1 %arg17 = %, :77: arith.shruioutLHS#  = f32 ,blockedtensor<ttg.convert_layout)% 34 :123%>x%
,136 ->476           x %%:tensor<1:209cst_16 4x  =  :tensor<xf32tensor<arith.maxnumf 432, 64 tensor<xx#x%4x4ilinear32arg164x1>x,x16, 
i 32x#      8%xiblocked%, arg17i83102# 32, > = blocked:, ##blocked
      tt.clampf6 blocked>2% >f32
      >206% 
%
       = 100->        128%arith.andi, tt.reduce.return = 138  tensor< arith.ori  = %%64%%tt.reshape204,cst_18x209126  ,32 , %% x:%137205%i 127  cst_238f32 : :,, 
: tensor<  #      tensor<4tensor<propagateNanblocked}4x4 3)x4x=> : 4xx32 
(3216xnone      tensor<xxi %4ii1:78x328,   = 4, , #tensor<tt.reshapex##blockedblocked4 32blocked>23x%x
>>473f32       
x , %->      1:#129 %x blocked = tensor<207f32tensor<>arith.addi 4 = , 4) -> %xtt.splat#xtensor<128,64 blocked1284 x%>xx%i196
bf164cst_118       , x :, :%#f32 # 103blocked, tensor<4blocked! = 1#x48ttarith.fptoui>ttgx>.  .32
      ptr<bf16> %->slice<{dim = 2, parent = #blocked}>x%->101 >i139  tensor<
32 = tensor<:4      , #tt.reshape4x x%blocked> 32tensor<482
%x4x =       %105!x32ttg.convert_layout130 =  tt4x arith.shrui:.xbf16%  ptr<bf16>, 1, 81%129tensor<#x# , 4blockedf32blocked:%x3>, > cst_11 4
#
tensor<:x      linear      4 1%>%xtensor<x208 7944i = to = xx48tt.addptr math.absff32x32,  tensor< , x#%4%#i32linear207x78ttg, #>,4 .blocked>  x:slice<{dim = 2, parent = #blocked}>
      ->%1 >% 197xtensor< 131tensor< i4-> = 4:8x arith.minuix , 4tensor< 4tensor<#x4%130x4linear32x,ix>x4 832
bf16x%, x      , f32cst_22#!%#,  ttgtt104blocked#:.. = >ttg slice<{dim = 2, parent = #blocked}>ptr<bf16>arith.fptoui
.tensor<>,        slice<{dim = 2, parent = #linear}>4x
#%%>4x      blocked10280
32%3  =       x140>:arith.extf%i = ,  8332tt.reshape tensor<% = , # tensor<479tt.expand_dimsblocked%1064x  > x4:%
:32x 82       x1tensor< {%tensor<ix4axis132 = 464f32x = arith.shruix4, , 42 x##x : %1blockedblocked32i113,x3>x32 i> bf16}%8
to,  cst_17 ,        #:: #tt.storetensor<blocked tensor<blocked 4>tensor<4x>%x 44 2084toxx32-> ,x 4xtensor< 1tensor<xi4%x4f3232x174ix, , 4,84##blockedx , xttg>i8%#32.
      , 206blockedxslice<{dim = 2, parent = #linear}>%# >f32>133linear:
,   = 2>       #->arith.ori 
tensor<%blocked %132      4105>tensor<,%x = 
      4 14132arith.addi%x%131 = x 814 ttg.convert_layout!% = x: tt103"1 %.,txtensor<140ptr<bf16> tf324x , %., 4x:#cst_29r#32 blocked elinearxtensor<3:d>i4> u
32x
tensor<c      , 4    4e%#x}x"84blockedi
4( = >
8    x%tt.expand_dims      , tt.return180 %#
x)%134 = linear  }i <81arith.trunci2
8{ { >}, axisaxis%133 
# =  =  ->
linear22: {-#> :  :  tensor<

iitensor<44        3232xxexternal%}}4x4_resources: {
106> 32x     =  (:ximlir_reproducerarith.addi{ i328: {
 
tensor<, ,       %      4#blocked#ttgpipeline104^bb0x>.: ,(4 slice<{dim = 2, parent = #blocked}>" %xto>b%arg16f32 
ucst: , tensor<      i f32#4x%l:, ttg4142 = t %.xarith.extuiitensor<arg17slice<{dim = 2, parent = #blocked}>32 n4: >x%.xf32 i141m4)->8 ox: , :d1
tensor<# ux        4blockedtensor<li%x>4e82094
x(,  = x      4o#arith.maxnumf1%xpblocked x135 = it>%f32tt.reshape8i
arg16,  , m      ,#%#i% blocked134ttgz107%> :.slice<{dim = 2, parent = #blocked}>e = arg17
 >-arith.subf       tensor<4 am :%x4tod% 85x -cst_6f32 = 32tensor<l,
tt.bitcastx4d          ixs%tt.reduce.return%84-102 83, xu % #blockedis:209:>16a    ->, gtensor<:tensor< #ttge4 4tensor<.{xf32x4slice<{dim = 2, parent = #blocked}>ld4
4x>sx      x4x
-1}116x      lx)x2%if32 : f32x143m, (tensor<, i8 = i#4#, #arith.shlitblockedxlinearblocked =>4>7%0
x >
142       32->      , t%x %%a108f32tensor<outLHScst_30r = , 4,  gmath.exp2#x%:e blocked4outRHS t%>x = tensor<-107) -> 1tt.split4a tensor<x xr:4i%1354c x32 :xhtensor<4,  i=4x#tensor<16gxf32linear4, f4, >x#ttgxx#
4x.91ttg      16xslice<{dim = 2, parent = #blocked}>5x.%2>0f32slice<{dim = 2, parent = #blocked}>86x
}, > = i      ,#
tt.bitcast8% blocked       , 144t>%%#blocked = r
82847>tt.bitcasti       =   -> t%ttg.convert_layout: %o109  tensor<143n = %tensor<4x -arith.extf8144:s  xx c%:416tensor<f-78 xx4t tensor<1i8xo:4x, #4- xf32blockedxctensor<4, 2>if4x#
16,xf32blocked      ,  4, >%#cx# 136ttgo32ttg-> = .nx. arith.shlislice<{dim = 2, parent = #blocked}>vebf16slice<{dim = 2, parent = #blocked}>tensor< > r, >4%->t-# xoutRHS, iblocked->4 tensor<n> x%cst_24d tensor<1 :xeto4x 4x xitensor<x-tensor<4324bf16t4x, x4, oxf32#x#-4, blocked16ttglx#>x.l32ttg
i8slice<{dim = 2, parent = #blocked}>vx.      , #>mf32slice<{dim = 2, parent = #linear}>%blocked2
{, >87>
      i#
 =       %nblocked      arith.addi%137145d>%  =  = e
83%arith.ori tt.expand_dimsx       = 85% -%tt.expand_dims,outLHS,%b110   144i = %%% {ttt.broadcast82cst_28136axisw  {  : = i%axis: 2d108 =  tensor< : t 2tensor<4xih: : 44x32= ix16}0tensor<324x },4}xi: x 1x8,  a4:i#tensor<lx 32blocked4l1tensor<, 2>xox4#
      4cf32xlinear%138xat, 4> = bf16e#x
tt.reshape, -blockedf32       #a>, %%ttg.m #88137slice<{dim = 2, parent = #blocked}>dg->ttg =  :>p .arith.addi  utensor<slice<{dim = 2, parent = #linear}> tensor<->-4>%4 sx 86x4tensor<h4->,x164ax  xxr32tensor<%i84ex4cst_1, xdf32x #blocked1-m, 4:2xe#x >bf16mblocked1tensor< ->, or>x4 #y
f32xtensor<blocked,      , 44> %#xx
c111linear164      o = >xx%narith.mulf
ii8146v       32,  = e%%, #tt.broadcastr10984#blocked8 t, = blocked>
%-t tt.expand_dims>      145r% 
% i110%      139:t 81% =  o: {89tt.reshape tensor<n axis = %4x-tensor< = tt.bitcast1054a42  :xmx : % 1d4i87tensor<4xgx32 x4bf16, p32}:x#ux  1blocked-f32:tensor<x>t,  4i8 o#tensor<x, ->-blocked44# l>xxlineartensor<l
41> 4v      xx-> xm{%f32itensor<44a112, 32x4xr = #, x32ctt.bitcastttg#ixh .linear8bf16=%slice<{dim = 2, parent = #blocked}>>, , g111> #ttg#f  ->.blockedx:-> slice<{dim = 2, parent = #blocked}>>9  tensor<>
5tensor<tensor<4
            044x%% xx4140147f44x =  = tzxx1tt.reshapett.reshape=t321x  rxxi%106%uf32f3232 :146e, , ,   }###tensor<4:,blockedblockedlinearx  >>>4xtensor<c 

14a->            xxn %%i84otensor<8590, xn4 =  = #32ixtt.bitcasttt.bitcastblockedxc4  >bf16ax%% ->, l328388 #ix  tensor<blockedzi::4>e32  x ->{, tensor<tensor<4  #44xtensor< blockedxxi4m>448, xa
xx#128x-      11linearxi%xx2bf16t113f32i>, e = , 32
      #raarith.andi#, %141blockedt linear# = 1io%>blockedttg.convert_layout>n112 > 
s,-> %      =  ->140%1%tensor<  1480cst_74tensor<: =   x4 amdgpu.scaled_upcast_fp4m:4xtensor<4 a x4x%xtensor<1x4138-4x1x nxixi8scaleu432i,  mx, 32#linear%-32#, 2147rxlinear#>  {ei>blocked->axisw32
>  = ri,       
tensor<41te#%      x : sblocked86%4i=> = 91x32-
tt.bitcast = i}1       arith.andi8,   %% #:r11484%ttg e =  89.tensor<giarith.shrui:,slice<{dim = 2, parent = #blocked}>4o   >xn%tensor<%
      64-1124cst_27%xs,x 142ii 4: = 8m%x arith.extui, pcst_81tensor< #l x4%blockedif:f32x1418y , 4 >=tensor<#x:,n4blocked1  orx>xtensor<tensor<m4 i4x4ax->324xl 32 , x128txtensor<#i8xei4linear, bf16, s32x>##t, 4
ttgblocked-#x      .slice<{dim = 2, parent = #blocked}>1cblocked1%>>on>x92  v
i = to->e      32arith.andi  r%,  tensor<tensor<g115#%44e = blocked90x4xnarith.andi>,x128c 
 ixe%      %16bf16=f114%cst_4, , a,87 ##l % = :ttgblockedscst_9arith.addi .1e  tensor<slice<{dim = 2, parent = #blocked}>> :%4>
t 85x
            otensor<,4%%p4 x143 = 149-dx%1arith.shli = o4cst_28xi arith.cmpiwx 32% n32:, #142eq=x blocked,,titensor<>  r324
%%u, x      cst_30139e#4% :,},blockedx93   >1 = tensor<4%c
xtt.bitcastxcst_31s      i 4 e,%32%x: 116, 91i c = # 16tensor<oarith.andilinear:, 4n > #ttgxv%
tensor<.4e112      4slice<{dim = 2, parent = #blocked}>xr,%x>
it 884      8-% = x%, ccst_10arith.addi1144#f  x = ttg-:%itt.bitcast .to 8632%143slice<{dim = 2, parent = #blocked}>-tensor<,,  :>l4 # 
lvx%lineartensor<      m{4cst_1>4x%ix  4150n32:->x = dx  itt.expand_dimseitensor<tensor<16 x3244, %-b, xx#149i#blocked44ttg {t>xx.axisw
11slice<{dim = 2, parent = #blocked}> = id      xx>2t%if32  : h11732, -> i= = , #tensor<4320arith.addi#linearx}} blocked>4 , %>
x:c115
      bf16 o,      %, tensor<n %94#ttg4ve%89 = .slice<{dim = 2, parent = #blocked}>xrcst_11 = tt.bitcast>
4t- tt.bitcast       xa: %%145ir %92 = 1itensor<87 tt.expand_dims, t4 : #h-x:  %144ttgt4tensor<tensor< {.ox44xaxis = slice<{dim = 2, parent = #blocked}>-l32x42>lx4x :  vmix1i->{321x32} i, xi tensor<nd#i32:4eblocked32,  xx->, #tensor<44b
#blockedx4xi      linear>x1t%> bf16xwi118 ->, id = -> #1tarith.subi tensor<ttg, h tensor<4.slice<{dim = 2, parent = #blocked}>#=%4x> blocked0cst_12x4->>},4x 
, x1tensor<4       %1xx%ca117xf324151no i, x = n:32#1tt.broadcasti , blockedx ctensor<#>bf16, %a4linear
#blocked150lx>      > i4
%95
      :zx       = % e{32%math.log2146 = tensor< x90 tt.broadcast 4 mi = %%145xa32tt.bitcast93 4x,   : x-#%:tensor<1iblocked88 4xxte> tensor<4xir
:411a       xx, t%tensor<4bf16#i1194x, blockedo = x1#blocked>narith.cmpi4x> s xf32 ->->=ult1,   10,x#tensor<tensor<  ilinear44m%32>xx4a115, 
4xxx,#      3232- blocked%xxn%>96bf16, iucst_12  = #1m ->math.log2blocked, -:  >#r tensor<%
      blockedetensor<494%>w4x 147 = 
rx4:tt.reshape       i4x %%tx1tensor<146152e32x4  = sxix: tt.reshape=i324tensor<4 -32, xx4%1, #1x151 #blockedx32 rblocked>f32x:e>
, bf16,  g
      ##tensor<i      %blockedblocked4o%91>> xn120 = 
->4- = arith.andi       xsarith.shrui %tensor<32i %974xxm%89 = 128ip116,math.floorx1l,  bf16, , i %%#blocked#fy%cst_27951blocked=cst_11  >>n ::
 o:        ->r tensor<tensor<% mtensor<44148 = tensor<a4xxamdgpu.scaled_upcast_fp44lx44 x t4xx%128ex11138xs32xx itxif32scale1-i32,  , c32, #%147#o, #linear {blockednv#linear>axis1erblocked>
 = >g>
      1
en
      % :       ce      %98i32%=f%92 = }153a121 = math.floor  = l = arith.andi :arith.selectsearith.ori %   t %96tensor<%o%90 4x152p120,:64, -,  x%do %tensor<icst_0wn%cst_448, , =cst_13 x#blocked%tr :48148u: x> : e tensor<1,tensor<}tensor<4x 4,4xf32tensor<x x4, 4128c4x#xxsx1blocked128ie32x>x1,xi
bf16, ,  i32      ##s32, %blockedblockedym, #9911>b#blocked = >, oblocked>arith.subf tensor<l>
 ->4-
      % xd      %97tensor<128c%93,4xe122 =  xbf16, = tt.bitcast%128,  arith.shrui cst_26x#e % bf16, blockedn%91:#blocked1a121  1>b,:tensor<>
l  4
            e%tensor<x%%-11844149154l xx =  = i:41arith.cmpittg.local_allocn xx  etensor<1f32eq,%-4x,  153ixi#% n432linear139:fx, >, o32#
 (,xlinear      %tensor< i>%cst_314c32 100 :xo, -> =  128n# arith.subftensor<xvblockedtensor< 4bf16e>4%x, r
x984#t      4,xblocked-%x i1b1231%8>u = xcst_5, )iarith.selectf32 #ttg -> l , #:.!t%linear slice<{dim = 2, parent = #blocked}>ttgi119>tensor<>.n-, 
4
memdesc<4x128xbf16, #shared, #smem>f%      x      
u122%4%      n, 94x150 = %c% = 1tt.expand_dims 155-116tt.bitcastx%149 = t :  f32 {ttg.local_loadotensor<%, axis -492# = %lx blocked2154l4:> :  vmx 
i:{32tensor<      32 ftx4%}!zix101 ttg=t14 = : .r, xtt.clampftensor<4memdesc<4x128xbf16, #shared, #smem>u#1 x eblockedx%4->}>i99x ), 32,itensor<"tensor<,  14,4#%, x
      xblockedcst_25#128disable_threading4>,ttg.x: x  slice<{dim = 2, parent = #blocked}>bf16false32->%>, ,
x cst_24 ->#      itensor<, ttgverify_each324 tensor<4.: , xpropagateNanxdot_op<{opIdx = 0, parent = #blocked3}>true#4 4>
blockedx=x1
    }>1 x      
  }
xnonei1%
      f32 , 156#-}%, :# = 
124# blockedarith.extui = blockedtensor<>
 arith.maxui>4      % /tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:0
x%70 %:       4151: 115error: %x = tensor<,Failures have been detected while processing an MLIR pass pipeline951tt.broadcast4x 
 = x 32%/tmp/torchinductor_root/t3/ct3t3fw7xnhqwm57kt7agtaxeqou6t67nnepo76oz4ssegp6addy.py:18:0math.log2f32%xcst_14:  , 150i8 note: %# , :Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`93linear:# 
 > ttgtensor<:
tensor<4.slice<{dim = 2, parent = #blocked4}>4       x> xtensor<%4xto441021 xx = xtensor<324tt.clampfi4xx 1, x32i1%#blockedxi32x100>16, , f32, ->##,   ttgblocked#%tensor<.>linearcst_184slice<{dim = 2, parent = #blocked4}>
>,x>
      
 4x      %      %32%157125%cst_23x =  = 96,iarith.shliarith.subi =  1  math.log2propagateNan, %156%  #,124%=blocked ,94 >%  none
cst_19%:        :cst_14 :%  tensor< 152tensor<4:4tensor< = x32 x4tt.reshapextensor<4x i4x4%16, x1x151#4x1 ttgxf32x:.slice<{dim = 2, parent = #blocked4}>32, f32 >x#, tensor<
      iblocked#[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 4, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank4]:E1110 11:31:41.210000 504 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
4x%32>blocked4158, 
>x = #      
32tt.bitcastblocked%      x >97%i%157
 = 1031,        math.floor = #:% arith.fptouiblocked 126% >tensor< = 95% ->4arith.shli 101 x32 : tensor<x% :4i125tensor< x16,4tensor<128,  x4x#%4xittg.cst_15x41slice<{dim = 2, parent = #blocked4}> 1x, >:x1#  f32xblocked-> tensor<, f321>tensor<4#, 
      4xxlinear#%324>linear153 = xx
>arith.select bf1632       %152, x%98to, #i =  %ttg32math.floortensor<cst_0.slice<{dim = 2, parent = #blocked4}>,  4, >
#%x%      blocked964148%159> x :  = 
:1tensor<4tt.expand_dims       xx %tensor<i128%15812748x { = x, iaxisarith.shrui4#1 =  xlinear, 2%1># : 123x
blocked1i32,f32      >, } , %tensor< %#1044x:cst_16blocked = 128  >arith.fptouixtensor<:
 %bf164       102, xtensor<% #32499:blocked1xx =  >bf164arith.subftensor<
      , x 4%#32x%x154ttg.i974 = slice<{dim = 2, parent = #blocked4}>32,xttg.local_alloc>,  1  #%x%->blockedcst_26f32153 > ,  tensor<
:#:4       blocked x%tensor<>(321284 tensor<x = xto4x1arith.ori4 128x xtensor<xbf16, %14bf16, #126xx#blockedblocked,f3241>4> , x)
%#1 ->       127linearx!ttg% >i.memdesc<4x128xbf16, #shared, #smem>160 = :
8
      tt.broadcast       , % tensor<%#155 = %4100blockedttg.local_load159x = >  4arith.subf
%:x       154 32%% tensor<4x98105:xi, =  3232 arith.addi!ttgx, % .1#cst_5%memdesc<4x128xbf16, #shared, #smem>xblocked 103 bf16>:,->, 
   #      tensor<%tensor<blocked4%4cst_294>129x x -> = 4:128 arith.addix xtensor< 1tensor<bf164x%x4, 32128f32x#x,, 4ttg32 #x.x%blocked1dot_op<{opIdx = 0, parent = #blocked3}>bf16cst_11>x>,  
i
      #blocked:      8%1564> %,  = 
      tensor<101#arith.extui%1614 = linear  = xtt.clampf>%tt.trans 4 
70%x%       :1603299%  {x,106tensor<order = i  = 4xarray<i32%arith.addi3232: , cst_25 x0, #,%i2blocked 1048, >%,, 1
cst_24 #>      ,%ttg} % cst.slice<{dim = 2, parent = #blocked4}>:130propagateNan >  =  : tensor<4arith.shrui= tox32  tensor< x%none4tensor<32129 x4xx,:432bf16  xx, #%tensor<1iblockedcst_114x164 xi, > :48#->  x, ttgtensor<4tensor<1#.x4xblockedslice<{dim = 2, parent = #blocked4}>32xxf32>>324, 

      xbf16x#      %157, 32linear% = #x>107arith.shliblockedi
 =  932      arith.subf%>
, % 156,      #102% %blocked = cst_6%162>tt.clampf,cst_19 = 
 %  tt.reshape       100%:%%,102 161131  tensor<  = %:4:arith.minuicst_18 x32  ,tensor<xtensor<% 4i164130%x, x32,cst_234#ttgx ,x.32% 1slice<{dim = 2, parent = #blocked4}>xcst_22propagateNanx>bf16,   f32
#:=,       blocked9  #%158>tensor<noneblocked =  4 >tt.bitcast ->x:
%157 4        tensor<xtensor<%:128x324108 32xx = tensor<xbf16i4math.exp24, #32x xblocked, 1%325>#x107x
      blockedf32 i%163>, :16 = 
# , amdgpu.scaled_upcast_fp4       blockedtensor<#ttg%%>4.slice<{dim = 2, parent = #blocked4}>77132
x> scale =       4  arith.shrui%x->%162 103 = 1  {%arith.fptouixtensor<axis = 113 f3240,%, x32 : i 101#x32}% blockedbf16 cst_17:>, :   
#ttgtensor<:tensor<      .slice<{dim = 2, parent = #blocked4}>64 4%>xtensor<x109
      3244 = %xxxarith.extf159i41  = 8xx%tt.expand_dims, #32f3278 blocked3x,  %>i#:158,32linear  { , >tensor<axistensor<# 4 = 128blockedtox2x> 4 : 32
tensor<xixbf16      43232, %xx} #1334bf16:blocked = x,  5>arith.ori1#tensor< -> xblocked4x %i>32tensor<1328 x128x,, tobf1632 # , xbf16%lineartensor<#ttg, 131>4.slice<{dim = 2, parent = #blocked4}>#blocked 
x>5>:      4 
 %x->      %tensor<10432 1644 = xtensor< = xarith.fptouif324arith.cmpi4 , x32 x%#xeq32102blocked1,xi >x 32:
bf16%,        , 70#tensor<%#blocked,blocked41104> >x = 
      %
4tt.broadcast%cst_20      x 160 %1% = : 134x108tt.broadcasttensor< = f32  4arith.trunci, :%x32 # 159x%blockedtensor< i133>4:8,   x #:to4tensor<4ttg  xx.slice<{dim = 2, parent = #blocked4}>tensor<tensor<132>
44xx      xxf321%44, x165 = xx#bf16tt.expand_dims321blocked,  xx>#blocked%ii 4>164328-> -> {, ,   axis = ##tensor<tensor<2blockedblocked44 : >>xxi32 
432} to      xx32: %32x tensor<105xbf16, tensor<4 = f32#blocked4xxarith.addi, 4>324 #
      xx%blocked%i32103>161 = 1x,
tt.trans, i        #8%%%160ttg, cst_29111 {.slice<{dim = 2, parent = #blocked4}>#  = order = > blocked:arith.mulfarray<->>  i 
tensor<%32tensor<      4109: 4%x,0x321354 %, x = x11021tt.reshape1 , x x:1i%i8 >}1, 134, tensor< :# #4 blocked4:linearxtensor<> >44x
tensor<
x32x      4      3232%166x%xx = 4106f32bf16tt.broadcastx = , ,  32arith.addi##%165x blockedblocked i%>4>:8104
  , ,      ->tensor<# % 4blocked%112tensor<x32>cst = 4x  tt.bitcastx1->: 32xx  %32i1tensor<tensor<111x, 44 bf16, #xx:#blockedblocked444 9>>xxtensor<
       ->1614%162 xxx = tensor<2i4tt.reshape 4x8x%x32i, 32161x8#x :32, blockedf32 xi#>, tensor<1blocked
#4x, #7      blocked32blocked>%>x4
107 32>       = ->x
%arith.subf bf16      outLHS tensor<, %, %4#blocked167%cst_6x9 = outRHS,4> tt.trans  =  x->%tt.split%32 166 102xtensor< {% i128order135:32x =   , 32array<i:tensor<#xbf1632 4blocked, : tensor<x>#blocked0, 44
5>2xx      
      , 41%%1xx113163 = >16f32 = amdgpu.scaled_upcast_fp4}x, arith.andi  2# %: xblocked%77tensor<4i>112 x328
,scalex,         32#%%%162xblocked108cst_7 {i7 =  axis = 1>math.exp2:0,     : #->%tensor<i32blocked 1074} 4tensor< x:>4:4  x xtensor<-> 4tensor<3264tensor<4x4xxx3216xi32xx432x32ix, ix81#8i, xblocked, #1#f32>blocked3, blocked, 
>,#2#       blocked9>blocked%tensor<>
>114128
            
 = x32%%      arith.shruix168 = 136% bf16, tt.reshape = 109%# arith.shli = 112blocked% arith.extf,5167%  > :outRHS%%  ,78cst_8->tensor<    4x%::tensor<32cst_2  128x tensor<tensor<x32:4432x xxxi1tensor<44bf16, 4xx, #blockedx3232#blocked94xx5>xbf16i> 16, 32
->x#, #       iblockedblocked%tensor<8>>164 = 128,  
arith.cmpix32#to       xblocked %eq,i2tensor<115 1, >4 = %#
xarith.andi70,blocked      4  5%x%%>
13732114cst_20       = x, %arith.orif32 : 169 , %tensor< = %#cst_94arith.selectoutLHSblocked x32 ,>:x% 
 i168, %      tensor<8, %136%4#ttgcst_21 110x., : = 4slice<{dim = 2, parent = #blocked4}>% tt.broadcastx>163tensor< 32
       : 4%x%tensor<x108i165 = 1284 32tt.expand_dims x32x:, %164x16 # {i1xtensor<blockedaxis, #i4> = blocked8x
25, 4       : >#x%i32, blocked1x116}tensor<2f32 =  128x>, arith.andi:32
#  x      blocked%tensor<bf16, %>1124x#138 ,32blocked5 = -> x>tt.reshape %i
       tensor<cst_101%170%4 ,  = 137x:#ttg.local_alloc 4 ttg. :xtensor<slice<{dim = 2, parent = #blocked4}>%169 324>  tensor<xx->:4f324  x, xtensor<(4#324xtensor<xblockedx32x12816>i1xx
      32x32i%, ix8111 = #1, bf16, arith.mulfblocked#blocked, # >4#blocked%
>blocked2109      
      5>,%%>)  117166 -> ->% =  = ! 110arith.additt.broadcastttgtensor<   .memdesc<128x32xbf16, #shared, #smem>4:%%
x 115165      64tensor<, %171x4 :  = ix%tensor<ttg.local_load 84cst_114x%, x 32x170#32:1 :blockedx x 8f32tensor<i!>, 41ttg
#x, .memdesc<128x32xbf16, #shared, #smem>      blocked4# %>xblocked4-> 139
32>tensor< =       x 128tt.reshape%i->x32 11232 x% = , tensor<bf16105tt.bitcast#4,   blockedx32#:%>x32ttg 111
x.tensor<       idot_op<{opIdx = 1, parent = #blocked3}>4:%1181>x  = , 
      4tensor<arith.subi#%172x4 blocked = 1x%4tt.dotx4cst_12> ix,
%832       155, x%%,#f32117167 linear,   = %171>#: tt.trans, blockedtensor<  ->>4%166%  x {cst_3tensor<->4order =  4 xarray<:xtensor<32i 44x32tensor<xxi: 4xi43201288x, , x, 32#2bf16#xblocked, , ttgi>1#ttg.32
>.dot_op<{opIdx = 0, parent = #blocked3}>slice<{dim = 2, parent = #blocked}>,       }>>#%  
blocked119: *      > = tensor< %
arith.cmpi4tensor<140       x128 = %ult32xxtt.reshape113,3232  =  xx%arith.andi%ibf16106 1151,  %,, #:112 #ttg ,%blocked.tensor< cst_124>dot_op<{opIdx = 1, parent = #blocked3}>4%  >xcst_7:-> 4   ->x:tensor<tensor< 1 44tensor<xtensor<xx4i4432xx8xx3232, 432xx#xxif32blocked32i1, #>x32, blocked i, #3->32#blocked> , blocked9
tensor<#>>      4blocked

%x>            173 = 4
%%arith.addfx      120168 i% =  = %8114arith.shruitt.reshape 172,  =  %,#arith.shrui%167 linear 116 :%2%, cst_3>112 tensor<4 
,%x:       cst_1132 %% xtensor<141cst_8:324x =   x32ttg.convert_layout:tensor<i1x  4, f32%tensor<x#, 14044blocked# xx9>blocked:432 3 xx->>tensor<32i 
      4x32tensor<%174xi, 128 = 432#x32arith.truncfx, blockedx i#>i%8blocked
1173, >      ,  #
%#blocked:linear      1215> 2% = 
      tensor<4>115arith.ori%x32  =  169x->arith.andi%120 = f32  ,arith.select, #tensor<%  blocked4114%%3x,cst_13168, >4  % x%:cst_21, toicst_9  % 8:tensor<163 : tensor<,  4tensor<4#tensor<x128xxttg443232.xxxxslice<{dim = 2, parent = #blocked}>432ibf16, >xx1#blocked
32i, 3      x32#blocked>%i, 5
14232#>       = , blocked, %175arith.extui#>tensor< =  blocked
128arith.extsi%>      x 141
%32%       122x13:% = bf16  116arith.shrui, #:tensor< =  blocked5 4arith.andi%>
tensor<x 121      44%,%170xix112  = 32i,%ttg.local_alloc, 8 118 #, % %ttg#cst_10:169.ttg   :slice<{dim = 1, parent = #blocked3}>.:tensor< > slice<{dim = 2, parent = #blocked}> 4(to>tensor<xtensor<  44128tensor<4toxxx32x 432xitensor<xxbf1664, 432i, ##xx32blocked5ttg4i, >).slice<{dim = 1, parent = #blocked3}>x32# -> >i, blocked!
      16#>ttg%, blocked
.memdesc<128x32xbf16, #shared, #smem>176#>      
       = ttg
%%171arith.extsi.      123 =  slice<{dim = 2, parent = #blocked}>% = ttg.local_load %>117arith.select%11 
 =  170:      arith.addi% : % 119 i143%, !32 = 115%ttg toarith.shli,122.memdesc<128x32xbf16, #shared, #smem>   ,  i%%%->64142cst_11116 
,  : tensor<128       :tensor<x%% 432177cst_30tensor<xx =  44bf16tt.splat:xx,   432#ttg%tensor<xx.dot_op<{opIdx = 1, parent = #blocked3}>176432i> :xx1
       4i, %i64x32#172 =  i, blockedtt.dot->16#>  , blocked, %155tensor<#>tensor<,4ttg
4 x.      x%islice<{dim = 2, parent = #blocked}>%417164>118x,, 
 = 32 #      arith.subix%ttg% icst_3.144%32 slice<{dim = 1, parent = #blocked3}> = cst_12, :>tt.bitcast ,# 
% blockedtensor<      143%>4% 117
x128178:       x =  :%bf16, arith.additensor< 124#ttg 4tensor< = .dot_op<{opIdx = 0, parent = #blocked3}>%x4arith.maxui>1774x  ,x4x%*  i32115tensor<%17516x,128 :, i x #32%32tensor<ttg, cst_14x4.# bf16xslice<{dim = 2, parent = #blocked}>blocked:, i64>> #,  
tensor<ttg#->      4.ttg %xdot_op<{opIdx = 1, parent = #blocked3}>.slice<{dim = 1, parent = #blocked3}>tensor<1194>>4 = x 
xarith.cmpi32->      4 x %xultitensor<179bf16,324 = ,  , xarith.extsi#%#32 ttg115blockedx%.,>f3232slice<{dim = 2, parent = #blocked}> 
, # :>%      blocked 
cst_12%3>tensor<       125
32%: =       x145 arith.subi%i32 = tensor< 173, tt.expand_dims4% = # x124arith.addfttg.%4, slice<{dim = 0, parent = #blocked3}>144x %> {32%172 axisxcst_14,to = i   232:%tensor< : ,  cst_332i#tensor< x32blocked4:i}>x 64,  
4tensor<#ttg:      x4x. %3232slice<{dim = 0, parent = #blocked3}>tensor<120xx>4 = if32
      xarith.shrui32, %4 , #blocked180x%#3> = bf16116blocked
      arith.extsi, ,>% # 
174 = %ttg%      arith.truncf30 .cst_11% :slice<{dim = 2, parent = #blocked}> 126% >: = 173i  arith.shli 32 ->tensor< :to 4%  tensor<x125tensor<i44,4x64xx32 32
      4x%x%181xicst_15f32 = 132 , #tt.splatx, :blocked %bf16# 3>180 , blockedtensor< : #>4toiblocked
x 64>      4tensor< ->
%121x4        = 32xtensor<%arith.orix3232x146 ixbf16i64 = %32, , tt.broadcast120, ## ,#blocked3ttg.% blocked>slice<{dim = 0, parent = #blocked3}>145%>
      > cst_13
%175
:        =        :%arith.extsi%tensor< 127 1824tensor< = % = x4arith.shrui13arith.addi4x   x4%:%1x123 181x32,tensor<,bf16x 4 , i%x%179#32cst_16i32 :blocked,  ,  >#:#ttgtensor< blocked .32->>tensor<slice<{dim = 1, parent = #blocked3}>xi 
4> 64tensor<      xto , 4%4tensor<#ttgx122x4.4 = 32xslice<{dim = 0, parent = #blocked3}>xarith.shruixi>32 i64, 
x%32#      bf16121, ttg%183, ,#. = # blockedslice<{dim = 1, parent = #blocked3}>arith.muliblocked%>> >118

%
             7      :%%176,% 128 =  147tensor< = arith.extsi % = 4arith.ori%6tt.reshapex 11  : 4%:  %x126ii14632,32 64 x to
:i%        32127i64%184tensor<,  
 = 4#:      tt.addptrxblocked %177 4>tensor< = %x
4tt.splat arg232      x%,x%4176 bf16123x :%,  = 32 183#arith.selectxi :blocked i64 >%32 ->! 119,  tt->, #tensor<. %blocked4ptr<bf16>tensor<122>x, 4, 
iix%      6464128116%, 
x : 129#ttg      bf16tensor< = .slice<{dim = 1, parent = #blocked3}>%185, 4arith.addi> = #x 
tt.expand_dims blocked4%      %1781x128%178 {>32, = axis
x arith.addi  =       i%%1%1cst_11177 : 148,  ,i = #: 32}amdgpu.scaled_upcast_fp4blocked %175  >tensor< ::%, 4  138tensor<xtensor<tensor< 4444scalexxxx 432ii64%xx64, , 14732i#ttg# {x32.ttgaxisi, slice<{dim = 1, parent = #blocked3}>.slice<{dim = 1, parent = #blocked3}> = 32#>>1, blocked
 -> : #>       iblocked
%179tensor<32>       = 4}
%arith.extsix       130 1:% = %x 124arith.shrui32 itensor< =  :644arith.maxui% , x 129tensor<#64%,32blockedx115 x3>i,%i
8 cst_1132      , % , %#cst_14:#186blocked  ttg = 8:tensor<.slice<{dim = 0, parent = #blocked3}>arith.extsi> 4>  ,tensor<xto % 44tensor<arg13tensor<xx32 :4432x xxxii12832i6432xx32,  tobf16i, #ttg , 32#.slice<{dim = 0, parent = #blocked3}>i#, blocked>
64blocked#>      
1blocked
%      >>      180 = %187 
%arith.extsi = ->      131 tt.expand_dims % = % tensor<125arith.minui30%1754 =    {xarith.subi%:axis = 128 130 1x%,i : ibf16124 3232, ,% } # cst_22 to :blocked%:i 1cst_14 64tensor<> tensor<
4
:4      x       x%i%tensor<4181641494x = ,  = x32tt.splat#arith.cmpi4x ttg xi%180.eq3232 slice<{dim = 1, parent = #blocked3}>,x, :>  i# ->%32blockedi64 139, > tensor<,#
-> 4 blocked      tensor<x%>%32x1cst_31
132ix        = 64, i64:%arith.shrui#,  126 ttg.#tensor< = %slice<{dim = 0, parent = #blocked3}>blocked34arith.shli113>>
x ,
      4%       %188x125%% = i,cst_17182 = arith.muli8  arith.addi , %: %#cst_15 %181186ttg tensor<,,.:4  slice<{dim = 2, parent = #blocked}> x%%176>tensor<4179 
4x :      x32:  %4xtensor<i64150xi32x
       = 3232i%tt.expand_dimsx, 64, 189 i##ttg = %32blocked.slice<{dim = 0, parent = #blocked3}>tt.splat 149, >>% {#

186 axisblocked            : = >%% 2
133183i :        =  = 64 i%arith.oriarith.muli->32127   } = %%tensor<4 arith.shrui1327x: ,,1 %  xtensor<123%%i4,131664x   , 4%:: #xcst_16 iblockedi tensor<6431:4
>,  x      
#tensor<4%      ttg4x184%190.x32 =  = slice<{dim = 2, parent = #blocked}>4xtt.addptrarith.muli>xi   3232%%->x, arg2189 i#,,tensor<32blocked  4, >%%x#
1831874blocked        x>%: : 1
134!tttensor<x       = .4i%arith.trunciptr<bf16>x1128 ,1x,  = % i#arith.ori133i6464blocked  
      , >%:%#
126 185 = blocked3      ,tensor<tt.expand_dims>% 4 
      151%x%% = 1274178191 = tt.broadcast x {tt.addptr :32axis =  % x1%150tensor<i : 184, 432i32 :x, } %188 4#:  tensor<xblockedtensor<:432>4x xx i64!4ito, ttx32 #.1, tensor<ttgptr<bf16>x#4.,iblockedxslice<{dim = 1, parent = #blocked3}> 1>4>i, 
x 64#      32->
blocked%x       >129itensor<%  = 84192 = ->arith.addi, xtt.expand_dims  #1 tensor<%blockedx%4128>i182x,
64 {4       , axisx%%# = 32cst_11135blocked30x  = > : ii: tt.reshape
321tensor<       }, 4%% #x134186 = : blocked4 arith.extsitensor<>x: 32
32 %xi      xtensor<arg1364%i4 :, 15232x # = , 4ittg.tt.reshape#x32slice<{dim = 0, parent = #blocked3}> blocked32 >%>xto ->151
i         8itensor<:%, 641 130#
      xtensor< = blocked%324arith.shrui>187xx   = i644%->tt.expand_dims , x32129 %#x,tensor<175blockedi 4 {3>1%xaxis = 
, cst_1141      # x : %blocked:16i193 = > x32}tt.broadcast tensor<2  ->4x:% xi 190tensor<48tensor< 4x, 4x:x32#blockedi 128x764, tensor<xi>#4i32
ttgx11,       .x, #%slice<{dim = 1, parent = #blocked3}>i64#blockedoutLHS> , blocked>, ->#1
% blocked>      outRHStensor<3
% = 4>      131tt.splitx % =  1-> 153arith.minui%xtensor< =  135i644arith.select% , x 130:#32%, blocked3xi152 tensor<>64, %4
, #%cst_22x      blockedcst_0 4%3, :x188>% 16 = 
148tensor<xarith.muli       : 42 %194tensor<xx% = 44i186,tt.expand_dims xx8 %17912832, %176 {axisxx#  = iiblocked: 01327i : , , >64i32## 
      }blockedblocked->%189 1>  = : >
tensor<tt.splattensor<,       4 32tensor<%x%x41324186i64x = x :, 128arith.shrui16 #ttgx xi64.slice<{dim = 0, parent = #blocked3}>bf16%i8 >, 113, ->  ->#,#tensor< blocked blocked4tensor<1%2x1>cst_17>1xx
 
i32x      :      64i% %, 64, 154tensor<136#blocked# = 4 = 3>blockedttg.local_allocxarith.shli
      3 4 %>%153x%190 = 
 32outRHSarith.muli       :x,%189% i , 195 = (32%%187tt.broadcast tensor<, cst_2 %1944# :  xblocked:tensor<: 128> 4tensor<x
tensor<x1bf16      41xx32, %xi64x#1334, iblocked = x#641arith.ori16blocked, > x3#blocked)%i>
3 -> 1328      > !,, %191->ttg %# =  .131blockedtt.addptrtensor<4memdesc<4x128xbf16, #shared, #smem> 2 x32
:>%x       
184i%tensor<      , 641554%%188,  = x137 :#ttg.local_load4 =  blocked3 xarith.ori!>
%32 tt      154x%.ptr<bf16>% ioutLHS,196:32,  =  ,  itt.addptr!#%64 ttgblocked136
%.>       191,memdesc<4x128xbf16, #shared, #smem>
:%         192 = %->%tensor<tt.expand_dims180 1344  tensor< = x%: 4arith.trunci4182!ttx x {.128%16axis = ptr<bf16>x133x0,bf16 i :  , :8ii# , 3264ttgtensor<#} 
.4blocked:       dot_op<{opIdx = 0, parent = #blocked3}>x2tensor<%197>4>32 = 
x
xarith.addi      32      i %x%64, %156i138#ttg195 = 32 = .slice<{dim = 0, parent = #blocked3}>,arith.extui, tt.reshape>   # -> %%blocked%tensor<119370>137x    32x::to:i64    , tensor<tensor<tensor<tensor<#blocked44443xxxx>323244
xxxx      ii3216%648xx193, , ii = #blocked#88tt.broadcast 3ttg, , %190>.## 
      slice<{dim = 2, parent = #blocked4}>blockedblocked: %>>2tensor<4198 =  
>xarith.extsi to       1x% %->i64arg4tensor<135 ,  4 = tensor<#blocked:xtt.reshape43 i32 x>32x%64  toi134x-> 16 i i, :8tensor<64# , 4
      ttgtensor<#x%.4blocked32x199 = slice<{dim = 2, parent = #blocked4}>x8itt.splat>4>64 
x
, #%198      32      blocked3 %x%>:157i139
  = 8 =       iarith.shli, tt.reshape%64  # 194->%blocked% =  156>105tt.expand_dimstensor<,   4 ->:%x%  1791cst_19tensor<tensor< {xi 44axis64, :xx = # 440blockedtensor<xx : 34161i>
xxx32      322i}%xx8 200 = ii, : arith.cmpi 168#tensor<slt,, , linear32x ##>i64%ttgblocked , 185,.7-># %slice<{dim = 2, parent = #blocked4}>> ttg199>
tensor<. :
      4slice<{dim = 0, parent = #blocked3}>       %x>tensor<%outLHS4 4158, x->x = %i 1tt.bitcastoutRHS8tensor<x  = , 1i%tt.split#x3264157 ttgx,  %.i#:135slice<{dim = 2, parent = #blocked}>64blocked  >, 3tensor<:
#>4       blocked
xtensor<%3      324140>%xx = 
201i4tt.reshape       = 16x %arith.extsi, 16%195 #x106 = %ttg2 tt.broadcastarg5 .x: :slice<{dim = 2, parent = #blocked4}>i % >8tensor<194i , 4 32->#x:  blocked4 to tensor<7xtensor<i644>11
x xx      32->i32%x 8x202 = bf16tensor<, itt.splat , 4#64, %201#xblocked# :ttg4>blocked .x 3islice<{dim = 2, parent = #blocked4}>16->>64 >x  ->
itensor<->       84 tensor<%, xtensor<1159#44x = blockedxx32xtt.expand_dims2i32i >8x64, %
, i#blocked158      #643 {%linear, >
axis1362#       =  = >blocked%2arith.shli
3203 =  :        >arith.cmpii%%
 32outRHS141      slt}, = %,  ttg.convert_layout196 =  :% tt.addptr%192 cst_2% ,tensor< 140% 4: 191%202x :, 32tensor<  :x4tensor<% tensor<bf16x4180 1, 4x:x#x4 32ttg16x!xi.xitt64slice<{dim = 2, parent = #blocked4}>i8.ptr<bf16>, >8, ,# , # blocked->#lineari643> blocked2
      
tensor<2>%      4> 197%x
-> = 20432       arith.addi = x%tensor< tt.broadcast 11374%195%x = x,200bf16arith.ori4  ,  x%:#%i193 blockedoutLHS8 tensor<4,, : 4> #tensor<x
%ttg41x      136.xi% slice<{dim = 2, parent = #blocked}>32x1, 160:>i# =  
64, blockedtt.broadcasttensor<      #3 4%142blocked> %x = 3>->1594arith.extui
  x       tensor<:16x%%1984 i141 = x32tensor<8 arith.extsi x4, :%ix# arg4132blockedtensor< :, x24 #1>xiblockedx
4323>bf16      x 
, %ito      #1388 %205blocked = , i = 4tt.reshape#64tt.broadcast> ttg
  %.      %->137slice<{dim = 2, parent = #blocked}>%203  >199 :tensor<:  =  4 tott.splattensor<1xtensor<  x324tensor<%32xxx4198i324x :1xx4 , bf1616xi#, xi64 blocked#i16->3>blocked8,   ->4, #tensor< >#ttg4tensor<
blocked.x4      2slice<{dim = 2, parent = #blocked}>1xx32%>>i64x161 
, i = ->      #blocked1, tt.trans %3#blocked tensor<143>
3%4 =       %>160xarith.shli200 = 
 {64 arith.cmpi       orderx%slt,% = i142 206 = array<8,%185arith.andi i,  ,%32#% %204: blockedcst_30199, 08  :%205, >:  2
 tensor<:,       tensor<4 1%4x1tensor<>139xx4} = 4i64x32 tt.reshapex, #x: iblocked3i %16>
1, tensor<105,       #4 #%blockedx:ttg201 = 332 .arith.extsi>xtensor<slice<{dim = 2, parent = #blocked}> 
324>%      xx
arg5%bf164       :207, x%  = #1144itt.splatblockedx = 32  4itt.bitcastto%>8  196 , %i ->#14364: linear 
       tensor<>:%!4 -> 202ttx tensor< = .32tensor<4tt.splatptr<bf16> x4x ->32x4% x4x201 tensor<4bf16xi: x, i16i32#8, 64 xblocked, #->!9#ttg tt>ttg.tensor<.ptr<bf16>
.slice<{dim = 2, parent = #blocked}>1,       slice<{dim = 2, parent = #blocked}>>x#%> 32blocked162
->x3> =        i
tt.reshape%tensor<64       1404, #%% = xblocked208 = 161tt.reshape43tt.addptr   x>
%207:%bf16      %, 106, 203 tensor< # = %4:ttgarith.cmpi197x .  :32tensor<slice<{dim = 2, parent = #blocked}>slt x4>,tensor<32x
 4x4      %xbf16x%19232, 1145, x#x = %!ttblockeditt.expand_dims202.98  ptr<bf16>>, %:,  #144 #blocked->blocked {tensor<13 >axisx32>tensor<  = x,128->2i x  : 64, tensor<432tensor<i#xx432blocked32bf16x}3>x, 4 
i#x:      64blockedi %204, 58tensor< = #>, 4tt.broadcastblocked
#x 3      linear4%>%2x200
163>bf16        = 
, : tt.storeamdgpu.scaled_upcast_fp4      #ttgtensor<  %.4%%141slice<{dim = 2, parent = #blocked}>x20877 = >1,  ttg.convert_layout x%scale ->i174 % 1,%140tensor<,  162 4#% {:xblocked206axis 43>  = tensor<x :041->  : xx tensor<i4bf16tensor<4432x, x32x}i#x32 8blockedix:, >1, ! #
#blockedtt.tensor<linear      3ptr<bf16>, 642%>#x>146
      blocked32  = %3>x->tt.broadcast205
i   =     8tensor<%tt.broadcast }, 4145%
#x 203    blocked4: :tt.return3x  
>itensor<tensor<  },841
 , xx}tensor<#432x
128ttgxi
x.11, {-#32slice<{dim = 2, parent = #blocked}>x#
x>bf16blocked  bf16
, 3>external,       # _resources: {
#%blocked->    blocked142> mlir_reproducer5 =  tensor<4: {>arith.extui->x
   32      ->%tensor<xpipeline 1414i: tensor< x1"128:4, bx x#ui32tensor<32blocked3lx4x>tbf16xbf16
i, 4,       %n#x#206.blockediblocked = m58>arith.andio>, 
 d
#      %u      ttg%204l%.147,e(164slice<{dim = 2, parent = #blocked}> =  o = >tt.reshape%parith.cmpi  205t to% imeq 146:i, tensor<  ze%4:tensor<-70x 4a,4tensor<xmd x432-l%ixxdcst_20164is , x1-:#32, #us ttgxblocked3atensor<.bf16>
g4slice<{dim = 2, parent = #blocked}>,       %ex>#207 = {32
blockedtt.splatlx      > di% %s-8143->196li,  =   m#arith.shlitensor<: ittg 4!ttt.%x.=slice<{dim = 2, parent = #blocked4}>142128ptr<bf16>0 >,x ta
 bf16->r      %,  ge%cst_30#tensor<t165 blocked4- = :1xatt.expand_dims >32xrc tensor<
!tth=%4      .g164x%ptr<bf16>f {4148 = , xaxisxamdgpu.scaled_upcast_fp4#95 = i blocked0216%1383>} : ,  
, i#scale      t32ttg %r}.%208it slice<{dim = 2, parent = #blocked}>147 = on:> {tt.addptr- 
axis sctensor<       = %207f-4%1,tx144 :  o32 = i%-xtt.bitcast32197ci } :f1%  ,, 143:tensor< # : 4cttg tensor<x32o.tensor<4xnslice<{dim = 2, parent = #blocked4}>4x!ttv>x64.e 4xptr<bf16>r->xi, #t i8blocked3-tensor<16, >i4, #, nx#blockedtensor<de32ttg84xx.>x-t1slice<{dim = 2, parent = #blocked}>,32xo-x> ili tensor<64l1->4, vm,  x128#blocked{#tensor<x3>iblocked4bf16
      n4x, tt.stored>4# e
xblocked%208x-      bf161,b%, > i166# %t = ttg->174wtt.broadcast. ,id slice<{dim = 2, parent = #blocked}>tensor< t%>4%h165
x206=0       128 }:%x:,  145bf16 atensor< = , tensor<ll4tt.expand_dims#4ocx blockedxa32%132tx144>xe-1 {
!axaxis      %tt.mdi = 149ptr<bf16>g12 = , p,  : arith.cmpi#u-#i blocked3shblocked32eq>a4},
r>      e :%}d--> 139
m tensor<,    emtensor<4 tt.returno4x%
rx4cst_31  y32x },xbf16:
 32,  }cox#tensor<4
nittgx
v1.4{-#er, slice<{dim = 2, parent = #blocked}>x
t-#>i  tblocked 8externalri4->, _resources: {t> #
on
tensor<ttg    -      4.mlir_reproducera%xslice<{dim = 2, parent = #blocked}>: {md1674>
g = x
      putt.trans1      pipeline- x%: t%bf16150"o166,  = b- {#tt.expand_dimsullorderblocked iv = >%lmarray<
149ti{i       {na32%axis.mrc: 146 = odh0 = 2ul=g, tt.broadcast : e(f2 iox, %32pt91145}im5>  i0}::z    ef:tensor<tensor<-t 44aztensor<xxm=444d-txxxldru321isexx1-}32bf16, u,x, #ttgsa i#.geca1blockedslice<{dim = 2, parent = #blocked}>{n, >>lon#  diblocked->->sc4  -lal>tensor<tensor<imi 44iz->xxte{ 44=0 tensor<xx  4321tamxxxrax32bf16ige-x, 1tit32#, -exblocked#arri>blockedca1
>ht,       
=i#blocked%      gfon9147%x9s> = 15150=
tt.reshape = },1       tt.broadcast t0%% ri 168146%tom =  150n-att.reshape: scx  :f--%tensor< ton1674tensor<-cu x4fm:4x,- x4x rtensor<321coe4xxnwxbf16iveri32, 1rtx#, t-e32blocked#is=x>blockednd-1i >ex r1-> -te,  -> o-g#tensor<tensor<lliblocked44vmo9xx{in>1284nd- xxexs->bf1632-bi , xitmtensor<#iwip128blocked1dtlx1, hi32>#=0fx
      blocked},yi%>
 a=1148      lln,  = %oor#amdgpu.scaled_upcast_fp4152camblocked  = ta5%tt.reshapeel>138 -a 
 %mt      scale151de%  gps169%:ut = 147 -s-carith.select {tensor<hao axis4ren% = xdv16814-e,  : xmerg%i32mencst_2132xoce, }iry=% 1, fa163:, cols :  #nvetensor<tensor<blockeder t1284>t-oxx ->trp-3264 itdxixtensor<oo1i4n-w, 8xan#, 128md=blocked#xigpt5blocked1u-r>8, tou, >#-le}tensor<,blockedlv,128 1m{ cxtensor<>ase324
rc,xx      h= bf16128%gc, x153fxon#bf16 = 95veblocked, arith.select0 r5# ft->blocked%tc
1152zf      >, =t-t% %ro-170->cst_0uel =  , }lttg.local_alloctensor<%, v 4148cam%x : n{169128tensor<oin x4nid:bf16xce , 128ax-(#xlbtensor<blockediiit12811zewix>, {dt32
#  hx      blockedma=bf16%1x0, 149>-},# = , i cblockedarith.cmpitensor<teo5 4ran>eqxtiv),128oer ->  xnst-!%bf16=1attg139, 0 r.,#maitmemdesc<128x32xbf16, #shared, #smem> blockedx-h
%1nu-t      cst_31>m-o% 
re-171:      %wrl =  154ilttg.local_loadtensor< = tevm 4ttg.local_allocs{i%x =-n1704%1d x153 e:i rex 8:gi-!,  onbttg#(-i.ttgtensor<sitmemdesc<128x32xbf16, #shared, #smem>.4mpwi slice<{dim = 2, parent = #blocked}>xlid->>128ft 
xy=htensor<      bf16no=128%, rm0}x150#al,32 = blocked t xtt.expand_dims1escbf16 >t-an, %)co#149 -> onittg {!nc.axisttgveraldot_op<{opIdx = 1, parent = #blocked3}> = .giz>2memdesc<4x128xbf16, #shared, #smem>ee
 : 
n{      i      ce %32%= m172}155faa =   = lx-tt.dot:ttg.local_loadsi   ete%tensor<% r1554154toat,x p-i 4:doon%x wns171i!==,1ttgt1 , .ru0%#memdesc<4x128xbf16, #shared, #smem>e} mcst_3ttg , a .->csx:slice<{dim = 2, parent = #blocked}> e,- >tensor< cntensor< 4onu4->xvm-x 128err128tensor<xt-ex4bf16cwbf16x4, fr, x#-i#1ttgttettgx.os.idot_op<{opIdx = 0, parent = #blocked3}>-l=dot_op<{opIdx = 0, parent = #blocked3}>1>lv->, 
m1  #      {ir*blocked%ne >156dgtensor<
 = ei128      arith.extuixox% -bn32151%i-x = 70twsibf16tt.broadcast idm,  :tp#% h=lttg150tensor<0i. 4}fydot_op<{opIdx = 1, parent = #blocked3}>:x, =n> 32co tensor<xor->4invm x8eraltensor<4, t 4x#-tx1ttgae32x.risxislice<{dim = 2, parent = #blocked4}>ttf321>h-c, ,  -to##too-nblockedblocked lve3>tensor<lr> 4vg
->xme       32{nc%tensor<xie=1734inf = x16dalarith.addf4, es x#x-e%32ttgbi 172x.twt,islice<{dim = 2, parent = #blocked4}>ido 1>thp-%, 
=dcst_3#      0}o blocked%,w:>157 n= 
 = ctrtensor<      arith.shliaue4% no}x152%n, 32 = 156icxtt.reshape,csf32  ale, %%i,#151cst_19ze blocked  {sy3::  m>  mab
tensor<tensor<xo      44x-il-%x32td1744xece = xir,arith.truncf3216a  x, te%i#in1731, ttgona #.sb:blockedslice<{dim = 2, parent = #blocked4}>=le >>1-ltensor< 
      0 i4->%manx 158xe32tensor< = -n-x4tt.bitcastumif32x -n, 128%rf#x157ewo,blockedi r 31:ico>,  ten #tensor<s=vtoblocked4-er 1x1ttensor<>32 -4
xrbx      ieu32%16gilx153, itbf16 = #ttgoni, arith.select.-sn-# slice<{dim = 2, parent = #blocked4}>ifublocked%>mn3152 plc>, ->i-
% fyto      cst_0tensor<=n-%, 4oll175%xrv = 14832mmarith.extsi : xa{ tensor<bf16l f%4, tt13x#esz 128ttgt-=:x.cot islice<{dim = 2, parent = #blocked4}>nvrtensor<1>eru4, 
gee}x#      n)iblocked%c"321159e=,, > = fa
#, tt.expand_dimsls      ttgtensor< edisable_threading.4% t: slice<{dim = 1, parent = #blocked3}>x158ofalse>128 {p,
 xaxis-      tobf16 = dverify_each , 2o: tensor<# : wtrue4blockedin=
x132tr    }i>}u
64
 e}  },       :, 
#% c#-}ttg154tensor<se
. = 4,slice<{dim = 1, parent = #blocked3}>ttg.local_allocx > 32s
%153/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0xy       : bf16m%:error: , b176 Failures have been detected while processing an MLIR pass pipeline#o = (
ttglarith.extsitensor<4/tmp/torchinductor_root/5f/c5fay6dh2cyu6vjiqilgbytbqkqd5di6bm3dut2fs5f7zdeffehg.py:18:0.- x128: slice<{dim = 2, parent = #blocked4}>d%xnote: >c11bf16Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
 e , ->,:#   blockedtensor<4ei1xn32 >32ato)xb  -> 1li!xe64ttgbf16-
      ., l%memdesc<4x128xbf16, #shared, #smem>#i177
blockedn =       4ett.splat%>- 155
i% =       n176ttg.local_load%f  160o:% = , 154tt.broadcast i  c64:%o  159n->! v ttg:etensor<. r4memdesc<4x128xbf16, #shared, #smem>tensor<tx 4-i->xb64 32u, tensor<xi#41lttgxxt.128bf16islice<{dim = 1, parent = #blocked3}>x, n>bf16#-
, blockedf      #4u%ttg>n178. c = dot_op<{opIdx = 0, parent = #blocked3}>->-arith.addi> t 
tensor<o%      4-177%xl,15632l  = xv%arith.extui32m175 x{ %bf16f:[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 7, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank7]:E1110 11:31:41.246000 507 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
70, t  #ztensor<:blocked=4 4txtensor<>ri4
u64x      e, 32%}#x161)ttgi = ".8tt.trans,slice<{dim = 1, parent = #blocked3}>,  
>#%      
ttg160disable_threading      . {: %slice<{dim = 2, parent = #blocked4}>orderfalse179> = , =  array<
arith.extsitoi        32verify_each%tensor<: : 3240true x, 
:322    } x, 
tensor<i1  }3216>
x, }#-}i# 
32ttg:, . #slice<{dim = 2, parent = #blocked4}>tensor<ttg>4.
xslice<{dim = 0, parent = #blocked3}>      32/tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0>%x:  to15732error:   = xFailures have been detected while processing an MLIR pass pipelinetensor<arith.shlibf16
32 , /tmp/torchinductor_root/os/coskrv2u2s2qfnooggtc5a7exftk3emzbeae7q5c6xdtn6nlefwk.py:18:0x%#: i156blockednote: 64,4Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`,  >
#% ttgcst_19->.  slice<{dim = 0, parent = #blocked3}>:tensor<> 4
tensor<x      432%xx1803232 = xxarith.extsiibf16 16, %, #30#blocked ttg9:.> slice<{dim = 2, parent = #blocked4}>
i>      32
%       162to% =  158tt.reshapei =  64tt.bitcast%
 161      % %157:181   = :tensor<tt.splat 4 tensor<x%432180xx 3232:xx ibf16i16, 64, # #blocked->ttg9 .>tensor<slice<{dim = 2, parent = #blocked4}> 32>->x  i->tensor<64 128, tensor<x#432ttgxx.32bf16slice<{dim = 0, parent = #blocked3}>x, >bf16#
, blocked      #5%ttg>182.
 = slice<{dim = 2, parent = #blocked4}>      arith.addi>% 
163%       = 181%amdgpu.scaled_upcast_fp4,159   = %%tt.expand_dims77179   %scale:158   {%tensor<axis16232 =  {x[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 2, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank2]:E1110 11:31:41.247000 502 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
2axisi :  = 64i0, 32 : #}ittg 32.:}slice<{dim = 0, parent = #blocked3}>  >tensor<:
4       xtensor<%3264183xx = bf1632arith.muli, x #i%ttg87., ,slice<{dim = 2, parent = #blocked4}># >blocked% 36->>  ,:tensor<  4tensor<ix1286432x
x32      1x%xbf16184bf16,  = , #tt.addptr#blocked blocked5%4>arg2> ,
->        %%tensor<183160128  = x:tt.broadcast32  x!%bf16tt159, . #ptr<bf16>:blocked, 5 tensor<>i4
64x32      
x%      1164%x = 185bf16arith.cmpi = ,  tt.expand_dims#eq blocked,%4 178>% { 70axis->, =   1tensor<% : 4cst_20ix 3232:}x  32tensor<:x4 bf16xtensor<, 324#xxblockedii4864>, , 
#ttg#      .ttg%slice<{dim = 2, parent = #blocked4}>.161>slice<{dim = 1, parent = #blocked3}> = 
>tt.trans        %->%165 160 = tensor< {tt.expand_dims4order x = %1array<164xi {i32axis64:  = , 02#,  : blocked2i3, 32>1}
>       }:%  186:tensor< =  4arith.extsitensor<x 432%xxarg1332i x1:32,  x#ibf16ttg32, . #slice<{dim = 2, parent = #blocked4}>toblocked> 4 i>->64 -> 
 tensor<      tensor<4%4x187x32 = 32xtt.expand_dimsx1 32x%xi175bf161 {, , axis## = blockedblocked194 : >>i

32            }%% 162166: =  =  tt.reshapett.broadcasttensor<  4%%x161165i  64::,   #tensor<tensor<ttg44.xxslice<{dim = 1, parent = #blocked3}>3232>xx 321->xx bf16itensor<, 14#, xblocked#19>blockedx 4i->>64  , tensor<->#128 blockedxtensor<3324>xx
bf1632      , x%#32188blockedx = 5iarith.muli>1 
, %      #186%blocked,1634  = >%amdgpu.scaled_upcast_fp4
176        %%:77167   = iscalett.trans64  
%%      162166% { {189axisorder =  =  = tt.splat0array<  : i%i3218632:  }0: ,  :2i , 64tensor<1 64>->x} 32 tensor<x:4i x8tensor<1, 4x#xiblocked32643x, >32#,xblocked i3tensor<1>128, 
x#      32blocked%x4190bf16> = ,  arith.muli#-> blocked %5tensor<189>4, x ->32% x187tensor<32 128x:xi 321tensor<x, 4bf16#x, blocked1#9xblocked>i5
      64>%, 
168#       = blocked%tt.reshape3164 > = %
arith.cmpi167        %eq:191,  =  tensor<tt.addptr%4 70x%,32184 x,%32 cst_20x% i188:1  , :tensor<# 4blocked!x9tt32>.x ptr<bf16>i->,8  , tensor<i#12864ttgx
.32      slice<{dim = 2, parent = #blocked4}>x%>i192
1 =       , tt.expand_dims%# 165blocked% = 5182tt.expand_dims> { 
axis%       = 164%0 {169 : axis = i = arith.select322 } : i% 32168:},   %tensor<:cst_2132 , xtensor<%i416364x : , 32tensor<#x128ttgix.132slice<{dim = 0, parent = #blocked3}>, x>#i ttg1->.,  slice<{dim = 2, parent = #blocked4}>#tensor<>blocked1 5x->>32 , xtensor<tensor<i412864xx, 3232#xxblocked1bf163x, >i#
1blocked      , 5%#>193blocked
 = 4      tt.broadcast>% 
170%       = 190%ttg.local_alloc 166 : = % tt.broadcast169tensor<  4%:x165 1 (x:tensor<i 12864tensor<x, 432#xxblocked32bf163x, >1# xblocked->i5 1>tensor<, )4# -> xblocked!324ttgx>.i memdesc<128x32xbf16, #shared, #smem>64->
,        #tensor<%blocked41713x = >32ttg.local_load
x       32%%x170194i  = 1:tt.expand_dims,   #!%blockedttg1794. {>memdesc<128x32xbf16, #shared, #smem>axis
  =       ->0%  : 167tensor<i32 = 128}tt.transx  32:%x 166bf16tensor< {, 32order#x = ttgiarray<.64idot_op<{opIdx = 1, parent = #blocked3}>, 32>#: 
ttg0      ., %slice<{dim = 0, parent = #blocked3}>2172>,  =  1tt.dot->>  }%tensor< 1551:,x  32tensor<%x4171ix,6432 , x%#32cst_3blockedx 3i:>1 
, tensor<      #4%blockedx1954128 = >xtt.broadcast bf16 -> , %tensor<4#194xttg 32.:xdot_op<{opIdx = 0, parent = #blocked3}> 32>tensor<x 1i* x1tensor<32, 128x#xiblocked32649x, >bf16#
, blocked      #3%ttg>168.  = dot_op<{opIdx = 1, parent = #blocked3}>->tt.reshape>   tensor<%->4167 x tensor<32:4x xitensor<32644x, xf32#32, blockedx#332blocked>x3
i>      1
%,       196#% = blocked173tt.addptr9 =  >arith.addf%  191->%, 172 tensor<,%128 180x% 32cst_3:x  i:!1 tt, tensor<.#4ptr<bf16>blockedx,532 >xi
f3264      , 
%#      169blocked% = 3197arith.select> =  
arith.addi%       168%%, 174195% = ,cst_21arith.truncf ,  %%%193163173  :  :tensor<: 128 tensor<xtensor<4324xxx32i32x1xi, f3264#, , blocked##5blockedblocked>33, >>tensor< 
128to      x %32tensor<198x4 = bf16xarith.extsi, 32 #x%blockedbf16arg45,  >#:
blocked       3i%>32170
  =       tottg.local_alloc%  175i% = 64169arith.extsi
        :%% 13199(  = tensor<:tt.splat128  xtensor<%324198xx bf16i:, 32 #, iblocked#645ttg >).-> -> slice<{dim = 1, parent = #blocked3}> !>tensor<ttg 4.toxmemdesc<128x32xbf16, #shared, #smem> 1
tensor<x      4i%x64171i,  = 64#ttg.local_load, blocked #3%ttg>170.
 :slice<{dim = 1, parent = #blocked3}>       >%!
200ttg       = .%arith.cmpimemdesc<128x32xbf16, #shared, #smem>176   = slt->arith.extsi,   tensor<%%12811185x ,32: x %bf16i199, 32 # :ttg.to dot_op<{opIdx = 1, parent = #blocked3}> tensor<>i4
64x      
1%      x172%i = 177 = 64tt.dottt.splat,   #%155%blocked,1763 % >171:
,        i%%64201cst_3  =  ->arith.extsi:   tensor<tensor<%44arg5xx 128i:x64 bf16, i, #32#ttg ttg.to.slice<{dim = 1, parent = #blocked3}> dot_op<{opIdx = 0, parent = #blocked3}>>i> 
64*      
 %      tensor<178%128 = 202xarith.addi = 32 tt.splatx% bf16177%, ,201#  ttg%:.175 dot_op<{opIdx = 1, parent = #blocked3}>>  i->:64   tensor<tensor<->44 xxtensor<32i1x64, xf32#32, ttgx#.iblockedslice<{dim = 1, parent = #blocked3}>643>, >
#
      blocked      %3%179>173 = 
 = arith.extsi       arith.addf%% 32203%  = 172: arith.cmpi, tensor< %32sltcst_3x, i :32% , 192tensor<#,4ttg x.slice<{dim = 0, parent = #blocked3}>%32>202x  f32, to:#  blockedtensor<tensor<3321>xx
i32      64x%174, i = #64arith.truncfttg,  .#%slice<{dim = 0, parent = #blocked3}>>blocked173
      %3 180>:  = 
tensor<arith.extsi      4 %x32%204x30 = f32 tt.broadcast, : # %blockedi200332 > : to to tensor< i4tensor<64x4
1x      x32%ix1811bf16 = , , tt.splat## blockedblocked%33180>>  
:->        %itensor<175644 =  xarith.extsi->32  x%tensor<i13321,  x#:iblocked 643tensor<, >4#
xttg      i.%32slice<{dim = 0, parent = #blocked3}>205, > = #
tt.broadcastttg       .%%slice<{dim = 1, parent = #blocked3}>182203> =   arith.addi:to tensor<  4%tensor<x1811i,x64 32, %x#179ittg 1.:, slice<{dim = 1, parent = #blocked3}> #>tensor<blocked
323      x>%i 17664-> = ,  arith.extsi#tensor< ttg4%.x11slice<{dim = 0, parent = #blocked3}>32 >x:
i       1i%, 32183#  = blockedtoarith.muli3  >i%
647      
,%       %206%6 = 177 arith.andi = : tt.splat % i204%64,176
        %:%205 184 i = :64tt.addptr   tensor<->%4 arg2xtensor<,324 xx%ii183164 , , : ##!blockedttgtt3..>slice<{dim = 1, parent = #blocked3}>ptr<bf16>
>,      
 %      i207%64 = 178
tt.splat =       % arith.addi 185%% = 196177tt.expand_dims , : % %178!175 {tt axis.: = ptr<bf16> 1 tensor< : ->4i x32tensor<i}464 x, :32# xttgtensor<!.4ttslice<{dim = 1, parent = #blocked3}>x.>iptr<bf16>
64,       , #%#blocked179ttg3 = .>arith.extsislice<{dim = 1, parent = #blocked3}>
 >      % %32->208   = :tensor<tt.addptr 4 tensor<x%32x1207ix,32i , 64%#, 197ttg# .blocked3:slice<{dim = 0, parent = #blocked3}>>>  
tensor<to      4 %xtensor<1863232 = xxarith.extsi!i tt64%., arg13ptr<bf16># , ttg:#. blockedslice<{dim = 0, parent = #blocked3}>i3>32>
 ,      to % tensor<180i4 = 64xarith.extsi
32       x%%i3018764  = , :tt.expand_dims#  blockedi%332175>  {
toaxis        = tt.storei1 64 : %
i208      32,%} 181 % = :174tt.splat , tensor< %4%180x206 i :64: ,  i#tensor<64ttg4 .x->slice<{dim = 1, parent = #blocked3}>32 >xtensor< !32->ttx .itensor<ptr<bf16>644, , x##1blockedttgx3.i>slice<{dim = 0, parent = #blocked3}>64
>,     
#}      blocked
%3    182>tt.return = 

arith.addi         %}%188
181 = },arith.muli
  
%%{-#179186
 ,  : external %_resources: {tensor<176
32     x:mlir_reproduceri : {64i
, 64      #
pipelinettg      : .%"slice<{dim = 0, parent = #blocked3}>189b> = u
tt.splati       l%%t183186i =  narith.muli:.  m%io764d, u ->l% e6tensor<( 4o:xp 1tixi64im
64i      , z%#e184blocked- = 3att.addptr>m 
d%      -arg2%l,190d  = s%183arith.muli-  u:%s 189a!,gtt e.%{ptr<bf16>187l, :d  sitensor<-644l
xi      1m%xi185it = 64=tt.expand_dims, 0 # %blockedt1783a {>raxis
g =       e1%t : 191-i = a32tt.addptrr} c %h:184= ,gtensor< f4%xx1889i 564:0,  }#!,ttgtt ..tslice<{dim = 1, parent = #blocked3}>ptr<bf16>r>,i  t->io 64ntensor<
-4      sx%c1192fx = -itt.expand_dimst64,  o#%-blocked182c3 {f>axis,
 =        0c% : o186in = 32varith.extsi}e  r%:targ13 - :tensor<i 32nixd32ie 64xto, - #tittgo64.-
slice<{dim = 0, parent = #blocked3}>l      >l% v187->m =  {tt.expand_dimstensor<i 1n%xd17532e {xxaxisi- = 64b1, i : #tiblockedw323i}>d 
t:      %h 193=tensor< = 04tt.broadcast %}x190,i  64:a,  l#tensor<lttg4o.xcslice<{dim = 1, parent = #blocked3}>1a>xt ie->64- , atensor<#m4blockeddx3g1>px ui->-64 s, tensor<h#4ablockedxr332e>xd
i-      64m%, e188#m = blockedoarith.muli3r >y%
,186       ,%c 194o% = n176tt.expand_dimsv  e:%r 179ti {-64axist
 = r      0 : i%it18932o = }ntt.splat - :a% m186tensor<d 32xig:64p , ui#-64ttgt .o->slice<{dim = 0, parent = #blocked3}>- > ltensor<->l4 vxtensor<m11{xxai32xr64ic, 64h#, =blocked#g3blockedf>3x
>9      
5%      0190%  = 195farith.muli = t tt.broadcastz%189 =,%t 194r% u187:e  }:tensor<, 1 tensor<xc432axxn1iox64ni, i64#c, blockeda#3lblocked>i3 z>->e
 {      tensor< %4 191xm = 32att.addptrxx i-%64i184, t,#e blockedr%3a188>t 
i:      o %n!196stt = =.tt.addptr1ptr<bf16> 0,%  191mi,a64 x
%-      180n% u192:m =  -tt.expand_dims!r tte%.w182ptr<bf16>r {,iaxis t = ie064s : 
=i      -32%1}197   = r:arith.addie  gtensor<%i32195ox,ni -64%s, 193i#ttg m.:pslice<{dim = 0, parent = #blocked3}> l>tensor<i 4f->xy 32=tensor<xn1iox64r32, mx#aiblockedl643 , >t#
eblocked      s3%t>198-
 = c      arith.extsio% n193 = %vtt.broadcastarg4e  r%:g190 e i32n: c toetensor< =4ifx64a1
lx      si%e64199 ,  = t#tt.splatoblocked p3%->198d  o->:w  ntensor<i=464tx r32->ux eitensor<}644,, x #1cblockedxs3ie>64,
,        #c%blockedo1943n = >vtt.expand_dims
e       r%%t179200- { = caxisarith.cmpif =  -0sltt : ,oi -32%l}185l ,v: m %{tensor<199i32 nx:di e64tensor<x, 4-#xbttg1i.xtslice<{dim = 0, parent = #blocked3}>iw>64i , d->#t blockedhtensor<3=1>0x
      }32%,x201 i = c64arith.extsio,  n#%vblockedarg5e3 r>:t
 -      ia%32r195 i = tottt.broadcast h i-%64t194
o       -:%l 202ltensor< = v1tt.splatmx {32%ix201ni d64:e,  x#i-blocked64b3 i>->t  w->tensor<i 1dtensor<xt432hxx=32i0x64}i, ,64# , blockedc#3ablocked>n3
o>      n
%i      203c% = a196arith.cmpil =  itt.addptrsltz ,e% {191% ,192  ,m% a180%x 202-: i :t! etttensor<r.1aptr<bf16>xt,32i xoiin6464s
, =      #1%blocked01973>  = 
marith.addi      a %x%204-195 = n,tt.broadcastu  m%%-193200r  e::w  rtensor<tensor<i44txxe321sxx=ii-6411, ,  ##rblockedblockede33g>>i
 o      ->n% -198tensor<s = 4iarith.extsixm 32p%xlarg4ii 1f:, y #=iblockedn323o >rto
m       ai%l64205 
 = t      tt.broadcaste% s199%t = 203-tt.splat c :o% n198tensor<v 1e:xr 32gixe64in 1c->, e #=tensor<blockedf43ax>l1 sx->ei  64tensor<t, 4o#xpblocked32-3xd>io
1w      , n%#=200blockedt = 3rarith.cmpi>u 
eslt      },%, 206 % = c185arith.andise, , % %204s199,y  m:%b 205otensor< l4:-x d1tensor<cx4eix,6432 , xe#inblocked1a3, b>#l
blockede      3-%>l201
i =       narith.extsi%e 207-% = iarg5tt.splatn  f:%o 196,i  32:c  oto!n ttvi.e64ptr<bf16>r
 t      ->-% b202tensor<u = 4itt.splatxl 32t%xi201!n tt-:.f ptr<bf16>ui, n64#c blocked-->3t >otensor<
-1      lx%l32208vx = mi64tt.addptr{,  f#blocked%t3207z>,=
 t      %r%197u203 e = :}arith.cmpi ) tensor<"slt, 4,%x
19232      ,xdisable_threading !: %ttfalse202., ptr<bf16>
:,        #blockedverify_eachtensor<3: 1>truex,
32     }xtensor<
i4  }64x
, 32#-}#x
blockedi364>, 
#      blocked%3204> = 
tt.broadcast       tt.store%/tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:0 200: % error: 208:Failures have been detected while processing an MLIR pass pipeline, 
 tensor</tmp/torchinductor_root/r2/cr2saybjh4nkyntgqdq4pentfojw7pkmneebzvf62mp734xev2c6.py:18:0%4: 174x1note: ,xPipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
 i%1206,  #:blocked 3tensor<>4 x->32 xtensor<!4ttx.32ptr<bf16>x, i#1blocked, 3#>blocked
3    >}

          %tt.return205
 =   tt.broadcast} 
%}203
 
:{-# 
tensor<  1externalx_resources: {32
x    imlir_reproducer1: {, 
#      blockedpipeline3: >" b->u itensor<l4txi32nx.im1o, d#ublockedl3e>(
o      p%t206i = marith.andii z%e204-,a m%d205- l:d stensor<-4uxs32axgie1{, l#dblockeds3->l
i      m%i207t = =tt.splat0  %t196a r:g e!ttt-.aptr<bf16>r c->h =tensor<g4fxx329x5!0tt}.,ptr<bf16> , t#rblockedi3t>o
n      -%s208c = tt.addptr[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 3, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank3]:E1110 11:31:41.263000 503 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
f -%t207o,- c%f197,  :c otensor<n4vxe32rxt!-tti.nptr<bf16>de, x#-blockedt3o>-,l ltensor<v4mx{32ixnid64e, x#-blockedb3i>t
w      itt.stored t%h208=,0 }%,174 ,a l%l206o c:a ttensor<e4-xa32mxd!gttp.uptr<bf16>-, s#hblockeda3r>e
d    -}m
e    mtt.returno
r  y},
 }c
o
n{-#v
e  rexternalt_resources: {-
t    rmlir_reproduceri: {t
o      npipeline-: a"mbdugiplut-itno.-mloldvuml{ea(rocpht=igmfixz9e5-0a mfdt-zl=dtsr-uues}a,g ec{alndosn-ilciamliitz=e0{  t amragxe-ti-taerrcaht=igofnxs9=5100} ,m atxr-intuomn--rsecwfr-ittoe-sc=f-,1  croengvieornt--siinmdpelxi-ftyo=-nlolrvmma{li ntdeesxt--bciotnwviedrtghe=n0c}e,= faalllsoec attoep--admodwgnp=ut-rsuhea}r,e dc-smee,m ocroyn,v ecrotn-vcefr-tt-ot-rliltvomn{-ianmddegxp-ub-ittow-ildltvhm={0a}r,c hc=ognfvxe9r5t0- afrtizt=ht-rtuoe-}l,l vcma{nionndiecxa-lbiiztew{i d tmha=x0-}i,t ecraantoinoincsa=l1i0z em{a x -mnauxm--irteewrraittieosn=s-=11 0r emgaixo-nn-usmi-mrpelwirfiyt=enso=r-m1a lr etgeisotn--csoinmvpelrigfeyn=cneo=rfmaalls et etsotp--cdoonwvne=rtgreunec}e,= fcasles,e  ctoonpv-edrotw-nc=ft-rtuoe-}l,l vcms{ei,n dseyxm-bboilt-wdicdet,h =e0n}a,b lceo-nlvienret--ianrfiot,h -ctoon-vlelrvtm-{biunidletxi-nb-itfwuindct-ht=o0-}l,l vcma{nfotnzi=ctarluiez}e){" , 
m      adisable_threadingx: -falsei,t
e      rverify_eacha: ttruei
o    }n
s  }=
1#-}0
 max-num-rewrites=-1 region-simplify=normal test-convergence=false top-down=true}, cse, symbol-dce, enable-line-info, convert-bu/tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0i: lerror: tFailures have been detected while processing an MLIR pass pipelinei
n-f/tmp/torchinductor_root/ax/caxufmlaky4jkk2x4oqaq64msnnhbq2fec4pb5glmnyuchr3clyw.py:18:0u: nnote: cPipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`-
to-llvm{ftz=true})",
      disable_threading: false,
      verify_each: true
    }
  }
#-}
/tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0: error: Failures have been detected while processing an MLIR pass pipeline
/tmp/torchinductor_root/y7/cy7x5redwtow3wcql2by2qe6mm5bzoehacdoxkuwodykghgvcuhb.py:18:0: note: Pipeline failed while executing [`ConvertTritonAMDGPUToLLVM` on 'builtin.module' operation]: reproducer generated at `std::errs, please share the reproducer above with Triton project.`
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 0, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank0]:E1110 11:31:41.267000 500 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Triton compilation failed: _batched_gemm_afp4_wfp4_pre_quant_kernel_0
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] def _batched_gemm_afp4_wfp4_pre_quant_kernel(
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     a_ptr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_ptr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     c_ptr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     b_scales_ptr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     M,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     N,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     K,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_am,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ak,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bk,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bn,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ck,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cm,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cn,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsb,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsn,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bsk,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Meta-parameters
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_M: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_N: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     BLOCK_SIZE_K: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GROUP_SIZE_M: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     NUM_KSPLIT: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SPLITK_BLOCK_SIZE: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     EVEN_K: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     GRID_MN: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     cache_modifier: tl.constexpr,
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] ):
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """Kernel for computing the matmul C = A x B.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A and B inputs are in the microscale fp4 (mxfp4) format.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A_scales and B_scales are in e8m0 format.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     A has shape (M, K), B has shape (K, N) and C has shape (M, N)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     """
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ab > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_am > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_ak > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bb > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bk > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bn > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cb > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cm > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_cn > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsb > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsk > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(stride_bsn > 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # -----------------------------------------------------------
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Map program ids `pid` to the block of C it should compute.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # This is done in a grouped ordering to promote L2 data reuse.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.program_id(axis=0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_unified = tl.program_id(axis=1)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_k = pid_unified % NUM_KSPLIT
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid = pid_unified // NUM_KSPLIT
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Cast batch id and batch dimension strides to int64 to avoid int32 overflow during offset calculation
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # Note: If you're attempting to cast strides to int64 to prevent integer overflow, use `tl.cast` instead of `.to()`.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # See https://github.com/ROCm/aiter/pull/597 for rationale
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_ab = tl.cast(stride_ab, tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_bb = tl.cast(stride_bb, tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stride_cb = tl.cast(stride_cb, tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pid_batch = tl.cast(pid_batch, tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if NUM_KSPLIT == 1:
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         remap_xcd(pid, GRID_MN)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m, pid_n = pid_grid(pid, num_pid_m, num_pid_n, GROUP_SIZE_M=GROUP_SIZE_M)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     else:
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_m = pid // num_pid_n
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         pid_n = pid % num_pid_n
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_batch >= 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_m >= 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     tl.assume(pid_n >= 0)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     # We assume 32 elements along K share the same scale.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     SCALE_GROUP_SIZE: tl.constexpr = 32
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     if (pid_k * SPLITK_BLOCK_SIZE // 2) < K:
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         num_k_iter = tl.cdiv(SPLITK_BLOCK_SIZE // 2, BLOCK_SIZE_K // 2)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for first block of A and B input matrices
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # The BLOCK sizes are of the elements and in fp4 we pack 2 per uint8 container.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_bf16 = tl.arange(0, BLOCK_SIZE_K)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split_bf16 = pid_k * SPLITK_BLOCK_SIZE + offs_k_bf16
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         a_ptrs = a_ptr + (
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_ab
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_am[:, None] * stride_am
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split_bf16[None, :] * stride_ak
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k = tl.arange(0, BLOCK_SIZE_K // 2)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_k_split = pid_k * (SPLITK_BLOCK_SIZE // 2) + offs_k
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_ptrs = b_ptr + (
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             pid_batch * stride_bb
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_k_split[:, None] * stride_bk
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[None, :] * stride_bn
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Create pointers for the first block of A and B scales
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_ks = (pid_k * (SPLITK_BLOCK_SIZE // SCALE_GROUP_SIZE)) + tl.arange(
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             0, BLOCK_SIZE_K // SCALE_GROUP_SIZE
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # B scales are N x K even though B operand is K x N.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         b_scale_ptrs = (
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales_ptr
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_bsb
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_bn[:, None] * stride_bsn
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + offs_ks[None, :] * stride_bsk
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         for k in range(pid_k * num_k_iter, (pid_k + 1) * num_k_iter):
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scales = tl.load(b_scale_ptrs)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # a_scales = tl.full((BLOCK_SIZE_M, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # b_scales = tl.full((BLOCK_SIZE_N, BLOCK_SIZE_K//SCALE_GROUP_SIZE), 127, dtype=tl.uint8)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Load the next block of A and B, generate a mask by checking the K dimension.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # If it is out of bounds, set it to 0.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             if EVEN_K:
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(a_ptrs)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(b_ptrs, cache_modifier=cache_modifier)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             else:
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 a_bf16 = tl.load(
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 b = tl.load(
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                     b_ptrs, mask=offs_k[:, None] < K - k * (BLOCK_SIZE_K // 2), other=0
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]                 )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a, a_scales = _mxfp4_quant_op(a_bf16, BLOCK_SIZE_K, BLOCK_SIZE_M, 32)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             accumulator += tl.dot_scaled(a, a_scales, "e2m1", b, b_scales, "e2m1")
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             # Advance the ptrs to the next K block.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             a_ptrs += BLOCK_SIZE_K * stride_ak
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_ptrs += (BLOCK_SIZE_K // 2) * stride_bk
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             b_scale_ptrs += (BLOCK_SIZE_K // SCALE_GROUP_SIZE) * stride_bsk
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c = accumulator.to(c_ptr.type.element_ty)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         # Write back the block of the output matrix C with masks.
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M).to(tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N).to(tl.int64)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_ptrs = (
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             c_ptr
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_batch * stride_cb
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cm * offs_cm[:, None]
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + stride_cn * offs_cn[None, :]
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]             + pid_k * stride_ck
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         )
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]         tl.store(c_ptrs, c, mask=c_mask)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] 
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] metadata: {'signature': {'a_ptr': '*bf16', 'b_ptr': '*u8', 'c_ptr': '*bf16', 'b_scales_ptr': '*u8', 'M': 'i32', 'N': 'i32', 'K': 'i32', 'stride_ab': 'i32', 'stride_am': 'i32', 'stride_ak': 'constexpr', 'stride_bb': 'i32', 'stride_bk': 'constexpr', 'stride_bn': 'i32', 'stride_cb': 'i32', 'stride_ck': 'i32', 'stride_cm': 'i32', 'stride_cn': 'constexpr', 'stride_bsb': 'i32', 'stride_bsn': 'i32', 'stride_bsk': 'constexpr', 'BLOCK_SIZE_M': 'constexpr', 'BLOCK_SIZE_N': 'constexpr', 'BLOCK_SIZE_K': 'constexpr', 'GROUP_SIZE_M': 'constexpr', 'NUM_KSPLIT': 'constexpr', 'SPLITK_BLOCK_SIZE': 'constexpr', 'EVEN_K': 'constexpr', 'GRID_MN': 'constexpr', 'cache_modifier': 'constexpr'}, 'device': 1, 'constants': {'stride_ak': 1, 'stride_bk': 1, 'stride_cn': 1, 'stride_bsk': 1, 'BLOCK_SIZE_M': 4, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 1, 'NUM_KSPLIT': 1, 'SPLITK_BLOCK_SIZE': 128, 'EVEN_K': True, 'GRID_MN': 64, 'cache_modifier': '.cg'}, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]], (3,): [['tt.divisibility', 16]], (4,): [['tt.divisibility', 16]], (5,): [['tt.divisibility', 16]], (6,): [['tt.divisibility', 16]], (7,): [['tt.divisibility', 16]], (8,): [['tt.divisibility', 16]], (10,): [['tt.divisibility', 16]], (12,): [['tt.divisibility', 16]], (13,): [['tt.divisibility', 16]], (14,): [['tt.divisibility', 16]], (15,): [['tt.divisibility', 16]], (17,): [['tt.divisibility', 16]]}], 'device_type': 'hip', 'num_warps': 4, 'num_stages': 1, 'debug': False, 'cc': 'gfx950'}
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] Traceback (most recent call last):
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     binary = triton.compile(*compile_args, **compile_kwargs)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     next_module = compile_ir(module, metadata)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]   File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0]     pm.run(mod)
[rank1]:E1110 11:31:41.267000 501 torch/_inductor/runtime/triton_heuristics.py:750] [22/0] RuntimeError: PassManager::run failed
Capturing batches (bs=16 avail_mem=88.29 GB):   0%|          | 0/6 [00:01<?, ?it/s]
[2025-11-10 11:31:41 DP0 TP0] Registering 0 cuda graph addresses
[2025-11-10 11:31:41 DP1 TP1] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/u4/cu4fnpc62wbtrsq3q6m4vrhrnsfq72pxqfvfwbdlgyuapc53vmbi.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP4 TP4] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/kb/ckbholskekd5monmzoob5oljoxgfz4xlzonoap6m2ll232d6zm3s.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP7 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/ak/cakbedn2f7cj4eqs3al5ygu2rdzforicyweesoc6i3q2nhz66hnv.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP2 TP2] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/xv/cxvgv42f65hkiltj6b5iwoiz2l5sndhmjhvwbjdojjhantp37qny.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP0 TP0] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/qg/cqgsnoaf7qv573naauflw76hoe7lt2j53i52yzx23qgjtfr4l44p.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP6 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/pj/cpjly2vl4nqwtzgee66y5vt32vu6dgbpxnwply3m77qu7msp2omg.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP5 TP5] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/tm/ctmceenu2imu4zi3rrqe5pil7qagahbhgnw5fnxnwfpfmryd77bb.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[2025-11-10 11:31:41 DP3 TP3] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 381, in __init__
    self.capture()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 500, in capture
    ) = self.capture_one_batch_size(bs, forward)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 692, in capture_one_batch_size
    run_once()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 679, in run_once
    logits_output_or_pp_proxy_tensors = forward(
  File "/opt/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 817, in compile_wrapper
    raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 979, in _compile_fx_inner
    raise InductorError(e, currentframe()).with_traceback(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 963, in _compile_fx_inner
    mb_compiled_graph = fx_codegen_and_compile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1646, in fx_codegen_and_compile
    return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 1506, in codegen_and_compile
    compiled_module = graph.compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2318, in compile_to_module
    return self._compile_to_module()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2328, in _compile_to_module
    mod = self._compile_to_module_lines(wrapper_code)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/graph.py", line 2396, in _compile_to_module_lines
    mod = PyCodeCache.load_by_key_path(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 3462, in load_by_key_path
    mod = _reload_python_module(key, path, set_sys_modules=in_toplevel)
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/compile_tasks.py", line 31, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_root/fp/cfplyp6avjs7k66evomdrkblvk3x7vmq4xbwl45377k5xadqi4oz.py", line 38, in <module>
    _batched_gemm_afp4_wfp4_pre_quant_kernel_0 = async_compile.triton('_batched_gemm_afp4_wfp4_pre_quant_kernel', '''
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/async_compile.py", line 486, in triton
    kernel.precompile(
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 437, in precompile
    self._precompile_worker()
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 459, in _precompile_worker
    compile_results.append(self._precompile_config(c))
  File "/opt/venv/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 748, in _precompile_config
    binary = triton.compile(*compile_args, **compile_kwargs)
  File "/opt/venv/lib/python3.10/site-packages/triton/compiler/compiler.py", line 322, in compile
    next_module = compile_ir(module, metadata)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 450, in <lambda>
    stages["llir"] = lambda src, metadata: self.make_llir(src, metadata, options)
  File "/opt/venv/lib/python3.10/site-packages/triton/backends/amd/compiler.py", line 325, in make_llir
    pm.run(mod)
torch._inductor.exc.InductorError: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2670, in run_scheduler_process
    scheduler = Scheduler(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 311, in __init__
    self.tp_worker = TpModelWorker(
  File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 237, in __init__
    self._model_runner = ModelRunner(
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 323, in __init__
    self.initialize(min_per_gpu_memory)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 480, in initialize
    self.init_device_graphs()
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 1996, in init_device_graphs
    self.graph_runner = graph_runners[self.device](self)
  File "/sgl-workspace/sglang/python/sglang/srt/model_executor/cuda_graph_runner.py", line 383, in __init__
    raise Exception(
Exception: Capture cuda graph failed: RuntimeError: PassManager::run failed

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

Possible solutions:
1. set --mem-fraction-static to a smaller value (e.g., 0.8 or 0.7)
2. set --cuda-graph-max-bs to a smaller value (e.g., 16)
3. disable torch compile by not using --enable-torch-compile
4. disable CUDA graph by --disable-cuda-graph. (Not recommended. Huge performance loss)
Open an issue on GitHub https://github.com/sgl-project/sglang/issues/new/choose 


[rank0]:[W1110 11:31:42.649786363 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
